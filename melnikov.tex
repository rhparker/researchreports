\documentclass[12pt]{article}
\usepackage[pdfborder={0 0 0.5 [3 2]}]{hyperref}%
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}%
\usepackage[shortalphabetic]{amsrefs}%
\usepackage{amsmath}
\usepackage{enumerate}
% \usepackage{enumitem}
\usepackage{amssymb}                
\usepackage{amsmath}                
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage{float}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{mathtools}
\usepackage{cool}
\usepackage{url}
\usepackage{graphicx,epsfig}
\usepackage{makecell}
\usepackage{array}

\def\noi{\noindent}
\def\T{{\mathbb T}}
\def\R{{\mathbb R}}
\def\N{{\mathbb N}}
\def\C{{\mathbb C}}
\def\Z{{\mathbb Z}}
\def\P{{\mathbb P}}
\def\E{{\mathbb E}}
\def\Q{\mathbb{Q}}
\def\ind{{\mathbb I}}

\graphicspath{ {images17/} }

\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{hypothesis}{Hypothesis}

\begin{document}

\section*{Melnikov Integrals for Linearization of KdV5 about Single Pulse}

\subsection*{Preliminaries}

A single-pulse solution $q(x; c)$ to KdV5 is a homoclinic orbit connecting the equilibrium solution at 0 to itself. The single pulse solves the stationary KdV5 equation

\begin{equation}
u_{xxxxx} - u_{xxx} + c u_x - 2 u u_x = \partial_x(u_{xxxx} - u_{xx} + c u - u^2) = 0
\end{equation}

as well as the integrated equation

\begin{equation}\label{4thorder}
u_{xxxx} - u_{xx} + c u - u^2 = 0
\end{equation}

where we can take the constant of integration to be 0 since the pulse decays to 0 at $\pm \infty$. \\

The energy of the system is given by 

\begin{equation} \label{energy}
E(u) = -\int_{-\infty}^{\infty} \left( \frac{1}{2}u_{xx}^2 + \frac{1}{2}u_x^2 + \frac{1}{2}cu^2 - \frac{1}{3}u^3 \right) dx
\end{equation}

and the full KdV5 equation (time-dependent, nonstationary) can be written as $u_t = \partial_x E'(u)$. It can be shown that this quantity is conserved (in time).\\

For a stationary solution $u$, we have $u_t = 0$, which implies $\partial_x E'(u(x)) = 0$, i.e. $E'(u(x))$ is constant. Since our homoclinic orbit connects the equilibrium at 0 to itself, and since $E'(0) = 0$, we can take this constant to be 0, which is the equation \eqref{4thorder} above. \\

We also have a Hamiltonian $H$ for the equilibrium ODE, which is (Champneys, 1998)

\begin{equation}\label{Hamiltonian}
H(u, u', u'', u''') = u'u''' - \frac{1}{2}(u'^2) - \frac{1}{2}(u'')^2 + \frac{c}{2}u^2 - \frac{1}{3}u^3 
\end{equation}

We can show this is conserved, i.e. independent of $x$

\begin{align*}
\frac{\partial H}{\partial x} &= u'u'''' + u''u''' - u'u'' - u''u''' + c u u' - u^2 u' \\
&= u'( u'''' - u'' + cu - u^2 ) \\
&= 0
\end{align*}

where in the last line we substituted in the 4th order stationary equation $\eqref{4thorder}$.\\

Since we know the form of the Hamiltonian explicitly, we can compute its total derivative.

\begin{equation}
DH(u, u', u'', u''') = (cu - u^2, u''' - u', -u'', u') = (u(c - u), u''' - u', -u'', u') 
\end{equation}

We are interested in the derivative of the Hamiltonian at the peak of a single pulse solution. We make the following hypothesis about the existence of a single-pulse solution (although this might have been proved in the literature; we will look this up)

\begin{hypothesis}\label{singlepulseexists}
For a speed $c_0 > 0$, a single pulse solution $q_0(x) = q(x; c_0)$ exists to \eqref{4thorder}. This single pulse solution is a homoclinic orbit connecting the equilibrium at $u = 0$ to itself and is exponentially localized.
\end{hypothesis}

First, we want to show that the total derivative $DH$ of the Hamiltonian \eqref{Hamiltonian} is nonzero at $q_0(0)$, the center of the single pulse.

\begin{lemma}\label{DHnonzero}
For the single pulse solution $q_0(x)$ from Hypothesis \ref{singlepulseexists}, the total derivative of the Hamiltonian \eqref{Hamiltonian} evaluated at $q_0(0)$ is nonzero.
\begin{proof}
We want to evaluate $DH$ at $q_0(0)$. Note that this point is the peak (maximum) of the single pulse and the single pulse is an even function, so all odd derivatives are zero. Thus we have

\[
DH(q_0, q_0', q_0'', q_0''')\Big|_{x = 0} = \Big(q_0(0)(c - q_0(0)), 0, -q_0''(0), 0 \Big)
\]

We want to show that this is nonzero. We can do that by showing that either the first component or the third component cannot be 0. The first component can only be 0 if $q_0(0) = 0$ or $q_0(0) = c$. Since the maximum of the pulse occurs at $x = 0$, and the pulse connects the equilibrium at $u = 0$ to itself, we cannot have $q_0(0) = 0$, otherwise we would not have a pulse in the first place. If $q_0(0) = c$, then we can substitute this into the ODE \eqref{4thorder} to get

\begin{align*}
q_0''''(0) - q_0''(0) + c q_0(0) - q_0(0)^2 &= 0 \\
q_0''''(0) - q_0''(0) + c^2 - c^2 &= 0 \\
q_0''''(0) = q_0''(0)
\end{align*}

If $q_0''(0) = 0$, this implies $q_0''''(0)$ = 0. In other words, the constant solution $q_0(x) = c$ is the unique solution to \eqref{4thorder} with initial condition $(u(0), u'(0), u''(0), u'''(0)) = (c, 0, 0, 0)$. This is not an exponentially decaying pulse, so this cannot be the case. Thus we conclude that if $q_0(0) = c$, we must have $q_0''(0) \neq 0$. In either case, the total derivative $DH(q_0, q_0', q_0'', q_0''')$ cannot vanish at $x = 0$.

\end{proof}
\end{lemma}

Before we continue, we will write $\eqref{4thorder}$ as a 4th order system. Note that we are following our usual notational convention, where capital letters represent vectors in the 4th order system, while small letters represent their scalar counterparts. As a 4th-order system, we have

\begin{equation}\label{nonlinearsystem}
U' = F(U; c) = A(0; c) U + N(U)
\end{equation}

where $U = (u_1, u_2, u_3, u_4) = (u, u', u'', u''')$ and $N(U) = N(u_1, u_2, u_3, u_4) = (0, 0, 0, u_1^2)$. Note that we have separated the equation in to a linear and a nonlinear part, and that for the nonlinear part, $N(0) = DN(0) = 0$. \\

Let $Q(x; c) = (q(x; c) q'(x; c), q''(x; c), q'''(x; c))$. From here, we show that we can define a manifold in $H^{-1}(0)$ at $Q(0; c_0)$.

\begin{lemma}\label{manifoldinH0}
The zero level set of the Hamiltonian $H^{-1}(0)$ contains a 3-dimensional manifold in a neighborhood of $Q(0; c_0)$.
\begin{proof}
By Lemma \ref{DHnonzero}, $DH(Q(0; c_0)) \neq 0$. For convenience, write $Q(x) = Q(x; c_0)$. From the proof of that lemma, either the first or the the third component of $DH(Q(0))$ is nonzero. Taking the first component to nonzero, using the IFT we can write $q_1$ locally as a graph over $(q_2, q_3, q_4)$. In other words, there exists a unique $C^1$ function $g: U \rightarrow \R$, where $U$ is an open neighborhood of $(q_2(0), q_3(0), q_4(0))$, such that $g(q_2(0), q_3(0), q_4(0)) = q_1(0)$ and $H(g(q_2, q_3, q_4), q_2, q_3, q_4 ) = 0$ on $U$. The three-dimensional surface:

\[
\{ (g(q_2, q_3, q_4), q_2, q_3, q_4) : (q_2, q_3, q_4) \in U \}
\]

is our desired manifold, which is contained in $H^{-1}(0)$. A similar formulation holds if the third component of $DH(Q(0))$ is nonzero.
\end{proof}
\end{lemma}

Next, we linearize \eqref{nonlinearsystem} about the equilibrium solution at 0. In doing so, we obtain the constant-coefficient matrix system $U' = A(0; c) U$, where

\[
A(0; c) = 
\begin{pmatrix}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
-c & 0 & 1 & 0 \\ 
\end{pmatrix}
\]

The eigenvalues of $A(0; c)$ are
\[
\nu = \pm \sqrt{ \frac{1 \pm \sqrt{1 - 4c} }{2}}
\]

For $c < 1/4$, all four eigenvalues are real (two positive and two negative), and for $c > 1/4$, the eigenvalues are two complex conjugate pairs (one pair with positive real part and one pair with negative real part). In both cases, we have a two-dimensional stable eigenspace and a two-dimensional unstable eigenspace. We designate the two stable eigenvalues by $\nu_1^s(c)$ and $\nu_2^s(c)$, where

\begin{align*}
\nu_1^s(c) &= \sqrt{ \frac{1 + \sqrt{1 - 4c} }{2}}\\
\nu_2^s(c) &= \sqrt{ \frac{1 - \sqrt{1 - 4c} }{2}}
\end{align*}

The corresponding eigenvectors are $v_1^s(c)$ and $v_2^s(c)$ (these can be written down exactly, but it's a mess). The unstable eigenvalues are $\nu_1^u(c)$ and $\nu_2^u(c)$, with corresponding eigenvectors $v_1^u(c)$ and $v_2^u(c)$. The stable and unstable eigenspaces are $E^s(c) = \text{span}\{ v_1^s(c), v_2^s(c) \}$ and $E^u(c) = \text{span}\{ v_1^u(c), v_2^u(c) \}$.\\

For what follows, we will be working in an exponentially weighted function space $X_\eta$, defined in the usual way by 

\[
X_\eta = \{ f \in C^0([0, \infty), \R^n) : \sup_{x \in [0, \infty)} |e^{\eta x} f(x)| < \infty 
\]

where the norm is given by

\[
||f||_\eta = \sup_{x \in [0, \infty)} |e^{\eta x} f(x)|
\]

This space is known to be a Banach space, and the weight $\eta > 0$ will be chosen later. Since we wish our functions to decay exponentially at $+\infty$, we want the weight to be positive.\\

We would like to show that we can take the derivative of our single pulse $q(x)$ with respect to the wave speed $c$, and that the derivative $q_c(x)$ is exponentially localized. For this to be the case, we will need the following hypothesis.

\begin{hypothesis}\label{transverseint}
For some $c_0 > 0$, the stable manifold $W^s(0; c_0)$ and the unstable manifold $W^u(0; c_0)$ for the equilibrium solution $u = 0$ intersect transversely in $H^{-1}(0)$ at a point $Q(0; c_0) \neq 0$, where $H$ is the Hamiltonian for the ODE. Since by Lemma \eqref{manifoldinH0} $H^{-1}(0)$ is a manifold in a neighborhood of $Q(0; c_0)$, this hypothesis makes sense.
\end{hypothesis}

This hypothesis is reasonable for the following two reasons.
\begin{enumerate}
	\item Numerics show that a single pulse solution exists for a wide range of speeds $c$.
	\item We know that $\dim W^s(0) = \dim E^s = 2$ and $\dim W^u(0) = \dim E^u = 2$. Since we are in $\R^4$, $\dim H^{-1}(0) = 3$. Since the intersection $W^s(0) \cap W^u(0)$ must contain $q'(0; c_0)$, the derivative of the pulse, it must have at least dimension 1. Since $W^s(0) + W^u(0) \in \dim H^{-1}(0)$, we have
	\begin{align*}
	\dim( W^s(0) + W^u(0) ) &= \dim W^s(0) + \dim W^u(0) - \dim W^s(0) \cap W^u(0) \\
	&= 2 + 2 - 1 = 3 \\
	&\geq \dim H^{-1}(0)
	\end{align*}
	and $H^{-1}(0)$ is a 3-dimensional manifold near $Q(0; c_0)$.
\end{enumerate}

What does this hypothesis get us? Although the existence of a pulse solution does not require transverse intersection (any type of intersection is sufficient), transverse intersection makes it likely (although we still need to prove it) that the intersection of stable and unstable manifolds persists for $c$ near $c_0$. If the intersection were not transverse, we could have a solution for $c = c_0$, but the manifolds could separate when $c$ is perturbed away from $c_0$, in which case we would not have a solution for $c$ near $c_0$.\\

We will show that $q_c(x)$ exists and is exponentially localized in a series of lemmas.\\

\begin{lemma}\label{transverseint}
Assume Hypothesis \ref{transverseint} is met. Then there exists a constant $\delta > 0$ such that $c \in (c - \delta, c + \delta)$, there is a unique intersection of the stable and unstable manifolds $W^s(0; c)$ and $W^u(0; c)$. This intersection is transverse. Thus we still have a single-pulse (homoclinic orbit) for $c$ near $c_0$. This homoclinic orbit $Q(x; c)$ is differentiable with respect to $c$ at $c = c_0$.
\begin{proof}

By Hypothesis \ref{transverseint}, $W^u(0; c_0)$ and $W^s(0; c_0)$ intersect transversely in $H^{-1}(0)$ at the point $Q_0 = Q(0; c_0)$. By Lemma \ref{manifoldinH0}, the level set $H^{-1}(0)$ contains a 3-dimensional manifold $M(c_0)$ in a neighborhood of this intersection point. Since $W^u(0; c_0)$ and $W^s(0; c_0)$ intersect transversely in $H^{-1}(0)$ at this intersection point, this means that

\[
T_{Q_0} W^u(0; c_0) + T_{Q_0} W^s(0; c_0) = T_{Q_0} M
\]

The intersection of the tangent spaces of the manifolds $W^u(0; c_0)$ and $W^s(0; c_0)$ is thus one-dimensional, and is the span of the single vector $v^c = F(Q_0; c_0)$, where $F$ is the RHS of \eqref{nonlinearsystem} (i.e. the derivative of the homoclinic orbit put into a 4-dimensional system). Since the tangent spaces of stable and unstable manifolds are two-dimensional, each contains another basis vector (in addition to $v_c$.) Thus we have vectors $v^s$ and $v^u$ in $\R^3$ such that

\begin{align*}
T^s &= T_{Q_0} W^s(0; c_0) = \text{span}\{ v^s, v^c \} \\
T^u &= T_{Q_0} W^u(0; c_0) = \text{span}\{ v^u, v^c \} \\
\end{align*}

For convenience, for these three basis vectors let $V^i = \text{span }\{v^i\}$. Since in a neighborhood of $Q_0$, $M = H^{-1}(0)$ is a manifold, $M$ is isomorphic (via a smooth bijection with smooth inverse) to $R^3$. Thus we can without loss of generality take $M$ to be $R^3$ with basis given by $\{v^s, v^u, v^c\}$. \\

Now let $\Sigma$ be the plane passing through $Q_0$ normal to $v^c$. In other words, 

\[
\Sigma = Q_0 + \text{span}\{ v^s, v^u \} = Q_0 + \text{span}\{v_c\}^\perp
\]

Next we show that $W^u(0; c) \cap \Sigma$ is a smooth one-dimensional manifold for $c$ near $c_0$. To do this, we first note that $W^u(0; c)$ is a smooth two-dimensional manifold near $Q_0$. This follows from the following two facts:
\begin{enumerate} 
\item By the stable manifold theorm, the local unstable manifold $W^u_{loc}(0; c)$ has the same smoothness in $U$ and $c$ as $F$ does. Since $F$ is smooth ($C^\infty)$ in $U$ and $c$, so is $W^u_{loc}(0; c)$.
\item The evolution operator $\Phi(x; c)$ for \eqref{nonlinearsystem} has the same smoothness in $x$ and $c$ as $F$ does, thus $\Phi(x; c)$ is smooth in $c$.
\item The unstable manifold is the forward evolution of the local unstable manifold in $x$ under the evolution operator $\Phi(x; c)$.
\item Thus since both $W^u_{loc}(0; c)$ and $\Phi(x; c)$ are smooth, so is $W^u(0; c)$.
\end{enumerate}

Next, for $c \in (c_0 - \delta, c_0 + \delta)$, we write $W^u(0; c)$ over the tangent space $T^u$. Note that $T^u$ is the tangent space of $W^u(0; c)$ at $Q_0$, i.e. $c$ is fixed at $c_0$. Since $W^u(0; c)$ depends smoothly on $c$, we can find $R > 0$, $\delta > 0$, and a smooth function $h^u: T^u \times (c_0 - \delta, c_0 + \delta) \rightarrow V^s$ such that for $c \in (c_0 - \delta, c_0 + \delta)$

\begin{align*}
W^u(0; c) = Q_0 + \{ (u, h^u(u; c)) : u \in T^u \text{ with } |u| \leq R \}
\end{align*}

Note that if we take $c = c_0$ we have 

\begin{align*}
h^u(0; c_0) &= 0 \\
D_u h^u(0; c_0) &= 0
\end{align*}

where the derivative is 0 since at $c = c_0$ we have written the manifold $W^u(0; c)$ as a graph over its own tangent space. \\

Now we want to restrict this map to our planar section $\Sigma$. Since the map $(x, y) \mapsto x$ from $V^s \times V^c$ to $V^s$ is smooth, $W^u(0; c) \cap \Sigma$ is a smooth manifold which we can write as

\[
W^u(0; c) \cap \Sigma = Q_0 + \{ (u, h^u(u; c)) : u \in V^u \text{ with } |u| \leq R \}
\]

We can repeat all of the above for the unstable manifold and obtain a similar smooth function $h^s: T^s \times (c_0 - \delta, c_0 + \delta) \rightarrow V^u$. We then have for the intersection $W^s(0; c) \cap \Sigma$

\[
W^s(0; c) \cap \Sigma = Q_0 + \{ (h^s(v; c), v) : v \in V^s \text{ with } |u| \leq R \}
\]

Note that we have ordered the coordinates in $\Sigma$ as $(u, v)$, where $u \in V^u$ and $v \in V^s$.\\

Recall that for $c = c_0$, $W^s(0; c_0) \cap W^u(0; c_0) \cap \Sigma$ is the single point $Q_0$. All that is left is to show that for $c$ near $c_0$ we still have a point of intersection in $W^s(0; c) \cap W^u(0; c) \cap \Sigma$. In other words, for $c$ near $c_0$, we seek a point $(u, v) \in V^u \times V^s$ such that $(u, v)$ is contained in both $W^u(0; c) \cap \Sigma$ and $W^s(0; c) \cap \Sigma$. Using the expressions above, this is equivalent to

\[
Q_0 + (u, h^u(u; c)) = Q_0 + (h^s(v; c), v)
\]

which is satisfied if

\begin{align*}
u &= h^s(v; c) \\
v &= h^u(u; c)
\end{align*}

What we would like to do is use the IFT on this to get the $(u, v)$ coordinates of the unique intersection of $W^s(0; c_0) \cap \Sigma$ and $W^u(0; c_0) \cap \Sigma$ as a function of $c$ for $c$ near $c_0$. To to this, define a function $K: V^u \times V^s \times (c_0 - \delta, c_0 + \delta) \rightarrow V^u \times V^s$ by

\begin{equation}
K(u, v, c) = \begin{pmatrix}
u - H^s(v; c) \\ v - h^u(u; c)
\end{pmatrix}
\end{equation}

and note that $K(0, 0, c_0) = 0$. In order to use the IFT to write $(u, v)$ as a function of $c$, we need to check that the Jacobian matrix in the $(u, v)$ variables is invertible at $(u, v, c) = (0, 0, c_0)$.

\begin{align*}
D_{(u, v)}K(u, v, c) = \begin{pmatrix}
1 & -h^s_v(v; c) \\
-h^u_u(u; c) & 1
\end{pmatrix}
\end{align*}

Evaluating this at $(u, c) = (0, c_0)$ we get the invertible matrix

\begin{align*}
D_{(u, v)}K(0, 0, c_0) = \begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
\end{align*}

where we used the fact that $D_v h^s(0; c_0) = D_u h^s(0; c_0) = 0$. Thus by the IFT we can find an open interval $U = (c_0 - \tilde{\delta}, c_0 + \tilde{\delta})$ with $0 < \tilde{\delta} \leq \delta$ and a unique smooth function $g: U \rightarrow V_u \times V_s$ such that

\begin{align*}
g(c_0) &= 0 \\
K(g(c), c) &= 0 \text{ for all } c \in U
\end{align*}

For $c \in U$, $P(c) = Q_0 + g(c)$ is the unique intersection point of $W^s(0; c) \cap W^u(0; c) \cap \Sigma$. (Uniqueness comes from the fact that this is a unique function of $c$, so for $c$ near $c_0$, there is exactly one $u = g(c)$ for which $K(g(c),c) = 0$). This intersection is transverse in $H(c)^{-1}(0)$ by uniqueness as well, since a single point of intersection in $\Sigma$ means that the intersection of $W^s(0; c)$ and $W^u(0; c)$ at $P(c)$ is one-dimensional. Since each manifold has one more dimension, the sum of their tangent spaces is three-dimensional.\\

Since we have a unique intersection of the stable and unstable manifolds for $c$ near $c_0$ at the point $P(c)$, we have a unique homoclinic orbit $Q(x; c)$ connecting the equilibrium at $U = 0$ to itself, which we can define by

\[
Q(x; c) = \Phi(x; c) P(c)
\]

where $\Phi(x; c)$ is the evolution operator of \eqref{nonlinearsystem}.\\

To show differentiability of $Q(0, c)$ at $c = c_0$, we note that near $c = c_0$,

\[
Q(0; c) = Q_0 + (g(c), h^u(g(c); c))
\]

which is smooth in $c$ since $g(c)$ and $h^u(u, c)$ are smooth in $c$.

\end{proof}
\end{lemma}

\begin{lemma}\label{qcexists}
$Q(x; c)$ is differentiable in $c$ for all $c$ near $c_0$ and for all $x$. 
\begin{proof}
Let $\Phi(x; c)$ be the solution operator for \eqref{nonlinearsystem}, where the initial condition is given at $x = 0$. Taking the initial condition to be $Q(0; c)$, by the property of the solution operator, for $c$ near $c_0$, $Q(x; c) = \Phi(x; c)Q(0; c)$.\\

By the existence and uniqueness theorem, $\Phi(x; c)$ is smooth in $c$ since the the RHS of \eqref{nonlinearsystem} is $C^\infty$ in $c$ (since $A(0; c)$ is a linear function of $c$ and $N(u)$ does not involve $c$ at all). By Lemma \ref{transverseint}, $Q(0; c)$ is smooth in $c$.
\end{proof}
\end{lemma}

Let $A(c) = A(0; c)$. Then $e^{A(c)x}$ is the fundamental matrix solution to the linear problem $U' = A(c) U$. Let $P^s(c)$ and $P^u(c)$ are the stable and unstable projections onto the stable and unstable eigenspaces of $A(c)$.\\

Since for $c > 0$ the matrix $A(c)$ is hyperbolic and since the eigenvalues of $A(c)$ are continuous functions of $c$ (in fact, we have explicit formulas for them, we can find $\alpha^s, \alpha^u > 0$ such that for all $c \in (c - \delta, c + \delta)$, where $\delta$ is the constant from Lemma \ref{transverseint}, all eigenvalues of $A(c)$ lie outside the open interval $(-\alpha^s, \alpha^u)$. For $c \in (c - \delta, c + \delta)$, we have the estimates

\begin{align*}
||e^{A(c)x}P^s(c)|| &\leq Me^{-\alpha^s x} && x \geq 0\\
||e^{A(c)x}P^u(c)|| &\leq Me^{\alpha^u x} && x \leq 0
\end{align*}

We are now in position to show that the derivative $q_c(x)$ of the single pulse with respect to the speed $c$ is exponentially localized.

\begin{lemma}\label{qc}
For the stationary, single-pulse solution $q(x; c)$ to the 5th order KdV equation in a frame moving with velocity $c$, the derivative $q_c(x)$ of the pulse with respect to $c$ is exponentially localized, thus $q_c(x) \in L^2(\R)$.
\begin{proof}
$q_c(x)$ exists for $c$ near $c_0$ by Lemma \ref{qcexists}, so we need to show that it is exponentially localized.\\

We proceed as in the proof of the stable manifold theorem (parameter-dependent version). We use an exponentially weighted function space $X_\eta$, defined above, and the exponential weight $\eta > 0$ will be chosen later.\\

Next we write \eqref{nonlinearsystem} in integrated form. For convenience, let $A(c) = A(0; c)$, so that the matrix exponential $e^{A(c)x}$ is the fundamental matrix solution to the linear problem $U' = A(c) U$. Let $P^s(c)$ and $P^u(c)$ be the stable and unstable projections onto the stable and unstable eigenspaces of $A(c)$. Then as long as $|U(x)|$ is uniformly bounded for $x \geq 0$, say $|U(x)| \leq \rho$ for $x \geq 0$, then $U(x)$ is given by

\[
U(x) = e^{A(c)x} P^s(c) a + \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy + \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy
\]

where $a$ is the initial condition. Note that $U$ will depend on $c$, but that (our specific case), $N$ does not.\\

First we define the spaces

\begin{align*}
B_1 &= (c_0 - \delta, c_0 + \delta) \\
B_2 &= \{ a \in \R^n : |P^s(c) a| \leq \rho/2M \text{ for all } c \in B_1\} \\
D &= \{ u \in X_\eta : ||u||_\eta \leq \rho \}
\end{align*}

where $\delta$ is the constant from Lemma \ref{transverseint}. Next define
\[
L_\eta(\rho) = \max \{ || DN(u) || : ||u||_\eta \leq \rho \}
\]

Note that since we are on the domain $[0, \infty)$ and $\eta > 0$, $|u(x)| \leq |u(x)e^{\eta x}|$ and so $||u|| \leq ||u||_\eta$. Since $N \in C^1$ and $||u|| \leq \rho$, $L(\rho)$ is well-defined and finite. (In this case, we know exactly what $N$ is. The Jacobian matrix $DN$ consists entirely of zeros except for one entry which is $2 u_1$, so here we have $L(\rho) \leq 2 \rho$.) From this, we can get a bound on $|N(U(x))|$ for $U$ with $||U||_\eta \leq \rho$. Let $U \in D$ and fix $x \geq 0. $Since $N \in C^1$ and $N(0) = 0$,

\begin{align*}
|N(U(x))| &= |N(U(x)) - N(0)| \\
&= \left| \int_0^1 DN(t U(x)) t U(x) du \right| \\
&\leq  \int_0^1 ||DN(tU(x))|| \: |U(x)| t dt \\
&\leq L(\rho) |U(x)|
\end{align*}

Multiplying both sides by $e^{\eta x}$ gives us the bound (pointwise in $x$, for $x \geq 0$)

\[
|N(U(x)) e^{\eta x}| \leq L(\rho)|U(x) e^{\eta x}|
\]

taking the supremum in $x$ gives us the bound

\begin{equation}\label{NUetabound}
||N(U)||_\eta \leq L(\rho) ||U||_\eta \leq L(\rho) \rho
\end{equation}

where everything is finite since we are assuming $U \in D$.\\

Note that since $DN(0) = 0$ and $N \in C^1$, $DN(u) \rightarrow 0$ as $u \rightarrow 0$, thus by the definition of $L(\rho)$, $L(\rho) \rightarrow 0$ as $\rho \rightarrow 0$. We also have for $U, V$ with $||U||_\eta, ||V||_\eta \leq \rho$

\[
||N(U) - N(V)||_\eta \leq L(\rho)(||U||_\eta - ||V||_\eta) 
\]
which is a consequence of the mean value inequality.\\

Now we define the map $F: D \times B_1 \times B_2 \rightarrow X_\eta$ by

\begin{equation}\label{F}
[F(U, c, a)](x) = e^{A(c)x} P^s(c) a + \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy + \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy
\end{equation}

First we show that $F$ is well-defined, i.e. it actually maps into $X_\eta$. We will look at each term on the RHS separately. Recall that since the domain of $F$ is $D$, we always have $||U||_\eta \leq \rho$.

\begin{align*}
|e^{\eta x} e^{A(c)x } P^s(c) a | &\leq M e^{\eta x} e^{-\alpha^s x} | P^s(c) a |\\
&= M e^{(\eta - \alpha^s)x} | P^s(c) a|
\end{align*}
For this to be uniformly bounded in $x$, we require $\eta \leq \alpha^s$, in which case we have $||e^{A(c)x}a ||_\eta \leq M| P^s(c) a |$.

\begin{align*}
\left| e^{\eta x} \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy \right| &= \left| \int_\infty^x e^{\eta x} e^{A(c)(x - y)}P^u(c) N(U(y))dy \right|\\
&\leq \int_x^\infty M e^{\eta x}e^{\alpha^u(x -y)}|N(U(y))|dy \\
&= M \int_x^\infty e^{\eta (x - y)}e^{\alpha^u(x -y)}| e^{\eta y} N(U(y))|dy \\
&\leq M \int_x^\infty e^{(\eta+\alpha^u)(x - y)} || N(U)||_\eta dy \\
&\leq M L(\rho) ||U||_\eta \int_x^\infty e^{(\eta+\alpha^u)(x - y)} dy \\
&= M L(\rho) ||U||_\eta \frac{1}{\alpha^u + \eta}
\end{align*}

Since $\eta$ and $\alpha^u$ are both positive, this imposes no additional restrictions on $\eta$.

\begin{align*}
\left| e^{\eta x} \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y)) \right| &= \left| \int_0^x e^{\eta x} e^{A(c)(x - y)}P^s(c) N(U(y)) dy \right|\\
&\leq \int_0^x M e^{\eta x}e^{-\alpha^s(x -y)}|N(U(y))|dy \\
&= M \int_0^x e^{\eta (x - y)}e^{-\alpha^s(x -y)}| e^{\eta y} N(U(y))|dy \\
&\leq M \int_0^x e^{(\eta-\alpha^s)(x - y)} || N(U)||_\eta dy \\
&\leq M L(\rho) ||U||_\eta \int_0^x e^{(\eta-\alpha^s)(x - y)} dy \\
&= M L(\rho) ||U||_\eta \frac{1 - e^{(\eta-\alpha^s)x} }{\alpha^s - \eta}
\end{align*}

Since $x \geq 0$, as long as $\eta < \alpha^s$ (we have this condition from above), $0 < e^{(\eta-\alpha^s)x} < 1$, thus we have

\[
\left| e^{\eta x} \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y)) \right| \leq M L(\rho) ||U||_\eta \frac{1}{\alpha^s - \eta}
\]

Putting all of this together and taking the supremum over $x \in [0, \infty)$, we have for $||U||_\eta \leq \rho$

\begin{equation}
||F(U, c, a)](x)||_\eta \leq M |a| + M L(\rho) \left( \frac{1}{\alpha^u+\eta}+\frac{1}{\alpha^s-\eta} \right) ||U||_\eta
\end{equation}

Since everything on the RHS is finite, we have shown that the codomain of $F$ is in fact $X_\eta$, so $F$ is well-defined. Since $a \in B_2$, $|P^s(c) a| \leq \rho/2M$. Since $L(\rho) \rightarrow 0$ as $\rho \rightarrow 0$, we can choose $\rho$ sufficiently small so that $L(\rho) < \frac{1}{2M} \left( \frac{1}{\eta+\alpha^u}+\frac{1}{\eta-\alpha^s} \right)^{-1}$. Having done this, and using the fact that $||U||_\eta \leq \rho$, we obtain the bound $||F(U, a, c)](x)||_\eta \leq \rho$. Thus for this choice of $\rho$ we actually have $F: D \times B_2 \times B_1 \rightarrow D$, which is what we want.\\

Now we need to show that $F: D \times B_2 \times B_1 \rightarrow D$ is a uniform contraction. For $U, V \in D$, following what we did above, 

\begin{align*}
| &e^{\eta x} ( F(U, c, a) - F(V, c, a) ) | \\
&= \left| \int_\infty^x e^{\eta x} e^{A(c)(x - y)}P^u(c) [N(U(y)) - N(V(y))]dy + \int_0^x e^{\eta x} e^{A(c)(x - y)}P^s(c)[N(U(y)- N(V(y))]dy \right| \\
&\leq M L(\rho) \left( \int_x^\infty e^{(\eta + \alpha^u)(x-y)}||U - V||_\eta dy + \int_0^x e^{(\eta - \alpha^s)(x-y)}||U - V||_\eta dy \right) \\
&= ML(\rho)||U - V||_\eta \left( \frac{1}{\eta + \alpha^u}+\frac{1}{\eta-\alpha^s} \right) \\
&\leq \frac{1}{2} ||U - V||_\eta 
\end{align*}

where in the last line we used our choice of $\rho$ from above. Since this is independent of $c$ and $a$, $F$ is a uniform contraction. By the uniform contraction mapping principle, there is a unique map $G: B_1 \times B_2 \rightarrow D$ such that $F(G(c, a), c, a) = G(c, a)$ for all $c \in B_1$ and $a \in B_2$. In other words, $G$ maps the pair of parameters $(c, a)$ to the unique fixed point of $F$ with those parameters. By the uniform contraction mapping principle, the maps $G$ and $F$ have the same smoothness in the parameters $c$ and $a$.\\

What does this get us? We note the following

\begin{enumerate}
	\item For each speed $c \in B_1$ and initial condition $a \in B_2$, $u(x) = G(c, a)(x)$ is the unique solution on $[0, \infty)$ to KdV5 with speed $c$ and initial condition $a$.

	\item $G(c, a)(x) \in D$, which implies $\sup_{x \in [0, \infty)} |e^{\eta x} G(c, a)(x)| \leq \rho$. In other words, for all $c \in B_1$, $a \in B_2$, and $x \geq 0$
	\begin{equation}
		|G(c, a)(x)| \leq \rho e^{-\eta x}
	\end{equation}
	Thus for these $a$ and $c$, the unique solution $G(c, a)(x)$ is uniformly exponentially bounded on $[0, \infty)$.

	\item $G(c, a)$ is as smooth as $F$ in $c$ and $a$.
\end{enumerate}

The key is this last property (smoothness). We would like the map $G$ to be differentiable in $c$. Let's first show that is indeed what we want. Then we will show that $F$ is smooth in $c$, implying $G$ is as well.\\

Recall that for $c = c_0$, a homoclinic orbit $q(x; c_0)$ exists. By the stable manifold theorem, since $q(x; c_0)$ is contained in the stable manifold $W^s(0; c_0)$, we can find $\tilde{x} \geq 0$ such that $q(x; c_0) \leq \rho$ for all $x \geq \tilde{x}$. Let $a_0 = q(\tilde{x}; c_0)$ be our initial condition. Then by uniqueness of the map $G$, we have 

\[
G(c_0, a_0)(x) = q(\tilde{x} + x; c_0)
\]

Taking the derivative with respect to $c$,

\[
G_c(c_0, a_0)(x) = q_c(\tilde{x} + x; c_0)
\]

For fixed $a_0$, $G$ maps $B_1 \rightarrow X_\eta$. The Frechet derivative $G_c$ is a bounded linear map from the tangent space of $B_1$ (which is $\R$, since $B_1 \subset \R$) to the tangent space of $X_\eta$ (which is isomorphic to $X_\eta$ itself since $X_\eta$ is a Banach space). We thus have for a perturbation $h \in R$

\[
G_c(c_0, a_0)h = q_c(\tilde{x} + \cdot \: ; c_0) h
\]

Thus since $G_c(c_0, a_0)$ is a bounded linear operator, $q_c(\tilde{x} + \cdot \: ; c_0) \in X_\eta$, and so the function $q_c(\tilde{x} + x ; c_0)$ decays exponentially in $x$. Since all we care about is asymptotic behavior, we conclude that $q_c(x ; c_0)$ decays exponentially in $x$.\\

All we need to do to complete the proof is show that the map $F$ defined in \eqref{F} is differentiable in $c$. Note that $F: D \times B_1 \times B_2 \rightarrow X_\eta$. Since the codomain is an exponentially weighted function space with exponentially weighted norm, we need to show that $F$ is Frechet differentiable in $c$ with respect to this norm. We will do this in a series of lemmas which follow this one. \\

We can similarly show (by, say, replacing $x$ with $-x$), that $q_c(x)$ at $c = c_0$ decays exponentially as $x \rightarrow -\infty$. From this, we will have the additional condition that $\eta < \alpha^u$. Thus as long as $0 < \eta < \alpha^s, \alpha^u$, we are all set, and the proof is complete.

\end{proof}
\end{lemma}

We now prove that the map $F: D \times B_1 \times B_2 \rightarrow X_\eta$ defined in \eqref{F} is Frechet differentiable with respect to $c$. We do this in a series of lemmas.\\

First, we prove a lemma about Frechet derivatives in exponentially weighted spaces with respect to a parameter under a change of variables dependent on that parameter. I'm sure this is known, but stuff on Frechet derivatives is hard to find.\\

\begin{lemma}\label{frechetfun}
Let $F(c): \R \rightarrow X_\eta$, where $X_\eta$ is the weighted exponential space

\[
X_\eta = \{ f \in C^0([0, \infty), \R^n) : \sup_{x \in [0, \infty)} |e^{\eta x} f(x)| < \infty \}
\]

with norm given by

\[
||f||_\eta = \sup_{x \in [0, \infty)} |e^{\eta x} f(x)|
\]

Suppose $F$ has a Frechet derivative $L$ at parameter value $c$, i.e. $L$ is a bounded linear operator from $\R \rightarrow X_\eta$ such that 
\[
\lim_{h \rightarrow 0} \frac{|| F(c+h) - F(c) - Lh ||_\eta }{|h|} = 0
\]

\begin{enumerate}[(i)]

\item Let $T(c)$ be an $n \times n$ matrix which is smooth in the parameter $c$. Then $T(c)F(c): \R \rightarrow X_\eta$ has Frechet derivative $T'(c)F(c) + T(c)L$ at $c$.

\item Let $S(c)$ be an $n \times n$ matrix which is smooth in the parameter $c$. Then $F(c)S(c): \R \rightarrow X_\eta$ has Frechet derivative $L S(c) + F(c)S'(c)$ at $c$.

\item Let $S(c) \in GL(n, \R)$ be a family of smooth invertible matrices paramaterized by $c$, where $S(c)$ is smooth and invertible in an open interval around a specific parameter value $c$. Then $S^{-1}(c)F(c)S: \R \rightarrow X_\eta$ has Frechet derivative $(S^{-1})'(c) F(c) S(c) + S^{-1}(c) L S (c) + S^{-1}(c) F(c) S'(c)$ at $c$.

\end{enumerate}

\begin{proof}

Let $||F(c)||_\eta = M$.\\

For (i), since by property of the norm, $||T(c)F(c)||_\eta = |T(c)| ||F(c)||_\eta = |T(c)|M$, $T(c)F(c)$ has codomain $X_\eta$ as claimed.

\begin{align*}
\lim_{h \rightarrow 0}&\frac{||T(c+h)F(c+h) - T(c)F(c) - (T'(c)F(c) + T(c)L)h||_\eta}{|h|} \\
&= \lim_{h \rightarrow 0}\frac{||T(c+h)F(c+h) - T(c)F(c+h) + T(c)F(c+h) - T(c)F(c) - (T'(c)F(c) + T(c)L)h||_\eta}{|h|} \\
&\leq \lim_{h \rightarrow 0}\frac{||T(c+h)F(c+h) - T(c)F(c+h) - T'(c)F(c) h ||_\eta}{|h|} \\
&\:\:+ \lim_{h \rightarrow 0}\frac{||T(c)F(c+h) - T(c)F(c) - T(c)L)h||_\eta}{|h|}
\end{align*}
We will evaluate the two limits on the RHS separately. For the second limit, we have

\begin{align*}
\lim_{h \rightarrow 0}&\frac{||T(c)F(c+h) - T(c)F(c) - T(c)L)h||_\eta}{|h|} \\
&= |T(c)| \lim_{h \rightarrow 0}\frac{||F(c+h) - F(c) - L)h||_\eta}{|h|} \\
&= 0
\end{align*}
since $|T(c)|$ is a constant, and the remaining limit is the definition of the Frechet derivative of $F(c)$ at $c$, thus is zero. For the first limit on the RHS,

\begin{align*}
\lim_{h \rightarrow 0}&\frac{||T(c+h)F(c+h) - T(c)F(c+h) - T'(c)F(c) h ||_\eta}{|h|} \\
&= \lim_{h \rightarrow 0}\frac{||T(c+h)F(c+h) - T(c)F(c+h) - T'(c)F(c+h)h + T'(c)F(c+h)h - T'(c)F(c) h ||_\eta}{|h|} \\
&\leq \lim_{h \rightarrow 0}\frac{||T(c+h)F(c+h) - T(c)F(c+h) - T'(c)F(c+h)h||_\eta}{|h|} + \lim_{h \rightarrow 0} \frac{||T'(c)F(c+h)h - T'(c)F(c) h ||_\eta}{|h|} \\
&\leq \lim_{h \rightarrow 0} \left| \frac{T(c+h) - T(c)}{h} - T'(c) \right| ||F(c+h)||_\eta + |T'(c)| \lim_{h \rightarrow 0} ||F(c+h) - F(c) ||_\eta \\
&= 0 \cdot M + |T'(c)| \cdot 0 \\
&= 0
\end{align*}

where we used the fact that $F$ is continuous as a function from $\R$ to $X_\eta$ (since it is Frechet differentiable) and that the norm is a continuous function, so we can pull the limit inside it. Thus we have proved (i).\\

For (ii), the proof is similar. For (iii), take $T(c) = S^{-1}(c)$ in (i), then use (ii).

\end{proof}
\end{lemma}

In the next lemma, we exhibit a property of 

\begin{lemma}\label{expproj}
If $A$ is an $n \times n$ matrix and $P$ is a projection on $\R^n$, 
\[
e^{Ax} P = e^{APx} P 
\]
Note that this does not require $P$ to commute with $A$.
\begin{proof} 
Using the fact that for a projection $P^2 = P$, thus $P^n = P$ for all $n$,
\begin{align*}
e^{Ax} P &= \left( \sum_{n = 0}^\infty \frac{ A^n x^n }{n!} \right) P \\
&= \left(1 + Ax + \frac{A^2 x^2}{2!} + \cdots \right) P \\
&= \left(P + AP^2 x + \frac{A^2 P^3 x^2}{2!} + \cdots \right)\\
&= \left(1 + AP x + \frac{A^2 P^2 x^2}{2!} + \cdots \right) P \\
&= \left( \sum_{n = 0}^\infty \frac{ [ A P x]^n}{n!} \right) P \\
&= e^{AP x} P
\end{align*}
\end{proof}
\end{lemma}

This next lemma seems irrelevant, but be used in the proof of the lemma following it.

\begin{lemma}\label{expineq}
For
\[
f(x) = \frac{e^x - x - 1}{x^2},
\]

\begin{enumerate}[(i)]
	\item $\lim_{x \rightarrow 0} f(x) = 1/2$
	\item $f(x) \geq 0$ for all $x$
	\item $f(x) \leq e^x$ for $x \geq 0$
	\item $f(x) \leq 1$ for $x \leq 0$
	\item $f(x) \leq 1 + e^x$ for all $x$
\end{enumerate}
\begin{proof}
These all make sense visually, but a rigorous proof follows.
\begin{enumerate}[(i)]
	\item Use L'Hopital's rule twice. $f(x)$ is continuous everywhere except at $x = 0$, which is a removable discontinuity.
	\item It suffices to look at the numerator since the denominator is nonnegative. Let $g(x) = e^x - x - 1$ and note that $g(0) = 0$ and $g'(x) = e^x - 1$. For $x < 0, g'(x) < 0$ and for $x > 0, g'(x) > 0$, thus $g(0) = 0$ is the minimum of $g$, and so $g(x)$ and $f(x) \geq 0$ for all $x$.
	\item 
	\[
	e^x - f(x) = \frac{1 + x + e^x (x^2 - 1)}{x^2}
	\]
	Let $g(x) = 1 + x + e^x (x^2 - 1)$ be the numerator of this. For $x \geq 0$, $e^x (x^2 - 1) \geq -1$, thus $g(x) \geq 0$ and so $e^x - f(x) \geq 0$ for $x \geq 0$.
	\item There are probably easier ways to show this, but this should work
	\[
	1 - f(x) = \frac{x^2 - e^x + x + 1)}{x^2}
	\]
	As before, let $g(x) = x^2 - e^x + x + 1$ be the numerator of this. We have $g(0) = 0$ and would like to show $g'(x) \leq 0$ for $x \leq 0$, from which it would follow that $g(x) \geq 0$ for $x 
	\leq 0$ since it would then decrease to 0 from the left. $g'(x) = 2x - e^x + 1$. We have $g'(0) = 0$ as well, and to show that $g'(x) \leq 0$ for all $x \leq 0$, it suffices to show that $g''(x) \geq 0$ for all $x \leq 0$ since then $g'(x)$ would increase to 0 from the left. $g''(x) = 2 - e^x \geq 0$ for $x \leq 0$, so our assertion is proved.
	\item This follows from the previous two.
\end{enumerate}
\end{proof}
\end{lemma}

We are in position to show Frechet differentiability of the function $F$ in \eqref{F}.

\begin{lemma}\label{derivatives2}
Let $0 < \eta < \alpha^s, \alpha^u$. For $c > 0$, the function $F: D \times B_1 \times B_2 \rightarrow X_\eta$ defined by 

\begin{equation}\label{F}
[F(U, c, a)](x) = e^{A(c)x} P^s(c) a + \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy + \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy
\end{equation}

is Frechet differentiable in $c$. The spaces $D$, $B_1$, and $B_2$ are defined in Lemma \ref{qc}.

\begin{proof}

Since $F$ is a the sum of three functions, we will show that the following three functions are Frechet differentiable in $c$.

\begin{enumerate}[(i)]
	\item $e^{A(c)x} P^s(c)$
	\item $\int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy$
	\item $\int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy$
\end{enumerate}

Note that since the initial condition $a$ is constant, we have removed it from (i) since it does not affect the derivative at all. In all three cases, we come up with candidate for the Frechet derivative using regular differentiation, and then show that it is also the Frechet derivative using the definition of the Frechet derivative. Recall that in the definition of $X_\eta$, the domain of the functions is $[0, \infty)$.\\

First, we look at (i). To do this, we employ the following change of variables. Recall that the two stable eigenvalues of $A(c)$ are designated $\lambda^s_1(c)$ and $\lambda^s_1(c)$. Their corresponding eigenvectors are $v^s_1(c)$ and $v^s_2(c)$. The unstable eigenvalues are $\lambda^u_1(c)$ and $\lambda^u_1(c)$, with corresponding eigenvectors $v^u_1(c)$ and $v^u_2(c)$. We are assuming $c > 0, c \neq 1/4$ so that the eigenvalues are distinct, thus the eigenvectors are linearly independent. \\

Let $S(c) = (v^s_1(c) | v^s_2(c) | v^u_1(c) | v^u_2(c))$, i.e. the matrix whose columns are the eigenvectors of $A(c)$. Then $S(c)^{-1} A(c) S(c) = D(c)$, where $D(c)$ is the diagonal matrix

\[
D(c) = \begin{pmatrix}
\lambda^s_1(c) &&& \\ & \lambda^s_2(c)&& \\ && \lambda^u_1(c) & \\ &&& \lambda^u_2(c) 
\end{pmatrix}
\]

It is easy to show (and is known from an ODE course) that $S(c)^{-1} e^{A(c)x} S(c) = e^{D(c) x}$. In the eigenbasis, the stable projection $P^s(c)$ onto $E^s(c)$ has a nice form which is independent of $c$.

\[
S(c)^{-1} P^s(c) S(c) = P_1 = \begin{pmatrix}
1 &&& \\ & 1 && \\ && 0 & \\ &&& 0 
\end{pmatrix}
\]

So we have
\begin{align*}
S(c)^{-1} e^{A(c) x} P^s(c) S(c) = S(c)^{-1} e^{A(c) x} S(c)^{-1} S(c) P^s(c) S(c) = e^{D(c) x} P_1
\end{align*}

Next, note that by the same argument as above, using the known formula for the matrix exponential of a diagonal matrix and Lemma \ref{expproj},

\begin{align*}
e^{D(c) x} P_1 &= e^{ D(c)P_1 x} P_1 = 
\begin{pmatrix}
e^{\lambda^s_1(c) x} &&& \\ & e^{\lambda^s_2(c) x} && \\ && 0 & \\ &&& 0 
\end{pmatrix}
\end{align*}

We can take the derivative with respect to $c$ of $e^{D(c) x}$:

\begin{align*}
\frac{\partial}{\partial c} e^{D(c) P_1 x} &=
\begin{pmatrix}
e^{\lambda^s_1(c) x} (\lambda^s_1)'(c) &&& \\ & e^{\lambda^s_2(c) x} (\lambda^s_2)'(c) && \\ && 0 & \\ &&& 0 
\end{pmatrix} \\
&= \begin{pmatrix}
e^{\lambda^s_1(c) x} &&& \\ & e^{\lambda^s_2(c) x}  && \\ && 0 & \\ &&& 0 
\end{pmatrix}
\begin{pmatrix} (\lambda^s_1)'(c) x &&& \\ & (\lambda^s_2)'(c) x && \\ && 0 & \\ &&& 0 \end{pmatrix}  \\
&= e^{D(c) P_1 x} P_1 \Lambda'(c) x
\end{align*}

where

\[
\Lambda(c) = \begin{pmatrix} \lambda^s_1(c) &&& \\ & \lambda^s_2(c)  && \\ 
&& \lambda^u_1(c)  & \\ &&& \lambda^u_2(c)  \end{pmatrix}
\]

Thus since $P_1$ is constant, we have

\begin{equation}\label{frechetcandidate}
\frac{\partial}{\partial c} e^{D(c) P_1 x} P_1 = e^{D(c) P_1 x} P_1 \Lambda'(c) x P_1
\end{equation}

Since $e^{A(c)x }P(c) = S(c) e^{D(c) x} P_1 S^{-1}(c)$, by Lemma \ref{frechetfun}, it suffices to show that $e^{D(c) x} P_1 = e^{D(c) P_1 x} P_1$ has a Frechet derivative. We will use \eqref{frechetcandidate} as our candidate. Note that as long as $0 < \eta < \alpha^s$, this is a bounded linear transformation from $\R$ to $X_\eta$ since

\begin{align*}
|e^{\eta x} e^{D(c) P_1 x} P_1 \Lambda'(c) x P_1| &\leq e^{\eta x} e^{-\alpha^s x} x |\Lambda'(c)||P_1| \\
&= e^{(\eta -\alpha^s) x} x |\Lambda'(c)| \\
&\leq C 
\end{align*}
since $|\Lambda'(c)|$ is constant, and $e^{(\eta -\alpha^s) x} x$ is bounded on $[0, \infty)$ as long as $0 < \eta < \alpha^s$.\\

We need to show that

\[
\lim_{h \rightarrow 0} \frac{|| e^{D(c+h) P_1 x} P_1 - e^{D(c) P_1 x} P_1 - e^{D(c) P_1 x} P_1 \Lambda'(c) x P_1||_\eta}{|h|} = 0
\]

Note that this is a diagonal matrix with only the first two entries nonzero. Thus it suffices to show that for $i = 1, 2$

\[
\lim_{h \rightarrow 0} \frac{|| e^{\lambda^s_i(c+h) x} - e^{\lambda^s_i(c) x} 
- e^{\lambda^s_i(c) x} (\lambda^s_i)'(c)x h ||_\eta}{|h|} = 0
\]

For convenience, we will let $\lambda(c) = \lambda^s_i(c)$. Using the Taylor theorem on $\lambda(c+h)$, we have
\[ 
\lambda(c+h) = \lambda(c) + \lambda'(c)h + r(h)h
\]
where the remainder term $r(h) \rightarrow 0$ as $h \rightarrow 0$.

\begin{align*}
\frac{e^{\eta x}| e^{\lambda(c+h) x} - e^{\lambda(c) x} - e^{\lambda(c) x} \lambda'(c)x h|}{|h|} &=
 \frac{e^{\eta x}| e^{(\lambda(c) + \lambda'(c)h + r(h)h) x} - e^{\lambda(c) x} - e^{\lambda(c) x} \lambda'(c)x h|}{|h|} \\
&= \frac{e^{\eta x} e^{\lambda(c)x}| e^{\lambda'(c)hx} e^{r(h)h x} - 1 - \lambda'(c)x h|}{|h|} 
\end{align*}

We also expand $e^{r(h)h x}$ using the Taylor theorem to one term (i.e. the ordinary mean value theorem)

\[
e^{r(h)h x} = 1 + e^{r(h)h\xi}r(h)hx
\]
where $\xi \in [0, x]$. Substituting this in, we get

\begin{align*}
&\frac{e^{\eta x}| e^{\lambda(c+h) x} - e^{\lambda(c) x} - e^{\lambda(c) x} \lambda'(c)x h|}{|h|}\\
&= \frac{e^{\eta x} e^{\lambda(c)x}| e^{\lambda'(c)hx}( 1 + e^{r(h)h\xi}r(h)hx )- 1 - \lambda'(c)x h|}{|h|} \\
&\leq \frac{e^{\eta x} e^{\lambda(c)x}| e^{\lambda'(c)hx} - 1 - \lambda'(c)x h|}{|h|} + \frac{e^{\eta x} e^{\lambda(c)x} e^{\lambda'(c)hx} e^{r(h)h\xi} | r(h)h x|}{|h|} \\
&= \frac{e^{\eta x} e^{\lambda(c)x}| e^{\lambda'(c)hx} - 1 - \lambda'(c)x h|}{|h|} + e^{\eta x} e^{\lambda(c)x} e^{\lambda'(c)hx} e^{r(h)h\xi}| r(h)| x \\
&\leq \frac{e^{\eta x} e^{\lambda(c)x}| e^{\lambda'(c)hx} - 1 - \lambda'(c)x h|}{|h|} + e^{\eta x} e^{\lambda(c)x} e^{\lambda'(c)hx} (1 + e^{r(h)h x}) | r(h)| x  \\
&\leq \frac{e^{\eta x} e^{\lambda(c)x}| e^{\lambda'(c)hx} - 1 - \lambda'(c)x h|}{|h|} + e^{\eta x} e^{\lambda(c)x} e^{\lambda'(c)hx} x | r(h)| + e^{\eta x} e^{\lambda(c)x} e^{\lambda'(c)hx} e^{r(h)h x} x | r(h) |
\end{align*}
where in the penultimate line we used the fact that the exponential function is monotonic, so since $\xi \in [0, x]$, $e^{r(h)h\xi}$ is bounded by either $e^{r(h)h x}$ or 1 depending on whether $r(h)h$ is positive or negative. Thus $e^{r(h)h\xi} \leq 1 + e^{r(h)h x}$.\\

All that remains is to show each of the three terms goes to 0 uniformly in $x$ as $h \rightarrow \infty$. First, we choose $\eta$ so that $0 \leq \eta \leq \text{Re} \lambda_1^s(c), \text{Re} \lambda_2^s(c)$, so we have $0 \leq \eta \leq \lambda$ here. Then let $a = \lambda - \eta$. Note that $\lambda'(c)$ is just some constant.\\

For the second term and third terms, choose $h$ sufficiently small so that $|\lambda'(c) h| \leq a/4$ and  $|r(h)h| \leq a/4$. (Recall that $r(h) \rightarrow 0 $ as $h \rightarrow 0$, so we can do this.) For the second term, we have

\begin{align*}
e^{\eta x} e^{\lambda(c)x} e^{\lambda'(c)hx} x | r(h)| &= e^{(\eta + \lambda(c) + \lambda'(c)h)x}x|r(h)| \\
&= e^{(\eta + \lambda(c) + a/4 )x}x|r(h)| \\
&= e^{-\alpha x}x|r(h)|
\end{align*}
where $\alpha = \eta + \lambda(c) + a/2  < 0$. Since $e^{-\alpha x}x$ is bounded in $x$ and $|r(h)| \rightarrow 0$ as $h \rightarrow \infty$, this term decays to 0 uniformly in $x$.\\

For the third term, we have

\begin{align*}
e^{\eta x} e^{\lambda(c)x} e^{\lambda'(c)hx} e^{r(h)h x} x |r(h)| &= e^{(\eta + \lambda(c) + \lambda'(c)h + r(h)h)x}x|r(h)| \\
&= e^{(\eta + \lambda(c) + a/4 + a/4)x}x|r(h)| \\
&= e^{(\eta + \lambda(c) + a/2)x}x|r(h)| \\
&= e^{-\alpha x}x|r(h)|
\end{align*}

where $\alpha = \eta + \lambda(c) + a/2  < 0$ is the same as above. Since $e^{-\alpha x}x$ is bounded in $x$ and $|r(h)| \rightarrow 0$ as $h \rightarrow \infty$, this term decays to 0 uniformly in $x$ as well.\\

Finally, for the first term, we have

\begin{align*}
\frac{e^{\eta x} e^{\lambda(c)x}| e^{\lambda'(c)hx} - 1 - \lambda'(c)x h|}{|h|} &= \frac{1}{|h|}e^{\eta x} e^{\lambda(c)x} \left| 1 + \lambda'(c)xh + \sum_{n = 2}^\infty \frac{(\lambda'(c)xh)^n}{n!} - 1 - \lambda'(c)xh\right|\\
&= \frac{1}{|h|}e^{\eta x} e^{\lambda(c)x} \left| \sum_{n = 2}^\infty \frac{(\lambda'(c)xh)^n}{n!} \right| \\
&= e^{\eta x} e^{\lambda(c)x} \left| \sum_{n = 2}^\infty \frac{(\lambda'(c)x)^n h^{n-1}}{n!} \right| \\
&= e^{\eta x} e^{\lambda(c)x} \left| \sum_{n = 0}^\infty \frac{(\lambda'(c)x)^{n+2} h^{n+1}}{(n+2)!} \right|\\
&= e^{\eta x} e^{\lambda(c)x} x^2 |\lambda'(c)|^2 |h| \left| \sum_{n = 0}^\infty \frac{(\lambda'(c)x)^{n} h^{n}}{(n+2)!} \right|\\
&= e^{\eta x} e^{\lambda(c)x} x^2 |\lambda'(c)|^2 |h| \left( \frac{e^{\lambda'(c)xh} - \lambda'(c)xh - 1}{(\lambda'(c)xh)^2} \right)
\end{align*}

The infinite sum was evaluated using Mathematica, but it is easy to verify manually. First, we note that as we take $h \rightarrow 0$, the term in parentheses above (the closed form for the sum) presents no problem by Lemma \ref{expineq}(i). Since the closed form expression for this sum is annoying, we will use the inequality in Lemma \ref{expineq}(v).

\begin{align*}
\frac{e^{\eta x} e^{\lambda(c)x}| e^{\lambda'(c)hx} - 1 - \lambda'(c)x h|}{|h|} &\leq e^{\eta x} e^{\lambda(c)x} x^2 |\lambda'(c)|^2 |h| \left( 1 + e^{\lambda'(c)xh} )\right) \\
&= |\lambda'(c)|^2  \left( e^{(\eta + \lambda(c)) x}x^2 + e^{(\eta + \lambda(c) + \lambda'(c)xh)x} x^2 \right)|h|
\end{align*}

By our choice of $\eta$ and for sufficiently small $h$ (as above) these exponential terms all have negative exponents, thus the RHS on the last line above is less than or equal to a constant multiplied by $|h|$ and so it decays to 0 uniformly in $x$.\\

Since everything decays to 0 uniformly in $x$, we have proved that (i) is Frechet differentiable.\\

The derivative of (iii) follows from that of (i) together with what we showed in Lemma \ref{qc}. For $x \geq 0$, let $L(c, x)$ be the Frechet derivative of $e^{A(c)(x)}P^s(c)$ with respect to $c$. We proved that this exists in (i) above. Our candidate for the Frechet derivative is

\begin{equation}\label{frechetcandidateint}
\int_0^x L(c, x - y) N(U(y)) dy
\end{equation}

First, we need to show this is a bounded linear transformation from $\R$ to $X_\eta$. To do this, we will use a little trick. Recall that we chose $\eta$ such that $0 < \eta < \alpha^s, \alpha^u$. Since this inequality is strict, we can find $\delta > 0$ such that $0 < \eta + \delta < \alpha^s, \alpha^u$. Since $e^{A(c)(x)}P^s(c)$ is Frechet differentiable for all $\eta < \alpha^s, \alpha^u$, it is Frechet differentiable for $\eta + \delta$. Thus we have

\begin{align*}
\left| e^{\eta x} \int_0^x L(c, x - y) N(U(y)) dy \right| &\leq \int_0^x |e^{\eta (x-y)} L(c, x - y)| |e^{\eta y} N(U(y))| dy\\
&= \int_0^x e^{-\delta (x-y)} |e^{(\eta + \delta) (x-y)} L(c, x - y)| |e^{\eta y} N(U(y))| dy\\
&\leq L(\rho)\rho ||L(c, \cdot) ||_{\eta + \delta} \int_0^x e^{-\delta(x-y)} dy\\
&= L(\rho)\rho ||L(c, \cdot) ||_{\eta + \delta} \frac{1 - e^{-\delta x}}{\delta}\\
&\leq \frac{L(\rho)\rho}{\delta}||L(c, \cdot) ||_{\eta + \delta}
\end{align*}

where in the third line we used \eqref{NUetabound} from Lemma \ref{qc}, since our domain for $U$ is $D$. $D$, $L(\rho)$, and $\rho$ are defined in Lemma \ref{qc}. We also used the fact that the Frechet derivative $L(c, x)$ is bounded for $\eta + \delta$, which we showed above. In the penultimate line we used the fact that $x \geq 0$ and $\delta > 0$. Since the RHS is a constant, \eqref{frechetcandidateint} is a bounded linear transformation from $\R$ to $X_\eta$.\\

To show that \eqref{frechetcandidateint} is actually the Frechet derivative, using the definition of the Frechet derivative,

\begin{align*}
\frac{1}{|h|}&e^{\eta x}\left| \int_0^x e^{A(c+h)(x - y)}P^s(c) N(U(y))dy - \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy - h \int_0^x L(c, x - y) N(U(y)) dy \right|\\
&= \frac{1}{|h|}e^{\eta x}\left| \int_0^x \left( e^{A(c+h)(x - y)}P^s(c) - e^{A(c)(x - y)}P^s(c) - h L(c, x - y) \right) N(U(y)) dy \right| \\
&\leq \int_0^x \left| \frac{ e^{\eta(x-y)} (e^{A(c+h)(x - y)}P^s(c) - e^{A(c)(x - y)}P^s(c) - h L(c, x - y))}{h}\right| \left| e^{\eta y} N(U(y)) \right| dy \\
&\leq \int_0^x \left| \frac{ e^{\eta(x-y)} (e^{A(c+h)(x - y)}P^s(c) - e^{A(c)(x - y)}P^s(c) - h L(c, x - y))}{h}\right| || e^{\eta y} N(U(y)) ||_\eta dy \\
&\leq L(\rho)\rho \int_0^x \left| \frac{ e^{\eta(x-y)} (e^{A(c+h)(x - y)}P^s(c) - e^{A(c)(x - y)}P^s(c) - h L(c, x - y))}{h}\right| dy
\end{align*}

where in the last line we used \eqref{NUetabound} from Lemma \ref{qc}.We need this to decay uniformly in $x$, so we use the same $\delta$ trick we used above. Using the same $\delta > 0$,

\begin{align*}
\frac{1}{|h|}&e^{\eta x}\left| \int_0^x e^{A(c+h)(x - y)}P^s(c) N(U(y))dy - \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy - h \int_0^x L(c, x - y) N(U(y)) dy \right|\\
&\leq L(\rho)\rho \int_0^x e^{-\delta(x-y)} \left| \frac{ e^{(\eta+\delta)(x-y)} (e^{A(c+h)(x - y)}P^s(c) - e^{A(c)(x - y)}P^s(c) - h L(c, x - y))}{h}\right| dy\\
&\leq L(\rho)\rho \int_0^x e^{-\delta(x-y)} \frac{ || e^{A(c+h)(\cdot)}P^s(c) - e^{A(c)(\cdot)}P^s(c) - h L(c, \cdot) ||_{\eta + \delta} }{|h|} dy\\
&= \leq L(\rho)\rho \frac{ || e^{A(c+h)(\cdot)}P^s(c) - e^{A(c)(\cdot)}P^s(c) - h L(c, \cdot) ||_{\eta + \delta} }{|h|} \int_0^x e^{-\delta(x-y)} dy\\
\end{align*}

In (i), we showed that $L(c, x)$ is the Frechet derivative of $e^{A(c)(x)}P^s(c)$ with respect to $c$ for any $0 < \eta < \alpha^s, \alpha^u$. In particular, this is true for $\eta + \delta$. Thus by the definition of the Frechet derivative, given $\epsilon > 0$, we can find $h$ sufficiently small such that 

\[
\frac{ || e^{A(c+h)(\cdot)}P^s(c) - e^{A(c)(\cdot)}P^s(c) - h L(c, \cdot) ||_{\eta + \delta} }{|h|} < \epsilon
\]

Thus for sufficiently small $h$, 

\begin{align*}
\frac{1}{|h|}&e^{\eta x}\left| \int_0^x e^{A(c+h)(x - y)}P^s(c) N(U(y))dy - \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy - h \int_0^x L(c, x - y) N(U(y)) dy \right|\\
&\leq L(\rho)\rho \epsilon \int_0^x e^{-\delta(x-y)} dy\\
&= L(\rho)\rho \epsilon \frac{1 - e^{-\delta x}}{\delta}\\
&\leq \frac{L(\rho)\rho}{\delta}\epsilon
\end{align*}

since $\delta > 0$ and $x \geq 0$. Since $\epsilon$ is arbitrary and everything else is a constant not depending on $x$, we have proved that (iii) is Frechet differentiable with respect to $c$.\\

For (ii), we first show Frechet differentiability of $e^{A(c)(x}P^u(c) N(U(y))$ on the exponentially weighted space $\{ f \in C^0((-\infty, 0], \R^n) : \sup_{x \in (-\infty, 0]} |e^{\eta x} f(x)| < \infty \}$, which is similar to (i). The Frechet differentiability of (ii) then follows similarly to that of (iii).

\end{proof}
\end{lemma}

We will also need the following hypotheses. Numerics suggest that these are reasonable.

\begin{hypothesis}\label{1dkernel}
The kernels of $H$, $\partial_x H$, and $H \partial_x$ are all one-dimensional. Thus we have
\begin{align*}
\ker H &= \text{span}\{ q' \} \\
\ker \partial_x H &= \text{span}\{ q' \} \\
\ker H \partial_x &= \text{span}\{ q \}
\end{align*}
Note that these only apply on the unbounded domain. For a bounded domain, for example, $\ker H \partial_x$ also contains the constant functions.
\end{hypothesis}

\begin{hypothesis}\label{qcIP}
$\langle q, q_c\rangle_{L^2(\R)} \neq 0$
\end{hypothesis}
Note that by Cauchy-Schwarz, $\langle q, q_c\rangle_{L^2(\R)} \leq ||q||_{L^2(\R)} ||q_c|_{L^2(\R)}$. Since the single pulse $q$ is exponentially localized, $q \in L^2(\R)$. By Lemma \ref{qc}, $q_c \in L^2(\R)$. Thus this inner product is well-defined.

\subsection*{First Construction}

Here we present one construction of the eigenfunction corresponding to an eigenvalue near 0 for the linearization of KdV5 about the single pulse. This corresponds to Sandstede (1998). For the single pulse, we only have two pieces which are connected by a single join at $x = 0$. We write the piecewise eigenfunction $V^\pm$ as a perturbation of the derivative $Q'$ of the single pulse, since we know that $Q'$ is an eigenfunction with eigenvalue 0. 

\begin{align*}
V^\pm(x) = Q'(x) + W^\pm(x)
\end{align*}

If we plug this into the integrated eigenvalue problem (defined in \texttt{KdV17}), we obtain the following system of equations, which are analogous to (3.7) in Sandstede (1998).

\begin{align*}
W^\pm(x)' &= A(q(x)) W^\pm(x) + \lambda B Q(x) + \lambda K^\pm B W^\pm(x) \\
W^\pm(x) &\in \C \psi(0) \oplus Y^+ \oplus Y^- \\
W^+(0) - W^-(0) &\in \C \psi(0) 
\end{align*}

We will use the third equation together with the jump distance to conclude that $W^-(0) = W^+(0)$, which is the matching condition we want.\\

Analogous to (3.14) in Sandstede (1998), we can write the fixed point equations for $W^\pm$ as

\begin{align*}
W^-(x) = \Phi^u_-(x, 0)b^- &+ \int_0^x \Phi^u_-(x, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] dy \\
&+ \int_{-\infty}^x \Phi^s_-(x, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] dy \\
W^+(x) = \Phi^s_+(x, 0)b^+ &+ \int_0^x \Phi^s_+(x, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] dy \\
&+ \int_{\infty}^x \Phi^u_+(x, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] dy
\end{align*}

In particular, note that compared to the double pulse (see \textrm{KdV17}), the boundary term is gone, and there is no longer a match at $\pm L$. To solve this, we use the equivalent of Lemmas 3.3 - 3.5 in Sandstede (1998).

\begin{lemma}\label{inv1}
There exist operators $B_1(\lambda)$ and $W_3(\lambda)$ such that 
\[
(b, W) = (B_1(\lambda), W_3(\lambda))
\]
Any bounded solution is given by this, and these operators are analytic in $\lambda$. We have the estimates
\begin{align*}
|B_1(\lambda)| &\leq C|\lambda| \\
||W_3(\lambda)||_\alpha &\leq C|\lambda|
\end{align*}
where $\alpha$ is chosen so that $0 < \alpha < \alpha^s, \alpha^u$
\begin{proof}
We follow what we did in \texttt{KdV17} as well as Lemmas 3.3 - 3.5 in Sandstede (1998), but we make the necessary simplifications for the single pulse. As in \texttt{KdV17}, we work in the exponentially weighted spaces $C^0_\alpha(-\infty, 0]$ and $C^0_\alpha[0, \infty)$, where $\alpha$ is chosen as above. These spaces and their norms are defined in \texttt{KdV17}. We define the linear operators $(L_1(\lambda)W^\pm)(x)$ from the exponentially weighted spaces to themselves by

\begin{align*}
(L_1(\lambda)W^-)(x) &= \lambda \left( \int_0^x (K_i^- B W^-)(y) dy + \int_{-\infty}^x (K_i^-B W^-)(y) dy \right) \\
(L_1(\lambda)W^+)(x) &= \lambda \left( \int_0^x (K_i^+ B W^+)(y) dy + \int_{\infty}^x (K_i^+ B W^+)(y) dy \right)
\end{align*}
We showed in \texttt{KdV17} that this operator is well-defined, i.e. it actually maps the exponentially weighted spaces to themselves, and that $||L_1(\lambda)W||_\alpha \leq C||W||_\alpha$ for our choice of $\alpha$.\\

We also define the linear operators $(L_2(\lambda)b)(x)$ from $\R^n$ to our exponentially weighted space by

\begin{align*}
(L_2(\lambda))(b^-) &= \Phi^u_-(x, 0)b^- + \lambda \left( \int_0^x \Phi^u_-(x, y) B Q(y)dy + \int_{-\infty}^x \Phi^s_-(x, y)B Q(y) dy \right)\\
(L_2(\lambda))(b^+) &= \Phi^s_+(x, 0)b^+ + \lambda \left( \int_0^x \Phi^s_+(x, y) B Q(y) dy + \int_{\infty}^x \Phi^u_+(x, y) B Q(y) dy \right)
\end{align*}

Since this is a simplified version of the operator in Lemma 3.3 of Sandstede (1998), the estimate there applies in this case, and we have

\[
||L_2(\lambda)(b)|| \leq C|b|
\]

Writing the fixed point problem as $(I - L_1(\lambda))W = L_2(\lambda)(b)$, we can invert the operator ($(I - L_1(\lambda))$ (I HAVE NEVER UNDERSTOOD WHAT YOU USED TO DO THIS, BUT IT SHOULD FOLLOW EXACTLY AS IN THE PAPER) to get
\[
W = (I - L_1(\lambda))^{-1} L_2(\lambda)(b) := W_1(\lambda)(b)
\]
with 
\[
||W_1(\lambda)(b)||_\alpha \leq C|b|
\]

Since we only have the join at $x = 0$ (i.e. we do not have the $d_i$), we do not need an equivalent to Lemma 3.4. Since the only thing we have changed is the function space (nonweighted to exponentially weighted), Lemma 3.5 should apply unchanged. Since there is no $a$ or $d$, $W_3 = W_1$. The only thing we need to be careful of is that $B_1(\lambda)$ is a function of $d$, which we do not have here. We should be able to take $d = 1$ (since it always takes that value here) and be all set. Thus applying Lemma 3.5 gives us

\begin{align*}
(b, W) = (B_1(\lambda), W_3(\lambda))
|B_1(\lambda)| &\leq C|\lambda| \\
||W_3(\lambda)||_\alpha &\leq C|\lambda|
\end{align*}

which is the result we want.
\end{proof}
\end{lemma}

Having done this, it only remains to estimate the single jump at $x = 0$.
\[
\xi = \langle \Psi(0), W^+(0) - W^-(0) \rangle
\]

Plugging in what we have, we get

\begin{align*}
\langle\Psi(0), W^+(0) &- W^-(0)\rangle = \langle \Psi(0), \Phi^u_-(0, 0)b^- + \int_{-\infty}^0 \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] dy  \\
&- \Phi^s_+(0, 0)b^+ - \int_\infty^0 \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] dy \rangle\\
&= \langle \Psi(0), b^- - b^+\rangle + \int_{-\infty}^0 \langle \Psi(0), \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] \rangle dy  \\
&- \int_\infty^0 \langle \Psi(0), \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] \rangle dy  \\
&= \int_{-\infty}^0 \langle \Psi(y), \lambda (K^- B W^-)(y) + \lambda B Q(y) \rangle dy \\
&- \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) + \lambda B Q(y)  \rangle dy \\
&= \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) > dy + \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) \rangle dy \right) \\
&+ \lambda \int_{-\infty}^\infty \langle\Psi(y), BQ(y) \rangle dy
\end{align*}

I am pretty sure that we matched things so that $b^+ = b^-$ (I CANNOT TELL IN THE PAPER WHERE THIS IS DONE, BUT THIS APPEARS TO BE USED IN (3.48) IN SANDSTEDE (1998)), so this term cancels.\\

The final integral on the RHS is the Melnikov integral, which we claim is 0. To see this, we first note that for the linearization of the fourth-order equation about the single pulse $q$, i.e. $H = \partial_x^4 - \partial_x^2 + c - 2q$, $Hq_c = -q$. (To show this, plug it in and use the fact that $q$ solves the orginal nonlinear 4th order equation.) Using this and the definition of $B$ (see \texttt{KdV17}) we have

\begin{align*}
 \int_{-\infty}^\infty \langle \Psi(y), BQ(y) \rangle dy &=  \int_{-\infty}^\infty \psi(y) q(y) dy \\
&= \langle \psi, q \rangle_{L^2(\R)} = -\langle \psi, H q_c \rangle_{L^2(\R)} \\
&= -\langle H^* \psi, q_c\rangle_{L^2(\R)} = -\langle H \psi, q_c \rangle_{L^2(\R)}
\end{align*}

The final inner product is well-defined by Cauchy-Schwarz since $\langle H \psi, q_c \rangle_{L^2(\R)} \leq ||H \psi||_{L^2(\R)} |q_c|_{L^2(\R)}$ and $q_c \in L^2(\R)$ by Lemma \ref{qc}. (We will show below that $H \psi$ = 0). The inner product $\langle \psi, q \rangle_{L^2(\R)}$ is similarly well-defined since $q$ is exponentially localized, as is $\psi$. (We sill show below that $\psi \in \ker H$, and since we are assuming that $\ker H$ is one-dimensional, $\psi$ is a multiple of $q'$, which is exponentially localized).\\

All that remains is show that $\psi \in \ker H$. Recall that the matrix $B$ places the 1st component of a vector into the 4th component and zeros out all the other components. Since $BQ(y)$ places the pulse $q(y)$ into the 4th component, $\psi$ is the 4th component of $\Psi$. $\Psi$ is the solution to the adjoint variational equation $U' = -A(q(x))^*U$, where 

\[ 
A(q(x))^* = 
 \begin{pmatrix}0 & 0 & 0 & 2q_2(x) - c \\ 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 1 \\ 0 & 0 & 1 & 0\end{pmatrix}
\]

This can be broken down into the four equations

\begin{align*}
\Psi_1' &= -(2q(x) - c) \Psi_4 \\
\Psi_2' &= -\Psi_1 \\
\Psi_3' &= -\Psi_2 - \Psi_4 \\
\Psi_4' &= -\Psi_3
\end{align*}

The scalar function $\psi$ we want is the fourth component $\Psi_4$. We will show that $H \Psi_4 = 0$, i.e. $\Psi_4 \in \ker H$.

\begin{align*}
H \Psi_4 &= \Psi''''_4 - \Psi''_4 + (c - 2q(x))\Psi_4 \\
&= -\Psi'''_3 + \Psi_3' + \Psi_1' \\
&= \Psi''_2 + \Psi''_4 + \Psi_3' + \Psi_1' \\
&= -\Psi_1' - \Psi_3' + \Psi_3' + \Psi_1'\\
&= 0
\end{align*}

We have shown that $\Psi' = -A(q(x))^*\Psi$ is equivalent to $\Psi_4 \in \ker H$. Since $H \psi = H \Psi_4 = 0$, we can conclude that the Melnikov integral above is 0. Since we are assuming that $\ker H$ is 1-dimensional and we know that $q' \in \ker H$, we conclude that $\psi = q'$.
\\

Thus for our jump we have

\[
\langle \Psi(0), W^+(0) - W^-(0) \rangle = \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy + \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) \rangle dy \right) 
\]

At this point, we can plug in our expressions for $W^\pm$ from above and see what we get. The idea is to get something equivalent to a Melnikov integral, but as a coefficient of $\lambda^2$. Looking at what we have, when we plug in $W^\pm$, the term in $BQ(y)$ will give us what we want. Unfortunately, this is a really big mess, so we will approach this from another angle.

\subsection*{Second Construction}

Here we present another construction for the eigenfunction of the linearization of KdV5 about the single pulse $q(x)$. Since the Melnikov integral above is 0, the idea here is to find an equivalent to the Melnikov integral for the $\lambda^2$ term in the expansion. This will only work for the single pulse, but the idea is that we can (somehow) extend this to multipulses, since, to leading order, multipulses are single pulses joined together.\\

Consider the eigenvalue problem $\partial_x H u = \lambda u$ and its integrated version $Hu = \lambda \int_a^x u$. For now, we won't worry about the lower limit of integration except to note that it has to be $\pm \infty$ in order to avoid a boundary term on the LHS.\\

We write the eigenfunction $u$ as a small perturbation of the derivative of the single pulse $q'(x)$.
\[
u(x) = q'(x) + \lambda v(x)
\]

For $\lambda = 0$, this reduces to $u(x) = q'(x)$, which we know is an eigenfunction (of both $H$ and $\partial x H$) with eigenvalue 0. Since we are interested in small $\lambda$, this a reasonable place to start. Assuming this a solution to our (nonintegrated, 5th order) eigenvalue problem, we get the following when we plug it in.

\begin{align*}
\partial_x H u &= \lambda u \\
\partial_x H (q' + \lambda v) &= \lambda(q' + \lambda v) \\
\partial_x H q' + \lambda \partial_x H v &= \lambda q' + \lambda^2 v \\
\lambda \partial_x H v &= \lambda(q' + \lambda v)
\end{align*}

If we assume that $\lambda \neq 0$ (which is reasonable, since we already know what happens when $\lambda = 0$), can divide by $\lambda$ to get (for $\lambda$ small)
\[
\partial_x H v = q' + \lambda v
\]

To leading order (neglecting the second term on the RHS), this is

\[
\partial_x H v = q'
\]

Note that $v$ does not appear on the RHS. We know the solution to this: $\partial_x H q_c = -q'$, so $\partial_x H (-q_c) = q'$, or $H (-q_c) = q$. Another way to see this is as follows. $\partial_x H v = q'$ is equivalent to $Hv = q$. For that to have a solution, $q$ must be in the range of $H$, which is perpendicular to the kernel of $H^*$. Thus we have the condition $\langle q, \psi \rangle = 0$ for all $\psi \in \ker(H^*)$. Since $H$ is self-adjoint, this becomes $\langle q, \psi \rangle = 0$ for all $\psi \in \ker H$. Since we are assuming that $\ker H$ is one-dimensional, i.e. $\ker(H) = \textrm{span} \{q'\}$, this condition is $\langle q, q' \rangle = 0$. We know this is true since $q$ is even and $q'$ is odd.\\

Thus it makes sense to write $v$ as a perturbation of $-q_c$.

\[
v(x) = -q_c(x) + \lambda w(x)
\]
since when $\lambda = 0$, $v$ solves the equation above. If we plug this into the equation $\partial_x H v = q' + \lambda v$, we get

\begin{align*}
\partial_x H(-q_c + \lambda w) &= q' + \lambda(-q_c + \lambda w) \\
q' + \lambda (\partial_x H) w &= q' + \lambda(-q_c + \lambda w) \\
\lambda \partial_x H w &= \lambda(-q_c + \lambda w)
\end{align*}

For $\lambda \neq 0$ (which, again, is the case we care about), this reduces to

\[
\partial_x H w = -q_c + \lambda w
\]

where we have written the eigenfunction $v(x)$ as
\[
v(x) = q'(x) - \lambda q_c(x) + \lambda^2 w(x)
\]

To leading order, this is

\[
\partial_x H w = -q_c
\]

Again, note that $w$ is not present on the RHS. Suppose we had a solution $\tilde{w}(x)$ to this. Then we could write $w(x) = \tilde{w}(x) + \lambda r(x)$ and repeat what we did above. This would give us an expansion of our eigenfunction which looks like $v(x) = q'(x) - \lambda q_c(x) + \lambda^2 \tilde{w}(x) + \lambda^3 r(x)$, which is one degree higher in $\lambda$ than we wish to go. In order for this to not be possible, we require the equation $\partial_x H w = -q_c$ to not have a solution (or at least not have one which is in $L^2$ or in our exponentially weighted space). This is equivalent to

\[
q_c \notin \textrm{Range}(\partial_x H)
\]

Since $\textrm{Range}(\partial_x H) = \ker (\partial_x H)^*$, this is equivalent to 

\[
\langle q_c, \phi \rangle \neq 0 \text{ for some }\phi \in \ker(\partial_x H)^*
\]

Since $\ker(\partial_x H)^* = H^* (\partial_x)^* = -H \partial_x$ (recall that $H$ is self-adjoint), this is equivalent to

\[
\langle q_c, \phi \rangle \neq 0 \text{ for some }\phi \in \ker(H \partial_x)
\]

By Hypothesis \ref{1dkernel}, $\ker(H \partial_x) = \textrm{span} \{q \}$, so this is equivalent to

\[
\langle q_c, q \rangle \neq 0
\]

which is Hypothesis \ref{qcIP}.\\

Let's look at what we have done so far. For the linearization about a single pulse, we have written our eigenfunction as an expansion in $\lambda$ to 2nd order.

\begin{equation}\label{eigenfntosecondorder}
v(x) = q'(x) - \lambda q_c(x) + \lambda^2 w(x)
\end{equation}

We have the following equation for $w$

\begin{equation}\label{wqc}
\partial_x H w = -q_c + \lambda w 
\end{equation}

where Hypothesis \ref{qcIP} assures that the leading-order problem $\partial_x H w = -q_c$ does not have a solution.\\

From here, we step back and look at what we are trying to accomplish. We want to find a solution to \eqref{wqc}. Suppose we were able to find a solution to the problem

\[
H w(x) = -\int^x q_c(y) dy + \lambda \int^x w(y) dy + C
\]

where we have intentionally left off the lower limits of integration and added an arbitrary constant at the end. We call this the integrated eigenvalue problem. If we can find a solution to this, we can differentiate it to get a solution to \eqref{wqc}. The key is that it does not matter what the lower limits of the two integrals are (the can be different) and what the constant $C$ is. We can set up the problem in any way which is convenient for us. So let's do that. For the left integral, which does not depend on $w$, we will always have a lower limit of $-\infty$ since $q_c$ is smooth, integrable (we showed $q_c \in L^2(\R)$), and we don't have to do any join for it. For the second integral, we will write the lower limit as $a$, where $a$ will be $\pm \infty$. Since we will be attempting to join the left half and the right half of $w$ at $x = 0$, it makes sense to choose two different limits here. We can take $C = 0$ as well. The integrated eigenvalue problem becomes
 
\[
H w(x) = -\int_{-\infty}^x q_c(y) dy + \lambda \int_a^x w(y) dy 
\]

At this point we proceed as in the previous section by writing the problem as a first order system and splitting the domain up into two pieces. The two pieces are the same as above, and we take the integration limits $a = \pm \infty$ on the two pieces. This gives us the following set of equations.

\begin{align*}
W^\pm(x)' &= A(q(x)) W^\pm(x) - (K^- B Q_c)(x) + \lambda (K^\pm B W^\pm)(x) \\
W^\pm(x) &\in \C \psi(0) \oplus Y^+ \oplus Y^- \\
W^+(0) - W^-(0) &\in \C \psi(0) 
\end{align*}

Note that for the integral involving $Q_c$ we always use the integration operator $K^-$ since we are always integrating from $-\infty$. We can write the fixed point equations for $W^\pm$ as

\begin{align*}
W^-(x) = \Phi^u_-(x, 0)b^- &+ \int_0^x \Phi^u_-(x, y)[\lambda (K^- B W^-)(y) - (K^- B Q_c)(y) ] dy \\
&+ \int_{-\infty}^x \Phi^s_-(x, y)[\lambda (K^- B W^-)(y) - (K^- B Q_c)(y) ] dy \\
W^+(x) = \Phi^s_+(x, 0)b^+ &+ \int_0^x \Phi^s_+(x, y)[\lambda (K^+ B W^+)(y) - (K^- B Q_c)(y) ] dy \\
&+ \int_{\infty}^x \Phi^u_+(x, y)[\lambda (K^+ B W^+)(y) - (K^- B Q_c)(y) ] dy
\end{align*}

Now we do the inversion as in the previous section and as in Sandstede (1998). The integration operator term $K^\pm B W^\pm$ is the same as above, so we can handle that with an exponentially weighted function space with the same choice of exponential weight $\alpha$. $Q_c$ is independent of $W^\pm$ and is integrable by Lemma \ref{qc}, so the $K^- B Q_c$ term is bounded by a constant. Thus we have the equivalent of Lemma \ref{inv1} in the previous section.

\begin{align*}
(b, W) &= (B_1(\lambda), W_3(\lambda))\\
B_1(\lambda)| &\leq C|\lambda|\\
||W_3(\lambda)||_\eta &\leq C|\lambda|\\
\end{align*}

Now we look at the jump as before. 

\begin{align*}
\langle \Psi(0), W^-(0) &- W^+(0) \rangle = \langle \Psi(0), \Phi^u_-(0, 0)b^- + \int_{-\infty}^0 \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) - (K^- B Q_c)(y)] dy  \\
&\:\:\:\:\:\:\:\: - \Phi^s_+(0, 0)b^+ - \int_\infty^0 \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) - (K^- B Q_c)(y) ] dy \rangle \\
&= \langle \Psi(0), b^- - b^+\rangle + \int_{-\infty}^0 \langle \Psi(0), \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) - (K^- B Q_c)(y) ] \rangle dy  \\
&\:\:\:\:\:\:\:\:- \int_\infty^0 \langle \Psi(0), \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) - (K^- B Q_c)(y) ] \rangle dy  \\
&= \int_{-\infty}^0 \langle \Psi(y), \lambda (K^- B W^-)(y) - (K^- B Q_c)(y) \rangle dy \\
&\:\:\:\:\:\:\:\:- \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) - (K^- B Q_c)(y) \rangle dy \\
&= -\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B Q_c)(y) \rangle dy - \int_{\infty}^0 \langle \Psi(y), (K^- B Q_c)(y) \rangle dy \right) \\
&\:\:\:\:\:\:\:\:+ \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy - \int_\infty^0 \langle \Psi(y), (K^+ B W^+)(y) \rangle dy \right) \\
&= -\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B Q_c)(y) \rangle dy + \int_0^{\infty} \langle \Psi(y), (K^- B Q_c)(y) \rangle dy  \right) \\
&\:\:\:\:\:\:\:\:+ \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy + \int_0^\infty \langle \Psi(y), (K^+ B W^+)(y) \rangle dy \right) \\
&= -\int_{-\infty}^\infty \langle \Psi(y), (K^- B Q_c)(y) \rangle dy \\
&\:\:\:\:\:\:\:\:+ \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy + \int_0^\infty \langle \Psi(y), (K^+ B W^+)(y) \rangle dy \right) 
\end{align*}

We are interested in the term not involving $\lambda$. (If we recall what we did above, these will correspond to the coefficient of $\lambda^2$ in the expansion \eqref{eigenfntosecondorder} of the eigenfunction.) Recall that we defined $\psi$ above as the 4th component of $\Psi$. 

\begin{equation}
M = -\int_{-\infty}^\infty \psi(y) \int_{-\infty}^y q_c(z) dz dy
\end{equation}

We showed above that $\psi \in \ker H$. By Hypothesis \ref{1dkernel}, $\psi = q'$, so $M$ becomes

\begin{equation}\label{defM}
M = -\int_{-\infty}^\infty q'(y) \int_{-\infty}^y q_c(z) dz dy
\end{equation}

Now we show that $M \neq 0$. To to this, we take \eqref{defM} and integrate by parts.

\begin{align*}
M &= -\int_{-\infty}^\infty q'(y) \int_{-\infty}^y q_c(z) dz dy \\
&= -\left( q(y) \int_{-\infty}^y q_c(z) dz \Big|_{-\infty}^{\infty} - \int_{-\infty}^\infty q(y) q_c(y) dy \right)\\
&= \langle q, q_c \rangle_{L^2(\R)}
\end{align*}

where the boundary term cancels since the single pulse $q$ decays at $\pm \infty$ and $q_c \in L^2(\R)$. By Hypothesis \ref{qcIP}, $M \neq 0$.\\

We can use our estimates to get something resembling (3.56) in Sandstede (1998), ALTHOUGH I DO NOT KNOW IF THIS IS USEFUL SINCE WE HAVE THE EQUIVALENT TO THE MELNIKOV INTEGRAL. We use here the estimate (3.50) in Sandstede (1998) $|\Psi(x)| \leq C e^{-\alpha_* |x|}$. (We use $\alpha_*$ here for the constant to distinguish it from the $\alpha$ we chose above.) We also use the estimate $||W|| = ||W_3(\lambda)||_\alpha \leq C|\lambda|$ for our chosen $\alpha < \alpha^s, \alpha^u$. For the last one, recall that the exponentially weighted norm is defined by

\begin{align*}
|| f ||_\eta &= \sup_{x \in [-a, 0]} |e^{-\eta x} f(x) | && f \in C^0_\eta[-a, 0] \\
|| f ||_\eta &= \sup_{x \in [0, a]} |e^{\eta x} f(x) | && f \in C^0_\eta[0, a] \\
\end{align*}

\begin{align*}
R(\lambda) &= \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy - \int_\infty^0 \langle \Psi(y), (K^+ B W^+)(y) \rangle dy \right) \\
|R(\lambda)| &\leq |\lambda|\left( \int_{-\infty}^0 C e^{\alpha_* y} \int_{-\infty}^y |w^-(z)| dz dy + \int_0^\infty C e^{-\alpha_* y} \int_y^\infty |w^+(z)| dz dy \right) \\
&= |\lambda|\left( \int_{-\infty}^0 C e^{\alpha_* y} \int_{-\infty}^y e^{\alpha z} |e^{-\alpha z} w^-(z)| dz dy + \int_0^\infty C e^{-\alpha_* y} \int_y^\infty e^{-\alpha z} |e^{\alpha z}w^+(z)| dz dy \right)\\
&\leq C |\lambda| ||W_3(\lambda)||_\alpha \left( \int_{-\infty}^0 e^{\alpha_* y} \int_{-\infty}^y e^{\alpha z} dz dy + \int_0^\infty e^{-\alpha_* y} \int_y^\infty e^{-\alpha z} dz dy \right)\\
&= \frac{C}{\alpha} |\lambda|^2 \left( \int_{-\infty}^0 e^{(\alpha_* + \alpha) y} dy + \int_0^\infty e^{-(\alpha_* + \alpha) y} \right) dy \\
&= \frac{2 C}{\alpha(\alpha + \alpha_*)} |\lambda|^2 
\end{align*}

So we should have for our jump

\[
\xi = M + R(\lambda)
\]

where $M$ is given above and we have the above estimate for the remainder $R(\lambda)$.\\

We know what the deal is in this case, i.e. there is no nonzero eigenvalue near 0 for the single pulse. Thus we should not be able to get the jump to be 0, although it is not clear at all that this is the case by looking at what we did above.

\subsection*{Double Pulse}

Now we combine stuff from the above two constructions and from Sandstede (1998) to generalize this to the double pulse. Recall from that paper that for a double pulse, we can write the eigenfunction as a perturbation of the derivative of the double pulse, where on the two ``big pieces'', the derivative is multiplied by a scaling constant. $Q_2$ is the double pulse solution.

\[
V_i^\pm = d_i Q_2' + W_i^\pm 
\]

Numerics suggest that the $d_i$ are definitely not identical. (For the interaction eigenfunction of the first unstable double pulse, for example, one side is significantly larger than the other.) Recalling what we did in the previous section, we can write this as

\begin{equation}\label{dpeigform}
V_i^\pm = d_i( Q_2' + \lambda Q_{2c} ) + W_i^\pm
\end{equation}

The perturbation $W_i^\pm$ is different in this case. When $\lambda = 0$, we can take $d_i = 1$ to get the correct eigenfunction $Q_2'$, so that is good. Also we will eventually want this in terms of the single pulse $Q$, but we leave it this for now to get some nice cancelation. Recall that the integrated eigenvalue problem is given in piecewise system form by

\[
(V_i^\pm)' = A(Q_2)V_i^\pm + \lambda K_i^\pm B V_i^\pm
\]

If we plug in \eqref{dpeigform} into this, we get 

\begin{align*}
(d_i Q_2 &- d_i \lambda Q_{2c} + W_i^\pm)' = \\
&d_i A(Q_2)Q_2' - d_i \lambda A(Q_2)Q_{2c} + A(Q_2) W_i^\pm + d_i \lambda KBQ_2' - d_i \lambda^2 KBQ_{2c} + \lambda K_i^\pm B W_i^\pm 
\end{align*}

where $K$ is the integral operator $Kf(x) = \int_{-\infty}^x f(y) dy$. As we did above, for the non-piecewise functions, we always take the lower limit of integration to be $-\infty$. We should be able to justify this by the same reasons we gave above. In any case, it won't work unless we do this.\\

We note the following relationships which can be derived from the eigenfunctions $q'$ and $q_c$.

\begin{align*}
(Q_2)' &= A(Q_2)Q_2 \\
(Q_{2c})' &= A(Q_{2})Q_{2c} - BQ_2  
\end{align*} 

For the second one, we can use the integration operator $K$ on $Q_2'$ to get

\[
(Q_{2c})' = A(Q_{2})Q_{2c} - KBQ_2'
\]

Using these expressions to cancel things, we get

\[
(W_i^\pm)' = A(Q_2)W_i^\pm - \lambda^2 d_i KBQ_{2c} + \lambda K_i^\pm BW_i^\pm
\]

We would like to write things in terms of the single pulse $Q$. Luckily, from Sandstede (1998) we know that

\[
Q_2 = Q + R_i^\pm
\]

where the remainder $R_i^\pm$ is small (and we have estimates on it). Then $Q_{2c} = Q_c + (R_i^\pm)_c$. Let
\[
G_i^\pm = A(Q_2) - A(Q) = A(Q + R_i^\pm) - A(Q)
\]

Then we have

\begin{equation}\label{inteigQ}
(W_i^\pm)' = A(Q)W_i^\pm - \lambda^2 d_i KBQ_{c} + \lambda K_i^\pm BW_i^\pm + G_i^\pm W_i^\pm - \lambda^2 d_i K_i^\pm B (R_i^\pm)_c
\end{equation}  

The first three terms on the RHS are exactly those from the single pulse case. The remaining terms hopefully are small. Following Sandstede (1998) and what we did above, we can write the fixed point equations for $W_i^\pm$ as

\begin{align*}
W_i^-(x) = \Phi^s_-(&x, -X_{i-1})a_{i-1}^- + \Phi^u_-(x, 0)b_i^- \\
&+ \int_0^x \Phi^u_-(x, y)[\lambda K_i^- BW_i^- - \lambda^2 d_i KBQ_{c} + G_i^- W_i^- - \lambda^2 d_i K_i^- B (R_i^-)_c ] dy \\
&+ \int_{-X_{i-1}}^x \Phi^s_-(x, y)[\lambda K_i^- BW_i^- - \lambda^2 d_i KBQ_{c} + G_i^- W_i^- - \lambda^2 d_i K_i^- B (R_i^-)_c ] dy \\
W_i^+(x) = \Phi^u_+(&x, X_i)a_i^+ + \Phi^s_+(x, 0)b_i^+ \\
&+ \int_0^x \Phi^s_+(x, y)[\lambda K_i^+ BW_i^+ - \lambda^2 d_i KBQ_{c} + G_i^+ W_i^+ - \lambda^2 d_i K_i^+ B (R_i^+)_c ] dy \\
&+ \int_{X_i}^x \Phi^u_+(x, y)[\lambda K_i^+ BW_i^+ - \lambda^2 d_i KBQ_{c} + G_i^+ W_i^+ - \lambda^2 d_i K_i^+ B (R_i^+)_c ]dy
\end{align*}

where in this case the join points are $(X_0, X_1, X_2) = (-\infty, L, \infty)$. Next we write down the equation for the jump distance (i.e. evaluate this at $x = 0)$. The following is analogous to (3.48) in Sandstede (1998). The $b_i$ cancel in that paper, so we will assume they cancel here too, although at some point we might want to look at that more carefully. In the meantime, we will just try and get this to work.

\begin{align*}
\langle \Psi(0), &W_i^-(0) - W_i^+(0) \rangle \\
= &\langle \psi(-X_{i-1}), a_{i-1}^-\rangle - \langle \psi(X_i), a_{i}^+\rangle\\
&-\lambda^2\left( \int_{-X_{i-1}}^0 \langle \Psi(y), d_i (K B Q_c)(y) \rangle dy - \int_{X_i}^0 \langle \Psi(y), d_i (K B Q_c)(y) \rangle dy \right) \\
&-\lambda^2 d_i \left( \int_{-X_{i-1}}^0 \langle \Psi(y), (K_i^- B (R_i^-)_c)(y) \rangle dy - \int_{X_i}^0 \langle \Psi(y), (K_i^+ B (R_i^+)_c)(y) \rangle dy \right) \\
&+\left( \int_{-X_{i-1}}^0 \langle \Psi(y), G_i^- W_i^-(y) \rangle dy - \int_{X_i}^0 \langle \Psi(y), G_i^+ W_i^+(y) \rangle dy \right) \\
&+ \lambda\left( \int_{-X_{i-1}}^0 \langle \Psi(y), (K_i^- B W_i^-)(y) \rangle dy - \int_{X_i}^0 \langle \Psi(y), (K_i^+ B W_i^+)(y) \rangle dy \right) 
\end{align*}

At this point, we will take $i = 1$ to make things easier. The $i = 2$ case will be similar. 

\begin{align*}
\langle \Psi(0), &W_1^-(0) - W_1^+(0) \rangle \\
= &-\langle \psi(L), a_{1}^+\rangle\\
&-\lambda^2 d_1 \left( \int_{-\infty}^0 \langle \Psi(y), (K B Q_c)(y) \rangle dy + \int_0^\infty \langle \Psi(y), (K B Q_c)(y) \rangle dy \right) + \lambda^2 d_1 \int_L^\infty \langle \Psi(y), (K B Q_c)(y) \rangle dy \\
&-\lambda^2 d_1 \left( \int_{-\infty}^0 \langle \Psi(y), (K_1^- B (R_1^-)_c)(y) \rangle dy - \int_{L}^0 \langle \Psi(y), (K_1^+ B (R_1^+)_c)(y) \rangle dy \right) \\
&+\left( \int_{-\infty}^0 \langle \Psi(y), G_1^- W_1^-(y) \rangle dy - \int_{L}^0 \langle \Psi(y), G_1^+ W_1^+(y) \rangle dy \right) \\
&+ \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K_i^- B W_i^-)(y) \rangle dy - \int_{L}^0 \langle \Psi(y), (K_i^+ B W_i^+)(y) \rangle dy \right) \\
= &-\langle \psi(L), a_{1}^+\rangle + \lambda^2 d_1 \langle q, q_c \rangle_{L^2(\R)} + \lambda^2 d_1 \int_L^\infty \langle \Psi(y), (K B Q_c)(y) \rangle dy \\
&-\lambda^2 d_1 \left( \int_{-\infty}^0 \langle \Psi(y), (K_1^- B (R_1^-)_c)(y) \rangle dy - \int_{L}^0 \langle \Psi(y), (K_1^+ B (R_1^+)_c)(y) \rangle dy \right) \\
&+\left( \int_{-\infty}^0 \langle \Psi(y), G_1^- W_1^-(y) \rangle dy - \int_{L}^0 \langle \Psi(y), G_1^+ W_1^+(y) \rangle dy \right) \\
&+ \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K_1^- B W_1^-)(y) \rangle dy - \int_{L}^0 \langle \Psi(y), (K_1^+ B W_1^+)(y) \rangle dy \right) 
\end{align*}

where we used the Melnikov result from the single pulse case above. Now all we have to do is hope the rest of the terms are sufficiently small.\\

We consider the other terms in the jump one at a time. For now, we will base this off the estimates in Sandstede (1998). This uses those estimates exactly, which may or may not be the case since the setup here is a little different. If this ends up working, we will adapt the things I did for the bound on the integration operator in the exponentially weighted norm, which should have no effect other than modifying constants. In any case, it's worth seeing what we think this will get us and then if we like it, we can fill in the details of the estimates.

\begin{enumerate}

\item For the ``remainder'' of the $Q_c$ integral term, we have
\begin{align*}
\int_L^\infty \langle \Psi(y), (K B Q_c)(y) \rangle dy &= \int_L^\infty q'(y) \int_{-\infty}^y q_c(z) dz\\
&= - q(L) \int_{-\infty}^L q_c(z)dz - \int_{L}^\infty q(z) q_c(z) dz
\end{align*}
where we used integration by parts to get the second line. This is a constant which depends only on the original single pulse $q$, so we will call it $\gamma_1$. It should be small since $q(L)$ is small; the first integral is bounded by a constant; and the second integral is integrating an exponentially decaying tail.

\item For the term involving $a$, we plug in $A_4(\lambda)$ and use the estimate from that. We also use the estimate 
\[
|\Psi(x)| \leq C e^{-\alpha|x|}
\]

\begin{align*}
\langle \psi(L), a_1^+ \rangle &= \langle \psi(L), P_0^u D_1 d \rangle + \langle \psi(L), (A_4(\lambda)(d))^+\rangle\\
&=  \langle \psi(L), P_0^u D_1 d \rangle + \mathcal{O} \left( e^{-\alpha L}[ (e^{-\alpha L} + e^{-\eta L} )|\lambda|^2 + (e^{-2\alpha L} + |G| + |\lambda|)D_1|d|]\right)
\end{align*} 

\item For the terms involving $G_1^\pm$, we use (3.54) and (3.55) in Sandstede (1998) to get

\begin{align*}
&\left| \int_{-\infty}^0 \langle \Psi(y), G_1^- W_1^-(y) \rangle dy - \int_L^0 \langle \Psi(y), G_1^- W_1^-(y) \rangle dy\right| \\
&\:\:\:\:\:\:\:\:\leq C|G|((e^{\alpha L} + |G|)|D| + |\lambda|)|d|
\end{align*}

This should all wind up in the remainder term.

\item For the terms involving $K_1^\pm B W_1^\pm$, we did those estimates when we did the inversion in the exponentially weighted space. So we should have something similar to (3.52) in Sandstede (1998), i.e.

\[
\left| \int_{-\infty}^0 \langle \Psi(y), (K_1^- B W_1^-)(y) \rangle dy - \int_{L}^0 \langle \Psi(y), (K_1^+ B W_1^+)(y) \rangle dy \right| \leq C(|D| + \lambda|)|d|
\]

This should also all wind up in the remainder term.

\item For the terms involving $K_1^\pm B (R_1^\pm)_c$, we know that $q_c$ is differentiable in $c$ and that the derivative $q_c$ is exponentially decaying, thus this thing should also be small and exponentially decaying. I am not sure what the best bound for it is, but it should also wind up in the remainder term.

\end{enumerate}

Thus we should have something resembling

\[
\langle \Psi(0), W_1^-(0) - W_1^+(0) \rangle = 
d_1 \langle q, q_c \rangle_{L^2(\R)} + \langle \psi(L), Q'(-L) \rangle(d_2 - d_1) + d_1 \gamma_1 + (R(\lambda)d)_1
\]

The one for the second piece should look the same except for a few minor differences. When we split up the integral for $Q_C$, we are left this time with a ``remainder'' of 

\begin{align*}
\int_{-\infty}^{-L} \langle \Psi(y), (K B Q_c)(y) \rangle dy &= \int_{-\infty}^{-L} q'(y) \int_{-\infty}^y q_c(z) dz\\
&= q(-L) \int_{-\infty}^{-L} q_c(z)dz - \int_{-\infty}^{-L} q(z) q_c(z) dz
\end{align*}

This is again a constant, which we will call $\gamma_2$. Thus we should have

\[
\langle \Psi(0), W_2^-(0) - W_2^+(0) \rangle = 
d_2 \langle q, q_c \rangle_{L^2(\R)} + \langle \psi(-L), Q'(L) \rangle(d_2 - d_1) + d_2 \gamma_2 + (R(\lambda)d)_2
\]

Putting these together, we have to solve the following system for $(d_1, d_2)$.

\begin{align*}
d_1 \langle q, q_c \rangle_{L^2(\R)} + \langle \psi(L), Q'(-L) \rangle(d_2 - d_1) + d_1 \gamma_1 + (R(\lambda)d)_1 = 0\\
d_2 \langle q, q_c \rangle_{L^2(\R)} + \langle \psi(-L), Q'(L) \rangle(d_2 - d_1) + d_2 \gamma_2 + (R(\lambda)d)_2 = 0
\end{align*}

We want this to have a solution in $d = (d_1, d_2)$ which is not the trivial solution. Thus if we write this in matrix form, that is equivalent to the matrix not being invertible.\\

First let

\begin{align*}
a &= \langle \psi(L), Q'(-L) \rangle \\
\tilde{a} &=\langle \psi(-L), Q'(L) \rangle
\end{align*}

Define the matrices

\begin{align*}
A = \begin{pmatrix}
-a & a \\ -\tilde{a} & \tilde{a} 
\end{pmatrix} &&
\Gamma = \begin{pmatrix}
\gamma_1 &  \\  & \gamma_2 
\end{pmatrix}
\end{align*}

Then we can define

\[
S(\lambda) = A + MI + \Gamma + R(\lambda) 
\]

The system above is equivalent to $S(\lambda)d = 0$. Thus our condition to have a solution, i.e. the condition to have both jumps be zero and thus a match is 

\[
\det S(\lambda) = 0
\]

We can get a bound on the remainder $R(\lambda)$ similar to what was done in Sandstede (1998).\\

This has, admittedly, involved quite a bit of hand-waving in the estimates we used, i.e. we tossed things in the remainder term because we wanted to. If this looks like we are on the right track, we can nail those things down.

\end{document}