\documentclass[12pt]{article}
\usepackage[pdfborder={0 0 0.5 [3 2]}]{hyperref}%
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}%
\usepackage[shortalphabetic]{amsrefs}%
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{amssymb}                
\usepackage{amsmath}                
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage{float}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{mathtools}
\usepackage{cool}
\usepackage{url}
\usepackage{graphicx,epsfig}
\usepackage{makecell}
\usepackage{array}

\def\noi{\noindent}
\def\T{{\mathbb T}}
\def\R{{\mathbb R}}
\def\N{{\mathbb N}}
\def\C{{\mathbb C}}
\def\Z{{\mathbb Z}}
\def\P{{\mathbb P}}
\def\E{{\mathbb E}}
\def\Q{\mathbb{Q}}
\def\ind{{\mathbb I}}

\graphicspath{ {images17/} }

\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}

\begin{document}

\section*{Melnikov Integrals for Linearization of KdV5 about Single Pulse}

\subsection*{Preliminaries}

A single-pulse solution $q(x; c)$ to KdV5 is a homoclinic orbit connecting the equilibrium solution at 0 to itself. The single pulse solves the stationary KdV5 equation

\begin{equation}
u_{xxxxx} - u_{xxx} + c u_x - 2 u u_x = \partial_x(u_{xxxx} - u_{xx} + c u - u^2) = 0
\end{equation}

as well as the integrated equation

\begin{equation}\label{4thorder}
u_{xxxx} - u_{xx} + c u - u^2 = 0
\end{equation}

where we can take the constant of integration to be 0 since the pulse decays to 0 at $\pm \infty$. \\

The energy of the system is given by 

\begin{equation} \label{energy}
E(u) = -\int_{-\infty}^{\infty} \left( \frac{1}{2}u_{xx}^2 + \frac{1}{2}u_x^2 + \frac{1}{2}cu^2 - \frac{1}{3}u^3 \right) dx
\end{equation}

and the full KdV5 equation (time-dependent, nonstationary) can be written as $u_t = \partial_x E'(u)$. It can be shown that this quantity is conserved (in time).\\

For a stationary solution $u$, we have $u_t = 0$, which implies $\partial_x E'(u(x)) = 0$, i.e. $E'(u(x))$ is constant. Since our homoclinic orbit connects the equilibrium at 0 to itself, and since $E'(0) = 0$, we can take this constant to be 0, which is the equation \eqref{4thorder} above. \\

We also have a Hamiltonian $H$ for the equilibrium ODE, which is (Champneys, 1998)

\begin{equation}\label{Hamiltonian}
H(u, u', u'', u''') = u'u''' - \frac{1}{2}(u'^2) - \frac{1}{2}(u'')^2 + \frac{c}{2}u^2 - \frac{1}{3}u^3 
\end{equation}

We can show this is conserved, i.e. independent of $x$

\begin{align*}
\frac{\partial H}{\partial x} &= u'u'''' + u''u''' - u'u'' - u''u''' + c u u' - u^2 u' \\
&= u'( u'''' - u'' + cu - u^2 ) \\
&= 0
\end{align*}

where in the last line we substituted in the 4th order stationary equation $\eqref{4thorder}$.\\

Since we know the form of the Hamiltonian explicitly, we can compute its total derivative.

\begin{equation}
DH(u, u', u'', u''') = (cu - u^2, u''' - u', -u'', u') = (u(c - u), u''' - u', -u'', u') 
\end{equation}

We are interested in the derivative of the Hamiltonian at the peak of a single pulse solution. We make the following assumption about the existence of a single-pulse solution (although this might have been proved in the literature; we will look this up)

\begin{assumption}For a speed $c_0 > 0$, a single pulse solution $q_0(x) = q(x; c_0)$ exists to \eqref{4thorder}. This single pulse solution is a homoclinic orbit connecting the equilibrium at $u = 0$ to itself and is exponentially localized.
\end{assumption}

We want to evaluate $DH$ at $q_0(0)$. Note that this point is the peak (maximum) of the single pulse and the single pulse is an even function, so all odd derivatives are zero. Thus we have

\[
DH(q_0, q_0', q_0'', q_0''')\Big|_{x = 0} = \Big(q_0(0)(c - q_0(0)), 0, -q_0''(0), 0 \Big)
\]

We want to show that this is nonzero. We can do that by showing that either the first component or the third component cannot be 0. The first component can only be 0 if $q_0(0) = 0$ or $q_0(0) = c$. Since the maximum of the pulse occurs at $x = 0$, and the pulse connects the equilibrium at $u = 0$ to itself, we cannot have $q_0(0) = 0$, otherwise we would not have a pulse in the first place. If $q_0(0) = c$, then we can substitute this into the ODE \eqref{4thorder} to get

\begin{align*}
q_0''''(0) - q_0''(0) + c q_0(0) - q_0(0)^2 &= 0 \\
q_0''''(0) - q_0''(0) + c^2 - c^2 &= 0 \\
q_0''''(0) = q_0''(0)
\end{align*}

If $q_0''(0) = 0$, this implies $q_0''''(0)$ = 0. In other words, the constant solution $q_0(x) = c$ is the unique solution to \eqref{4thorder} with initial condition $(u(0), u'(0), u''(0), u'''(0)) = (c, 0, 0, 0)$. This is not an exponentially decaying pulse, so this cannot be the case. Thus we conclude that if $q_0(0) = c$, we must have $q_0''(0) \neq 0$. In either case, the total derivative $DH(q_0, q_0', q_0'', q_0''')$ cannot vanish at $x = 0$.\\

Before we continue, we will write $\eqref{4thorder}$ as a 4th order system. Note that we are following our usual notational convention, where capital letters represent vectors in the 4th order system, while small letters represent their scalar counterparts. As a 4th-order system, we have

\begin{equation}\label{nonlinearsystem}
U' = A(0; c) U + N(U)
\end{equation}

where $U = (u_1, u_2, u_3, u_4) = (u, u', u'', u''')$ and $N(U) = N(u_1, u_2, u_3, u_4) = (0, 0, 0, u_1^2)$. Note that we have separated the equation in to a linear and a nonlinear part, and that for the nonlinear part, $N(0) = DN(0) = 0$. \\

Let $Q(x; c) = (q(x; c) q'(x; c), q''(x; c), q'''(x; c))$. From here, we show that we can define a manifold in $H^{-1}(0)$ at $Q(0; c_0)$.

\begin{lemma}\label{manifoldinH0}
The zero level set of the Hamiltonian $H^{-1}(0)$ contains a 3-dimensinal manifold in a neighborhood of $Q(0; c_0)$.
\begin{proof}
By what we showed above, $DH(Q(0; c_0)) \neq 0$. For convenience, write $Q(x) = Q(x; c_0)$. In this case, either the first or the the third component of $DH(Q(0))$ is nonzero. Taking the first component to nonzero, using the IFT we can write $q_1$ locally as a graph over $(q_2, q_3, q_4)$. In other words, there exists a unique $C^1$ function $g: U \rightarrow \R$, where $U$ is an open neighborhood of $(q_2(0), q_3(0), q_4(0))$, such that $g(q_2(0), q_3(0), q_4(0)) = q_1(0)$ and $H(g(q_2, q_3, q_4), q_2, q_3, q_4 ) = 0$ on $U$. The three-dimensional surface:

\[
\{ (g(q_2, q_3, q_4), q_2, q_3, q_4) : (q_2, q_3, q_4) \in U \}
\]

is our desired manifold, which is contained in $H^{-1}(0)$. A similar formulation holds if the third component of $DH(Q(0))$ is nonzero.
\end{proof}
\end{lemma}

Next, we linearize \eqref{nonlinearsystem} about the equilibrium solution at 0. In doing so, we obtain the constant-coefficient matrix system $U' = A(0; c) U$, where

\[
A(0; c) = 
\begin{pmatrix}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
-c & 0 & 1 & 0 \\ 
\end{pmatrix}
\]

The eigenvalues of $A(0; c)$ are
\[
\nu = \pm \sqrt{ \frac{1 \pm \sqrt{1 - 4c} }{2}}
\]

For $c < 1/4$, all four eigenvalues are real (two positive and two negative), and for $c > 1/4$, the eigenvalues are two complex conjugate pairs (one pair with positive real part and one pair with negative real part). In both cases, we have a two-dimensional stable eigenspace and a two-dimensional unstable eigenspace. We designate the two stable eigenvalues by $\nu_1^s(c)$ and $\nu_2^s(c)$, where

\begin{align*}
\nu_1^s(c) &= \sqrt{ \frac{1 + \sqrt{1 - 4c} }{2}}\\
\nu_2^s(c) &= \sqrt{ \frac{1 - \sqrt{1 - 4c} }{2}}
\end{align*}

The corresponding eigenvectors are $v_1^s(c)$ and $v_2^s(c)$ (these can be written down exactly, but it's a mess). The unstable eigenvalues are $\nu_1^u(c)$ and $\nu_2^u(c)$, with corresponding eigenvectors $v_1^u(c)$ and $v_2^u(c)$. The stable and unstable eigenspaces are $E^s(c) = \text{span}\{ v_1^s(c), v_2^s(c) \}$ and $E^u(c) = \text{span}\{ v_1^u(c), v_2^u(c) \}$.\\

For what follows, we will be working in an exponentially weighted function space $X_\eta$, defined in the usual way by 

\[
X_\eta = \{ f \in C^0([0, \infty), \R^n) : \sup_{x \in [0, \infty)} |e^{\eta x} f(x)| < \infty 
\]

where the norm is given by

\[
||f||_\eta = \sup_{x \in [0, \infty)} |e^{\eta x} f(x)|
\]

This space is known to be a Banach space, and the weight $\eta > 0$ will be chosen later. Since we wish our functions to decay exponentially at $+\infty$, we want the weight to be positive.\\

We would like to show that we can take the derivative of our single pulse $q(x)$ with respect to the wave speed $c$, and that the derivative $q_c(x)$ is exponentially localized. For this to be the case, we will need the following assumption.

\begin{assumption}\label{transverseint}
For some $c_0 > 0$, the stable manifold $W^s(0; c_0)$ and the unstable manifold $W^u(0; c_0)$ for the equilibrium solution $u = 0$ intersect transversely in $H^{-1}(0)$ at a point $Q(0; c_0)$, where $H$ is the Hamiltonian for the ODE. Since $H^{-1}(0)$ is a manifold in a neighborhood of $Q(0; c_0)$, this assumption makes sense.
\end{assumption}

This assumption is reasonable for the following two reasons.
\begin{enumerate}
	\item Numerics show that a single pulse solution exists for a wide range of speeds $c$.
	\item We know that $\dim W^s(0) = \dim E^s = 2$ and $\dim W^u(0) = \dim E^u = 2$. Since we are in $\R^4$, $\dim H^{-1}(0) = 3$. Since the intersection $W^s(0) \cap W^u(0)$ must contain $q'(0; c_0)$, the derivative of the pulse, it must have at least dimension 1. Since $W^s(0) + W^u(0) \in \dim H^{-1}(0)$, we have
	\begin{align*}
	\dim( W^s(0) + W^u(0) ) &= \dim W^s(0) + \dim W^u(0) - \dim W^s(0) \cap W^u(0) \\
	&= 2 + 2 - 1 = 3 \\
	&\geq \dim H^{-1}(0)
	\end{align*}
	and $H^{-1}(0)$ is a 3-dimensional manifold near $Q(0; c_0)$.
\end{enumerate}

What does this assumption get us? Although the existence of a pulse solution does not require transverse intersection (any type of intersection is sufficient), transverse intersection makes it likely (although we still need to prove it) that the intersection of stable and unstable manifolds persists for $c$ near $c_0$. If the intersection were not transverse, we could have a solution for $c = c_0$, but the manifolds could separate when $c$ is perturbed away from $c_0$, in which case we would not have a solution for $c$ near $c_0$.\\

We will show that $q_c(x)$ exists and is exponentially localized in a series of lemmas.\\

\begin{lemma}\label{transverseint}
For $c$ near $c_0$, the transverse intersection of manifolds is preserved. Thus we still have a single-pulse (homoclinic orbit) for $c$ near $c_0$, i.e. for $c \in (c_0 - \delta, c_0 + \delta)$ for some $\delta > 0$. 
\begin{proof}
By Assumption \ref{transverseint}, $W^u(0; c_0)$ and $W^s(0; c_0)$ intersect transversely in $H^{-1}(0)$ at the point $q(0; c_0)$. For convenience, let $q_0 = q(0; c_0)$. By the prior lemma, the level set $H^{-1}(0)$ contains a 3-dimensional manifold $M(c_0)$ in a neighborhood of this intersection point. Since $W^u(0; c_0)$ and $W^s(0; c_0)$ intersect transversely in $H^{-1}(0)$ at this intersection point, this means that

\[
T_{q_0} W^u(0; c_0) + T_{q_0} W^s(0; c_0) = T_{q_0} M
\]

The intersection of the tangent spaces of the manifolds $W^u(0; c_0)$ and $W^s(0; c_0)$ is thus one-dimensional, and is the span of the single vector $w(c_0) = q'(0; c_0)$. This leaves each tangent space with another linearly independent vector. Let $v^u(c_0)$ and $v^s(c_0)$ be these vectors. Note that $v(c_0)$, $v^u(c_0)$, and $v^s(c_0)$ are linearly independent.
\\

I think the rough idea is as follows.
\begin{enumerate}
	\item We perturb $c_0$ a small amount to $c$.
	\item Since our system is smooth, the stable and unstable manifolds vary smoothy with $c$. 
	\item Perturbing the stable manifold perturbs $v^s(c_0)$ to $v^s(c)$ and $w(c_0)$ to $w^s(c)$. As long as the perturbation is small enough, these will remain linearly independent by continuity.
	\item Perturbing the unstable manifold perturbs $v^u(c_0)$ to $v^u(c)$ and $w(c_0)$ to $w^u(c)$. As long as the perturbation is small enough, these will remain linearly independent by continuity.
	\item As long as the perturbation is small enough, $v^s(c)$ and $v^u(c)$ will remain linearly independent, and $w^u(c)$ and $w^s(c)$ will remain linearly independent from them, again by continuity.
	\item All four of these vectors must be contained in a 3-dimensional space, sice $H^{-1}(0)$ is 3-dimensional, which forces $w^u(c)$ and $w^s(c)$ to be linearly dependent.
	\item This means the transverse intersection is preserved.
\end{enumerate} 

Of course, this is not at all precise. So let's try to fix that.\\

The (parameter-dependent) stable manifold theorem says that for \eqref{nonlinearsystem} we can find constants $\rho > 0$, $M \geq 1$, and $\delta > 0$ and a smooth map (since \eqref{nonlinearsystem} is smooth) 
\[
h: \{ u_0 \in E^s(c_0) : |u_0| \leq \rho / 2M \} \times (c_0 - \delta, c_0 + \delta) \rightarrow E^u(c_0) 
\]
such that the local stable manifold $W^s_{loc}(0; c)$ is the graph of $h$ (with domain where $h$ is defined). We can do the same thing with the local unstable manifold. The key here is that this depends smootly on $c$.\\

THIS IS ALL A LITTLE SKETCHY. Let $\Phi(x; c)$ be the solution operator for \eqref{nonlinearsystem}, which depends smoothly on $c$. We can find $\tilde{x}$ such that $\tilde{F} q_0 = \Phi(\tilde{x}, c_0) q_0 \in W^s_{loc}(c_0)$. Thus $\Phi(\tilde{x}, c_0)$ is a smooth map from $M$ to $W^s_{loc}(c_0)$, so the differential $D\tilde{F}$ should be a linear map between the two tangent spaces $T_{q_0}M$ and $T_{\tilde{F} q_0} W^s_{loc}(c_0)$. We should have another smooth map $\tilde{G}$ between $W^s_{loc}(c_0)$ and $W^s_{loc}(c)$ which should be something like $\tilde{G}(x) = h( h^{-1}(x; c_0), c)$. So then $D\tilde{G}$ should be a linear map between the relevant tangent spaces. Finally we have another smooth map which sends us backwards on the stable manifold, something like $\tilde{H} = \Phi^{-1}(\tilde{y},c)$, where I don't think $\tilde{y} = \tilde{x}$ necessarily but can be chosen so that we get back to $x = 0$. So the smooth map we want should be the composition of these three maps.

\end{proof}
\end{lemma}

\begin{lemma}\label{qcexists}
$q(x; c)$ is differentiable in $c$ for all $c$ near $c_0$ and for all $x$. 
\begin{proof}
Let $\Phi(x; c)$ be the solution operator for \eqref{nonlinearsystem}, where the initial condition is given at $x = 0$. Taking the initial condition to be $q(0; c)$, by the property of the solution operator, for $c$ near $c_0$, $q(x; c) = \Phi(x; c)q(0; c)$.\\

By the existence and uniqueness theorem, $\Phi(x; c)$ is smooth in $c$ since the the RHS of \eqref{nonlinearsystem} is $C^\infty$ in $c$ (since $A(0; c)$ is a linear function of $c$ and $N(u)$ does not involve $c$ at all). By Lemma 1, $q(0; c)$ is smooth in $c$.
\end{proof}
\end{lemma}

\begin{lemma}\label{derivatives}
For $c_0 > 0$, $c_0 \neq 1/4$, the functions $e^{A(c)x}P^s(c)$ and $e^{A(c)x}P^u(c)$ are differentiable with respect to the speed $c$ at $c = c_0$. $A(c) = A(0; c)$, $e^{A(c)x}$ is the fundamental matrix solution to the linear problem $U' = A(c) U$, and $P^s(c)$ and $P^u(c)$ are the stable and unstable projections onto the stable and unstable eigenspaces of $A(c)$. 
\begin{proof}
We will only show this for $e^{A(c)x}P^s$, since the other is similar. We will find the derivatives of the two functions separately and then use the product rule, which is valid for Frechet derivatives. Since $e^{A(c)x}$ and $P^s(c)$ are both matrices, this should work fine.\\

For the matrix exponential, we can write it as:
\[
e^{A(c)x} = e^{(A(0) + Bc)x} = e^{A(0)x}e^{Bcx}
\]
where 
\[
B = \begin{pmatrix}0&0&0&0\\0&0&0&0\\0&0&0&0\\-1&0&0&0\end{pmatrix}
\]
Thus the derivative with respect to $c$ is
\[
\frac{\partial}{\partial c} e^{A(c)x} = e^{A(0)x}e^{Bcx}Bx = e^{A(c)x} Bx
\]
Thus $e^{A(c)x}$ is differentiable for all values of $c$. I am not sure whether this shows the Frechet derivative exists in the weighted space $X_\eta$ ($\eta$ to be chosen), but we can show that directly.

\begin{align*}
\lim_{|h| \rightarrow 0} &\left| \frac{e^{\eta x}}{h} \left( e^{A(c+h)x} - e^{A(c)x} - h e^{A(c)x} Bx  \right) \right|  \\
&= e^{\eta x} e^{A(0)x}\lim_{|h| \rightarrow 0} \left| \frac{1}{h} \left( e^{B(c+h)x} - e^{Bcx} - h e^{Bcx} Bx  \right) \right| \\
&= e^{\eta x} e^{A(0)x}e^{Bcx}\lim_{|h| \rightarrow 0} \left| \frac{1}{h} \left( e^{Bhx} - 1 - h Bx  \right) \right| \\ 
&= e^{\eta x} e^{A(c)x} \lim_{|h| \rightarrow 0} \left| \frac{1}{h} \left( e^{Bhx} - 1 - h Bx  \right) \right| 
\end{align*}

If we choose $\eta$ such that $0 < \eta < \text{Re} \lambda$ for all stable eigenvalues $\lambda$ of $A(c)$, $e^{\eta x} e^{A(c)x}$ is uniformly bounded in $x$. (This will be the case when we choose $\eta$ below.) Since the limit on the RHS is bounded, we have shown that $e^{A(c)x} Bx$ is the Frechet derivative in the weighted space $X_\eta$.\\

The projection is a little trickier. Since it does not depend on $x$, we don't have to worry about Frechet derivatives or exponentially weighted spaces. First, write the stable projecion $P^s(c)$ as

\[
P^s(c) = P^1(c) + P^2(c)
\]

where $P^1(c)$ + $P^2(c)$ are the projections onto the eigenspaces spanned $v_1^s(c)$ and $v_2^s(c)$, respectively. We are assuming $c \neq 1/4$, so these vectors are linearly independent since the corresponding eigenvalues are distinct. It suffices to show differentiability at $c_0$ for $P^1(c)$ since $P^2(c)$ is similar. Following Kato (1976), we will look at small perturbations of the operator $A(c_0)$:

\[
T(h) = A(c_0) + h B
\]

where $h \in R$ is small. This only perturbs the speed, which is what we want. The unperturbed operator is $T(0) = A(c_0)$. Let $\lambda = \nu^1(c_0)$, and let $\Gamma$ be a positively-oriented circle enclosing no other eigenvalues of $A(c_0)$. Since $c_0 \neq 1/4$, the eigenvalues of $A(c_0)$ are distinct, so we can always so this. For sufficiently small $h$, by (1.16) on p. 67 in Kato (1976), the eigenprojection onto $v_1^s(c_0 + h)$ is given by 

\[
P(h) = -\frac{1}{2 \pi i} \int_\Gamma R(\zeta, h) d \zeta
\]

where $R(\zeta, h) = (T(h) - \zeta)^{-1}$ is the resolvent operator and exists on $\Gamma$ or sufficiently small $h$. Since $T(h)$ is differentiable at $h = 0$ ($T'(h) = B$), by Theorem 5.4 on p. 111 of Kato (1976), $P(h)$ is differentiable at $h = 0$, and the derivative is given by
\[
P'(0) = -P T'(0) S - S T'(0) P = -P B S - S B P
\]
where $P = P^1(c_0)$ is the unperturbed projection and $S$ is the reduced resolvent of $T$ for $\lambda$ (defined on p. 40 of Kato. I think to get this you take the Laurent series for the resolvent and ditch the terms with negative powers. Since this is just some matrix, I think we are all set).\\

By construction, the derivative of $P^1(c)$ with respect to $c$ at $c = c_0$ is equal to $P'(0)$, thus $(P^1)'(c_0)$ exists. Similarly,$(P^2)'(c_0)$ exists, and so $(P^s)'(c_0)$ exists, with
\[
(P^s)'(c_0) = (P^1)'(c_0) + (P^2)'(c_0)
\]

By the product rule,

\begin{align*}
\frac{\partial}{\partial c} e^{A(c)x}P^s(c)\Big|_{c = c_0} &= e^{A(c_0)x} B x P^s(c_0) + e^{A(c_0)x} (P^s)'(c_0) \\
&= e^{A(c_0)x} ( BxP^s(c_0) + (P^s)'(c_0) )
\end{align*}

\end{proof}
\end{lemma}

\begin{lemma}\label{qc}
For the stationary, single-pulse solution $q(x; c)$ to the 5th order KdV equation in a frame moving with velocity $c$, the derivative $q_c(x)$ of the pulse with respect to $c$ is exponentially localized, thus $q_c(x) \in L^2(\R)$.
\begin{proof}
$q_c(x)$ exists for $c$ near $c_0$ by Lemma \ref{qcexists}, so we need to show that it is exponentially localized.\\

We proceed as in the proof of the stable manifold theorem (parameter-dependent version). We use an exponentially weighted function space $X_\eta$, defined above, and the exponential weight $\eta > 0$ will be chosen later.\\

Next we write \eqref{nonlinearsystem} in integrated form. For convenience, let $A(c) = A(0; c)$, so that the matrix exponential $e^{A(c)x}$ is the fundamental matrix solution to the linear problem $U' = A(c) U$. Let $P^s(c)$ and $P^u(c)$ be the stable and unstable projections onto the stable and unstable eigenspaces of $A(c)$. Then as long as $|U(x)|$ is uniformly bounded for $x \geq 0$, say $|U(x)| \leq \rho$ for $x \geq 0$, then $U(x)$ is given by

\[
U(x) = e^{A(c)x} P^s(c) a + \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy + \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy
\]

where $a$ is the initial condition. Note that $U$ will depend on $c$, but that (our specific case), $N$ does not.\\

First we define the spaces

\begin{align*}
B_1 &= (c_0 - \delta, c_0 + \delta) \\
B_2 &= \{ a \in \R^n : |P^s(c) a| \leq \rho/2M \text{ for all } c \in B_1\} \\
D &= \{ u \in X_\eta : ||u||_\eta \leq \rho \}
\end{align*}

where $\delta$ is the constant from Lemma \ref{transverseint}. Next define
\[
L_\eta(\rho) = \max \{ || DN(u) || : ||u||_\eta \leq \rho \}
\]

Note that since we are on the domain $[0, \infty)$ and $\eta > 0$, $|u(x)| \leq |u(x)e^{\eta x}|$ and so $||u|| \leq ||u||_\eta$. Since $N \in C^1$ and $||u|| \leq \rho$, $L(\rho)$ is well-defined and finite. (In this case, we know exactly what $N$ is. The Jacobian matrix $DN$ consists entirely of zeros except for one entry which is $2 u_1$, so here we have $L(\rho) \leq 2 \rho$.) From this, we can get a bound on $|N(U(x))|$ for $U$ with $||U||_\eta \leq \rho$. Let $U \in D$ and fix $x \geq 0. $Since $N \in C^1$ and $N(0) = 0$,

\begin{align*}
|N(U(x))| &= |N(U(x)) - N(0)| \\
&= \left| \int_0^1 DN(t U(x)) t U(x) du \right| \\
&\leq  \int_0^1 ||DN(tU(x))|| \: |U(x)| t dt \\
&\leq L(\rho) |U(x)|
\end{align*}

Multiplying both sides by $e^{\eta x}$ gives us the bound (pointwise in $x$, for $x \geq 0$)

\[
|N(U(x)) e^{\eta x}| \leq L(\rho)|U(x) e^{\eta x}|
\]

taking the supremum in $x$ gives us the bound

\[
||N(U)||_\eta \leq L(\rho) ||U||_\eta \leq L(\rho) \rho
\]

where everything is finite since we are assuming $U \in D$.\\

Note that since $DN(0) = 0$ and $N \in C^1$, $DN(u) \rightarrow 0$ as $u \rightarrow 0$, thus by the definition of $L(\rho)$, $L(\rho) \rightarrow 0$ as $\rho \rightarrow 0$. We also have for $U, V$ with $||U||_\eta, ||V||_\eta \leq \rho$

\[
||N(U) - N(V)||_\eta \leq L(\rho)(||U||_\eta - ||V||_\eta) 
\]
which is a consequence of the mean value inequality.\\

Since for $c > 0$ the matrix $A(c)$ is hyperbolic and since the eigenvalues of $A(c)$ are continuous functions of $c$, we can find $\alpha^s, \alpha^u > 0$ such that for all $c \in B_1$, all eigenvalues of $A(c)$ lie outside the open interval $(-\alpha^s, \alpha^u)$. For $c \in B$, we have the estimates

\begin{align*}
||e^{A(c)x}P^s(c)|| &\leq Me^{-\alpha^s x} && x \geq 0\\
||e^{A(c)x}P^u(c)|| &\leq Me^{\alpha^u x} && x \leq 0
\end{align*}

Now we define the map $F: D \times B_1 \times B_2 \rightarrow X_\eta$ by

\begin{equation}\label{F}
[F(U, c, a)](x) = e^{A(c)x} P^s(c) a + \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy + \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy
\end{equation}

First we show that $F$ is well-defined, i.e. it actually maps into $X_\eta$. We will look at each term on the RHS separately. Recall that since the domain of $F$ is $D$, we always have $||U||_\eta \leq \rho$.

\begin{align*}
|e^{\eta x} e^{A(c)x } P^s(c) a | &\leq M e^{\eta x} e^{-\alpha^s x} | P^s(c) a |\\
&= M e^{(\eta - \alpha^s)x} | P^s(c) a|
\end{align*}
For this to be uniformly bounded in $x$, we require $\eta \leq \alpha^s$, in which case we have $||e^{A(c)x}a ||_\eta \leq M| P^s(c) a |$.

\begin{align*}
\left| e^{\eta x} \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy \right| &= \left| \int_\infty^x e^{\eta x} e^{A(c)(x - y)}P^u(c) N(U(y))dy \right|\\
&\leq \int_x^\infty M e^{\eta x}e^{\alpha^u(x -y)}|N(U(y))|dy \\
&= M \int_x^\infty e^{\eta (x - y)}e^{\alpha^u(x -y)}| e^{\eta y} N(U(y))|dy \\
&\leq M \int_x^\infty e^{(\eta+\alpha^u)(x - y)} || N(U)||_\eta dy \\
&\leq M L(\rho) ||U||_\eta \int_x^\infty e^{(\eta+\alpha^u)(x - y)} dy \\
&= M L(\rho) ||U||_\eta \frac{1}{\alpha^u + \eta}
\end{align*}

Since $\eta$ and $\alpha^u$ are both positive, this imposes no additional restrictions on $\eta$.

\begin{align*}
\left| e^{\eta x} \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y)) \right| &= \left| \int_0^x e^{\eta x} e^{A(c)(x - y)}P^s(c) N(U(y)) dy \right|\\
&\leq \int_0^x M e^{\eta x}e^{-\alpha^s(x -y)}|N(U(y))|dy \\
&= M \int_0^x e^{\eta (x - y)}e^{-\alpha^s(x -y)}| e^{\eta y} N(U(y))|dy \\
&\leq M \int_0^x e^{(\eta-\alpha^s)(x - y)} || N(U)||_\eta dy \\
&\leq M L(\rho) ||U||_\eta \int_0^x e^{(\eta-\alpha^s)(x - y)} dy \\
&= M L(\rho) ||U||_\eta \frac{1 - e^{(\eta-\alpha^s)x} }{\alpha^s - \eta}
\end{align*}

Since $x \geq 0$, as long as $\eta < \alpha^s$ (we have this condition from above), $0 < e^{(\eta-\alpha^s)x} < 1$, thus we have

\[
\left| e^{\eta x} \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y)) \right| \leq M L(\rho) ||U||_\eta \frac{1}{\alpha^s - \eta}
\]

Putting all of this together and taking the supremum over $x \in [0, \infty)$, we have for $||U||_\eta \leq \rho$

\begin{equation}
||F(U, c, a)](x)||_\eta \leq M |a| + M L(\rho) \left( \frac{1}{\alpha^u+\eta}+\frac{1}{\alpha^s-\eta} \right) ||U||_\eta
\end{equation}

Since everything on the RHS is finite, we have shown that the codomain of $F$ is in fact $X_\eta$, so $F$ is well-defined. Since $a \in B_2$, $|P^s(c) a| \leq \rho/2M$. Since $L(\rho) \rightarrow 0$ as $\rho \rightarrow 0$, we can choose $\rho$ sufficiently small so that $L(\rho) < \frac{1}{2M} \left( \frac{1}{\eta+\alpha^u}+\frac{1}{\eta-\alpha^s} \right)^{-1}$. Having done this, and using the fact that $||U||_\eta \leq \rho$, we obtain the bound $||F(U, a, c)](x)||_\eta \leq \rho$. Thus for this choice of $\rho$ we actually have $F: D \times B_2 \times B_1 \rightarrow D$, which is what we want.\\

Now we need to show that $F: D \times B_2 \times B_1 \rightarrow D$ is a uniform contraction. For $U, V \in D$, following what we did above, 

\begin{align*}
| &e^{\eta x} ( F(U, c, a) - F(V, c, a) ) | \\
&= \left| \int_\infty^x e^{\eta x} e^{A(c)(x - y)}P^u(c) [N(U(y)) - N(V(y))]dy + \int_0^x e^{\eta x} e^{A(c)(x - y)}P^s(c)[N(U(y)- N(V(y))]dy \right| \\
&\leq M L(\rho) \left( \int_x^\infty e^{(\eta + \alpha^u)(x-y)}||U - V||_\eta dy + \int_0^x e^{(\eta - \alpha^s)(x-y)}||U - V||_\eta dy \right) \\
&= ML(\rho)||U - V||_\eta \left( \frac{1}{\eta + \alpha^u}+\frac{1}{\eta-\alpha^s} \right) \\
&\leq \frac{1}{2} ||U - V||_\eta 
\end{align*}

where in the last line we used our choice of $\rho$ from above. Since this is independent of $c$ and $a$, $F$ is a uniform contraction. By the uniform contraction mapping principle, there is a unique map $G: B_1 \times B_2 \rightarrow D$ such that $F(G(c, a), c, a) = G(c, a)$ for all $c \in B_1$ and $a \in B_2$. In other words, $G$ maps the pair of parameters $(c, a)$ to the unique fixed point of $F$ with those parameters. By the uniform contraction mapping principle, the maps $G$ and $F$ have the same smoothness in the parameters $c$ and $a$.\\

What does this get us? We note the following

\begin{enumerate}
	\item For each speed $c \in B_1$ and initial condition $a \in B_2$, $u(x) = G(c, a)(x)$ is the unique solution on $[0, \infty)$ to KdV5 with speed $c$ and initial condition $a$.

	\item $G(c, a)(x) \in D$, which implies $\sup_{x \in [0, \infty)} |e^{\eta x} G(c, a)(x)| \leq \rho$. In other words, for all $c \in B_1$, $a \in B_2$, and $x \geq 0$
	\begin{equation}
		|G(c, a)(x)| \leq \rho e^{-\eta x}
	\end{equation}
	Thus for these $a$ and $c$, the unique solution $G(c, a)(x)$ is uniformly exponentially bounded on $[0, \infty)$.

	\item $G(c, a)$ is as smooth as $F$ in $c$ and $a$.
\end{enumerate}

The key is this last property (smoothness). We would like the map $G$ to be differentiable in $c$. Let's first show that is indeed what we want. Then we will show that $F$ is smooth in $c$, implying $G$ is as well.\\

Recall that for $c = c_0$, a homoclinic orbit $q(x; c_0)$ exists. By the stable manifold theorem, since $q(x; c_0)$ is contained in the stable manifold $W^s(0; c_0)$, we can find $\tilde{x} \geq 0$ such that $q(x; c_0) \leq \rho$ for all $x \geq \tilde{x}$. Let $a_0 = q(\tilde{x}; c_0)$ be our initial condition. Then by uniqueness of the map $G$, we have 

\[
G(c_0, a_0)(x) = q(\tilde{x} + x; c_0)
\]

Taking the derivative with respect to $c$,

\[
G_c(c_0, a_0)(x) = q_c(\tilde{x} + x; c_0)
\]

For fixed $a_0$, $G$ maps $B_1 \rightarrow X_\eta$. The Frechet derivative $G_c$ is a bounded linear map from the tangent space of $B_1$ (which is $\R$, since $B_1 \subset \R$) to the tangent space of $X_\eta$ (which is isomorphic to $X_\eta$ itself since $X_\eta$ is a Banach space). We thus have for a perturbation $h \in R$

\[
G_c(c_0, a_0)h = q_c(\tilde{x} + \cdot \: ; c_0) h
\]

Thus since $G_c(c_0, a_0)$ is a bounded linear operator, $q_c(\tilde{x} + \cdot \: ; c_0) \in X_\eta$, and so the function $q_c(\tilde{x} + x ; c_0)$ decays exponentially in $x$. Since all we care about is asymptotic behavior, we conclude that $q_c(x ; c_0)$ decays exponentially in $x$.\\

All we need to do to complete the proof is show that the map $F$ is smooth in $c$. For convenience, we restate the definition of the map $F$.\\

\begin{equation}
[F(U, c, a)](x) = e^{A(c)x} P^s(c) a + \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy + \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy
\end{equation}

From Lemma \ref{derivatives}, $e^{A(c)x} P^s(c)$ is differentiable at $c = c_0$, thus we are all set with the first term on the RHS. For the second two terms, $N(U(y))$ does not depend on $c$, so we have the same two terms $e^{A(c)x} P^s(c)$ and $e^{A(c)x} P^u(c)$ inside the integral, both of which are differentiable at $c = c_0$ by Lemma \ref{derivatives}. Thus all we have to do is make sure we can pass the derivative inside the integral sign. Since these are Frechet derivatives in a weighted Banach space, I'm not exactly sure how this works, but my guess is that since both integrands are bounded (when multiplied by the exponential weight) by an integrable function (as we showed above when we found a bound for $||F||^\eta$), we have an analogue of the DCT and can do this.\\

Thus we have (I think) shown that $F$ is differerentiable in $c$.

We can similarly show (by, say, replacing $x$ with $-x$), that $q_c(x)$ at $c = c_0$ decays exponentially as $x \rightarrow -\infty$. From this, we will have the additional condition that $\eta < \alpha^u$. Thus as long as $0 < \eta < \alpha^s, \alpha^u$, we are all set.

\end{proof}
\end{lemma}

We will also need the following assumptions. Numerics suggest that these assumptions are reasonable.

\begin{assumption}\label{1dkernel}
The kernels of $H$, $\partial_x H$, and $H \partial_x$ are all one-dimensional. Thus we have
\begin{align*}
\ker H &= \text{span}\{ q' \} \\
\ker \partial_x H &= \text{span}\{ q' \} \\
\ker H \partial_x &= \text{span}\{ q \}
\end{align*}
Note that these only apply on the unbounded domain. For a bounded domain, for example, $\ker H \partial_x$ also contains the constant functions.
\end{assumption}

\begin{assumption}\label{qcIP}
$\langle q, q_c\rangle_{L^2(\R)} \neq 0$
\end{assumption}
Note that by Cauchy-Schwarz, $\langle q, q_c\rangle_{L^2(\R)} \leq ||q||_{L^2(\R)} ||q_c|_{L^2(\R)}$. Since the single pulse $q$ is exponentially localized, $q \in L^2(\R)$. By Lemma \ref{qc}, $q_c \in L^2(\R)$. Thus this inner product is well-defined.

\subsection*{First Construction}

Here we present one construction of the eigenfunction corresponding to an eigenvalue near 0 for the linearization of KdV5 about the single pulse. This corresponds to Sandstede (1998). For the single pulse, we only have two pieces which are connected by a single join at $x = 0$. We write the piecewise eigenfunction $V^\pm$ as a perturbation of the derivative $Q'$ of the single pulse, since we know that $Q'$ is an eigenfunction with eigenvalue 0. 

\begin{align*}
V^\pm(x) = Q'(x) + W^\pm(x)
\end{align*}

If we plug this into the integrated eigenvalue problem (defined in \texttt{KdV17}), we obtain the following system of equations, which are analagous to (3.7) in Sandstede (1998).

\begin{align*}
W^\pm(x)' &= A(q(x)) W^\pm(x) + \lambda B Q(x) + \lambda K^\pm B W^\pm(x) \\
W^\pm(x) &\in \C \psi(0) \oplus Y^+ \oplus Y^- \\
W^+(0) - W^-(0) &\in \C \psi(0) 
\end{align*}

We will use the third equation together with the jump distance to conclude that $W^-(0) = W^+(0)$, which is the matching condition we want.\\

Analagous to (3.14) in Sandstede (1998), we can write the fixed point equations for $W^\pm$ as

\begin{align*}
W^-(x) = \Phi^u_-(x, 0)b^- &+ \int_0^x \Phi^u_-(x, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] dy \\
&+ \int_{-\infty}^x \Phi^s_-(x, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] dy \\
W^+(x) = \Phi^s_+(x, 0)b^+ &+ \int_0^x \Phi^s_+(x, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] dy \\
&+ \int_{\infty}^x \Phi^u_+(x, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] dy
\end{align*}

In particular, note that compared to the double pulse (see \textrm{KdV17}), the boundary term is gone, and there is no longer a match at $\pm L$. To solve this, we use the equivalent of Lemmas 3.3 - 3.5 in Sandstede (1998).

\begin{lemma}\label{inv1}
There exist operators $B_1(\lambda)$ and $W_3(\lambda)$ such that 
\[
(b, W) = (B_1(\lambda), W_3(\lambda))
\]
Any bounded solution is given by this, and these operators are analytic in $\lambda$. We have the estimates
\begin{align*}
|B_1(\lambda)| &\leq C|\lambda| \\
||W_3(\lambda)||_\alpha &\leq C|\lambda|
\end{align*}
where $\alpha$ is chosen so that $0 < \alpha < \alpha_s, \alpha_u$
\begin{proof}
We follow what we did in \texttt{KdV17} as well as Lemmas 3.3 - 3.5 in Sandstede (1998), but we make the necessary simplifications for the single pulse. As in \texttt{KdV17}, we work in the exponentially weighted spaces $C^0_\alpha(-\infty, 0]$ and $C^0_\alpha[0, \infty)$, where $\alpha$ is chosen as above. These spaces and their norms are defined in \texttt{KdV17}. We define the linear operators $(L_1(\lambda)W^\pm)(x)$ from the exponentially weighted spaces to themselves by

\begin{align*}
(L_1(\lambda)W^-)(x) &= \lambda \left( \int_0^x (K_i^- B W^-)(y) dy + \int_{-\infty}^x (K_i^-B W^-)(y) dy \right) \\
(L_1(\lambda)W^+)(x) &= \lambda \left( \int_0^x (K_i^+ B W^+)(y) dy + \int_{\infty}^x (K_i^+ B W^+)(y) dy \right)
\end{align*}
We showed in \texttt{KdV17} that this operator is well-defined, i.e. it actually maps the exponentially weighted spaces to themselves, and that $||L_1(\lambda)W||_\alpha \leq C||W||_\alpha$ for our choice of $\alpha$.\\

We also define the linear operators $(L_2(\lambda)b)(x)$ from $\R^n$ to our exponentially weighted space by

\begin{align*}
(L_2(\lambda))(b^-) &= \Phi^u_-(x, 0)b^- + \lambda \left( \int_0^x \Phi^u_-(x, y) B Q(y)dy + \int_{-\infty}^x \Phi^s_-(x, y)B Q(y) dy \right)\\
(L_2(\lambda))(b^+) &= \Phi^s_+(x, 0)b^+ + \lambda \left( \int_0^x \Phi^s_+(x, y) B Q(y) dy + \int_{\infty}^x \Phi^u_+(x, y) B Q(y) dy \right)
\end{align*}

Since this is a simplified version of the operator in Lemma 3.3 of Sandstede (1998), the estimate there applies in this case, and we have

\[
||L_2(\lambda)(b)|| \leq C|b|
\]

Writing the fixed point problem as $(I - L_1(\lambda))W = L_2(\lambda)(b)$, we can invert the operator ($(I - L_1(\lambda))$ (I HAVE NEVER UNDERSTOOD WHAT YOU USED TO DO THIS, BUT IT SHOULD FOLLOW EXACTLY AS IN THE PAPER) to get
\[
W = (I - L_1(\lambda))^{-1} L_2(\lambda)(b) := W_1(\lambda)(b)
\]
with 
\[
||W_1(\lambda)(b)||_\alpha \leq C|b|
\]

Since we only have the join at $x = 0$ (i.e. we do not have the $d_i$), we do not need an equivalent to Lemma 3.4. Since the only thing we have changed is the function space (nonweighted to exponentially weighted), Lemma 3.5 should apply unchanged. Since there is no $a$ or $d$, $W_3 = W_1$. The only thing we need to be careful of is that $B_1(\lambda)$ is a function of $d$, which we do not have here. We should be able to take $d = 1$ (since it always takes that value here) and be all set. Thus applying Lemma 3.5 gives us

\begin{align*}
(b, W) = (B_1(\lambda), W_3(\lambda))
|B_1(\lambda)| &\leq C|\lambda| \\
||W_3(\lambda)||_\alpha &\leq C|\lambda|
\end{align*}

which is the result we want.
\end{proof}
\end{lemma}

Having done this, it only remains to estimate the single jump at $x = 0$.
\[
\xi = \langle \Psi(0), W^+(0) - W^-(0) \rangle
\]

Plugging in what we have, we get

\begin{align*}
\langle\Psi(0), W^+(0) &- W^-(0)\rangle = \langle \Psi(0), \Phi^u_-(0, 0)b^- + \int_{-\infty}^0 \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] dy  \\
&- \Phi^s_+(0, 0)b^+ - \int_\infty^0 \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] dy \rangle\\
&= \langle \Psi(0), b^- - b^+\rangle + \int_{-\infty}^0 \langle \Psi(0), \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] \rangle dy  \\
&- \int_\infty^0 \langle \Psi(0), \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] \rangle dy  \\
&= \int_{-\infty}^0 \langle \Psi(y), \lambda (K^- B W^-)(y) + \lambda B Q(y) \rangle dy \\
&- \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) + \lambda B Q(y)  \rangle dy \\
&= \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) > dy + \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) \rangle dy \right) \\
&+ \lambda \int_{-\infty}^\infty \langle\Psi(y), BQ(y) \rangle dy
\end{align*}

I am pretty sure that we matched things so that $b^+ = b^-$ (I CANNOT TELL IN THE PAPER WHERE THIS IS DONE, BUT THIS APPEARS TO BE USED IN (3.48) IN SANDSTEDE (1998)), so this term cancels.\\

The final integral on the RHS is the Melnikov integral, which we claim is 0. To see this, we first note that for the linearization of the fourth-order equation about the single pulse $q$, i.e. $H = \partial_x^4 - \partial_x^2 + c - 2q$, $Hq_c = -q$. (To show this, plug it in and use the fact that $q$ solves the orginal nonlinear 4th order equation.) Using this and the definition of $B$ (see \texttt{KdV17}) we have

\begin{align*}
 \int_{-\infty}^\infty \langle \Psi(y), BQ(y) \rangle dy &=  \int_{-\infty}^\infty \psi(y) q(y) dy \\
&= \langle \psi, q \rangle_{L^2(\R)} = -\langle \psi, H q_c \rangle_{L^2(\R)} \\
&= -\langle H^* \psi, q_c\rangle_{L^2(\R)} = -\langle H \psi, q_c \rangle_{L^2(\R)}
\end{align*}

The final inner product is well-defined by Cauchy-Schwarz since $\langle H \psi, q_c \rangle_{L^2(\R)} \leq ||H \psi||_{L^2(\R)} |q_c|_{L^2(\R)}$ and $q_c \in L^2(\R)$ by Lemma \ref{qc}. (We will show below that $H \psi$ = 0). The inner product $\langle \psi, q \rangle_{L^2(\R)}$ is similarly well-defined since $q$ is exponentially localized, as is $\psi$. (We sill show below that $\psi \in \ker H$, and since we are assuming that $\ker H$ is one-dimensional, $\psi$ is a multiple of $q'$, which is exponentially localized).\\

All that remains is show that $\psi \in \ker H$. Recall that the matrix $B$ places the 1st component of a vector into the 4th component and zeroes out all the other components. Since $BQ(y)$ places the pulse $q(y)$ into the 4th component, $\psi$ is the 4th component of $\Psi$. $\Psi$ is the solution to the adjoint variational equation $U' = -A(q(x))^*U$, where 

\[ 
A(q(x))^* = 
 \begin{pmatrix}0 & 0 & 0 & 2q_2(x) - c \\ 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 1 \\ 0 & 0 & 1 & 0\end{pmatrix}
\]

This can be broken down into the four equations

\begin{align*}
\Psi_1' &= -(2q(x) - c) \Psi_4 \\
\Psi_2' &= -\Psi_1 \\
\Psi_3' &= -\Psi_2 - \Psi_4 \\
\Psi_4' &= -\Psi_3
\end{align*}

The scalar function $\psi$ we want is the fourth component $\Psi_4$. We will show that $H \Psi_4 = 0$, i.e. $\Psi_4 \in \ker H$.

\begin{align*}
H \Psi_4 &= \Psi''''_4 - \Psi''_4 + (c - 2q(x))\Psi_4 \\
&= -\Psi'''_3 + \Psi_3' + \Psi_1' \\
&= \Psi''_2 + \Psi''_4 + \Psi_3' + \Psi_1' \\
&= -\Psi_1' - \Psi_3' + \Psi_3' + \Psi_1'\\
&= 0
\end{align*}

We have shown that $\Psi' = -A(q(x))^*\Psi$ is equivalent to $\Psi_4 \in \ker H$. Since $H \psi = H \Psi_4 = 0$, we can conclude that the Melnikov integral above is 0. Since we are assuming that $\ker H$ is 1-dimensional and we know that $q' \in \ker H$, we conclude that $\psi = q'$.
\\

Thus for our jump we have

\[
\langle \Psi(0), W^+(0) - W^-(0) \rangle = \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy + \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) \rangle dy \right) 
\]

At this point, we can plug in our expressions for $W^\pm$ from above and see what we get. The idea is to get something equivalent to a Melnikov integral, but as a coefficient of $\lambda^2$. Looking at what we have, when we plug in $W^\pm$, the term in $BQ(y)$ will give us what we want. Unfortunately, this is a really big mess, so we will approach this from another angle.

\subsection*{Second Construction}

Here we present another construction for the eigenfunction of the linearization of KdV5 about the single pulse $q(x)$. Since the Melnikov integral above is 0, the idea here is to find an equivalent to the Melnikov integral for the $\lambda^2$ term in the expansion. This will only work for the single pulse, but the idea is that we can (somehow) extend this to multipulses, since, to leading order, multipulses are single pulses joined together.\\

Consider the eigenvalue problem $\partial_x H u = \lambda u$ and its integrated version $Hu = \lambda \int_a^x u$. For now, we won't worry about the lower limit of integration except to note that it has to be $\pm \infty$ in order to avoid a boundary term on the LHS.\\

We write the eigenfunction $u$ as a small perturbation of the derivative of the single pulse $q'(x)$.
\[
u(x) = q'(x) + \lambda v(x)
\]

For $\lambda = 0$, this reduces to $u(x) = q'(x)$, which we know is an eigenfunction (of both $H$ and $\partial x H$) with eigenvalue 0. Since we are interested in small $\lambda$, this a reasonable place to start. Assuming this a solution to our (nonintegrated, 5th order) eigenvalue problem, we get the following when we plug it in.

\begin{align*}
\partial_x H u &= \lambda u \\
\partial_x H (q' + \lambda v) &= \lambda(q' + \lambda v) \\
\partial_x H q' + \lambda \partial_x H v &= \lambda q' + \lambda^2 v \\
\lambda \partial_x H v &= \lambda(q' + \lambda v)
\end{align*}

If we assume that $\lambda \neq 0$ (which is reasonable, since we already know what happens when $\lambda = 0$), can divide by $\lambda$ to get (for $\lambda$ small)
\[
\partial_x H v = q' + \lambda v
\]

To leading order (neglecting the second term on the RHS), this is

\[
\partial_x H v = q'
\]

Note that $v$ does not appear on the RHS. We know the solution to this: $\partial_x H q_c = -q'$, so $\partial_x H (-q_c) = q'$, or $H (-q_c) = q$. Another way to see this is as follows. $\partial_x H v = q'$ is equivalent to $Hv = q$. For that to have a solution, $q$ must be in the range of $H$, which is perpendicular to the kernel of $H^*$. Thus we have the condition $\langle q, \psi \rangle = 0$ for all $\psi \in \ker(H^*)$. Since $H$ is self-adjoint, this becomes $\langle q, \psi \rangle = 0$ for all $\psi \in \ker H$. Since we are assuming that $\ker H$ is one-dimensional, i.e. $\ker(H) = \textrm{span} \{q'\}$, this condition is $\langle q, q' \rangle = 0$. We know this is true since $q$ is even and $q'$ is odd.\\

Thus it makes sense to write $v$ as a perturbation of $-q_c$.

\[
v(x) = -q_c(x) + \lambda w(x)
\]
since when $\lambda = 0$, $v$ solves the equation above. If we plug this into the equation $\partial_x H v = q' + \lambda v$, we get

\begin{align*}
\partial_x H(-q_c + \lambda w) &= q' + \lambda(-q_c + \lambda w) \\
q' + \lambda (\partial_x H) w &= q' + \lambda(-q_c + \lambda w) \\
\lambda \partial_x H w &= \lambda(-q_c + \lambda w)
\end{align*}

For $\lambda \neq 0$ (which, again, is the case we care about), this reduces to

\[
\partial_x H w = -q_c + \lambda w
\]

where we have written the eigenfunction $v(x)$ as
\[
v(x) = q'(x) - \lambda q_c(x) + \lambda^2 w(x)
\]

To leading order, this is

\[
\partial_x H w = -q_c
\]

Again, note that $w$ is not present on the RHS. Suppose we had a solution $\tilde{w}(x)$ to this. Then we could write $w(x) = \tilde{w}(x) + \lambda r(x)$ and repeat what we did above. This would give us an expansion of our eigenfunction which looks like $v(x) = q'(x) - \lambda q_c(x) + \lambda^2 \tilde{w}(x) + \lambda^3 r(x)$, which is one degree higher in $\lambda$ than we wish to go. In order for this to not be possible, we require the equation $\partial_x H w = -q_c$ to not have a solution (or at least not have one which is in $L^2$ or in our exponentially weighted space). This is equivalent to

\[
q_c \notin \textrm{Range}(\partial_x H)
\]

Since $\textrm{Range}(\partial_x H) = \ker (\partial_x H)^*$, this is equivalent to 

\[
\langle q_c, \phi \rangle \neq 0 \text{ for some }\phi \in \ker(\partial_x H)^*
\]

Since $\ker(\partial_x H)^* = H^* (\partial_x)^* = -H \partial_x$ (recall that $H$ is self-adjoint), this is equivalent to

\[
\langle q_c, \phi \rangle \neq 0 \text{ for some }\phi \in \ker(H \partial_x)
\]

By Assumption \ref{1dkernel}, $\ker(H \partial_x) = \textrm{span} \{q \}$, so this is equivalent to

\[
\langle q_c, q \rangle
\]

which is Assumption \ref{qcIP}.\\

Let's look at what we have done so far. For the linearization about a single pulse, we have written our eigenfunction as an expansion in $\lambda$ to 2nd order.

\begin{equation}\label{eigenfntosecondorder}
v(x) = q'(x) - \lambda q_c(x) + \lambda^2 w(x)
\end{equation}

We have the following equation for $w$

\[
\partial_x H w = -q_c + \lambda w 
\]

where Assumption \ref{qcIP} assures that the leading-order problem $\partial_x H w = -q_c$ does not have a solution.\\

From here, we integrate both sides, just as we did earlier, to get the integrated eigenvalue problem. Our lower limit is written here as $a$, which is either $\pm \infty$ to avoid boundary terms. This gives us

\[
H w(x) = -\int_a^x q_c(y) dy + \lambda \int_a^x w(y) dy 
\]

The first integral on the RHS does not depend on $w$ but only on the single pulse we are linearizing about. By Lemma \ref{qc}, this integral is well-defined since $q_c \in L^2(\R)$. \\

At this point we proceed as in the previous section by writing the problem as a first order system and splitting the domain up into two pieces. The two pieces are the same as above, and we take the integration limits $a = \pm \infty$ on the two pieces. This gives us the following set of equations.

\begin{align*}
W^\pm(x)' &= A(q(x)) W^\pm(x) - (K^\pm B Q_c)(x) + \lambda (K^\pm B W^\pm)(x) \\
W^\pm(x) &\in \C \psi(0) \oplus Y^+ \oplus Y^- \\
W^+(0) - W^-(0) &\in \C \psi(0) 
\end{align*}

We can write the fixed point equations for $W^\pm$ as

\begin{align*}
W^-(x) = \Phi^u_-(x, 0)b^- &+ \int_0^x \Phi^u_-(x, y)[\lambda (K^- B W^-)(y) + (K^- B Q_c)(y) ] dy \\
&+ \int_{-\infty}^x \Phi^s_-(x, y)[\lambda (K^- B W^-)(y) + (K^- B Q_c)(y) ] dy \\
W^+(x) = \Phi^s_+(x, 0)b^+ &+ \int_0^x \Phi^s_+(x, y)[\lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) ] dy \\
&+ \int_{\infty}^x \Phi^u_+(x, y)[\lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) ] dy
\end{align*}

Now we do the inversion as in the previous section and as in Sandstede (1998). The integration operator term $K^\pm B W^\pm$ is the same as above, so we can handle that with an exponentially weighted function space with the same choice of exponential weight $\alpha$. $Q_c$ is independent of $W^\pm$ and is integrable by Lemma \ref{qc}, so the $K^\pm B Q_c$ term is bounded by a constant. Thus we have the equivalent of Lemma \ref{inv1} in the previous section.

\begin{align*}
(b, W) &= (B_1(\lambda), W_3(\lambda))\\
B_1(\lambda)| &\leq C|\lambda|\\
||W_3(\lambda)||_\eta &\leq C|\lambda|\\
\end{align*}

Now we look at the jump as before. 

\begin{align*}
\langle \Psi(0), W^+(0) &- W^-(0) \rangle = \langle \Psi(0), \Phi^u_-(0, 0)b^- + \int_{-\infty}^0 \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + (K^- B Q_c)(y)] dy  \\
&- \Phi^s_+(0, 0)b^+ - \int_\infty^0 \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) ] dy \rangle \\
&= \langle \Psi(0), b^- - b^+\rangle + \int_{-\infty}^0 \langle \Psi(0), \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + (K^- B Q_c)(y) ] \rangle dy  \\
&- \int_\infty^0 \langle \Psi(0), \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) ] \rangle dy  \\
&= \int_{-\infty}^0 \langle \Psi(y), \lambda (K^- B W^-)(y) + (K^- B Q_c)(y) \rangle dy \\
&- \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) \rangle dy \\
&= \int_{-\infty}^0 \langle \Psi(y), (K^- B Q_c)(y) \rangle dy + \int_{\infty}^0 \langle \Psi(y), (K^+ B Q_c)(y) \rangle dy  \\
&+ \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy - \int_\infty^0 \langle \Psi(y), (K^+ B W^+)(y) \rangle dy \right) \\
\end{align*}

We are interested in the terms not involving $\lambda$. (If we recall what we did above, these will correspond to the coefficient of $\lambda^2$ in the expansion \eqref{eigenfntosecondorder} of the eigenfunction.) Recall that we defined $\psi$ above as the 4th component of $\Psi$. 

\begin{equation}
M = \int_{-\infty}^0 \psi(y) \int_{-\infty}^y q_c(z) dz dy + \int_0^\infty \psi(y) \int_{\infty}^y q_c(z) dz dy 
\end{equation}

We showed above that $\psi \in \ker H$. By Assumption \ref{1dkernel}, $\psi = q'$, so $M$ becomes

\begin{equation}\label{defM}
M = \int_{-\infty}^0 q'(y) \int_{-\infty}^y q_c(z) dz dy + \int_0^\infty q'(y) \int_{\infty}^y q_c(z) dz dy
\end{equation}

To make this look nicer, we define the piecewise function
\[
\tilde{q}(x) = \begin{cases}
\int_{-\infty}^x q_c(z) dz & x < 0 \\
\int_{\infty}^x q_c(z) dz & x \geq 0
\end{cases}
\]

Numerics suggests that $q_c$ is even, so this is almost certainly not continuous at $x = 0$. Note that the derivative of $\tilde{q}$ is equal to $q_c$ except at $x = 0$ where it does not exist.\\

We can rewrite $M$ using $\tilde{q}(x)$

\[
M = \int_{-\infty}^0 q'(y) \tilde{q}(y) dy + \int_0^\infty q'(y) \tilde{q}(y) dy = \int_{-\infty}^\infty q'(y) \tilde{q}(y) dy = \langle q', \tilde{q} \rangle_{L^2(\R)}
\]

This makes $M$ into a nice $L^2$ inner product, analagous to the Melnikov intergral from the prior section.\\

Now we show that $M \neq 0$. To to this, we take \eqref{defM} and integrate by parts. Since $\tilde{q}$ is not differentiable at $x = 0$, we need to do this in two pieces.

\begin{align*}
M &= \int_{-\infty}^0 q'(y) \int_{-\infty}^y q_c(z) dz dy + \int_0^\infty q'(y) \int_{\infty}^y q_c(z) dz dy \\
&= \int_{-\infty}^0 q'(y) \tilde{q}(y) dy + \int_0^\infty q'(y) \tilde{q}(y) dy \\
&= q(y) \tilde{q}(y)\Big|_{-\infty}^{0-} - \int_{-\infty}^0 q(y) q_c (y) dy + q(y) \tilde{q}(y)\Big|_{0+}^{\infty} - \int_0^{\infty} q(y) q_c (y) dy \\
&= q(0)[\tilde{q}(0-) - \tilde{q}(0+)] - \int_{-\infty}^\infty q(y) q_c(y) dy \\
&= q(0)\left( \int_{-\infty}^0 q_c(y) dy - \int_{\infty}^0 q_c(y) dy \right) - \langle q, q_c \rangle \\
&= q(0) \int_{-\infty}^\infty q_c(y) dy - \langle q, q_c \rangle
\end{align*}

The second term on the RHS is nonzero by Assumption \ref{qcIP}. The first term on the RHS comes from the integration-by-parts boundary. The maximum of $q$ occurs at 0, so $q(0) \neq 0$, and numerics suggests that $q_c$ does not have mean 0, thus the first term is almost certainly nonzero.

We can rewrite this as

\begin{equation}
M = \int_{-\infty}^\infty [q(0) - q(y)] q_c(y) dy
\end{equation}

but I'm not sure if that buys us anything.\\

We can use our estimates to get something resembling (3.56) in Sandstede (1998), ALTHOUGH I DO NOT KNOW IF THIS IS USEFUL SINCE WE HAVE THE EQUIVALENT TO THE MELNIKOV INTEGRAL. We use here the estimate (3.50) in Sandstede (1998) $|\Psi(x)| \leq C e^{-\alpha_* |x|}$. (We use $\alpha_*$ here for the constant to distinguish it from the $\alpha$ we chose above.) We also use the estimate $||W|| = ||W_3(\lambda)||_\alpha \leq C|\lambda|$ for our chosen $\alpha < \alpha_s, \alpha_u$. For the last one, recall that the exponentially weighted norm is defined by

\begin{align*}
|| f ||_\eta &= \sup_{x \in [-a, 0]} |e^{-\eta x} f(x) | && f \in C^0_\eta[-a, 0] \\
|| f ||_\eta &= \sup_{x \in [0, a]} |e^{\eta x} f(x) | && f \in C^0_\eta[0, a] \\
\end{align*}

\begin{align*}
R(\lambda) &= \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy - \int_\infty^0 \langle \Psi(y), (K^+ B W^+)(y) \rangle dy \right) \\
|R(\lambda)| &\leq |\lambda|\left( \int_{-\infty}^0 C e^{\alpha_* y} \int_{-\infty}^y |w^-(z)| dz dy + \int_0^\infty C e^{-\alpha_* y} \int_y^\infty |w^+(z)| dz dy \right) \\
&= |\lambda|\left( \int_{-\infty}^0 C e^{\alpha_* y} \int_{-\infty}^y e^{\alpha z} |e^{-\alpha z} w^-(z)| dz dy + \int_0^\infty C e^{-\alpha_* y} \int_y^\infty e^{-\alpha z} |e^{\alpha z}w^+(z)| dz dy \right)\\
&\leq C |\lambda| ||W_3(\lambda)||_\alpha \left( \int_{-\infty}^0 e^{\alpha_* y} \int_{-\infty}^y e^{\alpha z} dz dy + \int_0^\infty e^{-\alpha_* y} \int_y^\infty e^{-\alpha z} dz dy \right)\\
&= \frac{C}{\alpha} |\lambda|^2 \left( \int_{-\infty}^0 e^{(\alpha_* + \alpha) y} dy + \int_0^\infty e^{-(\alpha_* + \alpha) y} \right) dy \\
&= \frac{2 C}{\alpha(\alpha + \alpha_*)} |\lambda|^2 
\end{align*}

So we should have for our jump

\[
\xi = M + R(\lambda)
\]

where $M$ is given above and we have the above estimate for the remainder $R(\lambda)$.\\

We know what the deal is in this case, i.e. there is no nonzero eigenvalue near 0 for the single pulse. Thus we should not be able to get the jump to be 0, although it is not clear at all that this is the case by looking at what we did above.

\end{document}