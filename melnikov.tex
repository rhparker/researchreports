\documentclass[12pt]{article}
\usepackage[pdfborder={0 0 0.5 [3 2]}]{hyperref}%
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}%
\usepackage[shortalphabetic]{amsrefs}%
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{amssymb}                
\usepackage{amsmath}                
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage{float}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{mathtools}
\usepackage{cool}
\usepackage{url}
\usepackage{graphicx,epsfig}
\usepackage{makecell}
\usepackage{array}

\def\noi{\noindent}
\def\T{{\mathbb T}}
\def\R{{\mathbb R}}
\def\N{{\mathbb N}}
\def\C{{\mathbb C}}
\def\Z{{\mathbb Z}}
\def\P{{\mathbb P}}
\def\E{{\mathbb E}}
\def\Q{\mathbb{Q}}
\def\ind{{\mathbb I}}

\graphicspath{ {images17/} }

\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}

\begin{document}

\section*{Melnikov Integrals for Linearization of KdV5 about Single Pulse}

\subsection*{Preliminaries}

A single-pulse solution $q(x; c)$ to KdV5 is a homoclinic orbit connecting the equilibrium solution at 0 to itself. The single pulse solves the stationary KdV5 equation
\begin{equation}
u_{xxxxx} - u_{xxx} + c u_x - 2 u u_x = \partial_x(u_{xxxx} - u_{xx} + c u - u^2) = 0
\end{equation}
as well as the integrated equation
\begin{equation}\label{4thorder}
u_{xxxx} - u_{xx} + c u - u^2 = 0
\end{equation}
where we can take the constant of integration to be 0 since the pulse decays to 0 at $\pm \infty$. \\

The energy of the system is given by 

\begin{equation} \label{energy}
E(u) = -\int_{-\infty}^{\infty} \left( \frac{1}{2}u_{xx}^2 + \frac{1}{2}u_x^2 + \frac{1}{2}cu^2 - \frac{1}{3}u^3 \right) dx
\end{equation}

and it can be shown that this quantity is conserved.\\

If we write \eqref{4thorder} as a first-order system and linearize about the equilibrium solution at 0, we obtain the constant-coefficient matrix system $U' = A(0; c) U$, where

\[
A(0; c) = 
\begin{pmatrix}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
-c & 0 & 1 & 0 \\ 
\end{pmatrix}
\]

The eigenvalues of $A(0; c)$ are
\[
\nu = \pm \sqrt{ \frac{1 \pm \sqrt{1 - 4c} }{2}}
\]

For $c < 1/4$, all four eigenvalues are real (two positive and two negative), and for $c > 1/4$, the eigenvalues are two complex conjugate pairs (one pair with positive real part and one pair with negative real part). In both cases, we have a two-dimensional stable eigenspace and a two-dimensional unstable eigenspace. We designate the two stable eigenvalues by $\nu_1^s(c)$ and $\nu_2^s(c)$, where

\begin{align*}
\nu_1^s(c) &= \sqrt{ \frac{1 + \sqrt{1 - 4c} }{2}}\\
\nu_2^s(c) &= \sqrt{ \frac{1 - \sqrt{1 - 4c} }{2}}
\end{align*}

The corresponding eigenvectors are $v_1^s(c)$ and $v_2^s(c)$ (these can be written down exactly, but it's a mess). The unstable eigenvalues are $\nu_1^u(c)$ and $\nu_2^u(c)$, with corresponding eigenvectors $v_1^u(c)$ and $v_2^u(c)$. The stable and unstable eigenspaces are $E^s(c) = \text{span}\{ v_1^s(c), v_2^s(c) \}$ and $E^u(c) = \text{span}\{ v_1^u(c), v_2^u(c) \}$.\\

We can also write the nonlinear equation as a first-order system
\begin{equation}\label{nonlinearsystem}
U' = A(0; c) U + N(U)
\end{equation}
where $U = (u_1, u_2, u_3, u_4) = (u, u', u'', u''')$ and $N(U) = N(u_1, u_2, u_3, u_4) = (0, 0, 0, u_1^2)$. Note that we have separated the equation in to a linear and a nonlinear part, and that for the nonlinear part, $N(0) = DN(0) = 0$.\\

We would like to show that we can take the derivative of our single pulse $q(x)$ with respect to the wave speed $c$, and that the derivative $q_c(x)$ is exponentially localized. For this to be the case, we will need the following assumption.

\begin{assumption}For some $c_0 > 0$, the stable manifold $W^s(0; c_0)$ and the unstable manifold $W^u(0; c_0)$ for the equilibrium solution $u = 0$ intersect transversely in $E^{-1}(0)$ at the point $q(0; c_0)$, where $E$ is the energy \eqref{energy}.
\end{assumption}

Since numerics show that a single pulse solution exists for a wide range of speeds $c$, this assumption is reasonable.\\

What does this assumption get us?
\begin{enumerate}
	\item A single pulse solution $q(x; c)$ exists for $c = c_0$. Since energy is conserved and the energy at $U = 0$ is zero, any pulse solution must be contained in the set $E^{-1}(0)$. Furthermore, the stable and unstable manifolds $W^s(0; c_0)$ and $W^u(0; c_0)$ must be contained in $E^{-1}(0)$ since these contain trajectories which approach $U = 0$ as $x \rightarrow \pm \infty$. Any pulse solution must leave 0 via the unstable manifold and approach 0 by the stable manifold.	Since a pulse solution is continuous, the stable and unstable manifolds must intersect somewhere along the pulse. We might as well take that point of intersection to happen when $x = 0$, i.e. at the point $q(0, c_0)$. Note that existence of a pulse solution does not require transverse intersection, only intersection.
	\item Transverse intersection makes it likely (although we still need to prove it) that the intersection of stable and unstable manifolds persists for $c$ near $c_0$. Numerics suggests that this is indeed the case.
\end{enumerate}

We will show that $q_c(x)$ exists and is exponentially localized in a series of lemmas.\\

\begin{lemma}\label{transverseint}
For $c$ near $c_0$, the transverse intersection of manifolds is preserved. Thus we still have a single-pulse (homoclinic orbit) for $c$ near $c_0$, i.e. for $c \in (c_0 - \delta, c_0 + \delta)$ for some $\delta > 0$.
\begin{proof}
This will use either stuff from differential topology or the implicit function theorem. Haven't figured out how yet.
\end{proof}
\end{lemma}

\begin{lemma}\label{qcexists}
$q(x; c)$ is differentiable in $c$ for all $c$ near $c_0$ and for all $x$. 
\begin{proof}
Let $\Phi(x; c)$ be the solution operator for \eqref{nonlinearsystem}, where the initial condition is given at $x = 0$. Taking the initial condition to be $q(0; c)$, by the property of the solution operator, for $c$ near $c_0$, $q(x; c) = \Phi(x; c)q(0; c)$. If we differentiate this expression with respect to $c$ (assuming we can do it), we get

\begin{equation}\label{diffat0}
q_c(x; c) = \left[ \frac{\partial}{\partial_c} \Phi(x; c) \right] q(0; c) + \Phi(x; c) \frac{\partial}{\partial_c} q(0; c)
\end{equation}

By the existence and uniqueness theorem, we note that the RHS of \eqref{nonlinearsystem} is $C^\infty$ in $c$ (since $A(0; c)$ is a linear function of $c$ and $N(u)$ does not involve $c$ at all), thus the solution is as well. Thus the first term on the RHS of \eqref{diffat0} always exists, so all we need to show is that the second term exists, i.e. that $q(x; c)$ is differentiable in $c$ at $x = 0$.\\

Somehow we get this from the robustness of transverse intersection (previous lemma), but don't know how that gives us differentiability.
\end{proof}
\end{lemma}

\begin{lemma}\label{qc}
For the stationary, single-pulse solution $q(x; c)$ to the 5th order KdV equation in a frame moving with velocity $c$, the derivative $q_c(x)$ of the pulse with respect to $c$ is exponentially localized, thus $q_c(x) \in L^2(\R)$.
\begin{proof}
$q_c(x)$ exists for $c$ near $c_0$ by Lemma \ref{qcexists}, so we need to show that it is exponentially localized.\\

We proceed as in the proof of the stable manifold theorem (parameter-dependent version). We use an exponentially weighted function space $X_\eta$, defined in the usual way by 

\[
X_\eta = \{ f \in C^0([0, \infty), \R^n) : \sup_{x \in [0, \infty)} |e^{\eta x} f(x)| < \infty 
\]

where the norm is given by

\[
||f||_\eta = \sup_{x \in [0, \infty)} |e^{\eta x} f(x)|
\]

The exponential weight $\eta$ will be chosen later, but it will be positive since we are on the interval $[0, \infty)$.\\

Next we write \eqref{nonlinearsystem} in integrated form. For convenience, let $A(c) = A(0; c)$, so that the matrix exponential $e^{A(c)x}$ is the fundamental matrix solution to the linear problem $U' = A(c) U$. Let $P(c)^s$ and $P(c)^u$ be the stable and unstable projections onto the stable and unstable eigenspaces of $A(c)$. Then as long as $|U(x)|$ is uniformly bounded for $x \geq 0$, say $|U(x)| \leq \rho$ for $x \geq 0$, then $U(x)$ is given by

\[
U(x) = e^{A(c)x}a + \int_\infty^x e^{A(c)(x - y)}P(c)^u N(U(y))dy + \int_0^x e^{A(c)(x - y)}P(c)^s N(U(y))dy
\]

where $a = P(c)^s u_0$, the stable projection of the initial condition. \\

NOTE: I DON'T THINK THE DEFINITIONS OF THE SPACE $B_1$ AND THE MAP $F$ ARE EXACTLY WHAT WE WANT. I HAVE LEFT IT THIS WAY TO SHOW WHAT I WAS THINKING. AFTER ALL OF THIS, I REVISIT THIS AND REDEFINE THEM SLIGHTLY TO WHAT I THINK WE WANT. IN ANY CASE, EVERYTHING SHOULD STILL HOLD WITH THE SMALL MODIFICATION MENTIONED BELOW.\\

First we define the spaces
\begin{align*}
B_1 &= (c_0 - \delta, c_0 + \delta) \\
B_2 &= \{ a \in E(c)^s : c \in B_1 \text{ and } |a| \leq \rho/2M \} \\
D &= \{ u \in X_\eta : ||u||_\eta \leq \rho \}
\end{align*}

where $\delta$ is the constant from Lemma \ref{transverseint}. Next define
\[
L_\eta(\rho) = \max \{ || DN(u) || : ||u||_\eta \leq \rho \}
\]

Note that since we are on the domain $[0, \infty)$ and $\eta > 0$, $|u(x)| \leq |u(x)e^{\eta x}|$ and so $||u|| \leq ||u||_\eta$. Since $N \in C^1$ and $||u|| \leq \rho$, $L(\rho)$ is well-defined and finite. (In this case, we know exactly what $N$ is. The Jacobian matrix $DN$ consists entirely of zeros except for one entry which is $2 u_1$, so here we have $L(\rho) \leq 2 \rho$.) From this, we can get a bound on $|N(u)|$ for $u$ with $||u||_\eta \leq \rho$. Since $N \in C^1$ and $N(0) = 0$,

\begin{align*}
|N(u)| &= |N(u) - N(0)| \\
&= \left| \int_0^1 DN(t u) tu du \right| \\
&\leq  \int_0^1 ||DN(tu)|| \: |u| t dt \\
&\leq L(\rho) |u|
\end{align*}

Multiplying both sides by $e^{\eta x}$ gives us $|N(u) e^{\eta x}| \leq L(\rho) e^{\eta x}$, and taking the supremum in $x$ gives us the bound

\[
||N(U)||_\eta \leq L(\rho) ||U||_\eta
\]

Note that since $DN(0) = 0$ and $N \in C^1$, $DN(u) \rightarrow 0$ as $u \rightarrow 0$, thus by the definition of $L(\rho)$, $L(\rho) \rightarrow 0$ as $\rho \rightarrow 0$. We also have for $U, V$ with $||U||_\eta, ||V||_\eta \leq \rho$

\[
||N(U) - N(V)||_\eta \leq L(\rho)(||U||_\eta - ||V||_\eta) 
\]
which is a consequence of the mean value inequality.\\

Since for $c > 0$ the matrix $A(c)$ is hyperbolic and since the eigenvalues of $A(c)$ are continuous functions of $c$, we can find $\alpha^s, \alpha^u > 0$ such that for all $c \in B_1$, all eigenvalues of $A(c)$ lie outside the open interval $(-\alpha^s, \alpha^u)$. For $c \in B$, we have the estimates

\begin{align*}
||e^{A(c)x}P(c)^s|| &\leq Me^{-\alpha^s x} && x \geq 0\\
||e^{A(c)x}P(c)^u|| &\leq Me^{\alpha^u x} && x \leq 0
\end{align*}

Now we define the map $F: D \times B_1 \times B_2 \rightarrow X_\eta$ by

\begin{equation}\label{F}
[F(U, c, a)](x) = e^{A(c)x}a + \int_\infty^x e^{A(c)(x - y)}P(c)^u N(U(y))dy + \int_0^x e^{A(c)(x - y)}P(c)^s N(U(y))dy
\end{equation}

First we show that $F$ is well-defined, i.e. it actually maps into $X_\eta$. We will look at each term on the RHS separately. Recall that since the domain of $F$ is $D$, we always have $||U||_\eta \leq \rho$.

\begin{align*}
|e^{\eta x} e^{A(c)x }a| &\leq M e^{\eta x} e^{-\alpha^s x} |a|\\
&= M e^{(\eta - \alpha^s)x} |a|
\end{align*}
For this to be uniformly bounded in $x$, we require $\eta \leq \alpha^s$, in which case we have $||e^{A(c)x}a ||_\eta \leq M|a|$.

\begin{align*}
\left| e^{\eta x} \int_\infty^x e^{A(c)(x - y)}P(c)^u N(U(y))dy \right| &= \left| \int_\infty^x e^{\eta x} e^{A(c)(x - y)}P(c)^u N(U(y))dy \right|\\
&\leq \int_x^\infty M e^{\eta x}e^{\alpha^u(x -y)}|N(U(y))|dy \\
&= M \int_x^\infty e^{\eta (x - y)}e^{\alpha^u(x -y)}| e^{\eta y} N(U(y))|dy \\
&\leq M \int_x^\infty e^{(\eta+\alpha^u)(x - y)} || N(U)||_\eta dy \\
&\leq M L(\rho) ||U||_\eta \int_x^\infty e^{(\eta+\alpha^u)(x - y)} dy \\
&= M L(\rho) ||U||_\eta \frac{1}{\eta+\alpha^u}
\end{align*}

Since $\eta$ and $\alpha^u$ are both positive, this imposes no additional restrictions on $\eta$.

\begin{align*}
\left| e^{\eta x} \int_0^x e^{A(c)(x - y)}P(c)^s N(U(y)) \right| &= \left| \int_0^x e^{\eta x} e^{A(c)(x - y)}P(c)^s N(U(y)) dy \right|\\
&\leq \int_0^x M e^{\eta x}e^{-\alpha^s(x -y)}|N(U(y))|dy \\
&= M \int_0^x e^{\eta (x - y)}e^{-\alpha^s(x -y)}| e^{\eta y} N(U(y))|dy \\
&\leq M \int_0^x e^{(\eta-\alpha^s)(x - y)} || N(U)||_\eta dy \\
&\leq M L(\rho) ||U||_\eta \int_0^x e^{(\eta-\alpha^s)(x - y)} dy \\
&= M L(\rho) ||U||_\eta \frac{1 - e^{(\eta-\alpha^s)x} }{\eta-\alpha^s}
\end{align*}

Since $x \geq 0$, as long as $\eta < \alpha^s$ (we have this condition from above), $0 < e^{(\eta-\alpha^s)x} < 1$, thus we have

\[
\left| e^{\eta x} \int_0^x e^{A(c)(x - y)}P(c)^s N(U(y)) \right| \leq M L(\rho) ||U||_\eta \frac{1}{\eta-\alpha^s}
\]

Putting all of this together and taking the supremum over $x \in [0, \infty)$, we have for $||U||_\eta \leq \rho$

\begin{equation}
||F(U, c, a)](x)||_\eta \leq M |a| + M L(\rho) \left( \frac{1}{\eta+\alpha^u}+\frac{1}{\eta-\alpha^s} \right) ||U||_\eta
\end{equation}

Since everything on the RHS is finite, we have shown that the codomain of $F$ is in fact $X_\eta$, so $F$ is well-defined. Since $a \in B_2$, $|a| \leq \rho/2M$. Since $L(\rho) \rightarrow 0$ as $\rho \rightarrow 0$, we can choose $\rho$ sufficiently small so that $L(\rho) < \frac{1}{2M} \left( \frac{1}{\eta+\alpha^u}+\frac{1}{\eta-\alpha^s} \right)^{-1}$. Having done this, and using the fact that $||U||_\eta \leq \rho$, we obtain the bound $||F(U, a, c)](x)||_\eta \leq \rho$. Thus for this choice of $\rho$ we actually have $F: D \times B_2 \times B_1 \rightarrow D$, which is what we want.\\

Now we need to show that $F: D \times B_2 \times B_1 \rightarrow D$ is a uniform contraction. For $U, V \in D$, following what we did above, 

\begin{align*}
| &e^{\eta x} ( F(U, c, a) - F(V, c, a) ) | \\
&= \left| \int_\infty^x e^{\eta x} e^{A(c)(x - y)}P(c)^u [N(U(y)) - N(V(y))]dy + \int_0^x e^{\eta x} e^{A(c)(x - y)}P(c)^s[N(U(y)- N(V(y))]dy \right| \\
&\leq M L(\rho) \left( \int_x^\infty e^{(\eta + \alpha^u)(x-y)}||U - V||_\eta dy + \int_0^x e^{(\eta - \alpha^s)(x-y)}||U - V||_\eta dy \right) \\
&= ML(\rho)||U - V||_\eta \left( \frac{1}{\eta + \alpha^u}+\frac{1}{\eta-\alpha^s} \right) \\
&\leq \frac{1}{2} ||U - V||_\eta 
\end{align*}

where in the last line we used our choice of $\rho$ from above. Since this is independent of $c$ and $a$, $F$ is a uniform contraction. By the uniform contraction mapping principle, there is a unique map $G: B_1 \times B_2 \rightarrow D$ such that $F(G(c, a), c, a) = G(c, a)$ for all $c \in B_1$ and $a \in B_2$. In other words, $G$ maps the pair of parameters $(c, a)$ to the unique fixed point of $F$ with those parameters. By the uniform contraction mapping principle, the maps $G$ and $F$ have the same smoothness in the parameters $c$ and $a$.\\

What does this get us? We note the following

\begin{enumerate}
	\item For each speed $c \in B_1$ and initial condition $a \in B_2$, $u(x) = G(c, a)(x)$ is the unique solution on $[0, \infty)$ to KdV5 with speed $c$ and initial condition $P(c)^s u(0) = a$ (this is actually the projection of the IC on the stable eigenspace).

	\item $G(c, a)(x) \in D$, which implies $\sup_{x \in [0, \infty)} |e^{\eta x} G(c, a)(x)| \leq \rho$. In other words, for all $c \in B_1$, $a \in B_2$, and $x \geq 0$
	\begin{equation}
		|G(c, a)(x)| \leq \rho e^{-\eta x}
	\end{equation}
	Thus for these $a$ and $c$, the unique solution $G(c, a)(x)$ is uniformly exponentially bounded on $[0, \infty)$.

	\item $G(c, a)$ is as smooth as $F$ in $c$ and $a$.
\end{enumerate}

The key (I think) is this last property (smoothness). We would like the map $G$ to be differentiable in $c$. For now, let's assume $G$ is differentiable in $c$, and make sure that gives us the result we want. Note that the codomain of $G$ is $D$ (not $\R$), so when we say ``differentiable in $c$'', we mean the Frechet derivative. So let's write that down at $c = c_0$. Note that if we keep $a$ fixed, we have a map from (a subset of) $\R$ to $D$. Then the following limit exists

\begin{align*}
\lim_{h \rightarrow 0} \frac{1}{|h|} || G(c_0 + h, a) - G(c_0, a) - f(h)||_\eta = 0
\end{align*}

where $f: B_1 \subset \R \rightarrow D$ is a bounded linear operator. This is equivalent (I believe, since we are in a metric space and the distance function is continuous) to 
\begin{align*}
\lim_{h \rightarrow 0} \frac{1}{|h|} || G(c_0 + h, a) - G(c_0, a)||_\eta &= \lim_{h \rightarrow 0} \frac{||f(h)||_\eta}{|h|} \\
&\leq \lim_{h \rightarrow 0} \frac{R|h|}{|h|} = R
\end{align*}
where in the last line we used the fact that $f$ is a bounded linear operator.\\

In particular, since the RHS is the supremum over $x \geq 0$, this holds for all $x$. Thus for all $x \geq 0$, 

\begin{align*}
\lim_{h \rightarrow 0} \frac{1}{|h|} |G(c_0 + h, a)(x) - G(c_0, a)(x)| e^{\eta x} &\leq R \\
\lim_{h \rightarrow 0} \frac{1}{|h|} |G(c_0 + h, a)(x) - G(c_0, a)(x)| &\leq R e^{-\eta x} \\
\end{align*}

The limit on the LHS looks like the derivative with respect to $c$ at $c_0$. \\

But we have a problem here (I think). Recall that we set the problem up in such a way that the initial condition $a$ lives on $E(c)^s$, but if with start with $a \in E(c_0)^s$ and change to $c$ near $c_0$, we do not expect $a \in E(C)^s$. So we need to make some modifications to the above so that the initial condition $a$ makes sense. Here is one possibility.\\

Redefine our spaces as follows.

\begin{align*}
B_1 &= (c_0 - \delta, c_0 + \delta) \\
B_2 &= \{ a \in \R^n : |P(c)^s a| \leq \rho/2M \text{ for all } c \in B_1\} \\
D &= \{ u \in X_\eta : ||u||_\eta \leq \rho \}
\end{align*}

Then redefine the map $F: D \times B_1 \times B_2 \rightarrow X_\eta$ by

\begin{equation}\label{F}
[F(U, c, a)](x) = e^{A(c)x} P(c)^s a + \int_\infty^x e^{A(c)(x - y)}P(c)^u N(U(y))dy + \int_0^x e^{A(c)(x - y)}P(c)^s N(U(y))dy
\end{equation}

This should work since the initial condition now gets projected onto the correct stable eigenspace. Everything above still holds since the estimates are exactly the same. So now we should be okay and can continue where we left off.\\

Recall that for $c = c_0$ a homoclinic orbit $q(x; c_0)$ exists. By the stable manifold theorem, since $q(x; c_0)$ is contained in the stable manifold $W^s(0; c_0)$, we can find $\tilde{x} \geq 0$ such that $q(x; c_0) \leq \rho$ for all $x \geq \tilde{x}$. Let $a = q(\tilde{x}; c_0)$ be our initial condition. Then by uniqueness of the map $G$, we have $G(c_0, a)(x) = q(\tilde{x} + x; c_0)$. Thus we have

\begin{align*}
\left| \lim_{h \rightarrow 0} \frac{q(\tilde{x} + x; c_0 + h) - q(\tilde{x} + x; c_0)}{h} \right| &\leq R e^{-\eta x} \\
\end{align*}

We proved above that the derivative $q_c(x)$ exists at $c = c_0$. The limit on the LHS is therefore this derivative, and so we have

\begin{align*}
\left| \frac{\partial}{\partial c}q(\tilde{x} + x)\Big|_{c = c_0} \right| &\leq R e^{-\eta x} \\
\end{align*}

which shows that $q_c(x)$ at $c = c_0$ decays exponentially as $x \rightarrow \infty$.\\

All we need to do to complete the proof is show that the map $F$ is differentiable with respect to $c$.\\

FILL IN DETAILS HERE.\\

We can similarly show (by, say, replacing $x$ with $-x$), that $q_c(x)$ at $c = c_0$ decays exponentially as $x \rightarrow -\infty$. From this, we have the additional condition that $\eta < \alpha^u$. Thus as long as $0 < \eta < \alpha^s, \alpha^u$, we are all set.

\end{proof}
\end{lemma}

We will also need the following assumptions. Numerics suggest that these assumptions are reasonable.

\begin{assumption}\label{1dkernel}
The kernels of $H$, $\partial_x H$, and $H \partial_x$ are all one-dimensional. Thus we have
\begin{align*}
\ker H &= \text{span}\{ q' \} \\
\ker \partial_x H &= \text{span}\{ q' \} \\
\ker H \partial_x &= \text{span}\{ q \}
\end{align*}
Note that these only apply on the unbounded domain. For a bounded domain, for example, $\ker H \partial_x$ also contains the constant functions.
\end{assumption}

\begin{assumption}\label{qcIP}
$\langle q, q_c\rangle_{L^2(\R)} \neq 0$
\end{assumption}
Note that by Cauchy-Schwarz, $\langle q, q_c\rangle_{L^2(\R)} \leq ||q||_{L^2(\R)} ||q_c|_{L^2(\R)}$. Since the single pulse $q$ is exponentially localized, $q \in L^2(\R)$. By Lemma \ref{qc}, $q_c \in L^2(\R)$. Thus this inner product is well-defined.

\subsection*{First Construction}

Here we present one construction of the eigenfunction corresponding to an eigenvalue near 0 for the linearization of KdV5 about the single pulse. This corresponds to Sandstede (1998). For the single pulse, we only have two pieces which are connected by a single join at $x = 0$. We write the piecewise eigenfunction $V^\pm$ as a perturbation of the derivative $Q'$ of the single pulse, since we know that $Q'$ is an eigenfunction with eigenvalue 0. 

\begin{align*}
V^\pm(x) = Q'(x) + W^\pm(x)
\end{align*}

If we plug this into the integrated eigenvalue problem (defined in \texttt{KdV17}), we obtain the following system of equations, which are analagous to (3.7) in Sandstede (1998).

\begin{align*}
W^\pm(x)' &= A(q(x)) W^\pm(x) + \lambda B Q(x) + \lambda K^\pm B W^\pm(x) \\
W^\pm(x) &\in \C \psi(0) \oplus Y^+ \oplus Y^- \\
W^+(0) - W^-(0) &\in \C \psi(0) 
\end{align*}

We will use the third equation together with the jump distance to conclude that $W^-(0) = W^+(0)$, which is the matching condition we want.\\

Analagous to (3.14) in Sandstede (1998), we can write the fixed point equations for $W^\pm$ as

\begin{align*}
W^-(x) = \Phi^u_-(x, 0)b^- &+ \int_0^x \Phi^u_-(x, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] dy \\
&+ \int_{-\infty}^x \Phi^s_-(x, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] dy \\
W^+(x) = \Phi^s_+(x, 0)b^+ &+ \int_0^x \Phi^s_+(x, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] dy \\
&+ \int_{\infty}^x \Phi^u_+(x, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] dy
\end{align*}

In particular, note that compared to the double pulse (see \textrm{KdV17}), the boundary term is gone, and there is no longer a match at $\pm L$. To solve this, we use the equivalent of Lemmas 3.3 - 3.5 in Sandstede (1998).

\begin{lemma}\label{inv1}
There exist operators $B_1(\lambda)$ and $W_3(\lambda)$ such that 
\[
(b, W) = (B_1(\lambda), W_3(\lambda))
\]
Any bounded solution is given by this, and these operators are analytic in $\lambda$. We have the estimates
\begin{align*}
|B_1(\lambda)| &\leq C|\lambda| \\
||W_3(\lambda)||_\alpha &\leq C|\lambda|
\end{align*}
where $\alpha$ is chosen so that $0 < \alpha < \alpha_s, \alpha_u$
\begin{proof}
We follow what we did in \texttt{KdV17} as well as Lemmas 3.3 - 3.5 in Sandstede (1998), but we make the necessary simplifications for the single pulse. As in \texttt{KdV17}, we work in the exponentially weighted spaces $C^0_\alpha(-\infty, 0]$ and $C^0_\alpha[0, \infty)$, where $\alpha$ is chosen as above. These spaces and their norms are defined in \texttt{KdV17}. We define the linear operators $(L_1(\lambda)W^\pm)(x)$ from the exponentially weighted spaces to themselves by

\begin{align*}
(L_1(\lambda)W^-)(x) &= \lambda \left( \int_0^x (K_i^- B W^-)(y) dy + \int_{-\infty}^x (K_i^-B W^-)(y) dy \right) \\
(L_1(\lambda)W^+)(x) &= \lambda \left( \int_0^x (K_i^+ B W^+)(y) dy + \int_{\infty}^x (K_i^+ B W^+)(y) dy \right)
\end{align*}
We showed in \texttt{KdV17} that this operator is well-defined, i.e. it actually maps the exponentially weighted spaces to themselves, and that $||L_1(\lambda)W||_\alpha \leq C||W||_\alpha$ for our choice of $\alpha$.\\

We also define the linear operators $(L_2(\lambda)b)(x)$ from $\R^n$ to our exponentially weighted space by

\begin{align*}
(L_2(\lambda))(b^-) &= \Phi^u_-(x, 0)b^- + \lambda \left( \int_0^x \Phi^u_-(x, y) B Q(y)dy + \int_{-\infty}^x \Phi^s_-(x, y)B Q(y) dy \right)\\
(L_2(\lambda))(b^+) &= \Phi^s_+(x, 0)b^+ + \lambda \left( \int_0^x \Phi^s_+(x, y) B Q(y) dy + \int_{\infty}^x \Phi^u_+(x, y) B Q(y) dy \right)
\end{align*}

Since this is a simplified version of the operator in Lemma 3.3 of Sandstede (1998), the estimate there applies in this case, and we have

\[
||L_2(\lambda)(b)|| \leq C|b|
\]

Writing the fixed point problem as $(I - L_1(\lambda))W = L_2(\lambda)(b)$, we can invert the operator ($(I - L_1(\lambda))$ (I HAVE NEVER UNDERSTOOD WHAT YOU USED TO DO THIS, BUT IT SHOULD FOLLOW EXACTLY AS IN THE PAPER) to get
\[
W = (I - L_1(\lambda))^{-1} L_2(\lambda)(b) := W_1(\lambda)(b)
\]
with 
\[
||W_1(\lambda)(b)||_\alpha \leq C|b|
\]

Since we only have the join at $x = 0$ (i.e. we do not have the $d_i$), we do not need an equivalent to Lemma 3.4. Since the only thing we have changed is the function space (nonweighted to exponentially weighted), Lemma 3.5 should apply unchanged. Since there is no $a$ or $d$, $W_3 = W_1$. The only thing we need to be careful of is that $B_1(\lambda)$ is a function of $d$, which we do not have here. We should be able to take $d = 1$ (since it always takes that value here) and be all set. Thus applying Lemma 3.5 gives us

\begin{align*}
(b, W) = (B_1(\lambda), W_3(\lambda))
|B_1(\lambda)| &\leq C|\lambda| \\
||W_3(\lambda)||_\alpha &\leq C|\lambda|
\end{align*}

which is the result we want.
\end{proof}
\end{lemma}

Having done this, it only remains to estimate the single jump at $x = 0$.
\[
\xi = \langle \Psi(0), W^+(0) - W^-(0) \rangle
\]

Plugging in what we have, we get

\begin{align*}
\langle\Psi(0), W^+(0) &- W^-(0)\rangle = \langle \Psi(0), \Phi^u_-(0, 0)b^- + \int_{-\infty}^0 \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] dy  \\
&- \Phi^s_+(0, 0)b^+ - \int_\infty^0 \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] dy \rangle\\
&= \langle \Psi(0), b^- - b^+\rangle + \int_{-\infty}^0 \langle \Psi(0), \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + \lambda B Q(y) ] \rangle dy  \\
&- \int_\infty^0 \langle \Psi(0), \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + \lambda B Q(y) ] \rangle dy  \\
&= \int_{-\infty}^0 \langle \Psi(y), \lambda (K^- B W^-)(y) + \lambda B Q(y) \rangle dy \\
&- \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) + \lambda B Q(y)  \rangle dy \\
&= \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) > dy + \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) \rangle dy \right) \\
&+ \lambda \int_{-\infty}^\infty \langle\Psi(y), BQ(y) \rangle dy
\end{align*}

I am pretty sure that we matched things so that $b^+ = b^-$ (I CANNOT TELL IN THE PAPER WHERE THIS IS DONE, BUT THIS APPEARS TO BE USED IN (3.48) IN SANDSTEDE (1998)), so this term cancels.\\

The final integral on the RHS is the Melnikov integral, which we claim is 0. To see this, we first note that for the linearization of the fourth-order equation about the single pulse $q$, i.e. $H = \partial_x^4 - \partial_x^2 + c - 2q$, $Hq_c = -q$. (To show this, plug it in and use the fact that $q$ solves the orginal nonlinear 4th order equation.) Using this and the definition of $B$ (see \texttt{KdV17}) we have

\begin{align*}
 \int_{-\infty}^\infty \langle \Psi(y), BQ(y) \rangle dy &=  \int_{-\infty}^\infty \psi(y) q(y) dy \\
&= \langle \psi, q \rangle_{L^2(\R)} = -\langle \psi, H q_c \rangle_{L^2(\R)} \\
&= -\langle H^* \psi, q_c\rangle_{L^2(\R)} = -\langle H \psi, q_c \rangle_{L^2(\R)}
\end{align*}

The final inner product is well-defined by Cauchy-Schwarz since $\langle H \psi, q_c \rangle_{L^2(\R)} \leq ||H \psi||_{L^2(\R)} |q_c|_{L^2(\R)}$ and $q_c \in L^2(\R)$ by Lemma \ref{qc}. (We will show below that $H \psi$ = 0). The inner product $\langle \psi, q \rangle_{L^2(\R)}$ is similarly well-defined since $q$ is exponentially localized, as is $\psi$. (We sill show below that $\psi \in \ker H$, and since we are assuming that $\ker H$ is one-dimensional, $\psi$ is a multiple of $q'$, which is exponentially localized).\\

All that remains is show that $\psi \in \ker H$. Recall that the matrix $B$ places the 1st component of a vector into the 4th component and zeroes out all the other components. Since $BQ(y)$ places the pulse $q(y)$ into the 4th component, $\psi$ is the 4th component of $\Psi$. $\Psi$ is the solution to the adjoint variational equation $U' = -A(q(x))^*U$, where 

\[ 
A(q(x))^* = 
 \begin{pmatrix}0 & 0 & 0 & 2q_2(x) - c \\ 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 1 \\ 0 & 0 & 1 & 0\end{pmatrix}
\]

This can be broken down into the four equations

\begin{align*}
\Psi_1' &= -(2q(x) - c) \Psi_4 \\
\Psi_2' &= -\Psi_1 \\
\Psi_3' &= -\Psi_2 - \Psi_4 \\
\Psi_4' &= -\Psi_3
\end{align*}

The scalar function $\psi$ we want is the fourth component $\Psi_4$. We will show that $H \Psi_4 = 0$, i.e. $\Psi_4 \in \ker H$.

\begin{align*}
H \Psi_4 &= \Psi''''_4 - \Psi''_4 + (c - 2q(x))\Psi_4 \\
&= -\Psi'''_3 + \Psi_3' + \Psi_1' \\
&= \Psi''_2 + \Psi''_4 + \Psi_3' + \Psi_1' \\
&= -\Psi_1' - \Psi_3' + \Psi_3' + \Psi_1'\\
&= 0
\end{align*}

We have shown that $\Psi' = -A(q(x))^*\Psi$ is equivalent to $\Psi_4 \in \ker H$. Since $H \psi = H \Psi_4 = 0$, we can conclude that the Melnikov integral above is 0. Since we are assuming that $\ker H$ is 1-dimensional and we know that $q' \in \ker H$, we conclude that $\psi = q'$.
\\

Thus for our jump we have

\[
\langle \Psi(0), W^+(0) - W^-(0) \rangle = \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy + \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) \rangle dy \right) 
\]

At this point, we can plug in our expressions for $W^\pm$ from above and see what we get. The idea is to get something equivalent to a Melnikov integral, but as a coefficient of $\lambda^2$. Looking at what we have, when we plug in $W^\pm$, the term in $BQ(y)$ will give us what we want. Unfortunately, this is a really big mess, so we will approach this from another angle.

\subsection*{Second Construction}

Here we present another construction for the eigenfunction of the linearization of KdV5 about the single pulse $q(x)$. Since the Melnikov integral above is 0, the idea here is to find an equivalent to the Melnikov integral for the $\lambda^2$ term in the expansion. This will only work for the single pulse, but the idea is that we can (somehow) extend this to multipulses, since, to leading order, multipulses are single pulses joined together.\\

Consider the eigenvalue problem $\partial_x H u = \lambda u$ and its integrated version $Hu = \lambda \int_a^x u$. For now, we won't worry about the lower limit of integration except to note that it has to be $\pm \infty$ in order to avoid a boundary term on the LHS.\\

We write the eigenfunction $u$ as a small perturbation of the derivative of the single pulse $q'(x)$.
\[
u(x) = q'(x) + \lambda v(x)
\]

For $\lambda = 0$, this reduces to $u(x) = q'(x)$, which we know is an eigenfunction (of both $H$ and $\partial x H$) with eigenvalue 0. Since we are interested in small $\lambda$, this a reasonable place to start. Assuming this a solution to our (nonintegrated, 5th order) eigenvalue problem, we get the following when we plug it in.

\begin{align*}
\partial_x H u &= \lambda u \\
\partial_x H (q' + \lambda v) &= \lambda(q' + \lambda v) \\
\partial_x H q' + \lambda \partial_x H v &= \lambda q' + \lambda^2 v \\
\lambda \partial_x H v &= \lambda(q' + \lambda v)
\end{align*}

If we assume that $\lambda \neq 0$ (which is reasonable, since we already know what happens when $\lambda = 0$), can divide by $\lambda$ to get (for $\lambda$ small)
\[
\partial_x H v = q' + \lambda v
\]

To leading order (neglecting the second term on the RHS), this is

\[
\partial_x H v = q'
\]

Note that $v$ does not appear on the RHS. We know the solution to this: $\partial_x H q_c = -q'$, so $\partial_x H (-q_c) = q'$, or $H (-q_c) = q$. Another way to see this is as follows. $\partial_x H v = q'$ is equivalent to $Hv = q$. For that to have a solution, $q$ must be in the range of $H$, which is perpendicular to the kernel of $H^*$. Thus we have the condition $\langle q, \psi \rangle = 0$ for all $\psi \in \ker(H^*)$. Since $H$ is self-adjoint, this becomes $\langle q, \psi \rangle = 0$ for all $\psi \in \ker H$. Since we are assuming that $\ker H$ is one-dimensional, i.e. $\ker(H) = \textrm{span} \{q'\}$, this condition is $\langle q, q' \rangle = 0$. We know this is true since $q$ is even and $q'$ is odd.\\

Thus it makes sense to write $v$ as a perturbation of $-q_c$.

\[
v(x) = -q_c(x) + \lambda w(x)
\]
since when $\lambda = 0$, $v$ solves the equation above. If we plug this into the equation $\partial_x H v = q' + \lambda v$, we get

\begin{align*}
\partial_x H(-q_c + \lambda w) &= q' + \lambda(-q_c + \lambda w) \\
q' + \lambda (\partial_x H) w &= q' + \lambda(-q_c + \lambda w) \\
\lambda \partial_x H w &= \lambda(-q_c + \lambda w)
\end{align*}

For $\lambda \neq 0$ (which, again, is the case we care about), this reduces to

\[
\partial_x H w = -q_c + \lambda w
\]

where we have written the eigenfunction $v(x)$ as
\[
v(x) = q'(x) - \lambda q_c(x) + \lambda^2 w(x)
\]

To leading order, this is

\[
\partial_x H w = -q_c
\]

Again, note that $w$ is not present on the RHS. Suppose we had a solution $\tilde{w}(x)$ to this. Then we could write $w(x) = \tilde{w}(x) + \lambda r(x)$ and repeat what we did above. This would give us an expansion of our eigenfunction which looks like $v(x) = q'(x) - \lambda q_c(x) + \lambda^2 \tilde{w}(x) + \lambda^3 r(x)$, which is one degree higher in $\lambda$ than we wish to go. In order for this to not be possible, we require the equation $\partial_x H w = -q_c$ to not have a solution (or at least not have one which is in $L^2$ or in our exponentially weighted space). This is equivalent to

\[
q_c \notin \textrm{Range}(\partial_x H)
\]

Since $\textrm{Range}(\partial_x H) = \ker (\partial_x H)^*$, this is equivalent to 

\[
\langle q_c, \phi \rangle \neq 0 \text{ for some }\phi \in \ker(\partial_x H)^*
\]

Since $\ker(\partial_x H)^* = H^* (\partial_x)^* = -H \partial_x$ (recall that $H$ is self-adjoint), this is equivalent to

\[
\langle q_c, \phi \rangle \neq 0 \text{ for some }\phi \in \ker(H \partial_x)
\]

By Assumption \ref{1dkernel}, $\ker(H \partial_x) = \textrm{span} \{q \}$, so this is equivalent to

\[
\langle q_c, q \rangle
\]

which is Assumption \ref{qcIP}.\\

Let's look at what we have done so far. For the linearization about a single pulse, we have written our eigenfunction as an expansion in $\lambda$ to 2nd order.

\begin{equation}\label{eigenfntosecondorder}
v(x) = q'(x) - \lambda q_c(x) + \lambda^2 w(x)
\end{equation}

We have the following equation for $w$

\[
\partial_x H w = -q_c + \lambda w 
\]

where Assumption \ref{qcIP} assures that the leading-order problem $\partial_x H w = -q_c$ does not have a solution.\\

From here, we integrate both sides, just as we did earlier, to get the integrated eigenvalue problem. Our lower limit is written here as $a$, which is either $\pm \infty$ to avoid boundary terms. This gives us

\[
H w(x) = -\int_a^x q_c(y) dy + \lambda \int_a^x w(y) dy 
\]

The first integral on the RHS does not depend on $w$ but only on the single pulse we are linearizing about. By Lemma \ref{qc}, this integral is well-defined since $q_c \in L^2(\R)$. \\

At this point we proceed as in the previous section by writing the problem as a first order system and splitting the domain up into two pieces. The two pieces are the same as above, and we take the integration limits $a = \pm \infty$ on the two pieces. This gives us the following set of equations.

\begin{align*}
W^\pm(x)' &= A(q(x)) W^\pm(x) - (K^\pm B Q_c)(x) + \lambda (K^\pm B W^\pm)(x) \\
W^\pm(x) &\in \C \psi(0) \oplus Y^+ \oplus Y^- \\
W^+(0) - W^-(0) &\in \C \psi(0) 
\end{align*}

We can write the fixed point equations for $W^\pm$ as

\begin{align*}
W^-(x) = \Phi^u_-(x, 0)b^- &+ \int_0^x \Phi^u_-(x, y)[\lambda (K^- B W^-)(y) + (K^- B Q_c)(y) ] dy \\
&+ \int_{-\infty}^x \Phi^s_-(x, y)[\lambda (K^- B W^-)(y) + (K^- B Q_c)(y) ] dy \\
W^+(x) = \Phi^s_+(x, 0)b^+ &+ \int_0^x \Phi^s_+(x, y)[\lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) ] dy \\
&+ \int_{\infty}^x \Phi^u_+(x, y)[\lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) ] dy
\end{align*}

Now we do the inversion as in the previous section and as in Sandstede (1998). The integration operator term $K^\pm B W^\pm$ is the same as above, so we can handle that with an exponentially weighted function space with the same choice of exponential weight $\alpha$. $Q_c$ is independent of $W^\pm$ and is integrable by Lemma \ref{qc}, so the $K^\pm B Q_c$ term is bounded by a constant. Thus we have the equivalent of Lemma \ref{inv1} in the previous section.

\begin{align*}
(b, W) &= (B_1(\lambda), W_3(\lambda))\\
B_1(\lambda)| &\leq C|\lambda|\\
||W_3(\lambda)||_\eta &\leq C|\lambda|\\
\end{align*}

Now we look at the jump as before. 

\begin{align*}
\langle \Psi(0), W^+(0) &- W^-(0) \rangle = \langle \Psi(0), \Phi^u_-(0, 0)b^- + \int_{-\infty}^0 \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + (K^- B Q_c)(y)] dy  \\
&- \Phi^s_+(0, 0)b^+ - \int_\infty^0 \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) ] dy \rangle \\
&= \langle \Psi(0), b^- - b^+\rangle + \int_{-\infty}^0 \langle \Psi(0), \Phi^s_-(0, y)[\lambda (K^- B W^-)(y) + (K^- B Q_c)(y) ] \rangle dy  \\
&- \int_\infty^0 \langle \Psi(0), \Phi^u_+(0, y)[\lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) ] \rangle dy  \\
&= \int_{-\infty}^0 \langle \Psi(y), \lambda (K^- B W^-)(y) + (K^- B Q_c)(y) \rangle dy \\
&- \int_\infty^0 \langle \Psi(y), \lambda (K^+ B W^+)(y) + (K^+ B Q_c)(y) \rangle dy \\
&= \int_{-\infty}^0 \langle \Psi(y), (K^- B Q_c)(y) \rangle dy + \int_{\infty}^0 \langle \Psi(y), (K^+ B Q_c)(y) \rangle dy  \\
&+ \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy - \int_\infty^0 \langle \Psi(y), (K^+ B W^+)(y) \rangle dy \right) \\
\end{align*}

We are interested in the terms not involving $\lambda$. (If we recall what we did above, these will correspond to the coefficient of $\lambda^2$ in the expansion \eqref{eigenfntosecondorder} of the eigenfunction.) Recall that we defined $\psi$ above as the 4th component of $\Psi$. 

\begin{equation}
M = \int_{-\infty}^0 \psi(y) \int_{-\infty}^y q_c(z) dz dy + \int_0^\infty \psi(y) \int_{\infty}^y q_c(z) dz dy 
\end{equation}

We showed above that $\psi \in \ker H$. By Assumption \ref{1dkernel}, $\psi = q'$, so $M$ becomes

\begin{equation}\label{defM}
M = \int_{-\infty}^0 q'(y) \int_{-\infty}^y q_c(z) dz dy + \int_0^\infty q'(y) \int_{\infty}^y q_c(z) dz dy
\end{equation}

To make this look nicer, we define the piecewise function
\[
\tilde{q}(x) = \begin{cases}
\int_{-\infty}^x q_c(z) dz & x < 0 \\
\int_{\infty}^x q_c(z) dz & x \geq 0
\end{cases}
\]

Numerics suggests that $q_c$ is even, so this is almost certainly not continuous at $x = 0$. Note that the derivative of $\tilde{q}$ is equal to $q_c$ except at $x = 0$ where it does not exist.\\

We can rewrite $M$ using $\tilde{q}(x)$

\[
M = \int_{-\infty}^0 q'(y) \tilde{q}(y) dy + \int_0^\infty q'(y) \tilde{q}(y) dy = \int_{-\infty}^\infty q'(y) \tilde{q}(y) dy = \langle q', \tilde{q} \rangle_{L^2(\R)}
\]

This makes $M$ into a nice $L^2$ inner product, analagous to the Melnikov intergral from the prior section.\\

Now we show that $M \neq 0$. To to this, we take \eqref{defM} and integrate by parts. Since $\tilde{q}$ is not differentiable at $x = 0$, we need to do this in two pieces.

\begin{align*}
M &= \int_{-\infty}^0 q'(y) \int_{-\infty}^y q_c(z) dz dy + \int_0^\infty q'(y) \int_{\infty}^y q_c(z) dz dy \\
&= \int_{-\infty}^0 q'(y) \tilde{q}(y) dy + \int_0^\infty q'(y) \tilde{q}(y) dy \\
&= q(y) \tilde{q}(y)\Big|_{-\infty}^{0-} - \int_{-\infty}^0 q(y) q_c (y) dy + q(y) \tilde{q}(y)\Big|_{0+}^{\infty} - \int_0^{\infty} q(y) q_c (y) dy \\
&= q(0)[\tilde{q}(0-) - \tilde{q}(0+)] - \int_{-\infty}^\infty q(y) q_c(y) dy \\
&= q(0)\left( \int_{-\infty}^0 q_c(y) dy - \int_{\infty}^0 q_c(y) dy \right) - \langle q, q_c \rangle \\
&= q(0) \int_{-\infty}^\infty q_c(y) dy - \langle q, q_c \rangle
\end{align*}

The second term on the RHS is nonzero by Assumption \ref{qcIP}. The first term on the RHS comes from the integration-by-parts boundary. The maximum of $q$ occurs at 0, so $q(0) \neq 0$, and numerics suggests that $q_c$ does not have mean 0, thus the first term is almost certainly nonzero.

We can rewrite this as

\begin{equation}
M = \int_{-\infty}^\infty [q(0) - q(y)] q_c(y) dy
\end{equation}

but I'm not sure if that buys us anything.\\

We can use our estimates to get something resembling (3.56) in Sandstede (1998), ALTHOUGH I DO NOT KNOW IF THIS IS USEFUL SINCE WE HAVE THE EQUIVALENT TO THE MELNIKOV INTEGRAL. We use here the estimate (3.50) in Sandstede (1998) $|\Psi(x)| \leq C e^{-\alpha_* |x|}$. (We use $\alpha_*$ here for the constant to distinguish it from the $\alpha$ we chose above.) We also use the estimate $||W|| = ||W_3(\lambda)||_\alpha \leq C|\lambda|$ for our chosen $\alpha < \alpha_s, \alpha_u$. For the last one, recall that the exponentially weighted norm is defined by

\begin{align*}
|| f ||_\eta &= \sup_{x \in [-a, 0]} |e^{-\eta x} f(x) | && f \in C^0_\eta[-a, 0] \\
|| f ||_\eta &= \sup_{x \in [0, a]} |e^{\eta x} f(x) | && f \in C^0_\eta[0, a] \\
\end{align*}

\begin{align*}
R(\lambda) &= \lambda\left( \int_{-\infty}^0 \langle \Psi(y), (K^- B W^-)(y) \rangle dy - \int_\infty^0 \langle \Psi(y), (K^+ B W^+)(y) \rangle dy \right) \\
|R(\lambda)| &\leq |\lambda|\left( \int_{-\infty}^0 C e^{\alpha_* y} \int_{-\infty}^y |w^-(z)| dz dy + \int_0^\infty C e^{-\alpha_* y} \int_y^\infty |w^+(z)| dz dy \right) \\
&= |\lambda|\left( \int_{-\infty}^0 C e^{\alpha_* y} \int_{-\infty}^y e^{\alpha z} |e^{-\alpha z} w^-(z)| dz dy + \int_0^\infty C e^{-\alpha_* y} \int_y^\infty e^{-\alpha z} |e^{\alpha z}w^+(z)| dz dy \right)\\
&\leq C |\lambda| ||W_3(\lambda)||_\alpha \left( \int_{-\infty}^0 e^{\alpha_* y} \int_{-\infty}^y e^{\alpha z} dz dy + \int_0^\infty e^{-\alpha_* y} \int_y^\infty e^{-\alpha z} dz dy \right)\\
&= \frac{C}{\alpha} |\lambda|^2 \left( \int_{-\infty}^0 e^{(\alpha_* + \alpha) y} dy + \int_0^\infty e^{-(\alpha_* + \alpha) y} \right) dy \\
&= \frac{2 C}{\alpha(\alpha + \alpha_*)} |\lambda|^2 
\end{align*}

So we should have for our jump

\[
\xi = M + R(\lambda)
\]

where $M$ is given above and we have the above estimate for the remainder $R(\lambda)$.\\

We know what the deal is in this case, i.e. there is no nonzero eigenvalue near 0 for the single pulse. Thus we should not be able to get the jump to be 0, although it is not clear at all that this is the case by looking at what we did above.

\end{document}