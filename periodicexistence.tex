\documentclass[12pt]{article}
\usepackage[pdfborder={0 0 0.5 [3 2]}]{hyperref}%
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}%
\usepackage[shortalphabetic]{amsrefs}%
\usepackage{amsmath}
\usepackage{enumerate}
% \usepackage{enumitem}
\usepackage{amssymb}                
\usepackage{amsmath}                
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage{float}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{mathtools}
\usepackage{cool}
\usepackage{url}
\usepackage{graphicx,epsfig}
\usepackage{makecell}
\usepackage{array}

\def\noi{\noindent}
\def\T{{\mathbb T}}
\def\R{{\mathbb R}}
\def\N{{\mathbb N}}
\def\C{{\mathbb C}}
\def\Z{{\mathbb Z}}
\def\P{{\mathbb P}}
\def\E{{\mathbb E}}
\def\Q{\mathbb{Q}}
\def\ind{{\mathbb I}}

\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\ran}{range}

\graphicspath{ {periodic/} }

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{hypothesis}{Hypothesis}

\newtheorem{notation}{Notation}

\begin{document}

\section{KdV5 with Periodic Boundary Conditions}

\subsection{Background}

In this section we will look at multipulse solutions to KdV5 in the case where we have periodic boundary conditions. Note that we cannot use an exponential weight in this case since our domain is of finite length. A periodic $n$-pulse is parameterized by the $n$ lengths $X_0, \dots, X_{n-1}$, where in general we will want one of the $X_i$ (representing the ``periodic piece'') to be larger than the others. (Since we have a periodic domain, for convenience we index the lengths starting with $X_0$ so that all the subscripts will be $\mod n$.) A diagram of a 2-pulse is shown below.

\begin{figure}[H]
\includegraphics[width=8.5cm]{dpimage}
\end{figure}

Let $X_m = \min \{ X_0, \dots, X_{n-1} \}$ and $X_M = \max \{ X_0, \dots, X_{n-1} \}$. Since we are on a periodic domain, we will always WLOG take $X_m = X_0$.\\

We would like to write the periodic double pulse as a small (piecewise) perturbation of the single pulse as was done in San98 (and San93). The method in those papers, however, does not give us the estimates we need. Instead, we will give another construction based on San97. This boils down to proving existence of the periodic double pulse, which is what we shall do. We assume that $c > 1/4$, since that is necessary for the existence of multipulses to KdV5. Thus the eigenvalues of the linearization about $0$ are complex and given by $\pm \alpha \pm \beta i$.\\

Since we are only interested in the existence problem here, we can use the 4th order (integrated) equation in the traveling frame

\begin{equation}\label{4thorder}
f(u) = u_{xxxx} - u_{xx} + c u - u^2 = 0
\end{equation}

This equation is Hamiltonian, with energy 

\begin{equation}\label{4thorderE}
H(u) = u_x u_{xxx} - \frac{1}{2}u_{xx}^2 - \frac{1}{2}u_x^2 + \frac{c}{2}u^2 - \frac{1}{3}u^3
\end{equation}

The Hamiltonian is conserved for any solution $u$ to \eqref{4thorder} since

\begin{align*}
\frac{d}{dx}H(u) = u_x(u_{xxxx} - u_{xx} + c u - u^2) = 0
\end{align*}

In what follows, we will write the problem as a first order system, i.e. we will take $U = (u_1, u_2, u_3, u_4) = (u, u_x, u_{xx}, u_{xxx})$. Then the problem becomes

\begin{equation}\label{4thordersystem}
U' = F(U) = \begin{pmatrix} 
u_2 \\ u_3 \\ u_4 \\ u_3 - c u_1 + u_1^2
\end{pmatrix}
\end{equation}

The Hamiltonian then takes the form

\begin{equation}
H(u_1, u_2, u_3, u_4) = u_2 u_4 - \frac{1}{2}u_3^2 - \frac{1}{2}u_2^2 + \frac{c}{2}u_1^2 - \frac{1}{3}u_1^3
\end{equation}

The gradient of the Hamiltonian is

\begin{equation}
\nabla H = (cu_1 - u_1^2, -u_2 + u_4, -u_3, u_2)
\end{equation}

It is straightforward to verify that $\langle F(U), \nabla H(U) \rangle = 0$ for all $U$.\\

The way we have written this, we can write our equation as $U' = \tilde{J} \nabla H$, where

\[
\tilde{J} = \begin{pmatrix}
0 & 0 & 0 & 1 \\
0 & 0 & -1 & 0 \\
0 & 1 & 0 & 1 \\
-1 & 0 & -1 & 0 \\
\end{pmatrix}
\]

This is not the standard symplectic matrix $J$, but $\tilde{J}$ is invertible and skew symmetric. \\

We note that 0 is an equilibrium of the system. Let $Q(x)$ be a homoclinic orbit connecting the equilibrium at 0 to itself. Such a homoclinic orbit is known to exist. Then since $Q(0)$ is not an equilibrium point of the system, we also know that $\nabla H(Q(0)) \neq 0$ since $\tilde{J}$ is invertible.

\subsection{Existence and Construction of Periodic Multipulses}

We look at the general equation

\begin{equation}\label{generaleq}
U'(x) = F(U)
\end{equation}

where $U \in \R^{2m}$ and $F$ is real-valued. (This should also extend to the complex-valued case.)\\

We take the following assumptions.

\begin{hypothesis}\label{assumptions}
\[\]
\begin{enumerate}
	\item $U = 0$ is a hyperbolic equilibrium of \eqref{generaleq}.
	\item There exists a homoclinic orbit $Q(x)$ connecting the equilibrium at 0 to itself.
	\item We have a nondegeneracy condition
	\[
	T_{Q(0)} W^u(0) \cap T_{Q(0)} W_s(0) = \R Q'(0)
	\]
	\item At least one of the following is true:
	\begin{enumerate}
		\item The system is reversible, and the homoclinic orbit $Q(x)$ is symmetric.
		\item The system is Hamiltonian, and $\nabla H(Q(0)) \neq 0$, where $H$ is the Hamiltonian energy
	\end{enumerate}
\end{enumerate}
\end{hypothesis}

By the nondegeneracy hypothesis, there exists a unique, bounded solution $\Psi(x)$ to the adjoint variational equation

\begin{equation}
W' = -D_U F(Q(x))^* W
\end{equation}

If we assume the system is Hamiltonian, we actually know the specific form of $\Psi(x)$.

% Lemma : Hamiltonian case

\begin{lemma}

If $U'(x) = F(U)$ is Hamiltonian, then

\begin{equation}
\Psi(x) = \nabla H(Q(x))
\end{equation}

where $H$ is the Hamiltonian energy associated with the system.

\begin{proof}

If the system is Hamiltonian, then $\langle F(Q(x)), \nabla H(Q(x)) \rangle = 0$ for all $x$. Taking the gradient of this and using known vector calculus identities, we have

\begin{align*}
0 &= \nabla \langle F(Q(x)), \nabla H(Q(x)) \rangle \\
&= D F(Q(x))^* \nabla H(Q(x)) + D^2 H(Q(x))^* F(Q(x)) \\
&= D F(Q(x))^* \nabla H(Q(x)) + D^2 H(Q(x)) Q'(x) \\
&= D F(Q(x))^* \nabla H(Q(x)) + \frac{d}{dx} \nabla H(Q(x))
\end{align*}

since the Hessian matrix is self-adjoint. Rearranging this, we have

\begin{equation}
\frac{d}{dx} \nabla H(Q(x)) = -D F(Q(x))^* \nabla H(Q(x)) 
\end{equation}

thus $\nabla H(Q(x))$ is a solution to the adjoint variational equation. Since $\nabla H$ is continuous and $Q(x)$ is bounded (even better, it decays exponentially to 0), so is $\nabla H(Q(x))$. By the nondegeneracy condition, there is a unique such solution, so we must have $\Psi(x) = \nabla H(Q(x))$.

\end{proof}
\end{lemma}

Next, we parameterize the stable and unstable manifolds near $Q(0)$. To do that we first write

\begin{align*}
T_{q(0)}W^u(0) &= \R Q'(0) \oplus Y^- \\
T_{q(0)}W^s(0) &= \R Q'(0) \oplus Y^+ \\
Z &= \R \Psi(0)
\end{align*}

By Hypothesis \ref{assumptions},

\[
\R^4 = \R Q'(0) \oplus Y^+ \oplus Y^- \oplus Z
\]
 
We have shown before that $Z$ is perpendicular to the other three. \\

We now write $W^u(0)$ and $W^s(0)$ as graphs over their own tangent spaces near $Q(0)$. Following San97, we can parameterize the unstable and stable manifolds near $Q(0)$ by the smooth functions

\begin{align*}
Q^-(\alpha, \beta^-) \\
Q^+(\alpha, \beta^+)
\end{align*}

where $\alpha \in \R$, $\beta^\pm \in Y^\pm$ and we have set things up so that $Q^+(\alpha, 0) - Q^-(\alpha, 0) \in Z$. Note that $Q^+(0, 0) = Q^-(0, 0) = Q(0)$. The parameter $\alpha$ is a phase parameter (which we will always take to be 0); although we could ignore it in our parameterization, we include it here to indicate that both manifolds are two-dimensional. \\

Next, we define the trajectories

\begin{align*}
Q^-(\alpha, \beta^-)(x) && x \leq 0 \\
Q^+(\alpha, \beta^-)(x) && x \geq 0
\end{align*}

which are the unique solutions to $U' = F(U)$ with ICs $Q^\pm(\alpha, \beta^\pm)$ for appropriate $x$. Note that since the ICs are on the stable/unstable manifolds, these decay exponentially in the appropriate direction with rate $\alpha$.\\

Using the parameterizations of the stable and unstable manifolds, we write the solution $U$ piecewise for $i = 0, \dots, n-1$ as

\begin{align*}
U_i^-(x) &= Q^-(0, \beta_i^-)(x) + V_i^-(x) && x \leq 0 \\
U_i^+(x) &= Q^+(0, \beta_i^+)(x) + V_i^+(x) && x \geq 0
\end{align*}

In essence, we are writing $U$ in terms of $2n$ parameters $\beta_i^\pm$ (representing ICs on the stable/unstable manifolds) and $n$ ``remainder'' functions $V_i^\pm(x)$.\\

We will choose $V_i^\pm(x)$ so that

\begin{align*}
V_i^-(0) &\in Z \oplus Y^- \\
V_i^+(0) &\in Z \oplus Y^+
\end{align*}

since the other directions are covered by $\beta_i^\pm$ (and $\alpha$, but we set that equal to 0).\\

Thus the problem we need to solve to construct the periodic multipulse is

\begin{align}
(U_i^\pm)' - F(U_i^\pm) &= 0 \\
U_i^+(X_i) - U_{i+1}^-(-X_i) &= 0 \\
U_i^+(0) - U_i^-(0) &= 0;
\end{align}

for $i = 0, \dots, {n-1}$. The subscripts are all mod $n$; in particular, $U_n^- = U_0^-$.\\

Let $\Phi_\pm(x, y; \beta^\pm)$ be the family of evolution operators for the variational equations

\begin{equation}
(V^\pm)' = D_U F(Q^\pm(0, \beta^\pm)(x)) V^\pm
\end{equation}

where these are defined on the appropriate interval. We can decompose these evolution operators via an exponential dichotomy.

\begin{lemma}\label{dichotomy1}
There exist projections

\begin{align*}
&P_+^s(y; \beta^+) && y \geq 0 \\
&P_+^u(y; \beta^+) = I - P_+^s(y; \beta^+) && y \geq 0 \\
&P_-^u(y; \beta^-) && y \leq 0 \\
&P_-^s(y; \beta^-) = I - P_-^u(y; \beta^-) && y \leq 0 \\
\end{align*}

such that the evolution operators $\Phi_\pm(x, y; \beta^\pm)$ can be decomposed as

\begin{align*}
\Phi^s_\pm(x, y; \beta^\pm) &= \Phi_\pm(x, y; \beta^\pm) P^s_\pm(y; \beta^\pm) \\
\Phi^u_\pm(x, y; \beta^\pm) &= \Phi_\pm(x, y; \beta^\pm) P^u_\pm(y; \beta^\pm) 
\end{align*}

where we have the estimates

\begin{align*}
|\Phi^s_+(x, y, \beta^+)| &\leq C e^{-\alpha(x - y)} && 0 \leq y \leq x \\
|\Phi^u_+(x, y, \beta^+)| &\leq C e^{-\alpha(y - x)} && 0 \leq x \leq y \\
|\Phi^u_-(x, y, \beta^+)| &\leq C e^{-\alpha(y - x)} && 0 \geq y \geq x \\
|\Phi^s_-(x, y, \beta^+)| &\leq C e^{-\alpha(x - y)} && 0 \geq x \geq y \\
\end{align*}

which also hold for derivatives with respect to the ICs $\beta^\pm$. In addition, the projections satisfy 

\begin{align*}
\Phi_\pm(x, y; \beta^\pm) P^{s/u}_\pm(y; \beta^\pm) 
= P^{s/u}_\pm(x; \beta^\pm) \Phi_\pm(x, y; \beta^\pm)
\end{align*}

i.e. it does not matter if we project or evolve first. Finally, the projections can be chosen such that at $y = 0$ we have, independent of $\beta^+$ and $\beta^-$

\begin{align*}
\ker P^s_+(0; \beta^+) &= Z \oplus Y^- \\
\ker P^u_-(0; \beta^-) &= Z \oplus Y^+ \\
\ran P^u_+(0; \beta^+) &= Z \oplus Y^- \\
\ran P^s_-(0; \beta^-) &= Z \oplus Y^+
\end{align*}

\begin{proof}
Since $D_U F(0)$ is hyperbolic by assumption, this follows from Lemma 5.1 in San97, which follows from Lemma 1.1 in San93.
\end{proof}
\end{lemma}

The next lemma is a bound on the difference between the exponential dichotomy projections and the projections onto the stable and unstable eigenspaces.

% lemma : bound on projection difference

\begin{lemma}\label{p1}

Let 

\begin{equation}
p_1(X; \beta^+, \beta^-) = \sup_{x \geq X} (|P^u_+(x; \beta^+) - P_0^u| + |P^s_-(-x; \beta^-) - P_0^s|)
\end{equation}

Then we have the $X$-dependent bound

\begin{equation}
p_1(X; \beta^+, \beta^-) = \mathcal{O}(e^{-\alpha X})
\end{equation} 

\begin{proof}
This should follow from Lemma 1.1 in San93 (doesn't everything?) and is used in San98. Unfortunately, I don't really understand that lemma, so I will look for a reference I actually understand.
\end{proof}
\end{lemma}

% rewrite as 1st order system

Next, we rewrite the problem $U'(x) = F(U)$ in piecewise fashion in such a way as to exploit what we did above. We want to solve piecewise

\begin{align*}
(U_i^\pm(x))' &= (Q^\pm(0, \beta_i^\pm)(x))' + (V_i^\pm(x))' = F\left(Q^\pm(0, \beta_i^\pm)(x) + V_i^\pm(x) \right) \\
\end{align*}

for $i = 0, \dots, n-1$. Using the fact that (by construction) $Q^\pm(0, \beta_i^\pm)(x)$ solves $U'(x) = F(U)$ on the appropriate interval, this becomes

\begin{align*}
F(Q^\pm(0, \beta_i^\pm)(x)) + (V_i^\pm(x))' &= F(Q^\pm(0, \beta_i^\pm)(x) + V_i^\pm(x) )
\end{align*}

Solving for $(V_i^\pm(x))'$, we have

\begin{align*}
(V_i^\pm(x))' &= F(Q^\pm(0, \beta_i^\pm)(x) + V_i^\pm(x) ) - F(Q^\pm(0, \beta_i^\pm)(x) )
\end{align*}

Now we Taylor about $F(Q^\pm(0, \beta_i^\pm)(x)$ to get the equivalent formulation

\begin{equation}\label{Vpiecewise}
(V_i^\pm(x))' = D_U F(Q^\pm(0, \beta_i^\pm)(x)) V_i^\pm(x)  + G_i^\pm(\beta_i^\pm, V_i^\pm)(x)
\end{equation}

where 

\begin{equation}\label{Gquadratic}
G_i^\pm(\beta_i^\pm, V_i^\pm)(x) = \mathcal{O}(|V_i^\pm|^2)
\end{equation}

independent of the parameters $\beta_i^\pm$. The fact that this is bound is independent of the $\beta_i^\pm$ follows from the fact that we have bounds on $Q^\pm(0, \beta_i^\pm)$ which are independent of $\beta_i^\pm$. Derivatives of $G_i^\pm$ with respect to the parameters $\beta_i^\pm$ are the same order in $V_i^\pm$.\\

At this point, we rewrite the (piecewise) differential equations \eqref{Vpiecewise} in integrated form as fixed point equations. Recall again that the subscripts are mod $n$, so that, for example, $X_0 = X_n$. Thus we have

\begin{align*}
V_i^+(x) &= \Phi^u_+(x, X_i; \beta_i^+) a_i^+  \\
&+ \int_{X_i}^x \Phi_+^u(x, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy \\
&+ \int_0^x \Phi_+^s(x, y, \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy \\ 
V_i^-(x) &= \Phi^s_-(x, -X_{i-1}, \beta_i^-) a_{i-1}^-  \\
&+ \int_{-X_{i-1}}^x \Phi_-^s(x, y, \beta_i^-) G_i^-(y, V_i^-(y),\beta_i^-)dy \\
&+ \int_0^x \Phi_-^u(x, y, \beta_i^-) G_i^-(y, V_i^-(y),\beta_i^-)dy \\
\end{align*}

where for the initial conditions $a_i^\pm$ we have

\begin{align*}
a_i^+ &\in E_0^u \\
a_i^- &\in E_0^s \\
\end{align*}

Note that we do not have initial conditions $b_i^\pm$ at $x = 0$ for the other side of the dichotomy. Since these ICs would live in $Y^\pm$, we have incorporated them into the $\beta_i^\pm$.\\

Next, we define the exponentially weighted norms

\begin{align*}
||V||_{X, +} = \sup_{x \in [0, X]} e^{\alpha(X - x)}|V(x)| \\
||V||_{X, -} = \sup_{x \in [-X, 0]} e^{\alpha(X + x)}|V(x)| \\
\end{align*}

Let $K_{X, +}$ be the spaces on continuous functions on the appropriate intervals equipped with these norms. These are known to be Banach spaces. Let $B_{X, \pm}(\rho)$ be the ball of radius $\rho$ in these spaces.\\

We will solve for the $V_i^\pm$ and the $\beta_i^\pm$ in a series of lemmas.\\

First, we solve for the functions $V_i^\pm(x)$ in terms of the initial conditions $a_i^\pm$. Note that $V_i^+(x)$ only depends on $a_i^+$ and $V_i^-(x)$ only depends on $a_{i-1}^-$

% lemma : solve for V_i^\pm

\begin{lemma}
There exist $\delta, \rho > 0$ such that for $|X_i| > 1/\delta$ and $|\beta_i^\pm| < \delta$, there exist unique solutions

\begin{align*}
V_i^-(a_{i-1}, \beta_i^-) &\in B_{X_{i-1}, -}(\rho) \\
V_i^+(a_i, \beta_i^+) &\in B_{X_i, +}(\rho) \\
\end{align*}

These depend smoothly on the $\beta_i^\pm$, and we have the estimates

\begin{align*}
||V_i^-||_{X_{i-1}, -} &\leq C |a_{i-1}^-| \\
||V_i^+||_{X_i, +} &\leq C |a_i^+|
\end{align*}

The estimates hold as well for derivatives of $V_i^\pm$ with respect to $\beta_i^\pm$.

\begin{proof}
This should just be Lemma 5.2 in San97. The following is a mostly filled-in version of that proof.\\

We can deal with the $2n$ pieces separately, so let's do the ``positive'' pieces here. The RHS of the fixed point equations defines a smooth mapping on $K_{X_i, +}$ (basically obvious since everything involved is smooth, although we could check this). We need to verify that the RHS maps to $K_{X_i, +}$, so we check the three terms individually. We use our estimates on $\Phi^{s/u}_\pm$ from Lemma \ref{dichotomy1} and $G$ from \ref{Gquadratic} and the fact that $V_i^+ \in K_{X_i, +}$.\\

For the first term, we have

\begin{align*}
e^{\alpha(X_i - x)} | \Phi^u_+(x, X_i; \beta_i^+) a_i^+ | 
&\leq C e^{\alpha(X_i - {}x} e^{-\alpha(X_i - x)} |a_i^+| \\
&\leq C |a_i^+|
\end{align*}

For the second term,

\begin{align*}
e^{\alpha(X_i - x)} &\left| \int_{X_i}^x \Phi_+^u(x, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy  \right| \\
&\leq C e^{\alpha(X_i - x)} \int_x^{X_i} e^{-\alpha(y - x)}|V_i^+(y)|^2 dy \\
&\leq C e^{\alpha(X_i - x)} \int_x^{X_i} 
e^{-\alpha(y - x)}(e^{-\alpha(X_i - y)})^2|e^{\alpha(X_i - y)} V_i^+(y)|^2 dy \\
&\leq C e^{\alpha(X_i - x)} \int_x^{X_i} 
e^{-\alpha(y - x)}(e^{-\alpha(X_i - y)})^2 dy \\
&\leq C \int_0^{X_i} e^{-\alpha (X_i - y)} dy \\
&\leq C
\end{align*}

The third term is similar. Thus the RHS of the fixed point equations does indeed map $K_{X_i, +}$ to itself.\\

Now that we know what spaces things live in, define 
$H: K_{X_i, +} \times E_0^s \rightarrow K_{X_i, +}$ by

\begin{align*}
H(V_i^+(x), a_i^+, \beta_i^+) &= V_i^+(x) - \Phi^u_+(x, X_i; \beta_i^+) a_i^+  \\
&- \int_{X_i}^x \Phi_+^u(x, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy \\
&- \int_0^x \Phi_+^s(x, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy 
\end{align*}

Since $Q(x)$ satisfies the original ODE, we know that $H(0, 0, 0) = 0$. We can check that the Frechet derivative of $H$ with respect to $V_i^+$ at $(V_i^+(x), a_i^+, \beta_i^+) = (0, 0, 0)$ is a Banach space isomorphism on $K_{X_i, +}$. Then using the implicit function theorem, we can solve for $V_i^+(x)$ in terms of $(a_i^+, \beta_i^+)$. This dependence is smooth, since the map $H$ is smooth. $V_i^-(x)$ is similar. \\

The estimate on $V_i^\pm$ comes from the estimate of the first term on the RHS of the fixed point equations, since the other terms (those involving the integrals) are quadratic in $V_i^\pm$. 

\end{proof}
\end{lemma}

Next, we look at the conditions $U_i^+(X_i) - U_{i+1}^-(-X_i) = 0$.

% Lemma : solve for a_i^\pm

\begin{lemma}\label{solvefora}
For any $X_i$ and $\beta_i^\pm$ chosen as in the previous lemma, there is a unique pair of initial conditions $(a_i^+, a_i^-) \in E_0^s \times E_0^u$ such that $U_i^+(X_i) - U_{i+1}^-(-X_i) = 0$. $(a_i^+, a_i^-)$ depends smoothly on $(\beta_i^+, \beta_{i+1}^-)$, and we have the following estimate, which is independent of $(\beta_i^+, \beta_{i+1}^-)$.

\begin{equation}
|a_i^\pm| \leq C e^{-\alpha X_i}
\end{equation}

which holds for $a_i^\pm$ as well as derivatives with respect to $\beta_i^\pm$.\\

We also have the following expressions for the $a_i^\pm$

\begin{align*}
a_i^+ &= P^s_0 \left( Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i) \right) 
+ \mathcal{O}( e^{-2 \alpha X_i} )\\
a_i^- &= P^u_0 \left( Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i) \right) 
+ \mathcal{O}( e^{-2 \alpha X_i} )
\end{align*}

\begin{proof}

First, plug in the fixed point equations to the expressions for $U_i^+$ and $U_{i+1}^-$ and evaluate them at $\pm X_i$ to get
\begin{align*}
U_i^+(X_i) &= Q^+(0, \beta_i^+)(X_i) + P^u_+(X_i; \beta_i^+) a_i^+ \\
&+ \int_0^{X_i} \Phi_+^s(X_i, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy \\ 
U_{i+1}^-(-X_i) &= Q^-(0, \beta_{i+1}^-)(-X_i) + P^s_-(-X_i; \beta_{i+1}^-) a_i^- \\
&+ \int_0^{-X_i} \Phi_-^u(-X_i, y; \beta_{i+1}^-) G_{i+1}^-(y, V_{i+1}^-(y),\beta_{i+1}^-)dy \\
\end{align*}

Adding and subtracting $P_0^{s/u}$ and recalling where the $a_i^\pm$ live, this becomes

\begin{align*}
U_i^+(X_i) &= Q^+(0, \beta_i^+)(X_i) + a_i^+ + (P^u_+(X_i; \beta_i^+) -  P^u_0)a_i^+ \\
&+ \int_0^{X_i} \Phi_+^s(X_i, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy \\ 
U_{i+1}^-(-X_i) &= Q^-(0, \beta_{i+1}^-)(-X_i) + a_i^- + (P^s_-(-X_i; \beta_{i+1}^-) - P^s_0) a_i^- \\ 
&+ \int_0^{-X_i} \Phi_-^u(-X_i, y; \beta_{i+1}^-) G_{i+1}^-(y, V_{i+1}^-(y),\beta_{i+1}^-)dy \\
\end{align*}

Subtracting these, we obtain the equation we need to solve

\begin{align*}
0 &= H(a_i^+, a_i^-, \beta_i^+, \beta_{i+1}^-) \\
&= a_i^+ - a_i^- + (P^u_+(X_i; \beta_i^+) -  P^u_0)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-) - P^s_0) a_i^-  \\
&+ Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i)\\
&+ \int_0^{X_i} \Phi_+^s(X_i, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy
- \int_0^{-X_i} \Phi_-^u(-X_i, y; \beta_{i+1}^-) G_{i+1}^-(y, V_{i+1}^-(y),\beta_{i+1}^-)dy 
\end{align*}

where $H: E_0^s \times E_0^u \times \R \times \R \rightarrow \R^4$. In the previous lemma, we solved for $V_i^\pm$ in terms of the $a_i^\pm$ and $\beta_i^\pm$, so we plug that in to get

\begin{align*}
H(a_i^+, &a_i^-, \beta_i^+, \beta_{i+1}^-) \\
&= a_i^+ - a_i^- + (P^u_+(X_i; \beta_i^+) -  P^u_0)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-) - P^s_0) a_i^-  \\
&+ Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i)\\
&+ \int_0^{X_i} \Phi_+^s(X_i, y; \beta_i^+) G_i^+(y, V_i^+(a_i^+, \beta_i^+)(y),\beta_i^+)dy \\
&- \int_0^{-X_i} \Phi_-^u(-X_i, y; \beta_{i+1}^-) G_{i+1}^-(y, V_{i+1}^-(a_i^-, \beta_{i+1}^-)(y),\beta_{i+1}^-)dy 
\end{align*}

Again, note that $H(0, 0, 0, 0) = 0$. We want to solve for $a_i^\pm$ using the implicit function theorem, so we need to look at $D_{a_i^\pm} H(0, 0, 0, 0)$.\\

When we differentiate with respect to $a_i^\pm$ at $a_i^\pm = 0$, we note that the the derivatives of the integral terms in $H$ will be 0 since $G_i^\pm$ is quadratic order in $V_i^\pm$, thus quadratic order in $a_i^\pm$ by the previous lemma. The $Q^\pm$ terms do not involve $a_i^\pm$.\\

Thus, taking the partial derivative with respect to $a_i^\pm = 0$, we get

\[
\frac{\partial}{\partial a_i^\pm} H(0, 0, 0, 0) = \pm 1 + \mathcal{O} (e^{-\alpha X_i})
\]

Thus, for sufficiently large $X_i$, $D_{a_i^\pm} H(0, 0, 0, 0)$ is invertible in a neighborhood of $(0, 0, 0, 0)$, so we can use the IFT to solve for $a_i^\pm$ in terms of $\beta_i^\pm$. \\

Now that we have found $a_i^\pm$ which satisfies the $H(a_i^+, a_i^-, \beta_i^+, \beta_{i+1}^-) = 0$, we can get an expression and estimates for the $a_i^\pm$. Recalling the spaces $a_i^\pm$ live in, we apply the projection $P^s_0$ to get

\begin{align*}
0 &= a_i^+ + P^s_0(P^u_+(X_i; \beta_i^+) -  P^u_0)a_i^+ 
+ P^s_0 \left( Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i) \right)\\
&+ P^s_0 \left( \int_0^{X_i} \Phi_+^s(X_i, y; \beta_i^+) G_i^+(y, V_i^+(a_i^+, \beta_i^+)(y),\beta_i^+)dy \right) \\
&- P^s_0 \left( \int_0^{-X_i} \Phi_-^u(-X_i, y; \beta_{i+1}^-) G_{i+1}^-(y, V_{i+1}^-(a_i^-, \beta_{i+1}^-)(y),\beta_{i+1}^-) dy \right)
\end{align*}

We have estimates for all of these terms. For the first two terms, we have

\begin{align*}
|P^s_0(P^u_+(X_i; \beta_i^+) -  P^u_0)a_i^+ | &\leq C e^{-\alpha X_i} |a_i^+| \\
|P^s_0 \left( Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i) \right)| &\leq C e^{-\alpha X_i}.
\end{align*}

using Lemma \ref{p1}. For the integral terms, we have

\begin{align*}
\left| \int_0^{X_i} \Phi_+^s(X_i, y; \beta_i^+) G_i^+(y, V_i^+(a_i^+, \beta_i^+)(y),\beta_i^+)dy \right| &\leq C \int_0^{X_i}e^{-\alpha(X_i - y)} |V_i^+(y)|^2 dy \\
&\leq C \int_0^{X_i}e^{-3 \alpha (X_i - y)} |e^{\alpha(X_i - y)} V_i^+(y)|^2 dy \\
&\leq C \int_0^{X_i}e^{-3 \alpha (X_i - y)} (||V_i^+||_{X_i, +})^2 dy \\
&\leq C |a_i^+|^2
\end{align*}

The other integral term is similar. In a hand-wavey fashion, we have something which looks like

\[
|a_i^+|(1 + \mathcal{O}(e^{-\alpha X_i}) + \mathcal{O}(|a_i^+|)) = 
\mathcal{O}( e^{-\alpha X_i} )
\]

which should give us the estimate we want

\begin{align*}
|a_i^\pm| \leq C e^{-\alpha X_i}
\end{align*}

To get an actual expression for $a_i^\pm$, we plug in all our estimates to get

\begin{align*}
a_i^+ = P^s_0 \left( Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i) \right) 
+ \mathcal{O}( e^{-2 \alpha X_i} )
\end{align*}

Similarly, we have

\begin{align*}
a_i^- = P^u_0 \left( Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i) \right) 
+ \mathcal{O}( e^{-2 \alpha X_i} )
\end{align*}

\end{proof}
\end{lemma}

Finally, we need the pieces to match at $x = 0$. In other words, we need to find $\beta_i^\pm$ such that $U_i^+(0) = U_i^-(0)$, i.e. 

\begin{align*}
Q^+(0, \beta_i^+) + V_i^+(0) &= Q^-(0, \beta_i^-) + V_i^-(0) && i = 0, \dots, n-1
\end{align*}

Before we do that, we will need to make a smooth change of coordinates near $Q(0)$. We will do that using a variation of the ``flow-box'' method. What we want to do is straighten out the stable and unstable manifolds near $Q(0)$ so that their non-intersecting directions lie along $Y^+$ and $Y^-$.

% lemma : straighten out manifolds

\begin{lemma}\label{straightenW}

There exists a differentiable map 

\[
H: \R \times Y^- \times Y^+ \times Z \rightarrow \R^4
\]

such that $H(0, 0, 0, 0) = Q(0)$, $H$ is invertible in a neighborhood of $Q(0)$, and

\begin{align*}
H^{-1}(Q^-(0, \beta^-) &= \beta^- \in Y^- \\
H^{-1}(Q^+(0, \beta^+) &= \beta^+ \in Y^+ \\
\end{align*}

for sufficiently small $\beta^\pm$.

\begin{proof}
We know that $Q'(0) = F(Q(0)) \neq 0$, i.e. the center of the pulse is not an equilibrium of the vector field $F$. Recall that $\R^4 = Z \oplus \R Q'(0) \oplus Y^+ \oplus Y^-$.\\

Let $S_y(P)$ be the solution operator for the ODE $U' = F(U)$, i.e. the operator which takes an initial condition $P$ and maps it to the point $H(y)$, where $H$ is the unique solution to $U' = F(U)$ such that $H(0) = P$.\\

Define the map $H: \R \times Y^- \times Y^+ \times Z \rightarrow \R^4$ by 

\begin{equation}
H(y; \beta^-, \beta^+, \gamma) = S_y(Q(0) + Q^-(0, \beta^-) + Q^-(0, \beta^+) + \gamma \Psi(0))
\end{equation}

In other words, $H(y; \beta^-, \beta^+, \gamma)$ is a trajectory of $U' = F(U)$ with initial condition $Q(0) + Q^-(\beta^-,0) + Q^-(\beta^+,0) + \gamma \Psi(0)$.\\ 

Near $Q(0)$, i.e. for small $x, \beta^\pm$ the stable and unstable manifolds are given by the curves

\begin{align*}
W^u &= H(x; \beta^-, 0, 0) \\
W^s &= H(x; 0, \beta^+, 0) 
\end{align*}

Their one-dimensional intersection is the homoclinic orbit $Q(x) = H(x; 0, 0, 0)$, whose tangent space is $Q'(x)$.\\

To complete the proof, we need to show that $H$ is invertible in a neighborhood of the origin. To compute the Jacobian of $H$ at the origin, we note the following.

\begin{align*}
H_y(0, 0, 0, 0) &= F(Q(0)) = Q'(0) \\
H_{\beta^-}(0, 0, 0, 0) &= (Q^-)_{\beta^-}(0,0) = Y^- \\
H_{\beta^+}(0, 0, 0, 0) &= (Q^+)_{\beta^+}(0,0) = Y^+ \\
H_{\gamma}(0, 0, 0, 0) &= Z
\end{align*}

Since $\R^4 = Z \oplus \R Q'(0) \oplus Y^+ \oplus Y^-$, the four partial derivatives of $H$ at the origin are linearly independent, thus the Jacobian of $H$ at the origin is invertible. Note that $H_y(0, 0, 0, 0) = Q(0)$. By the inverse function theorem, there exists open neighborhoods $N_1$ of 0 and $N_2$ of $Q(0)$ such that $H(N_1) = N_2$ and $H$ is invertible on $N_2$. \\

In particular, we have for sufficiently small $\beta^\pm$

\begin{align*}
H^{-1}(Q^-(0, \beta^-) &= \beta^- \in Y^- \\
H^{-1}(Q^+(0, \beta^+) &= \beta^+ \in Y^+ \\
\end{align*}

\end{proof}
\end{lemma}

Now we are ready to perform the match at $x = 0$ to solve for $\beta_i^\pm$. Before we do that, we change coordinates according to the prior lemma. In the new coordinates, near $Q(0)$ our ODE becomes

\begin{equation}
\tilde{U}' = DH(H^{-1}(\tilde{U})) F( H^{-1}(\tilde{U}) )
\end{equation}

where $H$ is defined in the previous lemma. If we match the $\tilde{U}_i^\pm$ at $x = 0$, then since $H^{-1}$ is a homeomorphism near $Q(0)$, we have also matched the $U_i^\pm$ at $x = 0$. For convenience, we will continue to write the ODE as $U' = F(U)$ after the coordinate change.\\

Note that because of our coordinate change, we have

\begin{align*}
P_Z(Q^\pm(0, \beta^\pm) &= 0 \\
P_{\R Q'(0)}(Q^\pm(0, \beta^\pm) &= 0 \\
P_{Y^\pm}(Q^\pm(\beta^\pm, 0)) &= \beta^\pm
\end{align*}

We wish to solve $U_i^+(0) - U_i^-(0) = 0$. Since $\R^4 = Z \oplus \R Q'(0) \oplus Y^+ \oplus Y^-$, it suffices to project this onto these four subspaces and solve separately on each subspace. Since $V_i^\pm(0) \in Z \oplus Y^\pm$, the projection on $\R Q'(0)$ is automatically 0. Thus we only need to solve the equations

\begin{align*}
P_{Y^\pm}(U_i^+(0) - U_i^-(0)) &= 0 \\
P_Z(U_i^+(0) - U_i^-(0)) &= 0 \\
\end{align*}

We will do each of these in turn. In the next lemma, we solve for $(\beta_i^+, \beta_i^-)$ for $i = 0, \dots, n-1$. We do this for each pair separately.

% lemma : solve for the \beta_i^\pm

\begin{lemma}\label{solveforbeta}
For $i = 0, \dots, n-1$ ,there exist $(\beta_i^+, \beta_i^-)$ such that $P_{Y^\pm}(U_i^+(0) - U_i^-(0)) = 0$ . We have the estimate

\begin{equation}
| (\beta_i^+, \beta_i^-) | \leq C (e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})
\end{equation}

\begin{proof}
Recall that $U_i^\pm = Q^\pm(0, \beta_i^\pm) + V_i^\pm$. Then since we have applied the change of coordinates above, we have

\begin{align*}
P_{Y^\pm}(Q^+(0, \beta_i^+) - Q^-(0, \beta_i^-)) &= \beta_i^+ - \beta_i^-
\end{align*}

Then the equation we want to solve becomes

\begin{equation}
H(\beta_i^+, \beta_i^-) = \beta_i^+ - \beta_i^- 
+ P_{Y^\pm}(V_i^+(0) - V_i^-(0)) = 0
\end{equation}

Substituting the fixed point equations evaluated at $x = 0$, we get

\begin{align*}
H(\beta_i^+, \beta_i^-) &= \beta_i^+ - \beta_i^- \\
&+ P_{Y^\pm} \Big( \Phi^u_+(0, X_i; \beta_i^+) a_i^+ 
+ \int_{X_i}^0 \Phi_+^u(0, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy \\
&- \Phi^s_-(0, -X_{i-1}, \beta_i^-) a_{i-1}^- 
- \int_{-X_{i-1}}^0 \Phi_-^s(0, y, \beta_i^-) G_i^-(y, V_i^-(y),\beta_i^-) dy \Big) 
\end{align*}

Next, since $\text{Ran }P_+^u(0; \beta^+) = Z \oplus Y^-$, the terms involving $\Phi^u_+$ can have no component in $Y^+$. Similarly, since $\text{Ran }P_-^s(0; \beta^-) = Z \oplus Y^+$, the terms involving $\Phi^s_-$ can have no component in $Y^-$. Thus we can separate our equation into the individual projections on $Y^-$ and $Y^+$. Redefining $H$ this way gives us

\begin{equation}
H(\beta^+, \beta^-) = 
\begin{pmatrix}
\beta_i^+ - P_{Y^+}\left(\Phi^s_-(0, -X_{i-1}, \beta_i^-) a_{i-1}^- 
- \int_{-X_{i-1}}^0 \Phi_-^s(0, y, \beta_i^-) G_i^-(y, V_i^-(y),\beta_i^-) dy\right) \\
\beta_i^- - P_{Y^-}\left( \Phi^u_+(0, X_i; \beta_i^+) a_i^+ 
+ \int_{X_i}^0 \Phi_+^u(0, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+)dy \right)
\end{pmatrix}
\end{equation}

Note the the $\beta_i^\pm$ ``mix''. What we would like to do now is invert this to solve for the $\beta_i^\pm$. This requires estimating the partial derivatives with respect to $\beta_i^\pm$ of the two terms. Since the estimates for $G$ and $\Phi$ also apply to the derivatives with respect to $\beta_i^\pm$, this is not hard to do.\\

For the $a_i^\pm$ terms we have

\begin{align*}
\left| \frac{\partial}{\partial \beta_i^+} \Phi^u_+(\beta_i^+, 0, X_i) a_i^+ \right| \leq C e^{-\alpha X_i}|a_i^+|
& \leq C e^{-2 \alpha X_i}
\end{align*}

where we used our estimate for $a_i^\pm$ from above. The $\beta_i^-$ term is similar, except it involves $X_{i-1}$. For the integral terms, we have

\begin{align*}
\left| \frac{\partial}{\partial \beta_i^-} \int_{-X_{i-1}}^0 \Phi_-^s(\beta_i^-, 0, y) G^-(y, V^-(y),\beta^-)dy \right| 
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} | V_i^-(y) |^2 dy \\
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} | |a_i^-|^2 dy \\
&\leq C e^{-2 \alpha X_{i-1}}
\end{align*}

where we used our estimates for $V_i^\pm$ and $a_i^\pm$ from above. The ``positive'' term is similar. \\

Putting all this together, the Jacobian of $H$ is given by

\begin{equation}
D H(\beta_i^+, \beta_i^-) = 
\begin{pmatrix}
1 & \mathcal{O}(e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} ) \\
\mathcal{O}(e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} ) &  1 
\end{pmatrix}
\end{equation}

which has determinant $1 + \mathcal{O}(e^{-4 \alpha X_i} + e^{-4 \alpha X_{i-1}})$, thus is invertible for sufficiently large $X_i$. Using the inverse function theorem, we can invert $H$ in a neighborhood of $Q(0)$, which corresponds to $(\beta_i^+, \beta_i^-) = (0, 0)$. Thus we have 

\[
(\beta^+, \beta^-) = H^{-1}(0, 0)
\]

We would like to get an estimate on this. By the inverse function theorem, $D H^{-1}$ is bounded in a neighborhood of $(0, 0)$, thus we have 

\begin{align*}
| (\beta_i^+, \beta_i^-) | &= | H^{-1}(0, 0) | \\
&= | H^{-1}(0, 0) - (0, 0) | \\
&= | H^{-1}(0, 0) - H^{-1}(H(0, 0)) | \\
& \leq C | (0, 0) - H(0, 0) | \\
& \leq C |H(0, 0)|
\end{align*}

Since $H(0, 0) \leq C (e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})$, this becomes

\[
| (\beta_i^+, \beta_i^-) | \leq C (e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})
\]

\end{proof}
\end{lemma}

Finally, we need to look at the projection on the adjoint solution $\Psi(0)$. To do this, we will show that this condition is satisfied for certain values of the lengths $X_i$. This makes sense based on what we know about the nonperiodic case.\\

Recall that from our change of coordinates we have
\begin{align*}
P_{Z}(Q^+(0, \beta_i^+) - Q^-(0, \beta_i^-)) &= 0
\end{align*}

Thus the equation we want to solve is

\begin{equation}
P_{Z^\pm}(V_i^+(0) - V_i^-(0)) = 0
\end{equation}

which we can write as

\begin{equation}
\langle \Psi(0), V_i^+(0) - V_i^-(0) \rangle = 0
\end{equation}

First, we come up with a nice expression for $\langle \Psi(0), V_i^+(0) - V_i^-(0) \rangle$. This agrees with (3.9) on p.2093 of SanStrut, which is good.

% first lemma for jump

\begin{lemma}\label{jumplemma1}

\begin{align*}
\langle \Psi(0), V_i^+(0) - V_i^-(0) \rangle = 
\langle \Psi(X_i), Q(-X_i) \rangle - \langle \Psi(-X_{i-1}), Q(X_{i-1}) \rangle + R_i
\end{align*}

where 

\begin{align*}
|R_i| \leq C ( e^{-3 \alpha X_i} +  e^{-3 \alpha X_{i-1}}
+ e^{-2 \alpha (X_i + X_{i+1})} + e^{-2 \alpha (X_{i-1} + X_i)})
\end{align*}

\begin{proof}

Substituting the fixed point equations evaluated at $x = 0$, we have

\begin{align*}
\langle \Psi(0), V_i^+(0) - V_i^-(0) \rangle &= \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+) a_i^+ \rangle
- \langle \Psi(0), \Phi^s_-(0, -X_{i-1}, \beta_i^-) a_{i-1}^- \rangle \\
&+ \int_{X_i}^0 \langle \Psi(0), \Phi_+^u(0, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+) \rangle dy \\
&- \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi_-^s(0, y, \beta_i^-) G_i^-(y, V_i^-(y),\beta_i^-) \rangle dy
\end{align*}

Before we continue, we note that for $x \geq 0$

\begin{align*}
|(\Phi_+^u(0, x; \beta^+) - \Phi_+^u(0, x; 0)| &\leq C |\beta^+| e^{-\alpha x} \\
|(\Phi_-^s(0, -x; \beta^-) - \Phi_-^s(0, -x; 0)| &\leq C |\beta^-| e^{-\alpha x} \\
\end{align*}

This follows from Lemma \ref{dichotomy1} together with smooth dependence on initial conditions. Together with the estimate on $\beta_i^\pm$ from Lemma \ref{solveforbeta}, we have for $x \geq 0$

\begin{align*}
|(\Phi_+^u(0, x; \beta_i^+) - \Phi_+^u(0, x; 0)| &\leq C e^{-\alpha x} (e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})\\
|(\Phi_-^s(0, -x; \beta_i^-) - \Phi_-^s(0, -x; 0)| &\leq C e^{-\alpha x} (e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}}) \\
\end{align*}

This implies for $x \geq 0$

\begin{align*}
|Q^+(0, \beta_i^+)(x) - Q(x)| \leq C e^{-\alpha x} (e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}}) \\
|Q^-(0, \beta_i^-)(-x) - Q(-x)| \leq C e^{-\alpha x} (e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}}) \\
\end{align*}

We also have the following estimate from Lemma \ref{p1}.

\begin{align*}
|P^u_+(X; \beta^+) - P_0^u| &\leq C e^{-\alpha X} \\
|P^s_-(-X; \beta^-) - P_0^s| &\leq C e^{-\alpha X}
\end{align*}

For $\langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+) a_i^+ \rangle $, we substitute for $a_i^+$ from Lemma \ref{solvefora} to get

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+) a_i^+ \rangle \\
&= \langle \Psi(0), \Phi_+(0, X_i; \beta_i^+) P^u_+(X_i; \beta_i^+) P^s_0 \left( Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i) \right) 
+ \mathcal{O}( e^{-2 \alpha X_i} ) \rangle \\
&= \langle \Psi(0), \Phi_+(0, X_i; \beta_i^+) P^u_+(X_i; \beta_i^+) P^s_0 \left( Q^+(0, \beta_i^+)(X_i) - Q^-(0, \beta_{i+1}^-)(-X_i) \right) \rangle  
+ \mathcal{O}( e^{-3 \alpha X_i} ) \\
&= \langle \Psi(0), \Phi_+(0, X_i; \beta_i^+) P^u_+(X_i; \beta_i^+) P^s_0 Q^+(0, \beta_i^+)(X_i) \rangle \\
&- \langle \Psi(0), \Phi_+(0, X_i; \beta_i^+) P^u_+(X_i; \beta_i^+) P^s_0 Q^-(0, \beta_{i+1}^-)(-X_i) \rangle
+ \mathcal{O}( e^{-3 \alpha X_i} ) \\
\end{align*}

For the first term on the RHS, we have

\begin{align*}
\langle \Psi(0), &\Phi_+(0, X_i; \beta_i^+) P^u_+(X_i; \beta_i^+) P^s_0 Q^+(0, \beta_i^+)(X_i) \rangle \\
&= \langle \Psi(0), \Phi_+(0, X_i; \beta_i^+) P^u_0 P^s_0 Q^+(0, \beta_i^+)(X_i) \rangle + \mathcal{O}(e^{-3 \alpha X_i}) \\
&= \langle \Psi(0), \Phi_+(0, X_i; \beta_i^+) P^s_0 P^u_0 Q^+(0, \beta_i^+)(X_i) \rangle + \mathcal{O}(e^{-3 \alpha X_i}) \\
&= \langle \Psi(0), \Phi_+(0, X_i; \beta_i^+) P^u_0 P^u_+(X_i; \beta_i^+) Q^+(0, \beta_i^+)(X_i) \rangle + \mathcal{O}(e^{-3 \alpha X_i}) \\
&= \langle \Psi(0), \Phi_+(0, X_i; \beta_i^+) P^u_0 P^u_+(X_i; \beta_i^+) \Phi_+(X_i, 0) Q^+(0, \beta_i^+)\rangle + \mathcal{O}(e^{-3 \alpha X_i}) \\
&= \langle \Psi(0), \Phi_+(0, X_i; \beta_i^+) P^u_0 \Phi_+(X_i, 0) P^u_+(0; \beta_i^+) Q^+(0, \beta_i^+)\rangle + \mathcal{O}(e^{-3 \alpha X_i}) \\
&= \mathcal{O}(e^{-3 \alpha X_i})
\end{align*}

From our change of coordinates, $Q^+(0, \beta_i^+) \in Y^+$, and this is wiped out by $P^u_+(0; \beta_i^+)$, which projects onto the unstable part of the exponential dichotomy on $\R^+$ at $x = 0$. We also used the fact that the spectral projections $P^u_0$ and $P^s_0$ commute. \\

For the second term on the RHS, we have

\begin{align*}
\langle \Psi(0), &\Phi_+(0, X_i; \beta_i^+) P^u_+(X_i; \beta_i^+) P^s_0 Q^-(0, \beta_{i+1}^-)(-X_i) \rangle \\
&= \langle \Psi(0), \Phi_+^u(0, X_i; \beta_i^+) P^s_-(-X_i; \beta_{i+1}^-) Q^-(0, \beta_{i+1}^-)(-X_i) \rangle + \mathcal{O}(e^{-3 \alpha X_i}) \\
&= \langle \Psi(0), \Phi_+^u(0, X_i; \beta_i^+) Q^-(0, \beta_i^-)(-X_i) \rangle + \mathcal{O}(e^{-3 \alpha X_i}) \\
&= \langle \Psi(0), \Phi(0, X_i) Q^-(0, \beta_{i+1}^-)(-X_i) \rangle + \mathcal{O}(e^{-3 \alpha X_i} + e^{-2 \alpha X_i} (e^{-2 \alpha X_i} + e^{-2 \alpha X_{i+1}})) \\
&= \langle \Psi(X_i), Q^-(0, \beta_i^-)(-X_i) \rangle + \mathcal{O}(e^{-3 \alpha X_i} + e^{-2 \alpha (X_i + X_{i+1})}) \\
&= \langle \Psi(X_i), Q(-X_i) \rangle + \mathcal{O}(e^{-3 \alpha X_i} + e^{-2 \alpha (X_i + X_{i+1})}) \\
\end{align*}

Thus we have

\begin{align*}
\langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+) a_i^+ \rangle
&= \langle \Psi(X_i), Q(-X_i) \rangle + \mathcal{O}(e^{-3 \alpha X_i} + e^{-2 \alpha (X_i + X_{i+1})})
\end{align*}

Similarly, we have

\begin{align*}
 \langle \Psi(0), \Phi^s_-(0, -X_{i-1}, \beta_i^-) a_{i-1}^- \rangle 
&= \langle \Psi(-X_{i-1}), Q(X_{i-1}) \rangle + \mathcal{O}(e^{-3 \alpha X_{i-1}} + e^{-2 \alpha (X_{i-1} + X_i)}) 
\end{align*}

For the integral terms, we have

\begin{align*}
\left| \int_{X_i}^0 \langle \Psi(0), \Phi_+^u(0, y; \beta_i^+) G_i^+(y, V_i^+(y),\beta_i^+) \rangle \right| dy &\leq C \int_0^{X_i} e^{-\alpha y} |V_i^+(y)|^2 dy \\
&\leq C \int_0^{X_i} e^{-\alpha y} e^{-2 \alpha(X_i - y)}|e^{-\alpha (X_i - y)} V_i^+(y)|^2 dy \\
&\leq C \int_0^{X_i} e^{-\alpha y} e^{-2 \alpha(X_i - y)}(||V_i^+||_{X_i, +})^2 dy \\
&\leq C e^{-\alpha X_i} \int_0^{X_i} e^{-\alpha (X_i - y)} |a_i^+|^2 dy \\
&\leq C e^{-3 \alpha X_i}
\end{align*}

The other integral term is similar, and is of order $e^{-3 \alpha X_{i-1}}$. Thus we have

\begin{align*}
\langle \Psi(0), V_i^+(0) - V_i^-(0) \rangle = 
\langle \Psi(X_i), Q(-X_i) \rangle - \langle \Psi(-X_{i-1}), Q(X_{i-1}) \rangle + R_i
\end{align*}

where 

\begin{align*}
|R_i| \leq C ( e^{-3 \alpha X_i} +  e^{-3 \alpha X_{i-1}}
+ e^{-2 \alpha (X_i + X_{i+1})} + e^{-2 \alpha (X_{i-1} + X_i)})
\end{align*}

We could probably simplify this, but it does not end up mattering.

\end{proof}
\end{lemma}

In the next lemma, we exploit symmetry properties to get an expression for $\langle \Psi(x), Q(-x) \rangle$.

% lemma : symmetry of IP

\begin{lemma}\label{otherIP}

For a reversible system, we have

\begin{equation}
\langle \Psi(x), Q(-x) \rangle = \langle \Psi(-x), Q(x) \rangle
\end{equation}

For a Hamiltonian system, for sufficiently large $|x|$ we have

\begin{equation}
\langle \Psi(x), Q(-x) \rangle = \langle \Psi(-x), Q(x) \rangle
+ \mathcal{O}(e^{-3 \alpha x})
\end{equation}

\begin{proof}
The reversibile case follows from Lemma 5.3 in San98. The Hamiltonian case follows from proof of Lemma 3.8 in SanStrut, where we flip the inner product since we are in a real vector space. 
\end{proof}
\end{lemma}

In order to have a multipulse solution, all that remains is to satisfy $V_i^+(0) - V_i^-(0) = 0$ along $\Psi(0)$ for all $i$. In the next lemma, we write down the set of equations we need to satisfy for this to be the case.

\begin{lemma}\label{IPsystem}
A periodic multipulse solution exists if and only if 

\begin{align}\label{jumpIPdiff}
\langle \Psi(-X_i), Q(X_i) \rangle - \langle \Psi(-X_{i-1}), Q(X_{i-1}) \rangle + R_i &= 0 && i = 0, \dots, n-1
\end{align}

where 

\begin{align*}
|R_i| = \mathcal{O} ( e^{-3 \alpha X_i} +  e^{-3 \alpha X_{i-1}}
+ e^{-2 \alpha (X_i + X_{i+1})} + e^{-2 \alpha (X_{i-1} + X_i)})
\end{align*}

\begin{proof}
We derived the equations we need to solve in Lemma \ref{jumplemma1}. Since we are assuming either a Hamiltonian system or reversibility, we use Lemma \ref{otherIP} to swap the signs on the first inner product in Lemma \ref{jumplemma1}. In the case of a Hamiltonian system, the $\mathcal{O}(e^{-3 \alpha X_i})$ term introduced when we change signs is incorporated into the remainder term $R_i$.
\end{proof}
\end{lemma}

In the next lemma, we exploit either reversibility or the Hamiltonian structure to simplify the set of equations we need to solve.

\begin{lemma}\label{IPsystemreduced}
If the system is reversible and we seek symmetric solutions, we only have to solve \eqref{jumpIPdiff} for $i = 0, \dots, \lceil \frac{n}{2} \rceil - 1$. If the system is Hamiltonian, we only have to solve the first $n-1$ equations in \eqref{jumpIPdiff}, i.e. for $i = 0, \dots, n-2$. The final equation is then automatically satisfied.

\begin{proof}
For a reversible system, if we seek symmetric solutions, we only have to solve for the left half, i.e. for the half-line $(-\infty, 0]$. We can then extend to $[0, \infty)$ by symmetry.\\

If the system is Hamiltonian, a heuristic argument is as follows. The energy $H$ is conserved, thus all solutions must exist within level sets of $H$. Recall that $\Psi(0) = \nabla H(Q(0)) \neq 0$. Thus the energy $H$ must change along any jump in the direction of $\Psi(0)$. In Lemma \ref{solvefora}, we matched the tails of the pieces. Assume we have matched $U_i^-(0) = U_i^+(0)$ for $i = 0, \dots, n-2$. In Lemma \ref{solveforbeta}, we matched the $Y^\pm$ components of $U_{n-1}^-(0) = U_{n-1}^+(0)$. All that remains is to match the $\R \Psi(0)$ component of $U_{n-1}^-(0) = U_{n-1}^+(0)$. But this is automatically 0 since the two pieces involved must have the same energy, and if this were nonzero there would be a jump in the energy at this point.\\

We will fill in a detailed argument later, or we will cite an appropriate reference.
\end{proof}
\end{lemma}

Up to this point, we have made no additional assumptions on our system. In order to satisfy the equations in Lemma \ref{IPsystem}, we will need to make some assumptions about the eigenvalues of $DF(0)$. This makes sense, since we know we need to have ``twisting manifolds'' to construct a nonperiodic multipulse. Thus we make the following additional hypothesis.

\begin{hypothesis}The spectrum of $DF(0)$ contain simple eigenvalues $\pm \alpha \pm i \beta$, for $\alpha, \beta > 0$. The real part of any other eigenvalue of $DF(0)$ lies outside $(-\alpha, \alpha)$. Thus the equilibrium at 0 is a hyperbolic equilibrium, with both stable and unstable manifolds having dimension at least 2.
\end{hypothesis}

With this additional hypothesis, we have an expression for $\langle \Psi(-x), Q(x) \rangle$

% lemma : expression for inner product

\begin{lemma}\label{IPform}
For $x > 0$ sufficiently large,

\begin{equation}\label{IPalphabeta}
\langle \Psi(-x), Q(x) \rangle
= s_0 e^{-2 \alpha x} \sin(2 \beta x + \phi) + \mathcal{O}(e^{-(2 \alpha + \gamma) x})
\end{equation}

where $0 < \gamma \leq 1$, $s_0 > 0$, and $\phi$ are constants.
\begin{proof}
Based on our assumptions in Hypothesis \ref{assumptions}, this follows from Lemma 6.1 in San98. In our case, we do not have a parameter $\mu$, so the $\mu$-dependent terms are constant. If it turns out that $\gamma > 1$, we take $\gamma = 1$.
\end{proof}
\end{lemma}

At this point, we will assume that we have a Hamiltonian system. Since we want to capture asymmetric solutions, we will not consider the reversibility case here, since applying the reversibility hypothesis always gives us symmetric solutions.\\

In the next lemma, we use Lemmas \ref{IPform} and \ref{IPsystemreduced} together with a change of variables to write down a more useful version of the system we need to solve. Before we do that, we define the following space.

\begin{equation}\label{setR}
\mathcal{R} = \left\{ \exp\left(-\frac{2 \pi \alpha}{\beta}m\right) : m \in \N_0 \right\} \cup \{ 0 \}
\end{equation}

Since $\mathcal{R}$ is closed and bounded, is is compact, thus complete.

% Lemma : system to solve, new version

\begin{lemma}
Under the above assumptions, a periodic multipulse solution exists if and only if for $i = 0, \dots, n-2$

\begin{equation}
G_i(a_1, \dots, a_{n-1}, r_m) = a_i \sin \left( - \frac{\beta}{\alpha} \log a_i \right) - a_{i-1} \sin \left( - \frac{\beta}{\alpha} \log a_{i-1} r_m \right) + \mathcal{O}(r_m^{\gamma / 2 \alpha}) = 0 \\
\end{equation}

where $a_i > 0$ and $r_m \in \mathcal{R}$.

\begin{proof}
From \eqref{jumpIPdiff}, \eqref{IPalphabeta}, and Lemma \ref{IPsystemreduced}, a solution exists if and only if

\begin{align}\label{diff1}
s_0 e^{-2 \alpha X_i} \sin(2 \beta X_i + \phi) - s_0 e^{-2 \alpha X_{i-1}} \sin(2 \beta X_{i-1} + \phi) + \mathcal{O}(e^{-(2 \alpha + \gamma) X_m}) &= 0 && i = 0, \dots, n-2
\end{align}

where $X_m = \min\{X_i\}$. Choose any $m \in \N_0$, and define

\begin{align}
r_m = e^{-(2 \pi \alpha /\beta) m} \in \mathcal{R} && m \in \N
\end{align}

Next, define

\begin{equation}
a_i = e^{-2\alpha X_i}e^{-\alpha \phi / \beta}\frac{1}{r_m}
\end{equation}

where we have the additional restriction that the $X_i$ are sufficiently large so that $e^{-2 \alpha X_i} < r_m$ for all $i$. This is fine, since we know that our result will only hold for sufficiently large $X_i$. Rearranging these two expressions, we note that

\begin{align*}
e^{-2 \alpha X_i} &= a_i r_m e^{\alpha \phi / \beta} \\
2 \beta X_i &= -(\beta / \alpha)\log a_i r_m - \phi 
\end{align*}

Substituting these into \eqref{diff1}, we get for $i = 0, \dots, n-1$

\begin{align}\label{diff2}
s_0 e^{\alpha \phi / \beta } a_i r_m \sin \left( - \frac{\beta}{\alpha} \log (a_i r_m) \right) - s_0 e^{\alpha \phi / \beta } a_{i-1} r_m \sin \left( - \frac{\beta}{\alpha} \log (a_{i-1} r_m) \right) + \mathcal{O}(r_m^{1 + \gamma / 2 \alpha}) &= 0 \\
\end{align}

Now, divide both sides by $r_m > 0$ and the constant $s_0 e^{\alpha \phi / \beta }$ to get

\begin{align}\label{diff2}
a_i \sin \left( - \frac{\beta}{\alpha} \log (a_i r_m) \right) -  a_{i-1} \sin \left( - \frac{\beta}{\alpha} \log (a_{i-1} r_m) \right) + \mathcal{O}(r_m^{\gamma / 2 \alpha}) &= 0 \\
\end{align}

Finally, we note that

\begin{align*}
\sin \left( - \frac{\beta}{\alpha} \log (a_i r_m) \right)&=
\sin \left( - \frac{\beta}{\alpha} \log a_i - \frac{\beta}{\alpha} \log r_m  \right) \\
&= \sin \left( - \frac{\beta}{\alpha} \log a_i -\frac{\beta}{\alpha}\left( -\frac{\alpha}{\beta}2\pi m \right) \right) \\
&= \sin \left( - \frac{\beta}{\alpha} \log a_i + 2 m \pi \right) \\
&= \sin \left( - \frac{\beta}{\alpha} \log a_i \right) 
\end{align*}

Making this substitution, we have for $i = 0, \dots, n-2$

\begin{align}\label{diff3}
a_i \sin \left( - \frac{\beta}{\alpha} \log a_i \right) - a_{i-1} \sin \left( - \frac{\beta}{\alpha} \log a_{i-1} r_m \right) + \mathcal{O}(r_m^{\gamma / 2 \alpha}) &= 0 \\
\end{align}

which are the equations we want. Note that $r_m$ only occurs in the remainder term.

\end{proof}
\end{lemma}

At this point, we would like to use the IFT to solve for the $a_i$ in terms of $r_m$. Before we can do that, we note that from the previous lemma we have $n-1$ equations but $n+1$ unknowns. Thus we expect to have a 1-parameter family of solutions, paramaterized by one of the unknowns. We can pick any of the $a_i$ to be the parameter. Since we are trying to construct a periodic solution and would like to be able to show that such a solution exists for any sufficiently large period, we will let $a_{n-1}$ be the parameter. Since this term only occurs in the $G_0$ equation, it should not be too hard to deal with.


% lemma

\begin{lemma}


\begin{proof}
Substituting \eqref{IPalphabeta} into the system of equations \eqref{jumpIPdiff}, and recalling from Lemma \ref{IPsystemreduced} that since we have a Hamiltonian system we can drop the last one, we have the following system to solve

\begin{align}\label{systemalphabeta}
s_0 e^{-2 \alpha X_i} \sin(2 \beta X_i + \phi) - s_0 e^{-2 \alpha X_{i-1}} \sin(2 \beta X_{i-1} + \phi) + R_i &= 0 && i = 0, \dots, n-2
\end{align}

where, after incorporating the remainder terms from Lemmas \ref{jumplemma1} and \ref{IPalphabeta} into $R_i$, we have

\begin{equation}
R_i = \mathcal{O}(e^{-(2 \alpha + \gamma) X_i} + e^{-(2 \alpha + \gamma) X_{i-1}})
\end{equation}

with $0 < \gamma \leq 1$. Note that \eqref{systemalphabeta} has $n$ unknowns $X_0, \dots, X_{n-1}$ but only $n-1$ equations. Thus we can take one of the $X_i$ as a free paramater. Since we want the ``periodic distance'' $X_{n-1}$ to be able to take any value (as long as it is sufficiently large), we will let $X_{n-1}$ be a free paramater and will solve for the other $X_i$ in terms of that.\\

We wish to solve for $X_0, \dots, X_{n-2}$ using the implicit function theorem. In order to do that, we make the following substitution. Recalling that $X_m = \min \{X_0, \dots X_{n-1} \}$, for $i = 0, \dots, n-2$ let

\begin{align}
a_i &= e^{-2 \alpha (X_i - X_m)} \\
r &= e^{-\alpha( 2 X_m + \phi / \beta ) }
\end{align}

Manipulating these two and solving for $2 \alpha X_i$ gives us

\begin{align*}
2 \alpha X_i &= -\log (a_i r) - \alpha \phi / \beta \\
\end{align*}

Taking the exponential and simplifying gives us

\begin{align*}
e^{-2 \alpha X_i} &= e^{\alpha \phi / \beta } a_i r
\end{align*}

\[
2 \alpha X_i = -\log a_i + 2 \alpha X_m
\]

Taking the log of $r$ gives us

\[
\log r = -2 \alpha X_m - \alpha \phi / \beta
\]

which we substitute above to get

\begin{align*}
2 \alpha X_i &= -\log a_i - \log r - \alpha \phi / \beta \\
&= -\log (a_i r) - \alpha \phi / \beta \\
\end{align*}

Finally, we have

\begin{align*}
e^{-2 \alpha X_i} &= a_i e^{-2 \alpha X_m} \\
&= e^{\alpha \phi / \beta } a_i r
\end{align*}

Substituting this into our expression for $\langle \Psi(X_i), Q(-X_i) \rangle$ and using Lemmas \ref{IPform} and \ref{otherIP}, we have

\begin{align*}
\langle \Psi(X_i), Q(-X_i) \rangle 
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( 2 \beta X_i  + \phi \right) + \mathcal{O}(e^{-(2 \alpha + \gamma) X_i}) \\
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( \frac{\beta}{\alpha} ( -\log (a_i r) - \alpha \phi / \beta ) + \phi \right) + \mathcal{O}(e^{-(2 \alpha + \gamma) X_i}) \\
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) + \mathcal{O}(e^{-(2 \alpha + \gamma) X_i}) \\
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) + \mathcal{O}(e^{-2 \alpha X_m (1 + \gamma / 2 \alpha)}) \\
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) + \mathcal{O}(r^{1 + \gamma / 2 \alpha})
\end{align*}

Similarly, we have

\begin{align*}
\langle \Psi(-X_{i-1}), Q(X_{i-1}) \rangle 
&= s_0 e^{\alpha \phi / \beta } a_{i-1} r \sin \left( - \frac{\beta}{\alpha} \log (a_{i-1} r) \right) + \mathcal{O}(r^{1 + \tilde{\gamma}}) \\
\end{align*}

where $\tilde{\gamma} = \min\{ 1, \gamma / 2 \alpha \}$. \\


\end{proof} 
\end{lemma}

% garbage

\begin{lemma}\label{rewritewithr}

\begin{align*}
\langle \Psi(0), V_i^+(0) - V_i^-(0) \rangle = 
s_0 e^{\alpha \phi / \beta } r \left[ a_i \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) - a_{i-1} \sin \left( - \frac{\beta}{\alpha} \log (a_{i-1} r) \right) \right] + R_i(a, r)
\end{align*}

with 

\begin{align*}
R_i(a, r) &= \mathcal{O}(r^{1 + \tilde{\gamma}}) && 0 < \tilde{\gamma} < 1
\end{align*}

where 

\begin{align*}
a_i &= e^{-2 \alpha (X_i - X_m)} \\
r &= e^{-\alpha( 2 X_m + \phi / \beta ) }
\end{align*}

and $X_m = \min \{ X_0, \dots, X_{n-1} \}$. Thus we will always have $a_i = 1$ for some $i$.

\begin{proof}

Taking the log of $a_i$ and solving for $2 \alpha X_i$, we get

\[
2 \alpha X_i = -\log a_i + 2 \alpha X_m
\]

Taking the log of $r$ gives us

\[
\log r = -2 \alpha X_m - \alpha \phi / \beta
\]

which we substitute above to get

\begin{align*}
2 \alpha X_i &= -\log a_i - \log r - \alpha \phi / \beta \\
&= -\log (a_i r) - \alpha \phi / \beta \\
\end{align*}

Finally, we have

\begin{align*}
e^{-2 \alpha X_i} &= a_i e^{-2 \alpha X_m} \\
&= e^{\alpha \phi / \beta } a_i r
\end{align*}

Substituting this into our expression for $\langle \Psi(X_i), Q(-X_i) \rangle$ and using Lemmas \ref{IPform} and \ref{otherIP}, we have

\begin{align*}
\langle \Psi(X_i), Q(-X_i) \rangle 
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( 2 \beta X_i  + \phi \right) + \mathcal{O}(e^{-(2 \alpha + \gamma) X_i}) \\
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( \frac{\beta}{\alpha} ( -\log (a_i r) - \alpha \phi / \beta ) + \phi \right) + \mathcal{O}(e^{-(2 \alpha + \gamma) X_i}) \\
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) + \mathcal{O}(e^{-(2 \alpha + \gamma) X_i}) \\
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) + \mathcal{O}(e^{-2 \alpha X_m (1 + \gamma / 2 \alpha)}) \\
&= s_0 e^{\alpha \phi / \beta } a_i r \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) + \mathcal{O}(r^{1 + \gamma / 2 \alpha})
\end{align*}

Similarly, we have

\begin{align*}
\langle \Psi(-X_{i-1}), Q(X_{i-1}) \rangle 
&= s_0 e^{\alpha \phi / \beta } a_{i-1} r \sin \left( - \frac{\beta}{\alpha} \log (a_{i-1} r) \right) + \mathcal{O}(r^{1 + \tilde{\gamma}}) \\
\end{align*}

where $\tilde{\gamma} = \min\{ 1, \gamma / 2 \alpha \}$. \\

For the remainder term $R_i$, we have from Lemma \ref{IPform}

\begin{align*}
R_i(a, r) &= \mathcal{O}( e^{-3 \alpha X_i} +  e^{-3 \alpha X_{i-1}}
+ e^{-2 \alpha (X_i + X_{i+1})} + e^{-2 \alpha (X_{i-1} + X_i)}) \\
&= \mathcal{O}( e^{-3 \alpha X_m} ) \\
&= \mathcal{O}(r^{1 + \tilde{\gamma}}) 
\end{align*}

since $0 < \tilde{\gamma} \leq 1$. Thus since all remainder terms are of order $r^{1 + \tilde{\gamma}}$, the result follows. 

\end{proof}
\end{lemma}

In the next lemma, we write down the equations we need to solve for a periodic multipulse solution to exist. This is analogous to Proposition 3.8 in SanStrut.

% lemma : equations to solve

\begin{lemma}\label{systemtosolve}
A periodic multipulse solution exists if and only if for $i = 0, \dots, n-1$

\begin{align*}
a_{i-1} \sin \left( - \frac{\beta}{\alpha} \log (a_{i-1} r) \right) - a_i \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) = \tilde{R}_i(a, r)
\end{align*}

where 

\begin{align*}
\tilde{R}_i(a, r) &= \mathcal{O}(r^{\tilde{\gamma}}) \\
\frac{d}{d a_i} \tilde{R}_i(a, r) &= \mathcal{O}(r^{\tilde{\gamma}}) \\
\end{align*}

for some $\tilde{\gamma} > 0$

\begin{proof}
In the previous lemma, set $\langle \Psi(0), V_i^+(0) - V_i^-(0) \rangle = 0$ and rearrange. Then divide by $r$ and the constants out front, so that

\[
\tilde{R}_i(a, r) = \frac{1}{s_0 r} e^{-\alpha \phi / \beta } R_i(a, r)
\]

where $r > 0$. The bound on $\tilde{R}_i(a, r)$ comes from the bound on $R(a, r)$ from Lemma \ref{rewritewithr}. By smoothness or somesuch, we get the bound on the derivative with respect to $a_i$.
\end{proof}
\end{lemma}

In the next lemma, we show since our system is Hamiltonian, we don't need to solve one of these equations.


In the next lemma, we (finally!) solve for the $a_i$. Since lots of periodic multipulses should be possible, there will not be a unique solution, but this will let us know which solutions are possible.

% lemma : possible solutions

\begin{lemma}

For $m \in \N$, define $r_m$ by

\begin{equation}
r_m =  e^{-(\pi \alpha / \beta) m}
\end{equation}

Then for sufficiently large $m$ there exists a solution $(a_0, a_1(r_m), \dots, a_{n-1}(r_m))$ to

\begin{align*}
a_{i-1} \sin \left( - \frac{\beta}{\alpha} \log (a_{i-1} r_m) \right) - a_i \sin \left( - \frac{\beta}{\alpha} \log (a_i r_m) \right) &= \tilde{R}_i(a, r_m)
&& i = 1, \dots, n-1
\end{align*}

where $a_0 = 1$, and for $i = 1, \dots, n-1$ we have

\begin{align*}
a_i(r_n) \approx a_i^0
\end{align*}

where

\begin{align*}
a_i^0 = e^{-\frac{\pi \alpha}{\beta} k_i^0 }
\end{align*}

for some $k_i^0 \in \N_0$. We should be able to get a nice bound on this estimate, but it does not matter for now.\\

This is a countable family of solutions indexed by the $n$ natural numbers
$(m, k_1^0, \dots, k_{n-1}^0)$.

\begin{proof}

From Lemma \ref{reducedsystemtosolve}, there are only $n-2$ equations to solve. Define the function $G: \R^n \rightarrow \R^{n-2}$ componentwise for $i = 1, \dots, n-1$ by

\begin{equation*}
G_i(a_0, \dots, a_{n-1}, r) = a_{i-1} \sin \left(-\frac{\beta}{\alpha} \log (a_{i-1} r) \right) - a_i \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) - \tilde{R}_i(a, r)
\end{equation*}

We have two more unknowns than equations, which is not good. Luckily there is a way out. Recall that by the way we set things up, $a_i = 1$ for some $i$. Since we are on a periodic domain, we can WLOG ``rotate'' things so that $a_0 = 1$ (i.e. $X_m = X_0$). This lets us remove $a_0$ from the picture, so we now have a system of equations $G: \R^{n-1} \rightarrow \R^{n-2}$ defined by 

\begin{align*}
G_1(a_1, \dots, a_{n-1}, r) &= \sin \left(-\frac{\beta}{\alpha} \log r \right) - a_1 \sin \left( - \frac{\beta}{\alpha} \log (a_1 r) \right) - \tilde{R}_1(a, r) \\
G_i(a_1, \dots, a_{n-1}, r) &= a_{i-1} \sin \left(-\frac{\beta}{\alpha} \log (a_{i-1} r) \right) - a_i \sin \left( - \frac{\beta}{\alpha} \log (a_i r) \right) - \tilde{R}_i(a, r) && i = 2, \dots, n-1 \\
\end{align*}

Next, we take $r = r_m$, where
\[
r_m =  e^{-(\pi \alpha / \beta) m}
\]

and $m \in \N$. Note that $(\beta / \alpha) \log r_m = -m \pi$, so that $\sin \left(-\frac{\beta}{\alpha} \log r_m \right) = \sin(m \pi) = 0$. Substituting $r_m$ into the equations for $G_i$, this becomes

\begin{align*}
G_1(a_1, \dots, a_{n-1}, r_m) &= -a_1 \sin \left( - \frac{\beta}{\alpha} \log a_1 \right) - \tilde{R}_1(a, r_m ) \\
G_i(a_1, \dots, a_{n-1}, r_m) &= a_{i-1} \sin \left(-\frac{\beta}{\alpha} \log a_{i-1} \right) - a_i \sin \left( - \frac{\beta}{\alpha} \log a_i \right) - \tilde{R}_i(a, r_m) && i = 2, \dots, n-1 \\
\end{align*}

Thus, as long as we take $r = r_m$, it suffices to consider the system of equations $\tilde{G}: \R^{n-1} \rightarrow \R^{n-2}$ defined by 

\begin{align}\label{arequation}
\tilde{G}_1(a_1, \dots, a_{n-1}, r) &= -a_1 \sin \left( - \frac{\beta}{\alpha} \log a_1 \right) - \tilde{R}_1(a, r) \\
\tilde{G}_i(a_1, \dots, a_{n-1}, r) &= a_{i-1} \sin \left(-\frac{\beta}{\alpha} \log a_{i-1} \right) - a_i \sin \left( - \frac{\beta}{\alpha} \log a_i \right) - \tilde{R}_i(a, r) && i = 2, \dots, n-1 \\
\end{align}

The advantage of this system is that the only dependence on $r$ is via the remainder term on the RHS, and we know that $\tilde{R}_i(a, r) = \mathcal{O}(r^{\tilde{\gamma}})$ from Lemma \ref{systemtosolve}. By continuity of the remainder term in $r$, we can send $r \rightarrow 0$ to get

\begin{align*}
\tilde{G}_1(a_1, \dots, a_{n-1}, 0) &= -a_1 \sin \left( - \frac{\beta}{\alpha} \log a_1 \right) \\
\tilde{G}_i(a_1, \dots, a_{n-1}, 0) &= a_{i-1} \sin \left(-\frac{\beta}{\alpha} \log a_{i-1} \right) - a_i \sin \left(-\frac{\beta}{\alpha} \log a_i \right) && i = 2, \dots, n-1 \\
\end{align*}

For $i = 1, \dots, n-1$, let

\begin{equation}
a_i^0 = e^{-\frac{\pi \alpha}{\beta} k_i^0 }
\end{equation}

for $k_i^0 \in \N_0$. Then we have $\tilde{G}(a_1^0, \dots, a_{n-1}^0, 0) = 0$. We are now in place to use the implicit function theorem to solve for $a_1, \dots, a_{n-1}$ in terms of $r$ near $(a_1^0, \dots, a_{n-1}^0, 0)$. To verify that we can do this, we need to take the partial derivatives of the component functions $\tilde{G}_i$ with respect to $a_i$.\\ 

First, we note that using the bound on the derivative of $\tilde{R}_i(a, r)$ from Lemma \ref{systemtosolve}, the derivative of $\tilde{R}_i(a, r)$ with respect to $a_i$ at $r = 0$ is always 0, thus this term will not contribute. We also note that

\begin{align*}
\frac{\partial}{\partial a_i} a_i \sin \left( - \frac{\beta}{\alpha} \log a_i r \right)\Big|_{a_i = a_i^0, r = 0}
&= \sin \left( - \frac{\beta}{\alpha} \log a_i r \right)\Big|_{a_i = a_i^0, r = 0} + a_i \cos \left( - \frac{\beta}{\alpha} \log a_i r \right)\left( -\frac{\beta}{\alpha} \frac{1}{a_i} \right) \Big|_{a_i = a_i^0, r = 0}\\
&= -\frac{\beta}{\alpha}(-1)^{k_i^0} \\
&= (-1)^{k_i^0 + 1}\frac{\beta}{\alpha}
\end{align*}

where we took the limit as $r \rightarrow 0$ as we did above. The Jacobian matrix of $\tilde{G}$ with respect to $(a_1, \dots, a_{n-1})$ at $(a_1^0, \dots, a_{n-1}^0, 0)$ is 

\begin{equation}
D\tilde{G}_{(a_1, \dots, a_{n-1})}(a_1^0, \dots, a_{n-1}^0, 0) 
= \dfrac{\beta}{\alpha}
\begin{pmatrix}
(-1)^{k_1^0} & & & \\
(-1)^{k_1^0 + 1} & (-1)^{k_2^0} \\
0 & (-1)^{k_2^0 + 1} & (-1)^{k_3^0} \\
\vdots & \vdots & \vdots \\
0 & 0 & 0 & \dots & (-1)^{k_{n-2}^0 + 1} & (-1)^{k_{n-1}^0} 
\end{pmatrix}
\end{equation}

Since this is lower triangular with all nonzero entries on the diagonal, it is invertible. Thus we can use the implicit function theorem to solve for $a_1, \dots, a_{n-1}$ in terms of $r$ near $(a_1^0, \dots, a_{n-1}^0, 0)$. In other words, there exists $r_0 > 0$ so that for $0 < r < r_0$ and $a_i$ close to $a_i^0$ we have functions $a_i(r)$ such that $a_i(0) = a_i^0$ and 

\[
\tilde{G}(a_1(r), \dots, a_{n-1}(r), r) = 0
\]

Now take $m \in \N$ so that $r_m < r_0$. Then

\[
G(a_1(r_m), \dots, a_{n-1}(r_m), r_m) = \tilde{G}(a_1(r_m), \dots, a_{n-1}(r_m), r_m) = 0
\]

which proves the lemma. For small $r_m$, $a_i(r_m) \approx a_i^0$. We can get a bound on this if we like, but it is not needed.

\end{proof}
\end{lemma}

What we really would like is to have all of this in terms of the lengths $X_i$, since those are the physically meaningful parameters. We accomplish this in the next lemma.

% lemma : write back in terms of the X_i

\begin{lemma}
For sufficiently large $m \in \N$, there exists a countable family of lengths

\[
(X_0(m), X_1(k_1^0; m), \dots, X_{n-1}(k_{n-1}^0; m))
\]

with $k_i^0 \in \N_0$ such that

\begin{align*}
\langle \Psi(X_i), Q(-X_i) \rangle - \langle \Psi(-X_{i-1}), Q(X_{i-1}) \rangle + R_i &= 0 && i = 0, \dots, n-1
\end{align*}

The lengths are given by

\begin{align*}
X_0(m) &= \frac{\phi}{2 \beta} + m \left( \frac{1}{4} \frac{2 \pi}{\beta} \right) \\
X_i(k_i^0; m) &\approx \frac{\phi}{2 \beta} + (k_i^0 + m) \left( \frac{1}{4} \frac{2 \pi}{\beta}\right)
\end{align*}

\begin{proof}

Recall that we have ``rotated'' the system so that $X_m = X_0$. Taking $r = r_m$ and solving for $X_0 = X_m$, we have 

\begin{align*}
X_0 &= \frac{\phi}{2 \beta} + m \frac{\pi}{2 \beta} \\
&= \frac{\phi}{2 \beta} + m \frac{1}{4} \frac{2 \pi}{\beta} \\
\end{align*}

Note that $\frac{2 \pi}{\beta}$ is the period of ``twisting'' of the stable and unstable manifolds about each other near the equilibrium point, so this agrees with our intuition of joins being possible approximately every ``quarter-twist''.\\

For the remaining $X_i$, we have $a_i(r_m) \approx e^{-\frac{\pi \alpha}{\beta} k_i^0 }$ from the previous lemma. Solving the expression for $a_i$ in terms of $X_i$ and using this approximation, we have for $i = 1, \dots, n-1$

\begin{align*}
X_i &\approx X_0 + \frac{\pi}{2 \beta}k_i^0 \\
&\approx \frac{\phi}{2 \beta} + (k_i^0 + m) \frac{1}{4} \frac{2 \pi}{\beta} 
\end{align*}

\end{proof}
\end{lemma}

We have successfully constructed a periodic multipulse. We combine these results in the following theorem

% put it all together

\begin{theorem}\label{2pconstruction}
Given the assumptions in Hypothesis \ref{assumptions}, a periodic $n$-pulse solution $Q_{n,p}(x)$ of $U' = F(U)$ exists. $Q_{n, p}(x)$ can be written piecewise as

\begin{align*}
\begin{cases}
Q^-(0, \beta_i^-)(x) + U_i^-(x) \\
Q^+(0, \beta_i^+)(x) + U_i^+(x)
\end{cases}
\end{align*}

for $i = 0, \dots, n-1$. $Q^-(\alpha, \beta_i^-)(0)$ parameterizes the unstable manifold near $Q(0)$ and $Q^+(\alpha, \beta_i^+)(0)$ parameterizes the stable manifold near $Q(0)$. $Q^\pm(0, \beta_i^\pm)(x)$ lies along the stable (unstable) manifold, and $U_i^\pm(x)$ is a remainder term.\\

For the remainder term $U_i^\pm(x)$, we have bounds

\begin{align*}
|U_i^-(x)| &\leq C e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + x)} \\
|U_i^+(x)| &\leq C e^{-\alpha X_i} e^{-\alpha(X_i - x)} \\
\end{align*}

For the initial conditions $\beta_i^\pm$, we have bounds

\begin{equation}
| \beta_i^\pm | \leq C (e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})
\end{equation}

This gives us bounds

\begin{align*}
|Q^\pm(0, \beta_i^\pm)(0) - Q(0)| = |\beta_i^\pm| \leq 
C \left( e^{-\alpha X_i} + e^{-\alpha X_{i-1}} \right)
\end{align*}

\end{theorem}

% corollary : our problem

\begin{corollary}
For KdV5, if $c > 0$ there exists an $n$-pulse solution $Q_{n, p}(x)$. This solution can be written piecewise as in Theorem \ref{2pconstruction}, and bounds on the pieces are given in that theorem.

\begin{proof}
All we need to do is verify the assumptions in Hypothesis \ref{assumptions} for KdV5. If $c > 0$, the eigenvalues of $DF(0)$ are the complex quartet $\pm \alpha \pm \beta$. The remaining assumptions are discussed in the opening section, except for the transversality condition, which is a standard assumption in the literature.
\end{proof}

\end{corollary}

\end{document}