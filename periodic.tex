\documentclass[12pt]{article}
\usepackage[pdfborder={0 0 0.5 [3 2]}]{hyperref}%
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}%
\usepackage[shortalphabetic]{amsrefs}%
\usepackage{amsmath}
\usepackage{enumerate}
% \usepackage{enumitem}
\usepackage{amssymb}                
\usepackage{amsmath}                
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage{float}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{mathtools}
\usepackage{cool}
\usepackage{url}
\usepackage{graphicx,epsfig}
\usepackage{makecell}
\usepackage{array}

\def\noi{\noindent}
\def\T{{\mathbb T}}
\def\R{{\mathbb R}}
\def\N{{\mathbb N}}
\def\C{{\mathbb C}}
\def\Z{{\mathbb Z}}
\def\P{{\mathbb P}}
\def\E{{\mathbb E}}
\def\Q{\mathbb{Q}}
\def\ind{{\mathbb I}}

\graphicspath{ {periodic/} }

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{hypothesis}{Hypothesis}

\newtheorem{notation}{Notation}

\begin{document}

\section{KdV5 with Periodic Boundary Conditions}

\subsection{Background}

In this section we will look at multipulse solutions to KdV5 in the case where we have periodic boundary conditions. Note that we cannot use an exponential weight in this case since our domain is of finite length. For now, we will hypothesize that such solutions exist.

\begin{hypothesis}\label{q2pexists}
Let $q(x; c)$ be a single pulse solution to KdV5 with wave speed $c$. Then for $c > 1/4$, there exists a double pulse, periodic wavetrain solution $q_{2p}(x; c)$ to KdV5. The centers of the two pulses are separated by a distance $2 X_1$, and the centers of the two pulse are each a distance $X_2$ from the periodic boundary.
\end{hypothesis}

Here is a diagram of the situation we have described.

\begin{figure}[H]
\includegraphics[width=8.5cm]{dpimage}
\end{figure}

Without loss of generality, we will take $X_2 \geq X_1$, since we are on the periodic domain, thus it does not matter what we choose to be the ``middle''.\\

We would like to write the periodic double pulse as a small (piecewise) perturbation of the single pulse as was done in San98 (and San93). The method in those papers, however, does not give us the estimates we need. Instead, we will give another construction based on San97.

\subsection{Construction of Periodic Double Pulse}

For now the details will be omitted, since what really matters here is if we can use this result to get what we want. If this works, the details will be added in here.

\begin{proposition}\label{2pconstruction}
Let $Q_{2p}(x)$ be a periodic double pulse solution with lengths $X_1$, $X_2$ as described above. Then $Q_{2p}(x)$ can be written piecewise as

\begin{align*}
\begin{cases}
Q^-(0, \beta_i^-)(x) + U_i^-(x) \\
Q^+(0, \beta_i^+)(x) + U_i^+(x)
\end{cases}
\end{align*}

where $Q^-(\alpha, \beta^-)(0)$ parameterizes the unstable manifold near $Q(0)$ and $Q^+(\alpha, \beta^+)(0)$ parameterizes the stable manifold near $Q(0)$. We have changed coordinates using the flow-box method so that

\begin{align*}
Q^-(\alpha, \beta_-)(0) - Q(0) \in Y^- \oplus \R Q'(0) \\
Q^+(\alpha, \beta_+)(0) - Q(0) \in Y^+ \oplus \R Q'(0) \\
\end{align*}

(we will always take $\alpha = 0$, but it is part of the parameterization.) The $x$ dependence of $Q^\pm(x)$ is the evolution along the appropriate manifold in the appropriate direction. For $U_i^\pm(x)$ we have bounds

\begin{align*}
|U_i^-(x)| &\leq C e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + x)} \\
|U_i^+(x)| &\leq C e^{-\alpha X_i} e^{-\alpha(X_i - x)} \\
\end{align*}

We also have bounds

\begin{align*}
|Q^\pm(0, \beta_i^\pm)(0) - Q(0)| = |\beta^\pm| \leq 
C \left( e^{-\alpha X_1} + e^{-\alpha X_2} \right)
\end{align*}

\end{proposition}

\subsection{Setup of Eigenvalue Problem}

To assess the stability of such double pulse solutions, we will look at the spectrum of the linearization of KdV5 about these periodic, double pulse solutions. As in the case on the unbounded domain with an exponential weight, we first write the eigenvalue problem as a first order system. We know that there are two eigenvalues at 0. We also know there will be two or four small eigenvalues from the pulse interactions. To locate those eigenvalues, we will follow the same procedure as in the unbounded case and as in San98. Thus, we will write the eigenfunction $V$ piecewise as

\[
V_i^\pm(x) = d_i (Q_{2p}'(x) + \lambda (Q_{2p})_c(x)) + W_i^\pm 
\]

Plugging this into the eigenvalue problem, we want to a system of the following form

\begin{enumerate}[(i)]
\item $(W_i^\pm)' = A(q_{2p}(x)) W_i^\pm + \lambda B W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm$
\item $W_1^+(X_1) - W_2^-(-X_1) = D_1 d$
\item $W_2^+(X_2) - W_1^-(-X_2) = D_2 d$
\end{enumerate}

where $A(q_{2p}(x))$ is the Jacobian of the linearization about the periodic double pulse, $B$ is the matrix defined previously, and 

\begin{align*}
D_1 d &= d_2(Q_{2p}'(-X_1) + \lambda (Q_{2p})_c(-X_1))
- d_1 ( Q_{2p}'(X_1) + \lambda (Q_{2p})_c(X_1) ) \\
D_2 d &= d_1(Q_{2p}'(-X_2) + \lambda (Q_{2p})_c(-X_2))
- d_2 ( Q_{2p}'(X_2) + \lambda (Q_{2p})_c(X_2) ) \\
\tilde{H} &= -B(Q_{2p})_c \\
H &= -B Q_c \\
\Delta H &= \tilde{H} - H
\end{align*}

We would like to exploit the construction of the periodic double pulse in Proposition \ref{2pconstruction}. To do this, we note that the Jacobian $A(q(x))$ depends linearly on $q(x)$ and its derivatives. Thus we have (piecewise)

\begin{equation}
A(q_{2p}(x)) = A(q^\pm(0, \beta_i^\pm)(x)) + A(u^\pm(x)) 
\end{equation}

For convenience, we let

\begin{align*}
G_i^\pm &= A(u^\pm(x))
\end{align*}

Then our system of equations to solve becomes

\begin{enumerate}[(i)]
\item $(W_i^\pm)' = A(q^\pm(0, \beta_i^\pm)(x)) W_i^\pm + \lambda B W_i^\pm + G_i^\pm W_i^\pm \lambda^2 d_i \tilde{H}_i^\pm$
\item $W_1^+(X_1) - W_2^-(-X_1) = D_1 d$
\item $W_2^+(X_2) - W_1^-(-X_2) = D_2 d$
\end{enumerate}

An important difference between this and the exponentially weighted case on the full line is that instead of a single term $A W_i^\pm$ we have the piecewise terms $A(q^\pm(0, \beta_i^\pm)(x)) $. We should be okay, since in all cases the functions $q^\pm(0, \beta_i^\pm)$ decay in the appropriate directions along the appropriate manifold. In San98, we have two piecewise terms $A^\pm W_i^\pm$ which depend on the parameter $\mu$. We can think of our case as similar, except we have four (fixed) parameters $\beta_i^\pm$, which give initial conditions on the appropriate manifolds.\\

We now need to formulate the other conditions for the problem. Recall that for the exponentially weighted case (or the hyperbolic case) the other conditions are given by

\begin{enumerate}[(i)]
\item $W_i^\pm(0) \in \C \psi(0) \oplus Y^+ \oplus Y^-$
\item $W_i^+(0) - W_i^-(0) \in \C \psi(0)$
\end{enumerate}

Let us briefly recall what the various spaces are involved in these conditions. Note at that all of the conditions are specified at $x = 0$, which is at the peak of the two pulses.

\begin{enumerate}
	\item $\text{span }\{Q'(0)\}$ is the span of the derivative of the pulse at $x = 0$. This is in both the stable and unstable manifolds of 0.
	\item $Y^+$ is the remaining dimension of the two-dimensional stable manifold.
	\item $Y^-$ is the remaining dimension of the two-dimensional unstable manifold.
	\item $\C \Psi(0)$ is the span of the solution to the adjoint variational equation, and since it is perpendicular to the unstable and stable manifolds, it fills out $\C^4$ when combined with the three things above.
\end{enumerate}

In this case, we will have an additional center space at $x = 0$, which gives us one more dimension. Let $Y^0$ be this center space. We will characterize this more fully later, but what we need to do now is figure out what role this plays in our conditions. Elements in the center space may blow up (not necessarily exponentially) at one of the ends. Thus if seek a localized eigenfunction, it is important that the initial condition at $x = 0$ not have a component in this center space. \\

This condition tells us where our perturbation must live. Since we are specifying our eigenfunction as $V_i^\pm(x) = d_i(q_{2p}'(x) + \lambda (q_{2p})_c(x)) + W_i^\pm $, and we know that $q_{2p}(x)$ and its derivatives have no component in the $Y^0$ since they both decay exponentially at both ends, this implies that $W_i^\pm(0)$ cannot have a component in $Y^0$. This also implies that $W_i^+(0) - W_i^-(0)$ cannot have a component in $Y^0$. Thus the conditions are exactly the same as for the version without the center space.\\

\begin{enumerate}
\item $W^\pm(0) \in \C \psi(0) \oplus Y^+ \oplus Y^-$
\item $W^+(0) - W^-(0) \in \C \psi(0) $
\end{enumerate}

Before we continue, we will rewrite the problem slightly. The idea is the following. The matrix $A(0)$ has an eigenvalue at 0, which gives it a center subspace. What we would like to do is combine the matrices $A(q^\pm(0, \beta_i^\pm)(x)) $ and $\lambda B$ to get a new matrix (depending on $\lambda$). In this new, $\lambda$-dependent matrix, the eigenvalue at 0 will perturb slightly to a small eigenvalue in a $\lambda$-dependent fashion.\\

We will still call the eigenspace corresponding to the small eigenvalue a center space, even though it might not technically be one. Thus we define

\[
\tilde{A}(q^\pm(0, \beta_i^\pm)(x); \lambda) = A(q^\pm(0, \beta_i^\pm)(x)) + \lambda B
\]

The first equation in the problem then becomes

\[
(W_i^\pm)' = \tilde{A}(q^\pm(0, \beta_i^\pm)(x); \lambda) W_i^\pm + G_i^\pm W_i^\pm + \lambda B W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm
\]

At this point, we drop the tilde over $A$ and the final version of the problem becomes

\begin{enumerate}[(i)]
\item $(W_i^\pm)' = A(q^\pm(0, \beta_i^\pm)(x); \lambda) W_i^\pm + G_i^\pm W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm$
\item $W_1^+(X_1) - W_2^-(-X_1) = D_1 d$
\item $W_2^+(X_2) - W_1^-(-X_2) = D_2 d$
\item $W^\pm(0) \in \C \psi(0) \oplus Y^+ \oplus Y^-$
\item $W^+(0) - W^-(0) \in \C \psi(0) $
\end{enumerate}

As a justification for the $\lambda$-dependent perturbation of the center eigenvalue of $A(q^\pm(0, \beta_i^\pm)(x); \lambda)$, we give the following heuristic argument. The matrix $A(q^\pm(0, \beta_i^\pm)(x); \lambda)$ is exponentially asymptotic (due to the exponential decay properties of $q^\pm(0, \beta_i^\pm)(x)$ and its derivatives in the appropriate directions). Let 

\[
A(\lambda) = \lim_{x \rightarrow \infty} A(q^+(0, \beta_i^+)(x); \lambda) 
= \lim_{x \rightarrow -\infty} A(q^-(0, \beta_i^-)(x); \lambda) = A(0; \lambda)
\]

Note that the limits do not depend on $i$ and that the two limits are equal due to decay properties of $q^\pm(0, \beta_i^\pm)(x)$ and its derivatives.\\

For $\lambda = 0$, $A(0)$ has an eigenvalue at 0. The characteristic polynomial for $A(\lambda)$ is $f(\nu; \lambda) = \lambda - c \nu + \nu^3 - \nu^5$, which to leading order is $f(\nu; \lambda) = \lambda - c \nu + \mathcal{O}(\nu^3)$. Thus, to leading order, this polynomial has a zero when $t = \lambda / c$, which is approximately the value of the spatial eigenvalue closest to 0. For small $\lambda$, numerics shows this is very close.\\

Before we continue, we will hypothesize the following bounds on the elements of our problem. We will eventually prove these, of course. The idea behind these hypothesized bounds is that deviation from the single pulse, nonperiodic case decreases exponentially with distance from the center, so we are letting the ``worst offender'' dictate the behavior. Since the $D_i$ equations only depend on $X_i$, the bound only involves that length parameter.

\begin{hypothesis}\label{problembounds}
We have the following estimates/bounds on terms in our problem
\begin{align*}
\Delta H &= \mathcal{O}(e^{-\alpha X_1} + e^{-\alpha X_2} ) \\
D_i &= ( Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) + \mathcal{O} \left( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\end{align*}
\end{hypothesis}

From Proposition \ref{2pconstruction}, we have the following piecewise bound for $G_i^\pm$

\begin{align*}
|G_i^-(x)| &\leq C e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + x) } \\
|G_i^+(x)| &\leq C e^{-\alpha X_i} e^{-\alpha(X_i - x) } \\
\end{align*}

Note that the bound is strongest at $x = 0$ and is weaker at $\pm X_i$. We also have the uniform bound for $G$

\begin{equation}\label{uniformG}  
||G|| = \sup |G_i^\pm(x)| \leq C (e^{-\alpha X_1} + e^{-\alpha X_2})
\end{equation}

\subsection{Characterization of Center Subspace}

Consider the first order linear system on $[0, \infty)$

\begin{equation}\label{justA}
V' = A(q^+(0, \beta^+)(x); \lambda) V
\end{equation}

Note that this paramaterized by both $\beta^+$ (the IC on the stable manifold) and by $\lambda$.\\

Let $\Phi(y, x; \beta^+, \lambda)$ be the evolution operator for \eqref{justA}. For $\lambda = 0$, as mentioned above, the matrix $A$ has a center subspace. As we peturb $\lambda$ slightly, this center subspace may peturb into a subspace which grows (or decays) exponentially, albeit at a slow rate since the spatial eigenvalue responsible for this is small. Thus instead of an exponential dichotomy, as in the hyperbolic case, we have an exponential trichotomy. This trichotomy will occur separately on $\R^+$ and $\R^-$.\\

Following HaleLin85, we will write this exponential trichotomy as follows. We have $\lambda$-dependent projections $P^s_\pm(x; \beta^+, \lambda)$, $P^u_\pm(x; \beta^+, \lambda)$ and $P^c_\pm(x; \beta^+, \lambda) = I - P^s_\pm(x; \beta^+, \lambda) - P^u_\pm(x; \beta^+, \lambda)$ (where the subscripts designate whether the trichotomy is on $\R^+$ or $\R^-$) such that

\begin{align*}
\Phi(y, x; \beta^+, \lambda)P^s_\pm(x; \beta^+, \lambda) &= P^s_\pm(y; \beta^+, \lambda)\Phi(y, x; \beta^+, \lambda) \\
\Phi(y, x; \beta^+, \lambda)P^u_\pm(x; \beta^+, \lambda) &= P^u_\pm(y; \beta^+, \lambda)\Phi(y, x; \beta^+, \lambda) \\
\Phi(y, x; \beta^+, \lambda)P^c_\pm(x; \beta^+, \lambda) &= P^c_\pm(y; \beta^+, \lambda)\Phi(y, x; \beta^+, \lambda) \\
\end{align*}

In other words, the projections commute with the evolution, so it does not matter if you project or evolve first. For $\lambda = 0$ the superscript $c$ is an actual center subspace, and for small $\lambda$, this is the subspace that the center subspace perturbs to. Using these projections, we can split the evolution up into evolution on the three subspaces by defining

\begin{align*}
\Phi^s_\pm(y, x; \beta^+, \lambda) &= \Phi(y, x; \beta^+, \lambda)P^s_\pm(x; \beta^+, \lambda) \\
\Phi^u_\pm(y, x; \beta^+, \lambda) &= \Phi(y, x; \beta^+, \lambda)P^u_\pm(x; \beta^+, \lambda) \\
\Phi^c_\pm(y, x; \beta^+, \lambda) &= \Phi(y, x; \beta^+, \lambda)P^c_\pm(x; \beta^+, \lambda) \\
\end{align*}

For the stable and unstable subspaces, we know what the eigenvalues of $A(0, 0)$ are. In particular, we have a constant $\alpha$ for which $\alpha$ is the smallest real part of the positive eigenvalues of $A(0)$ and $-\alpha$ is the largest real part of the negative eigenvalues of $A(0)$. For small $\lambda$ and $\beta^+$, the spatial eigenvalues will not perturb much, so for stable and unstable subspaces we will still have the bounds

\begin{align*}
|\Phi^s(y, x; \beta^+, \lambda)| \leq C e^{-\alpha(y-x)} \\
|\Phi^u(x, y; \beta^+, \lambda)| \leq C e^{-\alpha(y-x)}
\end{align*}

Technically, we should probably replace $\alpha$ by $\alpha - \delta$ for small $\delta$ to account for the perturbation, but it does not matter for now. Also, since $\beta^+$ is just the IC on the stable manifold, the decay rate does not change when this is altered.\\

For the center subspace, there is a small eigenvalue which is approximately $\nu = \lambda / c$. Thus we expect to have a $\lambda$-dependent bound for the center evolution resembling.

\begin{align*}
|\Phi^c_+(y, x; \beta^+, \lambda)| &\leq C e^{(\text{Re }\lambda)(y-x)/c} && y \geq x \geq 0 \\
|\Phi^c_-(x, y; \beta^+, \lambda)| &\leq C e^{(\text{Re }\lambda)/c} && x \leq y \leq 0 \\
\end{align*}

At this point, we want to make all of this precise. We start by proving the following lemma, based on Exercise 29 on p. 104 of Coddington and Levinson (1955).

\begin{lemma}Consider the eigenvalue problem on $\R^+$

\begin{equation}\label{veigproblem}
V(x)' = AV(x) + R(x)V(x)
\end{equation}

where $V(x) \in R^n$, $A$ is a constant, diagonalizable $n \times n$ matrix, and $R(x): \R \rightarrow \R^n$ is an integrable function which is globally Lipschitz continuous in $x$. Let $\nu$ be any eigenvalue of $A$ with corresponding eigenvector $p$, i.e. $A p = \nu p$. Then there is a unique solution $\phi(x)$ to \eqref{veigproblem} such that 

\[
\lim_{x\rightarrow\infty} \phi(x) e^{-\nu x} = p
\]

In other words, for large $x$, the solution $\phi(x)$ resembles that of the constant coefficient eigenvalue problem $V(x)' = AV(x)$.

\begin{proof}
Let $\sigma = \text{Re} \nu$. Let $\nu_1, \dots, \nu_n$ be the $n$ eigenvalues of $A$ with corresponding eigenvectors $p_1, \dots, p_n$. Since we are assuming that $A$ is diagonalizable, we have a complete set of $n$ of these. Order the eigenvalues by increasing real part; if more than one eigenvalue has the same real part, any order is fine, as long as we make sure that any eigenvalue besides $\nu$ with real part $\sigma$ occurs after $\nu$ in the list. Then $\nu = \nu_k$ for some $k$, $\text{Re} \nu_j < \sigma$ for $j < k$ (as long as $k \neq 1$), and $\text{Re} \nu_j \geq \sigma$ for $j \geq k$. \\

Let $e^{Ax}$ be the fundamental matrix solution for $U' = A U$, and split $e^{Ax}$ up into
\[
e^{Ax} = Y_1(x) + Y_2(x)
\]

where $Y_1$ involves only eigenvectors corresponding to eigenvalues $\nu_1, \dots, \nu_{k-1}$ and $Y_2$ involves only eigenvectors corresponding to eigenvalues $\nu_{k}, \dots, \nu_n$. Since $A$ is a constant-coefficient matrix, we can write down an explicit formula for $Y_1$ and $Y_2$. Essentially, all we need to do is change coordinates to the eigenbasis, evolve along the appropriate eigenvectors, and zero out the other ones. To be specific, let P be the $n \times n$ matrix with columns $p_1, \dots, p_n$. Since we are assuming $A$ is diagonalizable, this matrix is invertible, and $D = P^{-1}AP$ is diagonal with eigenvalues $\nu_1, \dots, \nu_n$ on the diagonal. Recall that the matrix exponential is given by $e^{Ax} = P^{-1}e^{Dx}P$. Starting with the matrix $D$, form the matrix $D_1$ by keeping only the eigenvalues $\nu_1, \dots, \nu_{k-1}$ on the diagonal, and form the matrix $D_2$ by keeping only the eigenvalues $\nu_{k}, \dots, \nu_n$ on the diagonal. Then we have

\begin{align*}
Y_1(x) &= P^{-1}e^{D_1x}P \\
Y_1(x) &= P^{-1}e^{D_2x}P \\
\end{align*}
 
Choose $\delta$ such that $0 < \delta < \sigma - \text{Re} \nu_{k-1}$, i.e. smaller than the spectral gap between $\nu$ and the eigenvalue with the next smallest real part. (If $k = 1$, $Y_1 = 0$, $Y_2 = e^{Ax}$, and we don't care about $\delta$). Then we can find a constant $C$ such that

\begin{align*} 
|Y_1(x)| &\leq Ce^{(\sigma - \delta)x} && x \geq 0 \\
|Y_2(x)| &\leq Ce^{\sigma x} && x \leq 0 
\end{align*}

Define the exponentially weighted function space with weight $\sigma$

\[
B_{\sigma, a} = \{ f \in C^0([a, \infty), \R^n) : \sup_{x \in [a, \infty)} |e^{-\sigma x} f(x)| < \infty 
\]

where $a$ will be chosen later. The norm on this space is given by

\[
||f||_{\sigma, a} = \sup_{x \in [a, \infty)} |e^{-\sigma x} f(x)|
\]

In other words, we allow functions in $B_{\sigma, a}$ to grow exponentially as $x \rightarrow \infty$ at a rate of $\sigma$ or slower. It is known that $B_{\sigma, a}$ is a Banach space. Define the operator $F$ on $B_{\sigma, a}$ by

\begin{align*}
F(\phi)(x) = e^{\nu x} p + \int_a^x Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2(x - y)R(y)\phi(y)dy
\end{align*}

where the $a$ in the integral is the same as in $B_{\sigma, a}$ and will be chosen later. First we show that $F: B_{\sigma, a} \rightarrow B_{\sigma, a}$. Let $\phi \in B_{\sigma, a}$. For $x \geq a$ we have

\begin{align*}
|e^{-\sigma x} &F(\phi)(x)| \leq e^{(\nu - \sigma) x} |p| + \int_a^x |Y_1(x - y)||R(y)||\phi(y)| dy + \int_x^\infty |Y_2(x - y)||R(y)||\phi(y)|dy \\
&\leq |p| + C \left( e^{-\sigma x}  \int_a^x e^{(\sigma - \delta)(x - y)}|R(y)||\phi(y)| dy + e^{-\sigma x}  \int_x^\infty e^{\sigma(x - y)}|R(y)||\phi(y)|dy \right) \\
&\leq |p| +  C \left( \int_a^x e^{-\delta(x - y)}|R(y)||e^{-\sigma y}\phi(y)| dy + \int_x^\infty |R(y)||e^{-\sigma y} \phi(y)|dy \right) \\
&\leq |p| + C ||\phi||_{\sigma, a}\left( \int_a^x e^{-\delta(x - y)}|R(y)| dy + \int_x^\infty |R(y)|dy \right) \\
&\leq |p| + C ||\phi||_{\sigma, a} \int_a^\infty |R(y)| dy 
\end{align*}

Since $R$ is integrable, the RHS is finite, thus the map $F: B_{\sigma, a} \rightarrow B_{\sigma, a}$ is well defined. Now we show the map $F$ is a contraction. Let $\phi, \psi \in B_{\sigma, a}$. For $x \geq a$ we have

\begin{align*}
|e^{-\sigma x}( &F(\phi)(x) - F(\psi)(x))| \leq \int_a^x |Y_1(x - y)||R(y)||\phi(y) - \psi(y)| dy + \int_x^\infty |Y_2(x - y)||R(y)||\phi(y) - \psi(y)|dy \\
&\leq C \left( e^{-\sigma x}  \int_a^x e^{(\sigma - \delta)(x - y)}|R(y)||\phi(y) - \psi(y)| dy + e^{-\sigma x}  \int_x^\infty e^{\sigma(x - y)}|R(y)||\phi(y) - \psi(y)|dy \right) \\
&\leq C \left( \int_a^x e^{-\delta(x - y)}|R(y)||e^{-\sigma y}(\phi(y) - \psi(y))| dy + \int_x^\infty |R(y)||e^{-\sigma y} (\phi(y) - \psi(y))|dy \right) \\
&\leq C ||\phi - \psi ||_{\sigma, a}\left( \int_a^x e^{-\delta(x - y)}|R(y)| dy + \int_x^\infty |R(y)|dy \right) \\
&\leq C ||\phi - \psi ||_{\sigma, a} \int_a^\infty |R(y)| dy 
\end{align*}

Since $R$ is integrable, we can choose $a$ sufficiently large so that

\[
\int_a^\infty |R(y)| dy < \frac{1}{2C}
\]

from which we conclude that

\[
||F(\phi) - F(\psi) ||_{\sigma, a} \leq \frac{1}{2} ||\phi - \psi ||_{\sigma, a}
\]

Since $F$ is a contraction on the Banach space $B_{\sigma, a}$, by the Banach Fixed Point Theorem the map $F$ has a unique fixed point, i.e. a unique $\phi(x) \in B_{\sigma, a}$ such that $F(\phi) = \phi$. Note that by the fixed point theorem and definition of $B_{\sigma, a}$, we only have $\phi(x)$ defined for $\phi \geq a$. However, choosing the initial condition $\phi(a)$ at $x = a$, by the existence and uniqueness of solutions to \eqref{veigproblem} and the global Lipschitz condition placed on $R(x)$ (which guarantees global existence of solutions), we can extend $\phi(x)$ uniquely to all of $\R$. This extension of $\phi(x)$ to $\R$ is given by the same formula we have for $\phi(x)$ when $x \geq a$.

\begin{equation}\label{fpphi}
\phi(x) = e^{\nu x} p + \int_a^x Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2(x - y)R(y)\phi(y)dy
\end{equation}

To see this, all we need to do is show that it satisfies the ODE \eqref{veigproblem}. Differentiating \eqref{fpphi}, we get

\begin{align*}
\phi'(x) &= \nu e^{\nu x} p + (Y_1(0) + Y_2(0))R(x)\phi(x) + \int_a^x Y_1'(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2'(x - y)R(y)\phi(y)dy \\
&= e^{\nu x} A p + e^{0A}R(x)\phi(x) + \int_a^x A Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x A Y_2(x - y)R(y)\phi(y)dy \\
&= A \left( e^{\nu x} p + \int_a^x Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2(x - y)R(y)\phi(y)dy \right) + R(x) \phi(x) \\
&= A \phi(x) + R(x) \phi(x)
\end{align*}

Thus $\phi(x)$ defined in \eqref{fpphi} is the unique extension that we seek. All that remains is to show what happens when $x \rightarrow \infty$. Since we are interested in end behavior, we only need to consider what happens when $x \geq a$. Since $\phi(x) \in B_{\lambda, a}$, $||\phi||_{\sigma, a}$ is finite and independent of $x$. Thus for $x \geq a$, using what we did above, 

\begin{align*}
|e^{-\sigma x} &(\phi(x) - e^{\nu x} p)| \leq C ||\phi||_{\sigma, a}\left( \int_a^x e^{-\delta(x - y)}|R(y)| dy + \int_x^\infty |R(y)|dy \right) \\
&\leq C ||\phi||_{\sigma, a}\left( \int_a^{x/2} e^{-\delta(x - y)}|R(y)| dy + \int_{x/2}^x |R(y)|+ \int_x^\infty |R(y)|dy \right)\\
&\leq C ||\phi||_{\sigma, a}\left( e^{-\delta(x/2)} \int_a^{x/2} e^{-\delta(x/2 - y)}|R(y)| dy + \int_{x/2}^\infty |R(y)|dy \right)\\
&\leq C ||\phi||_{\sigma, a}\left( e^{-\delta(x/2)} \int_a^{\infty} |R(y)| dy + \int_{x/2}^\infty |R(y)|dy \right)\\
&\leq ||\phi||_{\sigma, a}\left(\frac{1}{2} e^{-\delta(x/2)} + \int_{x/2}^\infty |R(y)|dy \right)
\end{align*}

Since $\delta > 0$, $R(x)$ is integrable, and $||\phi||_{\sigma, a}$ is constant, both terms on the RHS go to 0 as $x \rightarrow \infty$. Thus we conclude that

\[
\lim_{x \rightarrow \infty} |e^{-\sigma x} (\phi(x) - e^{\nu x} p)| = 0
\]

Pulling out a factor of $e^{\nu x}$, this becomes 

\[
\lim_{x \rightarrow \infty} |e^{(\nu - \sigma) x}||\phi(x) e^{-\nu x} - p)| = 0
\]

since $\text{Re} \phi = \nu$, $|e^{(\nu - \sigma) x} = 1$ for all $x$. Thus we conclude that

\[
\lim_{x \rightarrow \infty} |\phi(x) e^{-\nu x} - p)| = 0
\]  

from which it follows that

\[
\lim_{x\rightarrow\infty} \phi(x) e^{-\nu x} = p
\]

\end{proof}
\end{lemma}

\begin{corollary}The same result holds on $(-\infty, 0]$ if we take $x \rightarrow -\infty$, i.e. there is a unique solution $\tilde{\phi}(x)$ to \eqref{veigproblem} such that 

\[
\lim_{x\rightarrow -\infty} \tilde{\phi}(x) e^{-\nu x} = p
\]

This function in general will not be the same as $\phi(x)$ above.

\begin{proof}
First we replace $x$ with $-x$ in \eqref{veigproblem}

\begin{align*}
V'(-x) = A V(-x) + R(-x)V(-x)
\end{align*}

Let $\tilde{V}(x) = V(-x)$ and $\tilde{R}(x) = -R(-x)$. Then since $\tilde{V}'(x) = -V'(-x)$, we get

\begin{align*}
\tilde{V}'(x) = -A \tilde{V}(x) + \tilde{R}(x)\tilde{V}(x)
\end{align*}

Now we use the above lemma on $\tilde{V}$ (for $x \geq 0$). Since $-A$ has an eigenvector $p$ with corresponding eigenvalue $-\nu$, by the above lemma we can find a unique solution $\psi(x)$ such that 

\[
\lim_{x\rightarrow \infty} \psi(x) e^{(-\nu)(-x)} = p
\]

Let $\tilde{\phi(x)} = \psi(-x)$. Then $\tilde{\phi(x)}$ solves the original problem, and

\[
\lim_{x\rightarrow -\infty} \tilde{\phi}(x) e^{-\nu x } = p
\]

\end{proof}
\end{corollary}

Using this, we can derive an expression for the evolution on the center subspace. First, consider the following eigenvalue problem and its adjoint problem.

\begin{align}
V' &= A(q^+(0, \beta^+)(x); \lambda) V \label{eig:V} \\
W' &= -A(q^+(0, \beta^+)(x); \lambda)^* W \label{eig:W}
\end{align}

Note that $V$ and $W$ will depend on $\beta^+$, but (for convenience) we suppress that notation for now and will bring it back when needed. Let $\Phi(y, x; \beta^+, \lambda)$ be the evolution operator for \eqref{eig:V}.\\

We summarize some useful facts about this problem in the following lemma. Note that since we are in the space $\C^n$, we have defined the inner product on $\C^n$ by $\langle x, y \rangle = \sum x_i \bar{y_i}$, i.e. the complex conjugation is on the second component.

\begin{lemma}\label{eigadjoint}
Consider the linear ODE $V' = A(x)V$ and the corresponding adjoint problem $W' = -A(x)^* W$, where $A$ is an $n \times n$ matrix depending on $x$. Then the following are true.
\begin{enumerate}[(i)]
\item $\frac{d}{dx}\langle V(x), W(x) \rangle = 0$, thus the inner product is constant as $x$ varies.
\item If $\Phi(y, x)$ is the evolution operator for $V' = A(x)V$, then $\Phi(x, y)^*$ is the evolution operator for the adjoint problem $W' = -W(x)^* W$.
\end{enumerate}
\begin{proof}
For (i), take the derivative of the inner product and use the expressions for $V'$ and $W'$. For (ii), take the derivative of the expression $\Phi(y, x)\Phi(x, y) = I$.
\end{proof}
\end{lemma}

Let $\nu(\lambda)$ be the small eigenvalue of the asymptotic matrix $A(\lambda)$ with corresponding eigenvector $v_0(\lambda)$. Then since $\det(A - \nu I) = 0$ implies $\det(A^* - \overline{\nu}I) = 0$, $-\overline{\nu(\lambda)}$ is the small eigenvalue of $-A(\lambda)^*$; let $w_0(\lambda)$ be the corresponding eigenvector.\\

It would be great if there were a nice relationship between $v_0(\lambda)$ and $w_0(\lambda)$ (like there is with the corresponding eigenvalues), but without additional assumptions on $A(\lambda)$, this is not the case. Failing that, we would settle for knowing $\langle v_0(\lambda), w_0(\lambda) \rangle \neq 0$. Even this is too much to ask in the generic case. As an easy counterexample, if we take

\[
M = \begin{pmatrix}1 & 1 \\ 0 & 1 \end{pmatrix}
\]

$M$ has a single eigenvector $(1, 0)$ and $M^*$ has a single eigenvector $(0, 1)$, both corresponding to the lone eigenvalue 1. These are clearly orthogonal. Since we suspect the problem might be the Jordan block, we will prove the following lemma.

\begin{lemma}\label{perpeigs}
Let $A$ be an $n \times n$ matrix, and suppose $v$ and $w$ are solutions to $Av = \lambda v$ and $A^*w = \overline{\lambda}w$, respectively. Suppose $\lambda$ is a simple eigenvalue, i.e. is has algebraic multiplicity of 1. Then $\langle v, w \rangle \neq 0$.
\begin{proof}
Since $\lambda$ is simple, $\text{span} \{w\} = \ker(A^* - \overline{\lambda}I)$. Suppose $v \perp w$. Then $v \in \ker(A^* - \overline{\lambda I})^\perp = \text{ran}(A - \lambda I)$, where the equality holds since $A$ is finite dimensional, thus has closed range. But this implies $(A - \lambda I)v_1 = v$ for some $v_1$, which cannot be the case since $\lambda$ is simple, so there cannot be such a generalized eigenvector. We conclude that $\langle v, w \rangle \neq 0$
\end{proof}
\end{lemma}

Given this lemma, we make the following hypothesis.

\begin{hypothesis}\label{simplesmalleig}
For sufficiently small $\lambda$, the small eigenvalue $\nu(\lambda)$ of the matrix $A(\lambda)$ is simple.
\end{hypothesis}

I am not actually sure we need to state this as a hypothesis, since the eigenvalues of $A(\lambda)$ are analytic in $\lambda$, $A(0)$ has a simple eigenvalue at 0, and the rest of the eigenvalues of $A(0)$ are large, but we might as well put it here for now.\\

Given Hypothesis \ref{simplesmalleig} (or the argument above), $\nu(\lambda)$ is a simple eigenvalue of $A(\lambda)$, thus by Lemma \ref{perpeigs}, $\langle v_0(\lambda), w_0(\lambda) \rangle \neq 0$. Since eigenvalues are defined up to scalar multiples, we can scale $v_0(\lambda)$ and/or $w_0(\lambda)$ such that

\[
\langle v_0(\lambda), w_0(\lambda) \rangle = 1
\]

Note that $v_0(\lambda), w_0(\lambda)$ depend on $\lambda$ but not on $\beta^+$.\\
 
Now we have all the pieces in place to derive a formula for the projection and evolution on the center space for $x \geq 0$. Using Lemma \ref{veigproblem}, let $\tilde{v}_+(x; \beta^+, \lambda)$ and $\tilde{w}_+(x; \beta^+, \lambda)$ be solutions to the eigenvalue problem \eqref{eig:V} and its adjoint problem \eqref{eig:W} such that

\begin{align*}
\lim_{x \rightarrow \infty} e^{-\nu(\lambda) x} \tilde{v}_+(x; \beta^+, \lambda) = v_0(\lambda) \\
\lim_{x \rightarrow \infty} e^{\overline{\nu(\lambda)} x} \tilde{w}_+(x; \beta^+, \lambda) = w_0(\lambda) \\
\end{align*}

We would like to scale out the exponential term, so let

\begin{align*}
\tilde{v}_+(x; \beta^+, \lambda) &= e^{\nu(\lambda) x } v_+(x; \beta^+, \lambda) \\
\tilde{w}_+(x; \beta^+, \lambda) &= e^{-\overline{\nu(\lambda)} x } w_+(x; \beta^+, \lambda) \\
\end{align*}

Then we have

\begin{align*}
\lim_{x \rightarrow \infty} v_+(x; \beta^+, \lambda) = v_0(\lambda) \\
\lim_{x \rightarrow \infty} w_+(x; \beta^+, \lambda) = w_0(\lambda) \\
\end{align*}

Note that since we scaled out any exponential term, we know that this limit exists, although we do not have a decay rate for $|v_+(x; \beta^+, \lambda) - v_0(\lambda)|$.\\

By Lemma \ref{eigadjoint}, $\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle$ is constant for all $x \geq 0$. Thus, taking $x \rightarrow \infty$ and using the continuity of the inner product, we conclude that for all $x \geq 0$,

\[
\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle = \langle v_0(\lambda), w_0(\lambda) \rangle = 1
\]

Looking at the inner product $\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle$, we have for all $x \geq 0$,

\begin{align*}
\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle
&= \langle e^{\nu(\lambda) x } v_+(x; \beta^+, \lambda), e^{-\overline{\nu(\lambda)} x} \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= e^{\nu(\lambda) x } e^{-\nu(\lambda) x } \langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle \\
&= \langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle
\end{align*}

Combining these two results, it follows that $\langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle = 1$ for all $x \geq 0$.\\

We will now write the projection $P^c_+(x; \beta^+, \lambda)$ for $x \geq 0$ in terms of the adjoint solution $\tilde{w}_+(x; \beta^+, \lambda)$. To do this, let $R^s_+(x; \beta^+, \lambda)$, $R^u_+(x; \beta^+, \lambda)$, and $R^c(x; \beta^+, \lambda)$ be the ranges of the corresponding projections (stable, unstable, and center). The dimensions of these ranges are 2, 2, and 1 (respectively). Note that since $\tilde{v}_+(x; \beta^+, \lambda)$ is in the center range $R^c(x; \beta^+, \lambda)$ and that space is one-dimensional, $\tilde{v}_+(x; \beta^+, \lambda)$ is a basis vector for that space. Since we can scale the basis vector by any constant we want, we can divide by $e^{\nu(\lambda) x}$, so that $v_+(x; \beta^+, \lambda)$ is a basis vector for $R^c(x; \beta^+, \lambda)$. Since this space is one-dimensional, every element in $R^c(x; \lambda)$ is a scalar multiple of $\tilde{v}_+(x; \beta^+, \lambda)$. \\

Next we show that the projection $P^c_+(x; \beta^+, \lambda)$ is a projection on the adjoint solution $w_+(x; \beta^+, \lambda)$. To do this, we first show that $\tilde{w}(0; \beta^+, \lambda)$ is perpendicular to $R^s_+(0; \beta^+, \lambda)$. Let $u(0) \in R^s_+(0; \beta^+, \lambda)$. Then $u(x) = \Phi(x, 0; \beta^+, \lambda)u(0) \in R^s_+(x; \beta^+, \lambda)$ for all $x \geq 0$. Since the inner product $\langle u(x), \tilde{w}_+(x; \beta^+, \lambda) \rangle$ is constant in $x$, we let $x \rightarrow \infty$ and use the continuity of the inner product to get

\begin{align*}
\lim_{x \rightarrow \infty} \langle u(x), \tilde{w}_+(x; \beta^+, \lambda) \rangle &= \lim_{x \rightarrow \infty} e^{-\nu(\lambda) x} \langle u(x), w_+(x; \beta^+, \lambda) \rangle \\
&= \langle \lim_{x \rightarrow \infty} e^{-\nu(\lambda) x} u(x), w_0(\lambda) \rangle \\
&= 0
\end{align*}

since $u(x)$ decays exponentially at a faster rate than $|\nu(\lambda)|$. Thus we have $\tilde{w}(0; \beta^+, \lambda) \perp R^s(0; \beta^+, \lambda)$. By Lemma \ref{perpeigs}, $\tilde{w}_+(x; \beta^+, \lambda) \perp R^s_+(x; \beta^+, \lambda)$ for all $ \geq 0$.\\

Note that we cannot play the same game with $R^u_+(x; \beta^+, \lambda)$, since to get decay to 0 we would have to take $x \rightarrow -\infty$. Since everything we have done so far pertains to the dichotomy/trichotomy on $\R^+$, the results above are only valid for $x \geq 0$, so we cannot take $x \rightarrow -\infty$.\\

However, we really want to have $\tilde{w}_+(x; \beta^+, \lambda) \perp R^u_+(x; \beta^+, \lambda)$ for all $x \geq 0$. Since $\tilde{w}_+(x; \beta^+, \lambda)$ is a nonzero scalar multiple of $w_+(x; \beta^+, \lambda)$, this is equivalent to having $w_+(x; \beta^+, \lambda) \perp R^u_+(x; \beta^+, \lambda)$ for $x \geq 0$ (they are the same at $x = 0$). To attain this, we will change coordinates. The idea is that if we do this at $x = 0$ to get $w_+(0; \beta^+, \lambda) \perp R^u_+(0; \beta^+, \lambda)$, the invariance of the inner product in $x$ should take care of the rest.\\

Let $\{ a^s_1(0), a^s_2(0)\}$ be a basis for $R^s_+(0; \beta^+, \lambda)$ and let $\{a^u_1(0), a^u_2(0)\}$ be a basis for $R^u_+(0; \beta^+, \lambda)$. By the discussion above, $w_+(0)$ is already perpendicular to $\{ a^s_1(0), a^s_2(0)\}$. All we need to do is change coordinates so that $w_+(0)$ is perpendicular to $\{ a^u_1(0), a^u_2(0)\}$. This is easy to accomplish by Gram-Schmidt since the set $\{ w_+(0), a^u_1(0), a^u_2(0) \}$ is linearly independent. Note that by this process, $w_+(0)$ remains unchanged, while $\{ a^u_1(0), a^u_2(0) \}$ may be modified. For convenience, we will use the same notation $\{ a^u_1(0), a^u_2(0) \}$ for the basis vectors of $R^u_+(0; \beta^+, \lambda)$ after the coordinate change.\\

Let $a^u_i(x) = \Phi(x,0; \beta^+, \lambda)a^u_i(0)$, i.e. evolve the new basis vectors forward. These, together with $w_+(0)$, will remain linearly independent after evolution. For simplicity, consider one of these, say $a^u_1(x)$. Since $\Phi(x,0; \lambda) a^u_1(0)$ solves the eigenvalue problem with initial condition $a^u_1(0)$, by Lemma \ref{perpeigs} we have

\begin{align*}
\langle a^u_1(x), \tilde{w}_+(x; \beta^+, \lambda) \rangle &= \langle \Phi(x,0; \lambda) a^u_1(0), \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= \langle a^u_1(0), \tilde{w}(0; \beta^+, \lambda) \rangle \\
&= \langle a^u_1(0), w(0; \beta^+, \lambda) \rangle \\
&= 0
\end{align*}

Since $\tilde{w}_+(x; \beta^+, \lambda)$ is a scalar multiple of $w_+(x; \beta^+, \lambda)$, we also have for $x \geq 0$

\[
\langle a^u_1(x), w_+(x; \beta^+, \lambda) \rangle = 0
\]

Thus a single change of variables at $x = 0$ accomplishes what we want. Since $\tilde{w}_+(x; \beta^+, \lambda) \in R^c_+(x; \beta^+, \lambda)$ and is perpendicular to the other two spaces, to get the center range projection $P^c_+(x; \beta^+, \lambda)$, all we have to do is project onto $\tilde{w}_+(x; \beta^+, \lambda)$. To do this, we take the inner product with $\tilde{w}_+(x; \beta^+, \lambda)$ to get the component in the direction of the basis vector $\tilde{v}_+(x; \beta^+, \lambda)$. Thus for $x \geq 0$ and arbitrary $u$ we claim

\begin{align*}
P^c_+(x; \beta^+, \lambda)u &= \langle u, \tilde{w}_+(x; \beta^+, \lambda) \rangle \tilde{v}_+(x; \beta^+, \lambda) \\
&= e^{-\nu(\lambda)x} e^{\nu(\lambda) x }\langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda)
\end{align*}

The range of this is the span of $v_+(x; \beta^+, \lambda)$, which is what we want. To show that this is the projection onto the center range, all we need to do is verify that it is in fact a projection. To do this, we will show that $P^c_+(x; \beta^+, \lambda)P^c_+(x; \beta^+, \lambda) = P^c_+(x; \beta^+, \lambda)$.

\begin{align*}
P^c_+(x; \beta^+, \lambda)( P^c_+(x; \beta^+, \lambda) u ) &= \langle \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(x; \beta^+, \lambda) \rangle \langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= P^c_+(x; \beta^+, \lambda) u 
\end{align*}

where $\langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle = 1$ for all $x \geq 0$ by Lemma \ref{perpeigs}. Thus this is indeed a projection, and is in fact the projection we are looking for. From our definition of $P^c_+(x; \lambda)$ and the coordinate change we performed above, we have

\begin{align*}
\ker P^c_+(x; \beta^+, \lambda) &= \text{span }\{ w_+(x; \beta^+, \lambda) \}^\perp\\
\text{ran } P^c_+(x; \beta^+, \lambda) &= \text{span }\{ v_+(x; \beta^+, \lambda) \}
\end{align*}

If this were an orthogonal projection, that would mean that $(\ker P^c_+(x; \beta^+, \lambda))^\perp = \text{ran } P^c_+(x; \beta^+, \lambda)$, i.e. $\text{span }\{ w_+(x; \beta^+, \lambda) \}) = \text{span }\{ v_+(x; \beta^+, \lambda) \})$. This would mean that $v_+(x; \beta^+, \lambda)$ and $w_+(x; \beta^+, \lambda)$ are scalar multiples of each other. Since $\langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle = 1$ for all $x \geq 0$, this implies $v_+(x; \beta^+, \lambda) = w_+(x; \beta^+, \lambda)$, which is likely not true. \\

We will also derive an expression for the center evolution $\Phi^c_+(x,y; \beta^+, \lambda)$ for $x \geq 0$. For arbirary $u$ and $x, y \geq 0$

\begin{align*}
\Phi^c_+(x,y; \beta^+, \lambda)u &= \Phi(x,y; \beta^+, \lambda) P^c_+(y; \beta^+, \lambda) u \\
&= \Phi(x,y; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle v_+(y; \beta^+, \lambda) \\
&= \Phi(x,y; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} \tilde{v}_+(y; \beta^+, \lambda) \\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} \Phi(x,y; \beta^+, \lambda) \tilde{v}_+(y; \beta^+, \lambda) \\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} \tilde{v}_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} e^{\nu(\lambda)x} v_+(x; \beta^+, \lambda) \\
&= e^{\nu(\lambda)(x-y)} v_+(x; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle 
\end{align*}

where we used the fact that $\tilde{v}$ is a solution to the eigenvalue problem, thus under the evolution $\Phi(y, x; \beta^+, \lambda)$ we have $\Phi(y, x; \beta^+, \lambda)\tilde{v}_+(x; \beta^+, \lambda) = \tilde{v}_+(y; \beta^+, \lambda)$.\\

We can repeat we just did for the trichotomy on $\R^-$, which will give us analogous funcions $\tilde{v}_-(x; \beta^-, \lambda)$, $v_-(x; \beta^-, \lambda)$, $\tilde{w}_-(x; \beta^-, \lambda)$, and $w_-(x; \beta^-, \lambda)$. We can do a similar change of variables to make $w_-(0; \beta^-, \lambda)$ perpendicular to $R^s_-(0; \beta^-, \lambda)$. Since we have two more dimensions to work with, this is always possible. The equations for the projection $P^c_-(x; \beta^-, \lambda)$ and the evolution $\Phi^c_-(x,y; \beta^-, \lambda)$ will be the same except for the subscripts. Note that these are all dependent on the IC $\beta^-$.
\\

For the stable and unstable parts of the trichotomy, we have the following bounds. (WE MIGHT HAVE TO SHOW THIS, BUT THESE SHOULD BE OBVIOUS. ALSO WE SHOULD CHECK THE SIGNS.)

\begin{align*}
\Phi^s_-(x, y; \beta^-, \lambda) &\leq C e^{-\alpha(y - x)} && y \geq x \geq 0\\
\Phi^u_-(x, y; \beta^-, \lambda) &\leq C e^{\alpha(y - x)} && x \geq y \geq 0\\
\Phi^s_+(x, y; \beta^-, \lambda) &\leq C e^{-\alpha(y - x)} && 0 \geq x \geq y\\
\Phi^u_+(x, y; \beta^-, \lambda) &\leq C e^{\alpha(y - x)} && 0 \geq y \geq x \\\\
\end{align*}


\subsection{The Inversion}

At this point, we write down the fixed point equations for the problem. To do that, we take a look at where the equations came from in the hyperbolic case. These are very similar to the variation of constants formula, except that we split the solution up into stable, unstable, and center parts, evolve them separately (each with its own initial condition), and recombine them. Thus the fixed point equations will look like those in San98 and the exponentially weighted space with the addition of a center evolution term together with an initial condition in the center subspace. The other difference will be the dependence on the ICs $\beta_i^\pm$. Note that these are fixed as they come from the construction of the periodic double pulse.
\\ 

The fixed point equations for our problem are thus

\begin{align*}
W_i^-(x) = \Phi^s_-(&x, -X_{i-1}; \beta_i^-, \lambda) a_{i-1}^- + \Phi^u_-(x, 0; \beta_i^-, \lambda) b_i^- \\
&+ e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&+ \int_0^x \Phi^u_-(x, y; \beta_i^-, \lambda)[ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&+ \int_{-X_{i-1}}^x \Phi^s_-(x, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&+ \int_{-X_{i-1}}^x 
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
W_i^+(x) = \Phi^u_+(&x, X_i; \beta_i^+, \lambda)a_i^+ + \Phi^s_+(x, 0; \beta_i^+, \lambda)b_i^+ \\
&+ e^{\nu(\lambda)(x - X_i)} v_+(x; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&+ \int_0^x \Phi^s_+(x, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&+ \int_{X_i}^x \Phi^u_+(x, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&+ \int_{X_i}^x e^{\nu(\lambda)(x-y)} v_+(x; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

where

\begin{align*}
(a^-, a^+) &\in E^s \oplus E^u\\
(b^-, b^+) &\in R^u_-(0; 0) \oplus R^s_+(0; 0)\\
c^\pm &\in \text{span}\{v_0(\lambda)\}
\end{align*}

Recall that the eigenspaces $E^s$, $E^u$, and $E^c$ refer to the unpertubed problem, i.e. they are the eigenspaces of $A(0)$. The projections onto $E^s$, $E^u$, and $E^c$ are given by $P_0^s$, $P_0^u$, and $P_0^c$. The initial conditions on the stable and unstable subspaces lie in the corresponding spaces for the unperturbed problem. By contrast, the initial conditions on the center subspace is in the eigenspace for the perturbed problem. We can do this (and it will prove to be very useful!) since we have an equation for the evolution along this center subspace.\\

We will take the following notational conventions, which we use for convenience. The first one makes sense since periodic boundary conditions means that things ``wrap around'', so can can consider the problem as posed on a ``loop''.

\begin{enumerate}
\item $c_2^- = c_0^-$, $a_2^- = a_0^-$, $b_0^- = b_2^-$, $d_0 = d_2$, and $W_0 = W_2$

\item If we eliminate either a subscript or a superscript (or both) in the norm, we are taking the maximum of the eliminated things. For example,
	\begin{enumerate}
		\item $|c_i| = \max(|c_i^+|, |c_i^-|)$ 
		\item $|c^+| = \max(|c_1^+|, |c_2^+|)$
		\item $|c| = \max(|c_1^-|, |c_1^+|, |c_2^-|, |c_2^+|)$
	\end{enumerate}
	This is always well defined, since the maximum is over a finite number of terms.
\item Let

\begin{align*}
\tilde{c}_i^- &= e^{\nu(\lambda)X_i} c_i^- \\
\tilde{c}_i^+ &= e^{-\nu(\lambda)X_i} c_i^+
\end{align*}

These will come in handy, as the the coefficients $c$ are often multiplied by an exponential factor.\\

\end{enumerate}

Before performing the inversion, we will define the following three useful constants.

\begin{enumerate}

	\item Let $\delta > 0$ be a small. How small will be determined later. Then choose $|\lambda|$ sufficiently small and $X_1$ sufficiently large such that

	\begin{equation}
	e^{-\alpha X_1}, ||G||, |\lambda|, |\Delta H| < \delta
	\end{equation}

	\item Fix a constant $\tilde{\alpha}$, with $0 < \tilde{\alpha} < \alpha$. The idea is that we want $\tilde{\alpha}$ to be close to $\alpha$. Then choose $X_1$ sufficiently large such that $e^{-\alpha X_1} < \delta$.

	\item Choose $\tilde{\delta} > 0$ such that $\tilde{\delta} < \alpha - \tilde{\alpha}$. Then choose $\delta$ sufficiently small such that $3 |\nu(\lambda)| < \tilde{\delta}$ for all $|\lambda| < \delta$. Thus we have $3 |\nu(\lambda)| < \alpha - \tilde{\alpha}$. Since $\nu(\lambda) = \mathcal{O}(\lambda)$, this can be accomplished. We also make sure $\tilde{\alpha}$ is sufficiently close to $\alpha$ and $\tilde{\delta}$ is sufficiently small so that $\tilde{\delta} < \tilde{\alpha}$.

\end{enumerate}


Now, as in San98 and the exponentially weighted case, we will perform the inversion of our problem in a series of lemmas. The first step is to solve for $W$ in terms of $(a, b, c, d)$.\\

First, we obtain a bound on the terms from the fixed point equations which involve $W$. 

% Inversion, lemma 1 (L1 bound)

\begin{lemma}\label{L1}

Let $L_1(\lambda): V_w \rightarrow V_w$ be the linear operator defined piecewise by

\begin{align*}
(L_1(\lambda)W)_i^-(x) &= \int_0^x \Phi^u_-(x, y; \beta_i^-, \lambda) G_i^-(y)W_i^-(y) dy + \int_{-X_{i-1}}^x \Phi^s_-(x, y; \beta_i^-, \lambda) G_i^-(y)W_i^-(y) dy \\
&+ \int_{-X_{i-1}}^x 
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
(L_1(\lambda)W)_i^+(x) &= \int_0^x \Phi^s_+(x, y; \beta_i^+, \lambda) G_i^+(y) W_i^+(y) dy + \int_{X_i}^x \Phi^u_+(x, y; \beta_i^+, \lambda) G_i^+(y) W_i^+(y) dy \\
&+ \int_{X_i}^x e^{\nu(\lambda)(x-y)} v_+(x; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Then $L_1(\lambda): V_w \rightarrow V_w$ is a bounded linear operator with bound

\begin{equation}\label{L1bound}
||L_1(\lambda)W|| \leq C (e^{\nu(\lambda)X_1} + e^{\nu(\lambda)X_2}) ||G|| \: ||W||
\end{equation}

\begin{proof}
The first two integrals on the RHS of $L_1$ have the same bound as in San98 and in the exponentially weighted case. For the third integral, the negative piece has bound

\begin{align*}
\Big| \int_{-X_{i-1}}^x &e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \Big| \\
&\leq \int_{-X_{i-1}}^x e^{\nu(\lambda)(x-y)} |v_-(x; \beta_i^-, \lambda)| |G_i^-(y)|||W|||w_-(y; \beta_i^-, \lambda)|dy \\
&\leq C ||G||||W|| \int_{-X_{i-1}}^x e^{\nu(\lambda)(x-y)} dy \\
&= C ||G||||W|| \frac{e^{\nu(\lambda)x} - 1}{\nu(\lambda)} \\
&\leq C e^{\nu(\lambda)X_{i-1}} ||G|| \: ||W||
\end{align*}

where we used the fact that $x \leq 0$ on the negative piece. Since $v_-(x; 
\beta_i^-, \lambda)$ and $w_-(x; \beta_i^-, \lambda)$ are bounded and only depend on $\lambda$ (recall that we pulled out any exponential growth/decay in our expressions for $\tilde{v}$ and $\tilde{w}$), we incorporate those bounds into the constant $C$. The constant $C$ will depend on $\lambda$, but we suppress this dependence in the notation for simplicity. The positive piece has a similar bound with $X_{i-1}$ replaced with $X_i$. Thus we have the bound

\[
||L_1(\lambda)W|| \leq C (e^{\nu(\lambda)X_1} + e^{\nu(\lambda)X_2}) ||G|| \: ||W||
\]

\end{proof}
\end{lemma}

We would like a more useful bound than this for the following reason. Using the uniform bound $||G|$, the bound above will have a term of order $e^{\nu(\lambda)X_2} e^{-\alpha X_1}$. Suppose $\text{Re }\nu(\lambda) > 0$. If $X_2 > X_1$, $e^{\nu(\lambda)X_2}$ grows in $X_2$ and $e^{-\alpha X_1}$ decays in $X_1$. Thus, there is no telling what will happen as we vary $X_1$ and $X_2$ independently. One workaround is to make $X_1$ and $X_2$ depend on each other, e.g. $X_2 = k X_1$ for some $k \geq 0$. This does work (and we have shown it does!) but we do not want the two length parameters to be related, since we would like to send $X_2$ to $\infty$ without altering $X_1$.\\

For another (hopefully better!) way around this problem, we will use the piecewise bound on $|G_i^\pm(x)|$ from Proposition \ref{2pconstruction}.

% inversion lemma 1a - improved bound on L1

\begin{lemma}\label{L1better}

Let $L_1(\lambda): V_w \rightarrow V_w$ be the linear operator defined in the previous lemma. Then $L_1(\lambda): V_w \rightarrow V_w$ is a bounded linear operator with bound

\begin{equation}\label{L1bound2}
||L_1(\lambda)W|| \leq C ( e^{-(\alpha -|\nu(\lambda)|)X_1} + e^{-(\alpha -|\nu(\lambda)|)X_2})||W||
\end{equation}

Piecewise bounds are

\begin{align*}
||L_1(\lambda)_i^- W|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ||W|| \\
||L_1(\lambda)_i^+ W|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_i} ||W||
\end{align*}

\begin{proof}
The first two integrals on the RHS of $L_1$ have the same bound as in San98 and in the exponentially weighted case. For the third integral, we will use the piecewise bound for $G$. For the ``negative'' piece (where $x \leq 0$), we have

\begin{align*}
\Big| \int_{-X_{i-1}}^x &e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \Big| \\
&\leq C ||W|| \int_{-X_{i-1}}^x e^{\nu(\lambda)(x-y)} e^{-\alpha X_{i-1}}e^{-\alpha(X_{i-1} + y)}dy \\
&\leq C ||W|| \int_{-X_{i-1}}^x e^{|\nu(\lambda)| (x-y)} e^{-\alpha X_{i-1}}e^{-\alpha(X_{i-1} + y)}dy \\
&= C ||W|| e^{|\nu(\lambda)| x } e^{-2 \alpha X_{i-1}} \int_{-X_{i-1}}^x e^{-(\alpha + |\nu(\lambda)|) y} dy \\
&= C ||W|| e^{|\nu(\lambda)| x } e^{-2 \alpha X_{i-1}} \frac{1}{\alpha + \nu(\lambda)} \left( e^{-(\alpha + |\nu(\lambda)|)(-X_{i-1})} - e^{-(\alpha + |\nu(\lambda)|)x} \right) \\
&\leq C ||W|| e^{-2 \alpha X_{i-1}} \left( e^{(\alpha + |\nu(\lambda)|)X_{i-1}} + e^{-\alpha x}  \right) \\
&\leq C ||W|| e^{-2 \alpha X_{i-1}} \left( e^{\alpha X_{i-1}} e^{|\nu(\lambda)|X_{i-1}} + e^{\alpha X_{i-1}}  \right) \\
&\leq C ||W|| e^{-\alpha X_{i-1}} \left( e^{|\nu(\lambda)|X_{i-1}} + 1 \right) \\
&\leq C ||W|| e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} \\
\end{align*}

This can be made arbitrarily small for sufficiently large $X_{i-1}$. Thus for this bound we have

\begin{align*}
||L_1(\lambda)_i^- W|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ||W|| \\
||L_1(\lambda)_i^+ W|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_i} ||W||
\end{align*}

For a uniform bound, we have

\[
||L_1(\lambda)W|| \leq 
C (e^{-(\alpha -|\nu(\lambda)|)X_1} + e^{-(\alpha -|\nu(\lambda)|)X_2})||W||
\]

\end{proof}
\end{lemma}

Next, we obtain a bound on the terms from the fixed point equations which do not involve $W$. 

% inversion, lemma 2 (L2 bound)

\begin{lemma}\label{L2}

Let $L_2(\lambda): V_a \times V_b \times V_c \times V_d \rightarrow V_w$ be the linear operator defined piecewise by

\begin{align*}
L_2(\lambda)&(a,b,c,d)_i^-(x) = \Phi^s_-(x, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- + \Phi^u_-(x, 0; \beta_i^-, \lambda)b_i^- \\
&+ e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&+ \int_0^x \Phi^u_-(x, y; \beta_i^-, \lambda)\lambda^2 d_i \tilde{H}(y) dy + \int_{-X_{i-1}}^x \Phi^s_-(x, y; \beta_i^-, \lambda) \lambda^2 d_i \tilde{H}(y) dy \\
&+ \int_{-X_{i-1}}^x
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
L_2(\lambda)&(a,b,c,d)_i^+(x) = \Phi^u_+(x, X_i; \beta_i^+, \lambda)a_i^+ + \Phi^s_+(x, 0; \beta_i^+, \lambda)b_i^+ \\
&+ e^{\nu(\lambda)(x - X_i)} v_+(x; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&+ \int_0^x \Phi^s_+(x, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}(y) dy + \int_{X_i}^x \Phi^u_+(x, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}(y) dy \\
&+ \int_{X_i}^x e^{\nu(\lambda)(x-y)} v_+(x; \beta_i^+, \lambda) \langle \lambda^2 d_i \tilde{H}(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Then $L_2$ is a bounded linear operator with bound

\begin{equation}\label{L2bound}
|L_2(\lambda)(a,b,c,d)| \leq C (|a| + |b| + e^{|\nu(\lambda)|X_i}|c_i| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + |\lambda|^2 |d| )
\end{equation}

We also have the following piecewise, $x$-dependent bounds on $L_2$.

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^-(x)| &\leq C (e^{-\alpha(x + X_{i-1})}|a_{i-1}^-| + |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| ) \\
|L_2(\lambda)(a,b,c,d)_i^+(x)| &\leq C (e^{-\alpha(x - X_i)}|a_i^+| + |b| + e^{\nu(\lambda)x} |\tilde{c}_i^+| + |\lambda|^2 |d| ) 
\end{align*}

where the $\tilde{c}$ are defined above.

\begin{proof}
First, we note that $L_2$ comprises the terms from the fixed point equations which do not involve $W$. Most of the bounds on the individual terms are the same as in San98 and the exponentially weighted case. We will look at the ``minus'' piece. The ``plus'' piece will be similar. First, for the $c_{i-1}^-$ term we have

\[
e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \leq C e^{|\nu(\lambda)| X_{i-1} }|c_{i-1}^-|
\]

The first two integral terms are similar to San98. For the third (center) integral terms, we use the following trick involving $\tilde{\alpha}$ to eliminate any potential exponential growth.

\begin{align*}
&\left| \int_{-X_{i-1}}^x 
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, , \lambda) \langle \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \right| \\
&\leq C |\lambda|^2 |d| e^{\tilde{\alpha}x} \int_{-X_{i-1}}^x e^{-\tilde{\alpha}x} e^{\tilde{\alpha}y} e^{\nu(\lambda)(x-y)} |e^{-\tilde{\alpha}y}\tilde{H}(y)|dy \\
&\leq C |\lambda|^2 |d| e^{\tilde{\alpha}x} \int_{-X_{i-1}}^x e^{-\tilde{\alpha}(x-y)} e^{\nu(\lambda)(x-y)} |e^{-\tilde{\alpha}y}\tilde{H}(y)| dy \\
&\leq C |\lambda|^2 |d| e^{\tilde{\alpha}x} \int_{-X_{i-1}}^x e^{-(\tilde{\alpha} - |\nu(\lambda)|)(x-y)} dy \\
&\leq C |\lambda|^2 |d|
\end{align*}

where we use the facts that $|e^{-\tilde{\alpha}y}\tilde{H}(y)|$ is bounded (since the decay rate of $\tilde{H}$ is known) and that $|\nu(\lambda)| < \tilde{\alpha}$ by our choice of $\tilde{\alpha}$. The other center integral is similar. Thus, we attain the bound 

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^-(x)| &\leq C (e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{\nu(\lambda)(X_{i-1} + x)} |c_{i-1}^-| + |\lambda|^2 |d| ) \\
&= C (e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| ) 
\end{align*}

For the ``positive'' piece,

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^+(x)| &\leq C (e^{-\alpha(X_i - x)}|a_i^+| + |b| + e^{\nu(\lambda)(X_i - x)} |c_i^+| + |\lambda|^2 |d| ) \\
&\leq C (e^{-\alpha(X_i - x)}|a_i^+| + |b| + e^{\nu(\lambda)x} |\tilde{c}_i^+| + |\lambda|^2 |d| ) 
\end{align*}

The overall, uniform bound is

\[
|L_2(\lambda)(a,b,c,d)| \leq C (|a| + |b| + e^{|\nu(\lambda)|X_i}|c_i| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + |\lambda|^2 |d| )
\]

\end{proof}
\end{lemma}

Now we can perform the inversion

% inversion lemma 3 - invert to solve for W

\begin{lemma}\label{W1}
There exists a bounded linear operator $W_1: V_\lambda \times V_a \times V_b \times V_c \times V_d \rightarrow V_w$ such that 

\[
W = W_1(\lambda)(a,b,c,d)
\]

This operator is analytic in $\lambda$ and linear in $(a, b, c, d)$. The operator $W_1$ satisfies the bound

\begin{equation}\label{W1bound}
||W_1(\lambda)(a,b,c,d)|| \leq C ( |a| + |b| + e^{|\nu(\lambda)|X_i}|c_i| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + |\lambda|^2 |d| )
\end{equation}

We also have the piecewise bounds

\begin{align*}
||W_1(\lambda)(a,b,c,d)_i^-|| &\leq C ( |a_{i-1}^-| + |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + |\lambda|^2 |d| ) \\
||W_1(\lambda)(a,b,c,d)_i^+|| &\leq C ( |a_i^+| + |b| + e^{|\nu(\lambda)|X_i}|c_i^+| + |\lambda|^2 |d| )
\end{align*}

\begin{proof}
Let the linear operators $L_1$ and $L_2$ be defined as in the previous two lemmas. Then we can rewrite the fixed point equation as

\[
(I - L_1(\lambda))W = L_2(\lambda)(a,b,c,d)
\]

For $L_1$ we have the estimate from Lemma \ref{L1better}

\begin{align*}
||L_1(\lambda)W|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_1}||W|| \\
&\leq C e^{-\tilde{\alpha} X_1}||W|| \\
&\leq C \delta ||W||
\end{align*}

Thus if we choose $\delta$ sufficiently small (i.e. smaller than $C$), the operator norm of $L_1$ is less than 1, which implies that the operator $(I - L_1(\lambda))$ is invertible. The inverse $(I - L_1(\lambda))^{-1}$ is analytic in $\lambda$ and has operator norm 

\[
||(I - L_1(\lambda))^{-1}|| \leq \frac{1}{1 - ||L_1||}
\]

We can then write $W$ as
\[
W = W_1(\lambda)(a,b,c,d) = (I - L_1(\lambda))^{-1} L_2(\lambda)(a,b,c,d)
\]

which depends linearly on $(a,b,c,d)$ and analytically on $\lambda$. Since the operator norm of $L_1$ is bounded by a constant (independent of the $X_i$), we have the uniform bound

\[
||W_1(\lambda)(a,b,c,d)|| \leq C (|a| + |b| + e^{|\nu(\lambda)|X_i}|c_i| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + |\lambda|^2 |d| )
\]

The piecewise bounds are obtained by noting which piece of $L_2$ is involved with which piece of $W$.\\

We can obtain a piecewise, $x$-dependend bound for $W$ by substituting the $W_1$ bound into the expression $W = L_1 + L_2$ and using the bounds for $L_1$ and $L_2$ from the previous lemmas.

\begin{align*}
|W_i^-(x)| &\leq ||(L_1(\lambda)W)_i^-||\:||W_i^-|| + |L_2(\lambda)(a,b,c,d)_i^-(x)| \\
&\leq C \Big( e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ||W_i^-|| + e^{-\alpha(x + X_{i-1})}|a_{i-1}^-| + |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| \Big) \\
&\leq \Big( e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} (|a| + |b| + e^{\nu(\lambda)X_{i-1}}|c_{i-1}| + |\lambda|^2 |d|) \\
&+ e^{-\alpha(x + X_{i-1})}|a_{i-1}^-| + |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| \Big) \\
&\leq \Big( e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} |a| + e^{-\alpha(x + X_{i-1})}|a_{i-1}^-| + |b| + e^{-(\alpha - 2|\nu(\lambda)|)X_{i-1}} |c_{i-1}| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| \Big)
\end{align*}

Similarly, 

\begin{align*}
|W_i^+(x)| &\leq \Big( e^{-(\alpha -|\nu(\lambda)|)X_i} |a| + e^{-\alpha(x - X_i)}|a_{i-1}^-| + |b| + e^{-(\alpha - 2|\nu(\lambda)|)X_{i-1}} |c_{i-1}| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| \Big)
\end{align*}

\end{proof}
\end{lemma}

The next inversion step solves for the joins at $\pm X_i$, i.e. solves the equations

\begin{align*}
W_2^+(X_2) - W_1^-(-X_2) &= D_2 d \\
W_1^+(X_1) - W_2^-(-X_1) &= D_1 d \\
\end{align*}

For $i = 1, 2$, recalling our ``wrap-around'' notation, we can write this as

\begin{align*}
W_i^+(X_i) - W_{i-1}^-(-X_i) &= D_i d \\
\end{align*}

The next lemma performs this inversion.

% second inversion lemma

\begin{lemma}\label{inv2}
There exist operators

\begin{align*}
A_1: V_\lambda \times V_b \times V_c \times V_d \rightarrow V_a \\
W_2: V_\lambda \times V_b \times V_c \times V_d \rightarrow V_w \\
\end{align*}

such that $(a,W) = ( A_1(\lambda)(b,c,d), W_2(\lambda)(b,c,d) )$ solves our system. These operators are analytic in $\lambda$, linear in $(b,c,d)$, and bounds for them are given by

\begin{equation}
|A_1(\lambda)_i(b, c, d)| \leq C \Big( (e^{-\alpha X_i} + ||G||) |b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i|
+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d| \Big)
\end{equation} 

and

\begin{equation}
|W_2(\lambda)(b,c,d)|| 
\leq C \Big( |b| + e^{|\nu(\lambda)|X_i}|c_i| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + |D|)|d| \Big)
\end{equation} 

Furthermore, 

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_2(\lambda)_i^+(b, c, d) \\
a_i^- &= -P^s_0 D_i d + A_2(\lambda)_i^-(b, c, d)
\end{align*}

where $A_2$ is a bounded operator with estimate

\begin{align*}
|A_2&(\lambda)_i(b, c, d)| \\
&\leq C \Big( (e^{-\alpha X_i} + ||G||)|b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| + (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + (p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big)
\end{align*}

$(p_1(X_i; \lambda)$ and $p_4(X_i; \lambda)$ are defined in the proof below. 

\begin{proof}

Using the fixed point equations at $\pm X_i$, we have

\begin{align*}
W_i^+(X_i) &- W_{i-1}^-(-X_i) = P^u_+(X_i; \beta_i^+, \lambda) a_i^+ - P^s_-(-X_i; \beta_{i-1}^-, \lambda) a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i-1}^-, \lambda)b_{i-1}^- \\
&+ v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ - v_-(-X_i; \beta_{i-1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i-1}^-, \lambda) [ G_{i-1}^-(y) W_{i-1}^-(y) + d_{i-1} \lambda^2 \tilde{H}(y) ] dy
\end{align*}

We now manipulate this to get it into a form we can use. First, we get the coefficients $a_i^\pm$ by themselves by adding and subtracting $P_0^u a_i^+$ and $P_0^s a_i^-$. Recalling where the various $a_i^\pm$ live and what happens when we apply the projections on $E^u$ and $E^s$, this becomes

\begin{align*}
D_i d &= a_i^+ - a_i^- \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i-1}^-, \lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i-1}^-, \lambda)b_{i-1}^- \\
&+ v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ - v_-(-X_i; \beta_{i-1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i-1}^-, \lambda) [ G_{i-1}^-(y) W_{i-1}^-(y) + d_{i-1} \lambda^2 \tilde{H}(y) ] dy
\end{align*}

For a bound on the ``projection difference'', let

\[
p_1(X; \beta^+, \beta^-, \lambda) = \sup_{x \geq X} (|P^u_+(x; \beta^+, \lambda) - P_0^u| + |P^s_-(-x; \beta^-, \lambda) - P_0^s|)
\]

Note that this varies with $\beta^\pm$, $\lambda$ and with $X$. Based on San98, the bounds for $\beta_i^\pm$ from Proposition \ref{2pconstruction}, and intuition, we hypothesize the following bound. (WE SHOULD ACTUALLY SHOW THIS.)

\begin{hypothesis}\label{p1bound}
\begin{equation}
p_1(X; \lambda) = \mathcal{O}( e^{-\alpha X} +  e^{-2 \alpha X_1} + e^{-2 \alpha X_2} + |\lambda| )
\end{equation}
\end{hypothesis}

As long as $X$ is greater than the minimum of $X_1, X_2$, we have

\begin{equation}
p_1(X; \lambda) = \mathcal{O}( e^{-\alpha X_1} + e^{-\alpha X_2} + |\lambda| )
\end{equation}

Next we rearrange the above to get $a_i^- - a_i^+$ by itself on the LHS.

\begin{align*}
a_i^- - a_i^+ &= -D_i d  \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i-1}^-,\lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i-1}^-, \lambda) b_{i-1}^- \\
&+ v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ - v_-(-X_i; \beta_{i-1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i-1}^-, \lambda) [ G_{i-1}^-(y) W_{i-1}^-(y) + d_{i-1} \lambda^2 \tilde{H}(y) ] dy
\end{align*}

Since $a_i^- - a_i^+ \in E^+ \oplus E^-$, the RHS must lie in $E^+ \oplus E^-$ as well. Since $\C^5 = E^+ \oplus E^- \oplus E^0$, the RHS must have no component in the (unperturbed) center space. The vectors $v_\pm(\pm X_i; \beta_{i}^\pm,\lambda)$ are close to $v_0(\lambda)$, which is close to $v_0(0) \in E^0$. Define

\begin{align*}
\Delta v_\pm(X; \beta^\pm, \lambda) &= v_\pm(\pm X; \beta^\pm, \lambda) - v_0(\lambda) \\
\Delta w_\pm(X; \beta^\pm, \lambda) &= w_\pm(\pm X; \beta^\pm, \lambda) - w_0(\lambda)
\end{align*}

Then let

\begin{align*}
p_2(X; \lambda) &= |\Delta v_\pm(X; \beta^\pm, \lambda)| + |\Delta w_\pm(X; \beta^\pm, \lambda)|\\
&= |v_\pm(\pm X; \beta^\pm, \lambda) - v_0(\lambda)| + |w_\pm(\pm X; \beta^\pm, \lambda) - w_0(\lambda)|
\end{align*}

and

\begin{equation}\label{p3}
p_3(X; \lambda) = |v_0(\lambda) - v_0(0)| 
\end{equation}

Since $v_\pm(\pm x; \beta^\pm, \lambda) \rightarrow v_0(\lambda)$ and $w_\pm(\pm x; \beta^\pm, \lambda) \rightarrow w_0(\lambda)$ as $|x| \rightarrow \infty$, $p_2(X; \lambda) \rightarrow 0$ as $|x| \rightarrow \infty$, but we do not have a rate of convergence for it, thus we do not have a bound. Fortunately, this will not matter.\\

For $p_3$, we can expand $v_0(\lambda)$ in a Taylor series in $\lambda$ to get

\[
v_0(\lambda) = v_0(0) + \lambda \frac{\partial}{\partial \lambda}v_0(\lambda)\Big|_{\lambda = 0} + \mathcal{O}(\lambda^2)
\]

Since $\frac{\partial}{\partial \lambda}v_0(\lambda)\Big|_{\lambda = 0}$ is a constant, we have

\[
p_3(X; \lambda) = \mathcal{O}(\lambda) 
\]

To eliminate most of the component of $v_\pm(\pm X_i; \beta^\pm, \lambda)$ and use these bounds, we write $a_i^- - a_i^+$ as

\begin{align*}
a_i^- &- a_i^+ = -D_i d + (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i-1}^-, \lambda) - P_0^s)a_i^- \\
&+ v_0(0) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ 
- v_0(0) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i-1}^-, \lambda)b_{i-1}^- \\
&+ (v_0(0) - v_+(X_i; \beta_i^+, \lambda)) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&- (v_0(0) - v_-(-X_i; \beta_{i-1}^-, \lambda)) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i-1}^-, \lambda) [ G_{i-1}^-(y) W_{i-1}^-(y) + d_{i-1} \lambda^2 \tilde{H}(y) ] dy
\end{align*}

Let $P_0^\pm$ be the projection on $E^s \oplus E^u$. When we apply the projection, the $v_0(0)$ terms disappear, which leaves us with

\begin{align*}
a_i^- &- a_i^+ = P_0^\pm \Big(-D_i d \\
&+(v_+(X_i; \beta_i^+, \lambda) - v_0(0)) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&- (v_-(-X_i; \beta_{i-1}^-,\lambda) - v_0(0)) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i-1}^-, \lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i-1}^-, \lambda)b_{i-1}^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i-1}^-, \lambda) [ G_{i-1}^-(y) W_{i-1}^-(y) + d_{i-1} \lambda^2 \tilde{H}(y) ] dy \Big)
\end{align*}

Then we have

\begin{align*}
a_i^- - a_i^+ = -P_0^\pm D_i d + L_3(\lambda)_i(a, b, c, d)
\end{align*}

Where $L_3(\lambda)(a, b, c, d)_i$ is the rest of the terms on the RHS.

\begin{align*}
L_3(\lambda)&(a, b, c, d)_i = P_0^\pm \Big( \\
&(v_+(X_i; \beta_i^+, \lambda) - v_0(0)) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&- (v_-(-X_i; \beta_{i-1}^-, \lambda) - v_0(0)) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i-1}^-, \lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i-1}^-, \lambda)b_{i-1}^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i-1}^-, \lambda) [ G_{i-1}^-(y) W_{i-1}^-(y) + d_{i-1} \lambda^2 \tilde{H}(y) ] dy \Big)
\end{align*}

For the bound on $L_3$, we have seen most of the terms before. For the bound on the integral term involving $\tilde{H}$, we use the $\tilde{\alpha}$ trick to get a better bound. For the ``positive'' piece, this bound is

\begin{align*}
\left| \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) \tilde{H}(y) dy \right| 
&\leq C \int_0^{X_i} e^{-\alpha (X_i - y)}|\tilde{H}(y)| dy \\
&= C e^{-\tilde{\alpha}X_i} \int_0^{X_i} e^{-\alpha X_i} e^{\alpha y}  e^{\tilde{\alpha}X_i} e^{-\tilde{\alpha}y} |e^{\tilde{\alpha}y} \tilde{H}(y)| \\
&= C e^{-\tilde{\alpha}X_i} \int_0^{X_i} e^{-(\alpha - \tilde{\alpha})(X_i-y)} |e^{\tilde{\alpha}y} \tilde{H}(y)|\\
&\leq C e^{-\tilde{\alpha}X_i} 
\end{align*}

where we again used the fact that $|e^{\tilde{\alpha}y} \tilde{H}(y)|$ is bounded, since $\tilde{\alpha} < \alpha$ and $\tilde{H}(y)$ decays with rate $\alpha$. The ``negative'' piece is simlar.\\

For the integral term involving $W$, we use the piecewise bound on $W$ from Lemma \ref{W1bound}. For the ``positive'' piece, we have

\begin{align*}
&\left| \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) G_i^+(y) W_i^+(y) \right| \\
&\leq C \int_0^{X_i} e^{-\alpha(X_i - y)}|G_i^+(y)|(|a| + |b| + e^{\nu(\lambda)X_i}|c_i^+| + |\lambda|^2 |d| ) dy \\
&\leq C \left( ||G||(|a| + |b| + |\lambda|^2 |d|) + \int_0^{X_i} e^{-\alpha(X_i - y)}|G_i^+(y)|e^{\nu(\lambda)X_i}|c_i^+| dy \right) \\
&\leq C \left( ||G||(|a| + |b| + |\lambda|^2 |d|) + \int_0^{X_i} e^{-\alpha(X_i - y)}e^{-\alpha X_i} e^{-\alpha(X_i - y)} e^{\nu(\lambda)X_i}|c_i^+| dy \right)\\
&\leq C \left( ||G||(|a| + |b| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i^+| \int_0^{X_i} e^{-2\alpha(X_i - y)} dy \right) \\
&\leq C \left( ||G||(|a| + |b| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i^+| \right)
\end{align*}

where we used the fact that $|\nu(\lambda)| \leq \alpha$.  

The ``negative'' piece is similar. This works out the way we want, since the ``negative'' piece involves $W_{i-1}$, but the bound for $W_{i-1}$ involves $c_i^-$.\\

Thus we have the following bound for $L_3$.

\begin{align*}
L_3(\lambda)&(a, b, c, d)_i \leq C ( p_1(X_i; \lambda)|a_i|
+ e^{-\alpha X_i}|b| + p_4(X_i; \lambda)|c_i| \\
&+ ||G||(|a| + |b| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i^+| + e^{-\tilde{\alpha} X_i} |\lambda^2| |d| )
\end{align*}

where

\[
p_4(X_i; \lambda) = p_2(X_i; \lambda) + p_3(X_i; \lambda)
\]

Combining terms and simplifying, the final bound for $L_3$ is

\begin{align*}
L_3(\lambda)&(a, b, c, d)_i \leq C \Big( (p_1(X_i; \lambda) + ||G|| )|a_i|
+ (e^{-\alpha X_i} + ||G||)|b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| \Big)
\end{align*}

We use Hypothesis \ref{p1bound} for a bound on $p_1(X_i; \lambda)$. For $p_2(X_i; \lambda)$, we take $X_1$ sufficiently large so that $p_2(X_1; \lambda) < \delta$. $p_3(X_i; \lambda)$ is order $|\lambda|$. Thus we have

\begin{align*}
L_3(\lambda)&(a, b, c, d)_i \leq C \delta (|a_i| + |b| + |c_i| + |d|)
\end{align*}

Let $J_1: V_a \rightarrow \C^4$ be defined by $J_i(a_i) = (a_i^+ - a_i^-)$. The map $J_i$ is a linear isomorphism since $E^s \oplus E^u = \C^4$. Now consider the map

\[
S_i(a_i) = J_i (a_i) + L_3(\lambda)_i(a_i, 0, 0, 0) = J_i( I + J_i^{-1} L_3(\lambda)_i(a_i, 0, 0, 0))
\]

For sufficiently small $\delta$ we can get the operator norm 

\[
||J_i^{-1} L_3(\lambda)_i(\cdot, 0, 0, 0)|| < 1
\]

thus the map $a_i \rightarrow I + J_1^{-1} L_3(\lambda)_i(a_i, 0, 0, 0)$ is invertible and so the operator $S_i$ is invertible.\\

We can solve for $a$ to get

\[
a_i = A_1(\lambda)_i(b, c, d) = S_i^{-1}(-D_i d - L_3(\lambda)_i(0, b, c, d))
\]

Using the bound on $L_3$ together with $|D_i|$, $A_1$ will have bound

\begin{align*}
|A_1&(\lambda)_i(b, c, d)| \\
&\leq C \Big( (e^{-\alpha X_i} + ||G||) |b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i|
+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d| \Big)
\end{align*} 

We can plug this into our expression for $W_1$ to get $W_2(\lambda)$, which has uniform bound

\begin{align*}
|W_2&(\lambda)(b,c,d)|| 
\leq C \Big( |b| + e^{|\nu(\lambda)|X_i}|c_i| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + |D|)|d| \Big)
\end{align*}

The piecewise bounds are

\begin{align*}
|W_2(\lambda)(b,c,d)_i^-|| 
&\leq C \Big( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| \Big) \\
|W_2(\lambda)(b,c,d)_i^+|| 
&\leq C \Big( |b| + e^{|\nu(\lambda)|X_i}|c_i| + (|\lambda|^2 + |D_i|)|d| \Big)
\end{align*}

With a multipulse, we will need an analogue of (3.25) in San98. The idea here is that we hit our expression for $D_i d$ with projections to kill some of the terms. We start with

\begin{align*}
a_i^- &- a_i^+ = -D_i d + (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i-1}^-, \lambda) - P_0^s)a_i^- \\
&+ v_0(0) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ 
- v_0(0) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i-1}^-, \lambda)b_{i-1}^- \\
&+ (v_0(0) - v_+(X_i; \beta_i^+, \lambda)) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&- (v_0(0) - v_-(-X_i; \beta_{i-1}^-, \lambda)) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i-1}^-, \lambda) [ G_{i-1}^-(y) W_{i-1}^-(y) + d_{i-1} \lambda^2 \tilde{H}(y) ] dy 
\end{align*}

This time, we take projections $P^s_0$ and $P^u_0$ individually. Recalling where the $a_i^\pm$ and $v_0(0)$ live and that $v_0(0)$ is wiped out by both projections, this becomes 

\begin{align*}
a_i^+ &= P^u_0 D_i d - P^u_0 L_3(\lambda)_i(a, b, c, d) \\
a_i^- &= -P^s_0 D_i d + P^s_0 L_3(\lambda)_i(a, b, c, d)
\end{align*}

Define $A_2$ to be all the stuff on the RHS other than the $D_i d$ term. Thus we have 

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_2(\lambda)_i^+(b, c, d) \\
a_i^- &= -P^s_0 D_i d + A_2(\lambda)_i^-(b, c, d)
\end{align*}

We then can come up with a bound for $A_2$ using the bound for $L_3$ and the bound for $A_1$.

\begin{align*}
|A_2&(\lambda)_i(b, c, d)| \\
&\leq C |L_3(\lambda)_i(a, b, c, d)| \\
&\leq C \Big( (p_1(X_i; \lambda) + ||G|| )|A_1(\lambda)_i(b, c, d)| \\
&+ (e^{-\alpha X_i} + ||G||)|b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| + (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| \Big) \\
&\leq C \Big( (p_1(X_i; \lambda) + ||G|| )( (e^{-\alpha X_i} + ||G||)|b| + ( p_4(X_i; \lambda) + ||G|| )|c_i| + (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d|)  \\
&+ (e^{-\alpha X_i} + ||G||)|b| + ( p_4(X_i; \lambda) + ||G|| )|c_i| + (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| \Big) \\
&\leq C \Big( (p_1(X_i; \lambda) + ||G|| + 1)((e^{-\alpha X_i} + ||G||)|b| 
+ ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| + (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d|)\\
&+(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big)
\end{align*}

Simplifying this expression and eliminating higher order terms, we attain our bound for $A_2$.

\begin{align*}
|A_2&(\lambda)_i(b, c, d)| \\
&\leq C \Big( (e^{-\alpha X_i} + ||G||)|b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| + (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big)
\end{align*}

\end{proof}
\end{lemma}

Finally, we want to satisfy the conditions

\begin{align*}
P(\C Q'(0))W_i^-(0) &= 0 \\
P(\C Q'(0))W_i^+(0) &= 0 \\
P(Y^+ \oplus Y^- \oplus Y^0) ( W_i^+(0) - W_i^-(0) ) &= 0
\end{align*}

Since the stable and unstable range spaces at $\lambda = 0$ both contain $\C Q'(0)$, we decompose $b^\pm$ uniquely as $b^\pm = x^\pm + y^\pm$, where $x^\pm \in \C Q'(0)$ and $y^\pm \in Y^\pm$. Then since

\begin{equation}\label{directsum}
\C^n = \C\Psi(0) \oplus \C Q'(0) \oplus Y^+ \oplus Y^- \oplus Y^0
\end{equation}

(each of these is 1D in this case), the conditions above are equivalent to the following projections

\begin{align*}
P(\C Q'(0) \oplus Y^0 )W^-(0) &= 0 \\
P(\C Q'(0) \oplus Y^0 )W^+(0) &= 0 \\
P(Y^+ \oplus Y^-) (W^+(0) - W^-(0) ) &= 0
\end{align*}

where the range of each projection is indicated, and the kernel of each projection is just the other elements of the direct sum \eqref{directsum}. Since the first two equations wipe out any component in $\C Q'(0) \oplus Y^0$, we don't need to put that in the range of the third projection. \\

Let $y_0 = v_\pm(0; 0)$ be a unit vector for $Y^0$. Since there is only a small order $\lambda$ perturbation when we go from $y_0$ to $v_\pm(0; \lambda)$ the following two direct sums (where we choose either of $v_\pm(0; \lambda)$ for the last component) hold as well.

\begin{equation}\label{directsum2}
\C^n = \C\Psi(0) \oplus \C Q'(0) \oplus Y^+ \oplus Y^- \oplus v_\pm(0; \lambda)
\end{equation}

Thus we can able to use the following projections instead

\begin{align*}
P(\C Q'(0) \oplus \C v_-(0; \lambda) )W^-(0) &= 0 \\
P(\C Q'(0) \oplus \C v_+(0; \lambda) )W^+(0) &= 0 \\
P(Y^+ \oplus Y^-) (W^+(0) - W^-(0) ) &= 0
\end{align*}

To separate out the coefficients nicely, we write this as five projections

\begin{align*}
P(\C Q'(0) )W^-(0) &= 0 \\
P(\C Q'(0) )W^+(0) &= 0 \\
P(\C v_-(0; \lambda))W^-(0) &= 0 \\
P(\C v_+(0; \lambda))W^+(0) &= 0 \\
P(Y^+ \oplus Y^-) (W^+(0) - W^-(0) ) &= 0
\end{align*}

% inversion 3

\begin{lemma}
There exists an operator

\begin{align*}
B_1(\lambda): V_\lambda \times V_d \rightarrow V_b \times V_c \\
\end{align*}

such that 
\[
(b, \tilde{c}) = B_1(\lambda)d
\]

where

\begin{align*}
\tilde{c}_i^- &= e^{\nu(\lambda)X_i} c_i^- \\
\tilde{c}_i^+ &= e^{-\nu(\lambda)X_i} c_i^+
\end{align*}

and

\begin{align*}
(a,b,&\tilde{c}, W) 
= (A_1(\lambda)(B_1(\lambda)d, d), B_1(\lambda)d, W_2(\lambda)(B_1(\lambda)d, d))
\end{align*}

solves our system. The operator $B_1(\lambda)$ is analytic in $\lambda$ and linear in $d$ and has bound

\begin{align*}
|B_1(\lambda)(d)| &\leq C ( (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2} ) |D| + |\lambda|^2 )|d|
\end{align*}

\begin{proof}

At $x = 0$, the fixed point equations become

\begin{align*}
W_i^-(0) = \Phi^s_-(&0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- + b_i^- + (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \\
&+ e^{\nu(\lambda)X_{i-1}} v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&+ \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&+ \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
W_i^+(0) = \Phi^u_+(&0, X_i; \beta_i^+, \lambda)a_i^+ + b_i^+ + (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ \\
&+ e^{-\nu(\lambda) X_i} v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&+ \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

where we have added and subtracted $P^s_-(0; 0, 0))b_i^+$ and $P^u_-(0; 0, 0))b_i^-$ since we want the $b_i$ to disappear when we take the projection. Let

\begin{equation}\label{p5}
p_5(\lambda) = |P^u_-(0;\lambda) - P^u_-(0; 0, 0)| + |P^s_+(0;\lambda) - P^s_+(0; 0, 0)|
\end{equation}

We hypothesize the following bound for $p_5$, based on intuition and the bounds for the $\beta_i^\pm$

\begin{hypothesis}\label{p5bound}
$p_5(\lambda) = \mathcal{O}(e^{-2 \alpha X_1} + e^{-2 \alpha X_2} + |\lambda|)$
\end{hypothesis}

Before we start hitting things with all sorts of projections, we need to get the $c_i^\pm$ term into a useful form.

\begin{align*}
e^{\nu(\lambda)X_{i-1}} &v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&= e^{\nu(\lambda)X_{i-1}} v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_0(\lambda) \rangle c_{i-1}^- + e^{\nu(\lambda)X_{i-1}} v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), \Delta w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&= e^{\nu(\lambda)X_{i-1}} c_{i-1}^- v_-(0; \lambda) + e^{\nu(\lambda)X_{i-1}} c_{i-1}^- v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), \Delta w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle 
\end{align*}

where $\Delta v$ and $\Delta w$ are defined in Lemma \ref{inv2} and $\langle v_0(\lambda), w_0(\lambda) \rangle = 1$. Similarly, we have

\begin{align*}
e^{-\nu(\lambda)X_i} &v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&= e^{-\nu(\lambda)X_i} v_-(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_0(\lambda) \rangle c_i^- + e^{-\nu(\lambda)X_i} v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), \Delta w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&= e^{-\nu(\lambda)X_i} c_i^+ v_+(0; \beta_i^+, \lambda) + e^{-\nu(\lambda)X_i} c_i^+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), \Delta w_+(X_i; \beta_i^+, \lambda) \rangle 
\end{align*}

Next, we let

\begin{align*}
\tilde{c}_i^- &= e^{\nu(\lambda)X_i} c_i^- \\
\tilde{c}_i^+ &= e^{-\nu(\lambda)X_i} c_i^+
\end{align*}

Then these become

\begin{align*}
e^{\nu(\lambda)X_{i-1}} &v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&= \tilde{c}_{i-1}^- v_-(0; \beta_i^-, \lambda) + \tilde{c}_{i-1}^- v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), \Delta w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle \\
e^{-\nu(\lambda)X_i} &v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&= \tilde{c}_i^+ v_+(0; \beta_i^+, \lambda) + \tilde{c}_i^+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), \Delta w_+(X_i; \beta_i^+, \lambda) \rangle 
\end{align*}

Substituting these into the fixed point equations at $x = 0$, we have

\begin{align*}
W_i^-(0) &= x_i^- + y_i^- + v_-(0; \beta_i^-, \lambda) \tilde{c}_{i-1}^- v_-(0; \beta_i^-, \lambda) \\
&+\Phi^s_-(0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- + (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \\
&+ \tilde{c}_{i-1}^- v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), \Delta w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle \\
&+ \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&+ \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
W_i^+(0) &= x_i^+ + y_i^+ + v_+(0; \beta_i^+, \lambda) \tilde{c}_i^+ v_+(0; \beta_i^+, \lambda) \\
&+\Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ + (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ \\
&+ \tilde{c}_i^+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), \Delta w_+(X_i; \beta_i^+, \lambda) \rangle \\  
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&+ \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Plugging in the fixed point equations into the above set of projections, we get the matrix equation

\[
\begin{pmatrix}x_i^- \\ x_i^+ \\ 
\tilde{c}_{i-1}^- v_-(0; \lambda) \\
\tilde{c}_i^+ v_+(0; \lambda) \\
y_i^+ - y_i^- \end{pmatrix} + L_4(\lambda)(b, \tilde{c}) = 0
\]

where $L_4(\lambda)(b, \tilde{c})$ is the rest of the terms that don't get eliminated outright by the projections. Note that so far we have written $L_4$ entirely in terms of $\tilde{c}$. We will make sure this remains the case when we perform the substitutions for $W$ and $a$.\\

For the bound on $L_4$, we need to get bounds on the integral terms involving $W$ in a similar fashion to what we did before. First, we find a bound for the center integral involving $W$ on the ``minus'' piece.\\

\begin{align*}
&\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle \right| \\
&\leq C \int_{-X_{i-1}}^0 e^{\nu(\lambda)y} |G_i^-(y)| |W_i^-(y)| dy \\
&\leq C \int_{-X_{i-1}}^0 e^{\nu(\lambda)y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} |W_i^-(y)| dy
\end{align*}

Substituting the piecewise bound for $W_2$, we have

\begin{align*}
&\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle \right| \\
&\leq C \int_{-X_{i-1}}^0 e^{\nu(\lambda)y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} ( |b| + e^{\nu(\lambda)X_{i-1}}|c_{i-1}| + (|\lambda|^2 + D_{i-1})|d| )dy \\
&\leq C e^{-\alpha X_{i-1}} \int_{-X_{i-1}}^0 e^{|\nu(\lambda)|X_{i-1}} e^{-\alpha(X_{i-1} + y)} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + D_{i-1})|d| )dy \\
&\leq C e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + D_{i-1})|d| ) \int_{-X_{i-1}}^0 e^{-\alpha(X_{i-1} + y)} dy \\
&\leq C e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + D_{i-1})|d| ) \\
&\leq C ( e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} |b| + e^{-(\alpha - 2 |\nu(\lambda)|) X_{i-1}}|c_{i-1}| + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} (|\lambda|^2 + D_{i-1})|d| )
\end{align*}

We can also use this bound on the noncenter integral on the ``minus'' piece, since that integral does not contain the $e^{\nu(\lambda)y}$ term, which only makes things worse. (In fact, we can get a better bound, but it does not matter.)\\

Similarly, for the center integral involving $W$ on the the ``plus'' piece, we will have a bound

\begin{align*}
&\left| \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \right| \\
&\leq C ( e^{-(\alpha - |\nu(\lambda)|) X_i} |b| + e^{-(\alpha - 2 |\nu(\lambda)|) X_{i-1}}|c_i| + e^{-(\alpha - |\nu(\lambda)|) X_i} (|\lambda|^2 + D_i)|d| )
\end{align*}

The integrals not involving $W$ can be evaluated using the $\tilde{\alpha}$ trick, as we have done before. Thus we have the following bound on $L_4(\lambda)$. 

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\ 
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + p_5(\lambda) |b_i| \\
&+ p_2(X_{i-1}; \lambda) |\tilde{c}_{i-1}| + p_2(X_i; \lambda) |\tilde{c}_i| \\
&+ ( e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} |b| + e^{-(\alpha - 2 |\nu(\lambda)|) X_{i-1}}|c_{i-1}| + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} (|\lambda|^2 + D_{i-1})|d| ) \\
&+ ( e^{-(\alpha - |\nu(\lambda)|) X_i} |b| + e^{-(\alpha - 2 |\nu(\lambda)|) X_{i-1}}|c_i| + e^{-(\alpha - |\nu(\lambda)|) X_i} (|\lambda|^2 + D_i)|d| )  \\
&+ |\lambda|^2 |d| \Big)\\
\end{align*}

Before we continue, we need to get everything we have so far on the RHS in terms of the $\tilde{c}$. Fortunately, this is not hard to do since we can absorb another $|\nu(\lambda)|X_i$ using $\alpha$. This gives us

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + p_5(\lambda) |b_i| \\
&+ p_2(X_{i-1}; \lambda) |\tilde{c}_{i-1}| + p_2(X_i; \lambda) |\tilde{c}_i| \\
&+ ( e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} |b| + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}|\tilde{c}_{i-1}| + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} (|\lambda|^2 + D_{i-1})|d| ) \\
&+ ( e^{-(\alpha - |\nu(\lambda)|) X_i} |b| + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}|\tilde{c}_i| + e^{-(\alpha - |\nu(\lambda)|) X_i} (|\lambda|^2 + D_i)|d| )  \\
&+ |\lambda|^2 |d| \Big)\\
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + (p_5(\lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}) |\tilde{c}_{i-1}| + (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i})|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2})|D||d| + |\lambda|^2|d|
\Big)
\end{align*}

where $p_2(X; \lambda)$ is defined in Lemma \ref{inv2}. Luckily, $p_2(X; \lambda)$ does not enter into the final bound, since we do not have a decay rate for it, but we know that its limit is 0 as $|X| \rightarrow \infty$, which is all we need.\\

To finish the bound, we plug in $A_1$ for $|a|$

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\
&\leq C \Big( e^{-\alpha X_i} |A_1(\lambda)_i(b, c, d)| \\
&+  e^{-\alpha X_{i-1}} |A_1(\lambda)_{i-1}(b, c, d)| \\
&+ (p_5(\lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}) |\tilde{c}_{i-1}| + (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i})|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2})|D||d| + |\lambda|^2|d|
\Big) \\
&\leq C \Big( e^{-\alpha X_i} ( (e^{-\alpha X_i} + ||G||) |b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i|
+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d| ) \\
&+ e^{-\alpha X_{i-1}} ( (e^{-\alpha X_{i-1}} + ||G||) |b| + ( p_4(X_{i-1}; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_{i-1}} )|c_{i-1}|
+ (e^{-\tilde{\alpha} X_{i-1}} + ||G||) |\lambda^2| |d| + |D_{i-1}||d| ) \\
&+ (p_5(\lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}) |\tilde{c}_{i-1}| + (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i})|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2})|D||d| + |\lambda|^2|d|
\Big) \\
\end{align*}

We can do the same thing we did above to get this in terms of the $\tilde{c}$.

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\
&\leq C \Big( e^{-\alpha X_i} ( (e^{-\alpha X_i} + ||G||) |b| + ( p_4(X_i; \lambda) + e^{-(\alpha - 2|\nu(\lambda)|)X_i} )|\tilde{c}_i|
+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d| ) \\
&+ e^{-\alpha X_{i-1}} ( (e^{-\alpha X_{i-1}} + ||G||) |b| + ( p_4(X_{i-1}; \lambda) + e^{-(\alpha - 2 |\nu(\lambda)|)X_{i-1}} )|\tilde{c}_{i-1}|
+ (e^{-\tilde{\alpha} X_{i-1}} + ||G||) |\lambda^2| |d| + |D_{i-1}||d| ) \\
&+ (p_5(\lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}) |\tilde{c}_{i-1}| + (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i})|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2})|D||d| + |\lambda|^2|d|
\Big) \\
\end{align*}

Simplifying and eliminating higher order terms, this becomes

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\
&\leq C \Big(
(p_5(\lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}} + e^{-\alpha X_{i-1}} p_4(X_{i-1}; \lambda) ) |\tilde{c}_{i-1}| \\
&+ (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i} + e^{-\alpha X_i} p_4(X_i; \lambda) )|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2})|D||d| + |\lambda|^2|d|
\Big) \\
&\leq C \Big(
(p_5(\lambda) + e^{-\tilde{\alpha} X_1}  |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-\tilde{\alpha} X_{i-1}} + e^{-\alpha X_{i-1}} p_4(X_{i-1}; \lambda) ) |\tilde{c}_{i-1}| \\
&+ (p_2(X_i; \lambda) + e^{-\tilde{\alpha} X_i} + e^{-\alpha X_i} p_4(X_i; \lambda) )|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2})|D||d| + |\lambda|^2|d|
\Big)
\end{align*}

To do the inversion, we use Hypothesis \ref{p5bound} for $p_5(\lambda)$ and note that in the previous lemma we chose $X_1$ sufficiently large so that $p_2(X_1; \lambda) < \delta$. Thus we have

\begin{align*}
|L_4&(\lambda)_i(b, c, d)| \leq C \delta (|b| + |\tilde{c}|) + C ( (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2})|D||d|+ |\lambda|^2)|d|
\end{align*}

Thus for sufficiently small $\delta$, we can perform the inversion, as in the previous two lemmas.\\

Since the map $J_2$ defined by
\[
J_2( (x_i^+, x_i^-),(y_i^+, y_i^-), \tilde{c}_{i-1}^-, \tilde{c}_i^+ ) \rightarrow ( x_i^+, x_i^-, \tilde{c}_{i-1}^-, \tilde{c}_i^+, y_i^+ -  y_i^- )
\]

is an isomorphism, the operator

\[
S_2(x,y, \tilde{c}) = J_2(x+y, \tilde{c}) + L_4(\lambda)(x+y,\tilde{c}, 0)
\]

is invertible. Thus we have

\begin{equation}
(b,\tilde{c}) = B_1(\lambda)(d) = -S_2^{-1} L_4(\lambda)(0, 0, d)
\end{equation}

where we have the following bound on $B_1$

\begin{align*}
|B_1(\lambda)(d)| &\leq C ( (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2})|D| + |\lambda|^2 )|d|
\end{align*}
 
\end{proof}
\end{lemma}

For our final step, we estimate the jumps

\begin{equation}
\xi_i = \langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle 
\end{equation}

Recall that $\Psi(0)$ is the adjoint solution for the unperturbed problem linearized about the single pulse $q(x)$, i.e. with $\lambda = 0$ and $\beta_i^\pm = 0$. The equations for $W$ contain the evolution operator $\Phi^{(s/u)}_\pm(x, y; \beta_i^\pm, \lambda)$ which are for the perturbed system with $\lambda \neq 0$ and with ICs $\beta_i^\pm$.\\

For the adjoint solution $\Psi(x)$, we have estimate 

\begin{equation}
|\Psi(x)| \leq C e^{-\alpha|x|}
\end{equation}

which holds since we know exactly what $\Psi$ is (it involves only the single pulse $q(x)$ and its derivatives, all of which decay with rate $\alpha$). Note as well that $\Psi(0)$ is just a fixed constant.\\

\begin{align*}
W_i^+(0) - W_i^-(0) &= b_i^+ - b_i^- \\
&+ \Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- \\
&+(P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+  - (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \\
&+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \\
&- v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \\
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&+ \int_{X_i}^0 e^{-\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)(y)W_i^+(y) + \lambda^2 d_i \tilde{H}(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&- \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}(y) ] dy \\
&- \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)(y)W_i^-(y) + \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
\end{align*}

We will evaluate (or estimate) the terms in the jump equation in a series of lemmas.

% lemma : a terms in jump

\begin{lemma}\label{jumpa}
For the terms involving $a$ in the jump $\xi_i$, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle \\
&+ + \mathcal{O}\Big( (e^{-\alpha X_1} + e^{-\alpha X_2}) \Big( |\lambda| + e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2} )|D| \Big)|d| \Big)
\end{align*}

\begin{proof}

Recall the following expressions for $a_i^\pm$.

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_2(\lambda)_i^+(d))\\
a_i^- &= -P^s_0 D_i d + A_2(\lambda)_i^-(d))
\end{align*}

For $\langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ \rangle$, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle = \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda) P^u_0 D_i d \rangle + \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b, c, d) \rangle \\
\end{align*} 

Note that $\Psi(0)$ is the adjoint solution unperturbed by $\lambda$ and with $\beta_i^\pm = 0$, whereas the evolution $\Phi^u_+(0, X_i; \lambda)$ is perturbed by $\lambda$ and has $\beta_i^\pm \neq 0$. Let

\begin{equation}\label{p6}
p_6(y; \lambda) = |\Phi^u_+(0, y; \beta_i^+, \lambda) - \Phi^u_+(0, y; 0, 0)| + |\Phi^s_-(0, -y; \lambda) - \Phi^s_-(0, -y; 0, 0)| 
\end{equation}

For now, we take the following hypothesis, which should follow from the Taylor theorem and the bounds on $\beta_i^\pm$

\begin{hypothesis}\label{p6}
\begin{equation}\label{p6bound}
p_6(y; \lambda) \leq 
C (|\lambda| + e^{-\alpha X_1} + e^{-\alpha X_2} ) e^{-\alpha |y|}
\end{equation}
\end{hypothesis}

Adding and subtracting $\Phi^u_+(0, X_i; 0, 0)$, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle \\
&= \langle \Psi(0), \Phi^u_+(0, X_i; 0, 0) P^u_0 D_i d \rangle + \langle \Psi(0), (\Phi^u_+(0, X_i; \beta_i^+, \lambda) - \Phi^u_+(0, X_i; 0, 0)) P^u_0 D_i d \rangle \\
&+ \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle 
+ \mathcal{O}((|\lambda| + e^{-\alpha X_1} + e^{-\alpha X_2} ) e^{-\alpha X_i}|D_i||d|) + \langle \Psi(0), \Phi^u_+(0, X_i; \lambda) A_2(\lambda)_i^+(b,c,d) \rangle 
\end{align*}

Using the bound for $A_2$, the last term on the RHS has bound

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&\leq C e^{-\alpha X_i} |A_2(\lambda)_i(b,c,d)| \\
&\leq C e^{-\alpha X_i}  \Big( (e^{-\alpha X_i} + ||G||)|b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big)
\end{align*}

We want to plug in the $B_1$ bound here, but first we need to get this in terms of the $\tilde{c}$. This is not hard to do.

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&\leq C e^{-\alpha X_i} ( (e^{-\alpha X_i} + ||G||)|b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |2 \nu(\lambda)|)X_i} )|\tilde{c}_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|))
\end{align*}

Substituting $B_1$ for $b$ and $\tilde{c}$ and using the $B_1$ bound, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&\leq C e^{-\alpha X_i}  \Big( (e^{-\alpha X_i} + ||G||)|B_1(\lambda)(d)| \\
&+ ( p_4(X_i; \lambda) + e^{-(\alpha - |2 \nu(\lambda)|)X_i} )|B_1(\lambda)(d)| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big) \\
&\leq C e^{-\alpha X_i}  \Big( (e^{-\alpha X_i} + ||G||)( e^{-(\alpha - |\nu(\lambda)|) X_1} |D| + |\lambda|^2 )|d| \\
&+ ( p_4(X_i; \lambda) + e^{-(\alpha - |2 \nu(\lambda)|)X_i} )( e^{-(\alpha - |\nu(\lambda)|) X_1} |D| + |\lambda|^2 )|d| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big) 
\end{align*}

Collecting like terms and dropping higher order terms, this becomes

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&\leq C e^{-\alpha X_i} \Big( (e^{-\alpha X_i} + ||G|| + p_4(X_i; \lambda) + e^{-(\alpha - |2 \nu(\lambda)|)X_i} ) |\lambda|^2 ) \\
&+ (p_1(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1} + |G|| )|D| \Big)|d| \\
&\leq C \Big( e^{-(\alpha - \nu(\lambda)) X_i} |\lambda|^2 
+ e^{-(\alpha - \nu(\lambda)) X_i}( e^{-\alpha X_1} + ||G|| + p_1(X_i; \lambda))|D| )|d| \Big) \\
&\leq e^{-\alpha X_i} \Big( |\lambda|^2  + (p_1(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1} + ||G|| )|D| \Big)|d| 
\end{align*}

Thus, we conclude

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \mathcal{O}\Big(e^{-\alpha X_i} \Big( |\lambda|^2  + p_1(X_i; \lambda) + e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}+ ||G|| + |\lambda|)|D| \Big)|d| \Big)
\end{align*}

Similarly we have

\begin{align*}
\langle \Psi(0), &\Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= -\langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle
+ \mathcal{O}\Big(e^{-\alpha X_{i-1}} \Big( |\lambda|^2  + p_1(X_{i-1}; \lambda) + e^{-\tilde{\alpha} X_1} +e^{-\tilde{\alpha} X_2} + ||G|| + |\lambda|)|D| \Big)|d| \Big)
\end{align*}

Putting everything together, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle \\
&+ \mathcal{O}\Big( (e^{-\alpha X_1} + e^{-\alpha X_2}) \Big( |\lambda|^2  + p_1(X_1; \lambda) + p_1(X_2; \lambda) \\
&+ e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2} + ||G|| + |\lambda|)|D| \Big)|d| \Big)
\end{align*}

Recalling the bounds for $p_1$ and $||G||$, since $\tilde{\alpha} < \alpha$, this can be simplified to

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle \\
&+ \mathcal{O}\Big( (e^{-\alpha X_1} + e^{-\alpha X_2}) \Big( |\lambda| + e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2} )|D| \Big)|d| \Big)
\end{align*}

\end{proof}
\end{lemma}

Next, we look at the terms involving $b$. Note that the terms involving $b^\pm$ by themselves will vanish, since they are in the spaces $R^u_-(0; 0) \oplus R^s_+(0; 0)$ which are perpendicular to $\Psi(0)$. For the other terms involving $b$, we have the following lemma.

% lemma : b terms in jump

\begin{lemma}\label{jumpb}

For the terms involving $b$ in the jump $\xi_i$, we have

\begin{align*}
\langle \Psi(0), (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ \rangle
&\leq C p_5(\lambda) \Big( (e^{-\tilde{\alpha} X_1}+e^{-\tilde{\alpha} X_2})|D| + |\lambda|^2 \Big)|d|\\
\langle \Psi(0), (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \rangle
&\leq C p_5(\lambda)\Big( (e^{-\tilde{\alpha} X_1}+e^{-\tilde{\alpha} X_2})|D| + |\lambda|^2 \Big)|d|
\end{align*}

where $p_5(\lambda)$ is defined above.

\begin{proof}

Using the bound for $B_1$, we have for the ``negative'' piece

\begin{align*}
|\langle \Psi(0), &(P^u_-(0; \lambda) - P^u_-(0; 0))b_i^- \rangle|
\leq |\Psi(0)| p_5(\lambda)|b_i^-| \\
&\leq |\Psi(0)| p_5(\lambda)|B_1(\lambda)(d)| \\
&\leq C p_5(\lambda) \Big( (e^{-(\alpha - |\nu(\lambda)|) X_1} 
+ e^{-(\alpha - |\nu(\lambda)|) X_2}) |D| + |\lambda|^2 \Big)|d|\\
\end{align*}

Since $\alpha - |\nu(\lambda)| > \tilde{\alpha}$, this bound becomes

\begin{align*}
|\langle \Psi(0), &(P^u_-(0; \lambda) - P^u_-(0; 0))b_i^- \rangle|
\leq C p_5(\lambda) \Big( (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| + |\lambda|^2 \Big)|d|\\
\end{align*}

The ``positive'' piece is similar.

\end{proof}
\end{lemma}

Next, we look at the terms in the jump involving $c$.

% lemma : c terms in jump

\begin{lemma}\label{jumpc}
For the terms involving $c$ in the jump $\xi_i$, we have bounds

\begin{align*}
|\langle \Psi(0), &v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+,\lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \rangle| \\
&\leq C ( |\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )
( ( e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| + |\lambda|^2 )|d| \\
|\langle \Psi(0), &v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \rangle | \\
&\leq C ( |\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )
( ( e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| + |\lambda|^2 )|d|  \\
\end{align*}

\begin{proof}
Looking at the ``plus'' term, we have

\begin{align*}
\langle \Psi(0), v_+(0; \lambda) \langle v_0(\lambda), w_+(X_i; \lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \rangle &= \langle \Psi(0), v_+(0; \lambda) \rangle \langle v_0(\lambda), w_+(X_i; \lambda) \rangle \tilde{c}_i^+
\end{align*}

To get our bound, we will expand $v_+(0; \beta_i^+, \lambda)$ in a Taylor series about $(\beta_i^+, \lambda) = (0, 0)$. FOR NOW WE WILL ASSUME WE CAN ACTUALLY DO THIS.

\begin{align*}
v_+(0; &\beta_i^+, \lambda) = v_+(0; 0, 0) 
+ \lambda \frac{\partial}{\partial \lambda}v_+(0; \beta_i^+, \lambda)\Big|_{\lambda, \beta_i^+ = (0, 0)} 
+ \beta_i^+ \frac{\partial}{\partial \beta_i^+}v_+(0; \beta_i^+, \lambda)\Big|_{\lambda, \beta_i^+ = (0, 0)} \\
&+ \mathcal{O}(|\lambda|^2 + |\beta_i^+||\lambda| + |\beta_i^+|^2)
\end{align*}

When we take the inner product with $\Psi(0)$, the first term will vanish since 
$\langle \Psi(0), v_+(0; 0, 0) \rangle = 0$. Since the two derivatives in the expression above are constants, we will have

\begin{align*}
\langle \Psi(0), v_+(0; \lambda) \rangle &\leq C ( |\lambda| + |\beta_1^+| ) \\
&\leq C ( |\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )
\end{align*}

Plugging this in, together with the bound for $B_1$ (which is a bound for $e^{-\nu(\lambda)X_i} c_i^+$), we have

\begin{align*}
|\langle \Psi(0), &v_+(0; \lambda) \langle v_0(\lambda), w_+(X_i; \lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \rangle| \\ 
&\leq C ( |\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} ) |B_1(\lambda)(d)| \\
&\leq C ( |\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )
( ( e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2}) |D| + |\lambda|^2 )|d| \\
\end{align*}

Since $\alpha - |\nu(\lambda)| > \tilde{\alpha}$, this becomes 

\begin{align*}
|\langle \Psi(0), &v_+(0; \lambda) \langle v_0(\lambda), w_+(X_i; \lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \rangle| \\
&\leq C ( |\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )
( ( e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| + |\lambda|^2 )|d| 
\end{align*}
 
The other one is similar.\\

\end{proof} 
\end{lemma}

Next, we look at the integral terms in the jump $\xi_i$. First, we look at the ``noncenter'' integral terms. We split these into ones involving $W$ and ones not involving $W$. Before we can do that, we will need an improved estimate for $|W|$.

\begin{lemma}
We have the following improved, piecewise, $x$-dependent estimate for $|W_i^\pm(x)$

\begin{align*}
| W_i^-(x)| &\leq C \Big(e^{-\alpha(X_{i-1} + x)}( e^{|\nu(\lambda)| X_{i-1}} |\lambda|^2 + |D|) + e^{\nu(\lambda)x} |\lambda|^2 
+ |\lambda|^2 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| \Big) |d| \\
| W_i^+(x)| &\leq C \Big(e^{-\alpha(X_i - x)}( e^{|\nu(\lambda)| X_i} |\lambda|^2 + |D|) + e^{\nu(\lambda)x} |\lambda|^2 
+ |\lambda|^2 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| \Big) |d| \\
\end{align*}

\begin{proof}

Since we have 
\[
W_i^\pm = L_1(\lambda)W_i^\pm + L_2(\lambda)W_i^\pm 
\]

we can use the estimate for $L_1(\lambda)$ together with an improved estimate for $L_2(\lambda)$. We use the same estimate for $L_1(\lambda)$ as we have above. We will do the negative piece here. The positive piece is similar.

\[
||L_1(\lambda)_i^- W|| \leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ||W||
\]

Plugging in the piecewise bound for $W_2$ for $W$, we have

\begin{align*}
||L_1(\lambda)_i^- W|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ( |b| + e^{\nu(\lambda)X_{i-1}}|c_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| ) \\
&\leq C e^{-(\alpha - 3|\nu(\lambda)|)X_{i-1}} ( |b| + |\tilde{c}_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| ) 
\end{align*}

For $L_2(\lambda)$ we will use the estimate for the negative piece from Lemma \ref{L2}.

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^-(x)| &\leq C (e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| )
\end{align*}

Combining these, we have

\begin{align*}
| &W_i^-(x)| \leq C \Big(e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| \\
&+ e^{-(\alpha - 3|\nu(\lambda)|)X_{i-1}} ( |b| + |\tilde{c}_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| ) \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| \\
&+ e^{-\tilde{\alpha} X_{i-1}} ( |b| + |\tilde{c}_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| ) \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
\end{align*}

where we have chosen stuff so that $3|\nu(\lambda)| \leq \alpha - \tilde{\alpha}$.\\

At this point, we substitute in $A_3(\lambda)$ and $B_1(\lambda)$. First, we substutite $A_3(\lambda)$.

\begin{align*}
| &W_i^-(x)| \leq C \Big(e^{-\alpha(X_{i-1} + x)}|A_1(\lambda)_{i-1}(b, c, d)|| \\
&+ |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}( (e^{-\alpha X_{i-1}} + ||G||) |b| + ( p_4(X_{i-1}; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_{i-1}} )|c_{i-1}| \\
&+ (e^{-\tilde{\alpha} X_{i-1}} + ||G||) |\lambda^2| |d| + |D_{i-1}||d| ) \\
&+ |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}( e^{|\nu(\lambda)| X_{i-1}} |\tilde{c}_{i-1}| + |D_{i-1}||d| ) \\
&+ |b| + e^{\nu(\lambda)x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
\end{align*}

Finally, we substitute $|B_1(\lambda)(d)$ for $|b|$ and $\tilde{c}$.

\begin{align*}
| &W_i^-(x)| \leq C \Big(e^{-\alpha(X_{i-1} + x)}( e^{|\nu(\lambda)| X_{i-1}} ( e^{-(\alpha - |\nu(\lambda)|) X_1} |D| + |\lambda|^2 )|d| + |D_{i-1}||d| ) \\
&+ e^{\nu(\lambda)x} ( (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2})|D| + |\lambda|^2 )|d| \\ &+ ( (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2}) |D| + |\lambda|^2 )|d| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}( e^{|\nu(\lambda)| X_{i-1}} |\lambda|^2 + |D|)
+ (e^{-(\alpha - 2 |\nu(\lambda)|) X_1} +e^{-(\alpha - 2 |\nu(\lambda)|) X_2})|D| 
+ e^{\nu(\lambda)x} |\lambda|^2 \\ 
&+ (e^{-(\alpha - |\nu(\lambda)|) X_1} + e^{-(\alpha - |\nu(\lambda)|) X_2} )|D| 
+ |\lambda|^2 + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}| \Big) |d| \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}( e^{|\nu(\lambda)| X_{i-1}} |\lambda|^2 + |D|) + e^{\nu(\lambda)x} |\lambda|^2 
+ |\lambda|^2 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| \Big) |d| \\
\end{align*}

Similarly

\begin{align*}
| &W_i^+(x)| \leq C \Big(e^{-\alpha(X_i - x)}( e^{|\nu(\lambda)| X_i} |\lambda|^2 + |D|) + e^{\nu(\lambda)x} |\lambda|^2 
+ |\lambda|^2 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| \Big) |d| \\
\end{align*}
\end{proof}
\end{lemma}

We can now estimate the ``noncenter'' integrals which involve $W$.

\begin{lemma}\label{noncenterW}

\begin{align*}
\left| \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; \lambda) G_i^-(y) W_i^-(y) \rangle dy \right| &\leq C \Big( e^{-\alpha X_{i-1}} |\lambda|^2 + (e^{-(\alpha + \tilde{\alpha}) X_1} + e^{-(\alpha + \tilde{\alpha}) X_2})|D| \Big) |d| \\
\left| \int_{X_i}^0 \langle \Psi(0), \Phi^u_-(0, y; \lambda) G_i^+(y) W_i^+(y) \rangle dy \right| &\leq C \Big( e^{-\alpha X_i} |\lambda|^2 + (e^{-(\alpha + \tilde{\alpha}) X_1} + e^{-(\alpha + \tilde{\alpha}) X_2})|D| \Big) |d|
\end{align*}

\begin{proof}

We do the ``minus'' integral here. Substituting in our bound for $G_i^-(y)$ and the improved bound for $W_i^-(y)$ from the previous lemma,

\begin{align*}
&\left| \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; \lambda) G_i^-(y) W_i^-(y) \rangle dy \right| \\
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} |G_i^-(y)| ||W_i^-(y)|| dy \\
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} \Big(e^{-\alpha(X_{i-1} + y)}( e^{|\nu(\lambda)| X_{i-1}} |\lambda|^2 + |D|) \\
&+ e^{\nu(\lambda)y} |\lambda|^2 
+ |\lambda|^2 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| \Big) |d| dy \\
&\leq C e^{-\alpha X_{i-1}} (|\lambda|^2 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| ) |d| \int_{-X_{i-1}}^0 e^{\alpha y} dy \\
&+ C ( e^{(\alpha - |\nu(\lambda)|) X_{i-1}} |\lambda|^2 + e^{-\alpha X_{i-1}} |D|)|d|\int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha(X_{i-1} + y)} e^{-\alpha(X_{i-1} + y)} dy \\
&+ C e^{-\alpha X_{i-1}} |\lambda|^2 |d| \int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha(X_{i-1} + y)} e^{\nu(\lambda)y} dy
\end{align*}

We have three integrals to evaluate. The first one is a constant (independent of $X_{i-1}$. For the third one

\begin{align*}
\int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha(X_{i-1} + y)} e^{\nu(\lambda)y} dy 
&\leq \int_{-X_{i-1}}^0 e^{(\alpha - |\nu(\lambda)|) y} dy \leq C
\end{align*}

which is again a constant independent of $X_{i-1}$. We take the absolute value of $\nu(\lambda)$ in the exponential to account for both possible signs of $\nu(\lambda)$. For the second integral, we need something exponentially decaying in $X_{i-1}$, rather than just a constant (that easier bound is insufficient for our needs). But that is easy to obtain.

\begin{align*}
\int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha(X_{i-1} + y)} e^{-\alpha(X_{i-1} + y)} dy &= e^{-\alpha X_{i-1}} \int_{-X_{i-1}}^0 e^{-\alpha(X_{i-1} + y)} dy \leq C e^{-\alpha X_{i-1}}
\end{align*}

Putting this all together, we have

\begin{align*}
&\left| \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; \lambda) G_i^-(y) W_i^-(y) \rangle dy \right| \\
&\leq C \Big( e^{-\alpha X_{i-1}} (|\lambda|^2 
+ (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D|) + e^{-\alpha X_{i-1}} (e^{(\alpha - |\nu(\lambda)|) X_{i-1}} |\lambda|^2 + e^{-\alpha X_{i-1}} |D|) + e^{-\alpha X_{i-1}} |\lambda|^2 \Big) |d| \\
&\leq C \Big( e^{-\alpha X_{i-1}} |\lambda|^2 
+ (e^{-(\alpha + \tilde{\alpha}) X_1} + e^{-(\alpha + \tilde{\alpha}) X_2})|D| \Big) |d|
\end{align*}

Similarly, for the other integral,

\begin{align*}
&\left| \int_{X_i}^0 \langle \Psi(0), \Phi^u_-(0, y; \lambda) G_i^+(y) W_i^+(y) \rangle dy \right| \leq C \Big( e^{-\alpha X_i} |\lambda|^2 + (e^{-(\alpha + \tilde{\alpha}) X_1} + e^{-(\alpha + \tilde{\alpha}) X_2})|D| \Big) |d|
\end{align*}

\end{proof}
\end{lemma}

Next, we look at the ``noncenter'' integrals involving $H$. These will give us our higher order Melnikov integral.

% lemma : noncenter integrals involving H

\begin{lemma}\label{noncenterH}

\begin{align*}
\langle \Psi(0), &\int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}(y) dy - \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) \lambda^2 d_i \tilde{H}(y) dy \rangle \\ 
&= -d_i \lambda^2 \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy + \mathcal{O}\left( (|\lambda| + e^{-\alpha X_1} + e^{-\alpha X_2} ) |\lambda|^2 |d| \right)
\end{align*}

\begin{proof}

Looking at the ``negative'' integral (which is multipled by $d_i \lambda^2$), we write it as

\begin{align*}
\langle \Psi(0)&, \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) \tilde{H}(y) dy \rangle \\ 
&= \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; 0, 0) \tilde{H}(y) \rangle dy + 
\int_{-X_{i-1}}^0 \langle \Psi(0), (\Phi^s_-(0, y; \beta_i^-, \lambda) - \Phi^s_-(0, y; 0, 0)) \tilde{H}(y) \rangle dy
\end{align*}

where we use this trick in order to get the Melnikov term we want. Again, we will assume the bound from Hypothesis \ref{p6}. Using this, the second integral above is order $|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2}$.\\

For the first integral, we manipulate things to bring the limits out to $\pm \infty$ (to get the higher order Melnikov integral) and to replace $\tilde{H}$ by $H$ (so tha the Melnikov integral only involves the single pulse). We also use what we know about the evolution of the adjoint solution from a previous lemma (CITE IT HERE).

\begin{align*}
\int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; 0, 0) \tilde{H}(y) \rangle dy &= 
\int_{-X_{i-1}}^0 \langle \Psi(y), H(y) \rangle dy + \int_{-X_{i-1}}^0 \langle \Psi(y), \Delta H(y) \rangle dy \\
&= \int_{-\infty}^0 \langle \Psi(y), H(y) \rangle dy - \int_{-\infty}^{-X_{i-1}} \langle \Psi(y), H(y) \rangle dy \\
&+ \int_{-X_{i-1}}^0 \langle \Psi(y), \Delta H(y) \rangle dy 
\end{align*}

The first integral on the RHS is half of our Melnikov integral. The second is order $e^{-\alpha X_{i-1}}$, since we know the decay rate of $H$. The third is order $e^{-\alpha X_1} + e^{-\alpha X_2}$ (the order of $\Delta H$). When we do the ``plus'' piece, the first integral is the other half of the Melnikov integral; the second integral is order $e^{-\alpha X_i}$; and the third integral is the same order. Combining all of this gives us our desired result.
\end{proof}

\end{lemma}

Finally, we look at the ``center'' integral terms. As before, we can split this into integrals involving $W$ and integrals not involving $W$. First, we look at the integral involving $W$.

% lemma : center integrals involving W

\begin{lemma} 

\begin{align*}
\left| \langle \Psi(0), \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \rangle \right| &\leq C |\lambda| (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) (|\lambda|^2 + |D| ) |d| \\
\left| \Psi(0), \int_{X_i}^0 e^{-\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy  \right| &\leq C |\lambda| (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) (|\lambda|^2 + |D| ) |d|
\end{align*}

\begin{proof}

We do the ``minus'' integral here. Substituting in our bound for $G_i^-(y)$ and the improved bound for $W_i^-(y)$, we have

\begin{align*}
\langle \Psi(0) &, \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \rangle \\
&= \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \beta_i^- ,\lambda) \rangle \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^- , \lambda) \rangle dy \\
&\leq C |\langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle| 
\int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} |G_i^-(y)||W_i^-(y)| dy 
\end{align*}

From Lemma \ref{jumpc}, $|\langle \Psi(0), v_-(0; \lambda) \rangle| = \mathcal{O}(|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2})$. Thus we have

\begin{align*}
\langle \Psi(0) &, \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \lambda) \rangle dy \rangle \\
&\leq C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2}) \int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} |G_i^-(y)||W_i^-(y)| dy \\
&\leq C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2}) \int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} \Big(e^{-\alpha(X_{i-1} + y)}( e^{|\nu(\lambda)| X_{i-1}} |\lambda|^2 + |D|) \\
&+ e^{\nu(\lambda)y} |\lambda|^2 
+ |\lambda|^2 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| \Big) |d| dy \\
&\leq C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2}) e^{-\alpha X_{i-1}} (|\lambda|^2 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) |D| ) |d| \int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} dy \\
&+ C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2}) ( e^{(\alpha - |\nu(\lambda)|) X_{i-1}} |\lambda|^2 + e^{-\alpha X_{i-1}} |D|)|d|\int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} e^{-\alpha(X_{i-1} + y)} e^{-\alpha(X_{i-1} + y)} dy \\
&+ C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2}) e^{-\alpha X_{i-1}} |\lambda|^2 |d| \int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} e^{-\alpha(X_{i-1} + y)} e^{\nu(\lambda)y} dy
\end{align*}

These three integral terms are almost identical to those in Lemma \ref{noncenterW}. The only differences are there is a factor of $|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2}$ out front, and the $e^{\alpha y}$ in the integrals is replaced with $e^{-|\nu(\lambda)|y}$. \\

For the first integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} dy &\leq C e^{-|\nu(\lambda)| X_{i-1}}
\end{align*}

For the third integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} e^{-\alpha(X_{i-1} + y)} e^{\nu(\lambda)y} dy
&\leq \int_{-X_{i-1}}^0 e^{-\alpha X_{i-1}} e^{-(\alpha + 2|\nu(\lambda)|) y} dy \\
&\leq \int_{-X_{i-1}}^0 e^{-\alpha X_{i-1}} e^{-(\alpha + (\alpha - \tilde{\alpha})) y} dy \\
&= e^{(\alpha - \tilde{\alpha}) X_{i-1}} \int_{-X_{i-1}}^0 e^{-(\alpha + (\alpha - \tilde{\alpha})) X_{i-1}} e^{-(\alpha + (\alpha - \tilde{\alpha})) y} dy \\
&= e^{(\alpha - \tilde{\alpha}) X_{i-1}} \int_{-X_{i-1}}^0 e^{-(2 \alpha - \tilde{\alpha})( X_{i-1} + y)} dy \\
&\leq C e^{(\alpha - \tilde{\alpha}) X_{i-1}}
\end{align*}

For the second integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} e^{-\alpha(X_{i-1} + y)} e^{-\alpha(X_{i-1} + y)} dy &\leq \int_{-X_{i-1}}^0 e^{|\nu(\lambda)|X_{i-1}} e^{-2\alpha(X_{i-1} + y)}  dy \\
&\leq C e^{-|\nu(\lambda)|X_{i-1}}
\end{align*}

Putting this all together, we have

\begin{align*}
&\left| \langle \Psi(0), \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \lambda) \rangle dy \rangle \right| \\
&\leq C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2}) \Big( e^{-\alpha X_{i-1}} (|\lambda|^2 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2} ) |D|)e^{-|\nu(\lambda)|X_{i-1}} \\
&+ (e^{(\alpha - |\nu(\lambda)|) X_{i-1}} |\lambda|^2 + e^{-\alpha X_{i-1}} |D|)e^{-|\nu(\lambda)|X_{i-1}} \\
&+ e^{-\alpha X_{i-1}} e^{-|\nu(\lambda)|X_{i-1}} |\lambda|^2 \Big) |d| \\
&\leq C \Big( e^{-\tilde{\alpha} X_{i-1}} |\lambda|^3 + (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2} )|\lambda| |D| \Big) |d| \\
&\leq C |\lambda| (e^{-\tilde{\alpha} X_1} + e^{-\tilde{\alpha} X_2}) (|\lambda|^2 + |D| ) |d|
\end{align*}

The other integral has the same bound.

\end{proof}
\end{lemma}

% lemma : center not involving H

Finally, we look at the ``center'' integral term not involving $W$.

\begin{lemma}

\begin{align*}
\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle \langle \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \right| &\leq C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )| |\lambda|^2 |d|\\
\left| \int_{X_i}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_+(0; \beta_i^+, \lambda) \rangle \langle \lambda^2 d_i \tilde{H}(y), w_+(y; \beta_i^+,\lambda) \rangle dy \right| &\leq C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )| |\lambda|^2  |d| \\
\end{align*}

\begin{proof}

For the ``minus'' integral, we have

\begin{align*}
\langle \Psi(0) &, \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \rangle \\
&= \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle \langle \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy 
\end{align*}

From Lemma \ref{jumpc}, $\Psi(0), v_-(0; \lambda) \rangle| = \mathcal{O}(|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )$. Thus we have

\begin{align*}
&\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \lambda) \rangle \langle \lambda^2 d_i \tilde{H}(y), w_-(y; \lambda) \rangle dy \right| \\
&\leq C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )| |\lambda|^2 |d| 
\int_{-X_{i-1}}^0 e^{\nu(\lambda)y} |\tilde{H}(y) dy|
\end{align*}

Since we know that $\tilde{H}(y)$ decays exponentially with rate $\alpha$, this becomes

\begin{align*}
&\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle \langle \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \right| \\
&\leq C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )| |\lambda|^2  |d| 
\int_{-X_{i-1}}^0 e^{(\alpha - |\nu(\lambda)|)y} dy \\
&\leq C (|\lambda| + e^{-2 \alpha X_1} + e^{-2 \alpha X_2} )| |\lambda|^2  |d|
\end{align*}

The ``plus'' integral is similar.

\end{proof} 
\end{lemma}

We are now ready to put all of this together.

% lemma : jump expression

\begin{lemma}\label{jump}

We have the following expression for the jumps 

\[
\xi = \langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle
\]
at $x = 0$.

\begin{equation}\label{jumpexp}
\xi = \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^u_0 D_{i-1} d \rangle - d_i \lambda^2 \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy + R(\lambda)_i(d)
\end{equation}

where the remainder term $R(\lambda)_i(d)$ has bound

\begin{align*}
|R(\lambda)(d)_i| &\leq C \Big( e^{-\tilde{\alpha}X_1}( e^{-\alpha X_1} + p_5(\lambda) 
+ p_1(X_1; \lambda) + ||G|| + |\lambda|  ) |D| 
+ (e^{-\alpha X_1} + p_5(\lambda) + |\lambda| ) |\lambda|^2 \Big) |d|
\end{align*}

\begin{proof}
Using the fixed point equations at $x = 0$, we evaluate $\langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle$. The first two terms on the RHS of \eqref{jumpexp} come from Lemma \ref{jumpa}. The higher order Melnikov integral term comes from Lemma \ref{noncenterH}. For the remainder term, we use all the jump estimation lemmas to get the estimate

\begin{align*}
|R&(\lambda)(d)_i| \leq C ( (e^{-\alpha X_1} \Big( |\lambda|^2  + (p_1(X_1; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1} + ||G|| + |\lambda|)|D| ) |d| ) \\
&+ p_5(\lambda) ( e^{-\tilde{\alpha} X_1} |D| + |\lambda|^2 )|d| \\
&+ |\lambda| ( e^{-\tilde{\alpha} X_1} |D| + |\lambda|^2 )|d| \\
&+ ( e^{-\alpha X_1} |\lambda|^2 + e^{-(\alpha + \tilde{\alpha}) X_1} |D|) |d| \\
&+ ( |\lambda| + e^{-\alpha X_1} ) |\lambda|^2 |d| \\
&+ ( e^{-\tilde{\alpha} X_1} |\lambda|^3 + e^{-\tilde{\alpha} X_1} |\lambda| |D|) |d| \\
&+ |\lambda|^3 |d|
\end{align*}

Simplifying and dropping higher order terms, this becomes

\begin{align*}
R(\lambda)(d)_i &\leq C \Big( e^{-\tilde{\alpha}X_1}( e^{-\alpha X_1} + p_5(\lambda)
+ p_1(X_1; \lambda) + ||G|| + |\lambda|  ) |D| 
+ (e^{-\alpha X_1} + p_5(\lambda) + |\lambda| ) |\lambda|^2 \Big) |d|
\end{align*}

\end{proof}
\end{lemma}

We are now ready to substitute in all the things to get something we can solve for the eigenvalues $\lambda$.

\begin{theorem}

The eigenvalue problem has a solution for nonzero eigenvalue $\lambda$ if and only if

\begin{equation}\label{matrixdet}
E(\lambda) = \det S(\lambda) = \det(A - \lambda^2 MI + R(\lambda) ) = 0
\end{equation}

where $A$ is the matrix defined by

\[
A = 
\begin{pmatrix}
-a_1 + \tilde{a}_2 & a_1 - \tilde{a}_2 \\
-\tilde{a}_1 + a_2 & \tilde{a}_1 - a_2 
\end{pmatrix}
\]

The entries of the matrix $A$ are given by
\begin{align*}
a_i &= \langle \Psi (X_i), Q'(-X_i) \rangle \\
\tilde{a}_i &= \langle \Psi(-X_i), Q'(X_i) \rangle
\end{align*}

and the remainder $R(\lambda)$ has bound

\begin{align*}
|R(\lambda)(d)| &\leq C \Big( e^{-(\alpha + \tilde{\alpha})X_1}( e^{-\alpha X_1} + |\lambda|  )  
+ (e^{-\alpha X_1} + |\lambda| ) |\lambda|^2 \Big) |d|
\end{align*}

\begin{proof}

First, we plug in $D_i$ and $D_{i-1}$ into \eqref{jumpexp} from the previous lemma. 
Recall that we have the following expression for $D_i$ from Hypothesis \ref{problembounds}.

\[
D_i = ( Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) + \mathcal{O} \left( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\]

Substituting this into $\langle \Psi(X_i), P^u_0 D_i d \rangle$ and using the fact that $\Psi(\pm X_i)$ is order $e^{-\alpha X_i}$, we have

\begin{align*}
\langle \Psi(X_i), P^u_0 D_i d \rangle &= \langle \Psi(X_i), (Q'(X_i) + Q'(-X_i)(d_{i+1} - d_i ) \rangle + \mathcal{O} \left( e^{-2 \alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\end{align*}

Now we assume what was done in (3.36) in San98 applies here, i.e. that the ``matching'' terms $\langle \Psi(X_i), Q'(X_i) \rangle$ and $\langle \Psi(-X_i), Q'(-X_i) \rangle$ are higher order (say $\mathcal{O}(e^{-3 \alpha X_i}$) and can be tossed into the remainder. Thus we are only left with the ``nonmatching'' terms $\langle \Psi(X_i), Q'(-X_i) \rangle$ and similar. WE DO NEED TO VERIFY THIS. Then we get

\begin{align*}
\langle \Psi(X_i), P^u_0 D_i d \rangle &= \langle \Psi(X_i), Q'(-X_i) \rangle (d_{i+1} - d_i ) + \mathcal{O} \left( e^{-2 \alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\end{align*}

Similarly, we have

\begin{align*}
\langle \Psi(-X_{i-1}), P^u_0 D_{i-1} d \rangle &= \langle \Psi(-X_{i-1}), Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) + \mathcal{O} \left( e^{-2 \alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\end{align*}

Thus the jumps at $x = 0$ are given by

\begin{align*}
\xi_i &= \langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle \\
&= \langle \Psi(X_i), Q'(-X_i) \rangle (d_{i+1} - d_i ) + \langle \Psi(-X_{i-1}), Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) - \lambda^2 d_i M + R(\lambda)(d)_i
\end{align*}

where $M$ is the higher order Melnikov integral

\[
M = \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy
\]

The bound for the remainder term $R(\lambda)(d)_i$ in this expression is given by the bound for the remainder term from Lemma \ref{jump} together with the additional remainder terms from the substitution of $D_i$.

\begin{align*}
|R(\lambda)(d)_i| &\leq C \Big( e^{-\tilde{\alpha}X_1}( e^{-\alpha X_1} + p_5(\lambda) 
+ p_1(X_1; \lambda) + ||G|| + |\lambda|  ) |D| 
+ (e^{-\alpha X_1} + p_5(\lambda) + |\lambda| ) |\lambda|^2 \\
&+ e^{-2 \alpha X_1} (|\lambda| +  e^{-\alpha X_1} ) \Big) |d|
\end{align*}

For the the final remainder bound, we substitute the following estimates from prior lemmas and hypothesis.

\begin{align*}
||G|| &\leq C e^{-\alpha X_1} \\
|D| &\leq C e^{-\alpha X_1} |d| \\
|p_1(X_i; \lambda)| &\leq C (e^{-\alpha X_1} + |\lambda|) \\
|p_5(\lambda)| &\leq C|\lambda|
\end{align*}

Thus we have

\begin{align*}
|R(\lambda)(d)_i| &\leq C \Big( e^{-\tilde{\alpha}X_1}( e^{-\alpha X_1} + |\lambda|  ) e^{-\alpha X_1}
+ (e^{-\alpha X_1} + |\lambda| ) |\lambda|^2 
+ e^{-2 \alpha X_1} (|\lambda| +  e^{-\alpha X_1} ) \Big) |d|
\end{align*}

Simplifying this and dropping higher order terms, the bound becomes

\begin{align*}
|R(\lambda)(d)_i| &\leq C \Big( e^{-(\alpha + \tilde{\alpha})X_1}( e^{-\alpha X_1} + |\lambda|  )  
+ (e^{-\alpha X_1} + |\lambda| ) |\lambda|^2 \Big) |d|
\end{align*}

Since we are taking $\lambda = \mathcal{O}(e^{-\alpha X_1})$, this remainder bound is sufficient!\\

Taking $i = 1, 2$, the jump expressions become

\begin{align*}
\xi_1 &= \langle \Psi(X_1), Q'(-X_1) \rangle (d_2 - d_1 ) + \langle \Psi(-X_2), Q'(X_2) \rangle (d_1 - d_2 ) + \lambda^2 d_1 M + R(\lambda)(d)_1 \\
\xi_2 &= \langle \Psi(X_2), Q'(-X_2) \rangle (d_1 - d_2 ) + \langle \Psi(-X_1), Q'(X_1) \rangle (d_2 - d_1 ) + \lambda^2 d_2 M + R(\lambda)(d)_2
\end{align*}

Next, we define

\begin{align*}
a_i &= \langle \Psi (X_i), Q'(-X_i) \rangle \\
\tilde{a}_i &= \langle \Psi(-X_i), Q'(X_i) \rangle
\end{align*}

Finally, we write our jump equations in matrix form.

\[
E(\lambda) = \det S(\lambda) = \det(A - \lambda^2 MI + R(\lambda) ) = 0
\]

where $A$ is the matrix defined by

\[
A = 
\begin{pmatrix}
-a_1 + \tilde{a}_2 & a_1 - \tilde{a}_2 \\
-\tilde{a}_1 + a_2 & \tilde{a}_1 - a_2 
\end{pmatrix}
\]

Thus we have a solution for nonzero eigenvalue $\lambda$ if and only if $E(\lambda) = 0$.

\end{proof}
\end{theorem}

In our specific case, we can actually compute leading order expressions for the eigenvalues

\begin{corollary}
To leading order, the nonzero eigenvalues are given by

\begin{equation}
\lambda = \pm \sqrt{-2a/M}
\end{equation}

where $M$ is the higher order Melnikov integral and 

\begin{equation}
a = \langle \Psi (X_1), Q'(-X_1) \rangle 
+ \langle \Psi (X_2), Q'(-X_2) \rangle 
\end{equation}

\begin{proof}

As in the exponentially weighted case, we can use the (known) evenness and oddness of the functions involved to get

\[
\tilde{a}_i = \langle \Psi(-X_i), Q'(X_i) \rangle = -\langle \Psi(X_i), Q'(-X_i) \rangle = -a_i
\]

Thus the matrix $A$ becomes

\[
A = 
\begin{pmatrix}
-a_1 - a_2 & a_1 + a_2 \\
a_1 + a_2 & -a_1 - a_2 
\end{pmatrix}
\]

Let $a = a_1 + a_2$ and redefine $A$ by

\[
A = 
\begin{pmatrix}
-1 & 1 \\
1 & -1
\end{pmatrix}
\]

then we have the matrix equation

\[
E(\lambda) = \det S(\lambda) = \det(a A - \lambda^2 MI + R(\lambda) ) = 0
\]

Thus, to leading order we are computing the determinant of $a A + \lambda^2 MI$, i.e. 

\[
a A - \lambda^2 MI = 
\begin{pmatrix}
-a - \lambda^2 M & a \\
a & -a - \lambda^2 M
\end{pmatrix}
\]

The characteristic polynomial for this is

\begin{align*}
0 &= (-a - \lambda^2 M)^2 - a^2 \\
&= a^2 + 2 a \lambda^2 M + \lambda^4 M^2 - a^2 \\
&= 2 a \lambda^2 M + \lambda^4 M^2 \\
&= \lambda^2 M (2a + M \lambda^2 )
\end{align*}

This has two roots at 0 (which are expected) as well as two roots at $\pm \sqrt{-2a/M}$. These will be purely imaginary or real depending on the sign of $a$.

\end{proof}
\end{corollary}

\end{document}