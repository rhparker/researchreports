\documentclass[12pt]{article}
\usepackage[pdfborder={0 0 0.5 [3 2]}]{hyperref}%
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}%
\usepackage[shortalphabetic]{amsrefs}%
\usepackage{amsmath}
\usepackage{enumerate}
% \usepackage{enumitem}
\usepackage{amssymb}                
\usepackage{amsmath}                
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage{float}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{mathtools}
\usepackage{cool}
\usepackage{url}
\usepackage{graphicx,epsfig}
\usepackage{makecell}
\usepackage{array}

\def\noi{\noindent}
\def\T{{\mathbb T}}
\def\R{{\mathbb R}}
\def\N{{\mathbb N}}
\def\C{{\mathbb C}}
\def\Z{{\mathbb Z}}
\def\P{{\mathbb P}}
\def\E{{\mathbb E}}
\def\Q{\mathbb{Q}}
\def\ind{{\mathbb I}}

\graphicspath{ {images17/} }

\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{hypothesis}{Hypothesis}

\begin{document}

\section*{KdV5 with Periodic Boundary Conditions}

Here we look at the case with periodic boundary conditions. Note that we cannot use an exponential weight in this case since our domain is of finite length. As before, we are looking to solve the system

\begin{enumerate}[(i)]
\item $(W_i^\pm)' = A(q) W_i^\pm + G_i^\pm W_i^\pm + \lambda B W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm$
\item $W_i^\pm(0) \in \C \psi(0) \oplus Y^+ \oplus Y^-$
\item $W_i^+(0) - W_i^-(0) \in \C \psi(0) $
\item $W_1^+(L) - W_2^-(-L) = D_1 d $
\end{enumerate}

which is the piecewise eigenvalue problem written as a first order system in the unweighted norm. The eigenfunction here is given by $V_i^\pm = (Q' - \lambda Q_c)d_i + W_i\pm$.\\

Let's first look at this for the case of a wave train composed of single pulses. Recall that for the single pulse $q$, where there is only one join at the center, the eigenfunction is given by $V\pm = Q' - \lambda Q_c + W_i\pm$, and this becomes

\begin{enumerate}[(i)]
\item $(W^\pm)' = A(q) W_i^\pm + \lambda B W^\pm - \lambda^2 B Q_c$
\item $W^\pm(0) \in \C \psi(0) \oplus Y^+ \oplus Y^- \oplus Y^0$
\item $W^+(0) - W^-(0) \in \C \psi(0) $
\end{enumerate}

To do this for the wave train, we will use periodic BCs on the interval $[-T, T]$. For now, we state the existence of such wave trains as a hypothesis.

\begin{hypothesis}\label{qpexists}
For some value of $c$ (likely $> 1/4$) a periodic wavetrain solution $q_Tz(x)$ exists with period $2T$ for $T$ sufficiently large. We can choose the interval $[-T,T]$ so that the center of one of the peaks is at 0. The solution $q_T(x)$ is an even function on $[-T, T]$. The periodic solution is close to the single pulse solution $q(x)$ on $[-T, T]$, where we have the bound 

\[
||q_T(x) - q(x)||_{[-T, T]} \leq C e^{-\alpha T}
\]

which makes sense since the larger $T$ is, the more $q_T$ should resemble the single pulse on $[-T, T]$.
\end{hypothesis}

We need one more condition to ensure the eigenfunction satisfies the BCs. By Hypothesis~\ref{qpexists}, a wavetrain solution $q_p(x)$ exists, thus this function and all its derivatives must match at the endpoints of $[-T, T]$.  Thus for the periodic boundary condition for the eigenfunction we must have

\begin{align*}
Q_p'(-T) - \lambda (Q_p)c(-T) + W_i^-(-T) &= Q_p'(T) - \lambda (Q_p)_c(T) + W_i^+(T) \\
W_i^-(-T) - W_i^+(T) &= ( Q_p'(T) - Q_p'(-T) ) - \lambda( (Q_p)_c(T) - (Q_p)_c(-T) ) \\
&= 0
\end{align*}

Thus the system we are looking to solve in the periodic case is

\begin{enumerate}[(i)]
\item $(W^\pm)' = A(q_p) W_i^\pm + \lambda B W^\pm - \lambda^2 B (Q_p)_c$
\item $W^\pm(0) \in \C \psi(0) \oplus Y^+ \oplus Y^-$
\item $W^+(0) - W^-(0) \in \C \psi(0) $
\item $W_i^-(-T) - W_i^+(T) = 0 $
\end{enumerate}

Before we go to town on this, we will rewrite this in the following way. Let

\[
\tilde{A}(\lambda, q_p) = A(q_p) + \lambda B
\]

Then the first equation becomes 

\[
(W^\pm)' = \tilde{A}(\lambda, q_p) W_i^\pm - \lambda^2 B (Q_p)_c
\]

We would also like to write this in terms of the single pulse $q$ rather than the periodic solution $q_p$. To do this, let

\begin{align*}
\tilde{H} &= -B(Q_p)_c \\
H &= -B Q_c \\
G(\lambda) &= \tilde{A}(\lambda, q_p) - \tilde{A}(\lambda, q)
\end{align*}

Then the first equation becomes 

\[
(W^\pm)' = \tilde{A}(\lambda, q) W_i^\pm + G(\lambda) W_i^\pm + \lambda^2 \tilde{H}
\]

For now, we will assume we have these bounds (based on Hypothesis \ref{qpexists}).

\begin{align*}
|G(\lambda)(x)| &\leq C e^{-\alpha T} && x \in [-T, T]\\
|\tilde{H}(x) - H(x)| &\leq C e^{-\alpha T} && x \in [-T, T]
\end{align*}

Now we look at the eigenvalue problem

\begin{equation}
U' = \tilde{A}(\lambda, q) U = A(\lambda) U + R(q(x)) U
\end{equation}

where we split up $\tilde{A}(\lambda, q)$ so that all of the $x$ dependence is via the single pulse $q(x)$ and is contained in $R(x)$. Everything else (including the $\lambda$) is in the matrix $A(\lambda)$, which is a constant matrix and different from the $A$ above, but we are seriously running out of letters, so it will do for now. The matrix $\tilde{A}(\lambda, q)$ is exponentially asymptotic (due to the exponential decay properties of $q$ and its derivatives), and its limit as $|x| \rightarrow \infty$ is $A(\lambda)$.\\

For $\lambda = 0$, $A(\lambda)$ has an eigenvalue at 0. The characteristic polynomial for $A(\lambda)$ is $f(\lambda, \nu) = \lambda - c \nu + \nu^3 - \nu^5$, which to leading order is $f(\lambda, \nu) = \lambda - c \nu + \mathcal{O}(\nu^3)$. Thus, to leading order, this polynomial has a zero when $t = \lambda / c$, which is approximately the value of the spatial eigenvalue closest to 0. For small $\lambda$, numerics shows this is really close.\\

Before we continue, we will prove the following lemma, based on Exercise 29 on p. 104 of Coddington and Levinson (1955).

\begin{lemma}Consider the eigenvalue problem

\begin{equation}\label{veigproblem}
V(x)' = AV(x) + R(x)V(x)
\end{equation}

where $V(x) \in R^n$, $A$ is a constant, diagonalizable $n \times n$ matrix, and $R(x): \R \rightarrow \R^n$ is an integrable function which is globally Lipschitz continuous in $x$. Let $\nu$ be any eigenvalue of $A$ with corresponding eigenvector $p$, i.e. $A p = \nu p$. Then there is a unique solution $\phi(x)$ to \eqref{veigproblem} such that 

\[
\lim_{x\rightarrow\infty} \phi(x) e^{-\nu x} = p
\]

In other words, for large $x$, the solution $\phi(x)$ resembles that of the constant coefficient eigenvalue problem $V(x)' = AV(x)$.

\begin{proof}
Let $\sigma = \text{Re} \nu$. Let $\nu_1, \dots, \nu_n$ be the $n$ eigenvalues of $A$ with corresponding eigenvectors $p_1, \dots, p_n$. Since we are assuming that $A$ is diagonalizable, we have a complete set of $n$ of these. Order the eigenvalues by increasing real part; if more than one eigenvalue has the same real part, any order is fine, as long as we make sure that any eigenvalue besides $\nu$ with real part $\sigma$ occurs after $\nu$ in the list. Then $\nu = \nu_k$ for some $k$, $\text{Re} \nu_j < \sigma$ for $j < k$ (as long as $k \neq 1$), and $\text{Re} \nu_j \geq \sigma$ for $j \geq k$. \\

Let $e^{Ax}$ be the fundamental matrix solution for $U' = A U$, and split $e^{Ax}$ up into
\[
e^{Ax} = Y_1(x) + Y_2(x)
\]
where $Y_1$ involves only eigenvectors corresponding to eigenvalues $\nu_1, \dots, \nu_{k-1}$ and $Y_2$ involves only eigenvectors corresponding to eigenvalues $\nu_{k}, \dots, \nu_n$. Since $A$ is a constant-coefficient matrix, we can write down an explicit formula for $Y_1$ and $Y_2$. Essentially, all we need to do is change coordinates to the eigenbasis, evolve along the appropriate eigenvectors, and zero out the other ones. To be specific, let P be the $n \times n$ matrix with columns $p_1, \dots, p_n$. Since we are assuming $A$ is diagonalizable, this matrix is invertible, and $D = P^{-1}AP$ is diagonal with eigenvalues $\nu_1, \dots, \nu_n$ on the diagonal. Recall that the matrix exponential is given by $e^{Ax} = P^{-1}e^{Dx}P$. Starting with the matrix $D$, form the matrix $D_1$ by keeping only the eigenvalues $\nu_1, \dots, \nu_{k-1}$ on the diagonal, and form the matrix $D_2$ by keeping only the eigenvalues $\nu_{k}, \dots, \nu_n$ on the diagonal. Then we have

\begin{align*}
Y_1(x) &= P^{-1}e^{D_1x}P \\
Y_1(x) &= P^{-1}e^{D_2x}P \\
\end{align*}
 
Choose $\delta$ such that $0 < \delta < \sigma - \text{Re} \nu_{k-1}$, i.e. smaller than the spectral gap between $\nu$ and the eigenvalue with the next smallest real part. (If $k = 1$, $Y_1 = 0$, $Y_2 = e^{Ax}$, and we don't care about $\delta$). Then we can find a constant $C$ such that

\begin{align*} 
|Y_1(x)| &\leq Ce^{(\sigma - \delta)x} && x \geq 0 \\
|Y_2(x)| &\leq Ce^{\sigma x} && x \leq 0 
\end{align*}

Define the exponentially weighted function space with weight $\sigma$

\[
B_{\sigma, a} = \{ f \in C^0([a, \infty), \R^n) : \sup_{x \in [a, \infty)} |e^{-\sigma x} f(x)| < \infty 
\]

where $a$ will be chosen later. The norm on this space is given by

\[
||f||_{\sigma, a} = \sup_{x \in [a, \infty)} |e^{-\sigma x} f(x)|
\]

In other words, we allow functions in $B_{\sigma, a}$ to grow exponentially as $x \rightarrow \infty$ at a rate of $\sigma$ or slower. It is known that $B_{\sigma, a}$ is a Banach space. Define the operator $F$ on $B_{\sigma, a}$ by

\begin{align*}
F(\phi)(x) = e^{\nu x} p + \int_a^x Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2(x - y)R(y)\phi(y)dy
\end{align*}

where the $a$ in the integral is the same as in $B_{\sigma, a}$ and will be chosen later. First we show that $F: B_{\sigma, a} \rightarrow B_{\sigma, a}$. Let $\phi \in B_{\sigma, a}$. For $x \geq a$ we have

\begin{align*}
|e^{-\sigma x} &F(\phi)(x)| \leq e^{(\nu - \sigma) x} |p| + \int_a^x |Y_1(x - y)||R(y)||\phi(y)| dy + \int_x^\infty |Y_2(x - y)||R(y)||\phi(y)|dy \\
&\leq |p| + C \left( e^{-\sigma x}  \int_a^x e^{(\sigma - \delta)(x - y)}|R(y)||\phi(y)| dy + e^{-\sigma x}  \int_x^\infty e^{\sigma(x - y)}|R(y)||\phi(y)|dy \right) \\
&\leq |p| +  C \left( \int_a^x e^{-\delta(x - y)}|R(y)||e^{-\sigma y}\phi(y)| dy + \int_x^\infty |R(y)||e^{-\sigma y} \phi(y)|dy \right) \\
&\leq |p| + C ||\phi||_{\sigma, a}\left( \int_a^x e^{-\delta(x - y)}|R(y)| dy + \int_x^\infty |R(y)|dy \right) \\
&\leq |p| + C ||\phi||_{\sigma, a} \int_a^\infty |R(y)| dy 
\end{align*}

Since $R$ is integrable, the RHS is finite, thus the map $F: B_{\sigma, a} \rightarrow B_{\sigma, a}$ is well defined. Now we show the map $F$ is a contraction. Let $\phi, \psi \in B_{\sigma, a}$. For $x \geq a$ we have

\begin{align*}
|e^{-\sigma x}( &F(\phi)(x) - F(\psi)(x))| \leq \int_a^x |Y_1(x - y)||R(y)||\phi(y) - \psi(y)| dy + \int_x^\infty |Y_2(x - y)||R(y)||\phi(y) - \psi(y)|dy \\
&\leq C \left( e^{-\sigma x}  \int_a^x e^{(\sigma - \delta)(x - y)}|R(y)||\phi(y) - \psi(y)| dy + e^{-\sigma x}  \int_x^\infty e^{\sigma(x - y)}|R(y)||\phi(y) - \psi(y)|dy \right) \\
&\leq C \left( \int_a^x e^{-\delta(x - y)}|R(y)||e^{-\sigma y}(\phi(y) - \psi(y))| dy + \int_x^\infty |R(y)||e^{-\sigma y} (\phi(y) - \psi(y))|dy \right) \\
&\leq C ||\phi - \psi ||_{\sigma, a}\left( \int_a^x e^{-\delta(x - y)}|R(y)| dy + \int_x^\infty |R(y)|dy \right) \\
&\leq C ||\phi - \psi ||_{\sigma, a} \int_a^\infty |R(y)| dy 
\end{align*}

Since $R$ is integrable, we can choose $a$ sufficiently large so that

\[
\int_a^\infty |R(y)| dy < \frac{1}{2C}
\]

from which we conclude that

\[
||F(\phi) - F(\psi) ||_{\sigma, a} \leq \frac{1}{2} ||\phi - \psi ||_{\sigma, a}
\]

Since $F$ is a contraction on the Banach space $B_{\sigma, a}$, by the Banach Fixed Point Theorem the map $F$ has a unique fixed point, i.e. a unique $\phi(x) \in B_{\sigma, a}$ such that $F(\phi) = \phi$. Note that by the fixed point theorem and definition of $B_{\sigma, a}$, we only have $\phi(x)$ defined for $\phi \geq a$. However, choosing the initial condition $\phi(a)$ at $x = a$, by the existence and uniqueness of solutions to \eqref{veigproblem} and the global Lipschitz condition placed on $R(x)$ (which guarantees global existence of solutions), we can extend $\phi(x)$ uniquely to all of $\R$. This extension of $\phi(x)$ to $\R$ is given by the same formula we have for $\phi(x)$ when $x \geq a$.

\begin{equation}\label{fpphi}
\phi(x) = e^{\nu x} p + \int_a^x Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2(x - y)R(y)\phi(y)dy
\end{equation}

To see this, all we need to do is show that it satisfies the ODE \eqref{veigproblem}. Differentiating \eqref{fpphi}, we get

\begin{align*}
\phi'(x) &= \nu e^{\nu x} p + (Y_1(0) + Y_2(0))R(x)\phi(x) + \int_a^x Y_1'(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2'(x - y)R(y)\phi(y)dy \\
&= e^{\nu x} A p + e^{0A}R(x)\phi(x) + \int_a^x A Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x A Y_2(x - y)R(y)\phi(y)dy \\
&= A \left( e^{\nu x} p + \int_a^x Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2(x - y)R(y)\phi(y)dy \right) + R(x) \phi(x) \\
&= A \phi(x) + R(x) \phi(x)
\end{align*}

Thus $\phi(x)$ defined in \eqref{fpphi} is the unique extension that we seek. All that remains is to show what happens when $x \rightarrow \infty$. Since we are interested in end behavior, we only need to consider what happens when $x \geq a$. Since $\phi(x) \in B_{\lambda, a}$, $||\phi||_{\sigma, a}$ is finite and independent of $x$. Thus for $x \geq a$, using what we did above, 

\begin{align*}
|e^{-\sigma x} &(\phi(x) - e^{\nu x} p)| \leq C ||\phi||_{\sigma, a}\left( \int_a^x e^{-\delta(x - y)}|R(y)| dy + \int_x^\infty |R(y)|dy \right) \\
&\leq C ||\phi||_{\sigma, a}\left( \int_a^{x/2} e^{-\delta(x - y)}|R(y)| dy + \int_{x/2}^x |R(y)|+ \int_x^\infty |R(y)|dy \right)\\
&\leq C ||\phi||_{\sigma, a}\left( e^{-\delta(x/2)} \int_a^{x/2} e^{-\delta(x/2 - y)}|R(y)| dy + \int_{x/2}^\infty |R(y)|dy \right)\\
&\leq C ||\phi||_{\sigma, a}\left( e^{-\delta(x/2)} \int_a^{\infty} |R(y)| dy + \int_{x/2}^\infty |R(y)|dy \right)\\
&\leq ||\phi||_{\sigma, a}\left(\frac{1}{2} e^{-\delta(x/2)} + \int_{x/2}^\infty |R(y)|dy \right)
\end{align*}

Since $\delta > 0$, $R(x)$ is integrable, and $||\phi||_{\sigma, a}$ is constant, both terms on the RHS go to 0 as $x \rightarrow \infty$. Thus we conclude that

\[
\lim_{x \rightarrow \infty} |e^{-\sigma x} (\phi(x) - e^{\nu x} p)| = 0
\]

Pulling out a factor of $e^{\nu x}$, this becomes 

\[
\lim_{x \rightarrow \infty} |e^{(\nu - \sigma) x}||\phi(x) e^{-\nu x} - p)| = 0
\]

since $\text{Re} \phi = \nu$, $|e^{(\nu - \sigma) x} = 1$ for all $x$. Thus we conclude that

\[
\lim_{x \rightarrow \infty} |\phi(x) e^{-\nu x} - p)| = 0
\]  

from which it follows that

\[
\lim_{x\rightarrow\infty} \phi(x) e^{-\nu x} = p
\]

\end{proof}
\end{lemma}


Let $\Phi(y,x; \lambda)$ be the evolution operator for $U' = \tilde{A}(\lambda, q) U$. For $\lambda = 0$, this has a center subspace which will perturb slightly for $\lambda \neq 0$ into a subspace which grows (or decays) exponentially, albeit at a slow rate since the spatial eigenvalue responsible for this is small. Thus instead of an exponential dichotomy we have an exponential trichotomy. This will occur separately on $\R^+$ and $\R^-$.\\

Following Hale and Lin (1985), we will write this as follows. We have projections $P^s_\pm(x; \lambda)$, $P^u_\pm(x; \lambda)$ and $P^c_\pm(x; \lambda) = I - P^s_\pm(x; \lambda) - P^u_\pm(x; \lambda)$ (where the subscripts designate whether the trichotomy is on $\R^+$ or $\R^-$) such that

\begin{align*}
\Phi(y, x; \lambda)P^s_\pm(x; \lambda) &= P^s_\pm(y; \lambda)\Phi(y, x; \lambda) \\
\Phi(y, x; \lambda)P^u_\pm(x; \lambda) &= P^u_\pm(y; \lambda)\Phi(y, x; \lambda) \\
\Phi(y, x; \lambda)P^c_\pm(x; \lambda) &= P^c_\pm(y; \lambda)\Phi(y, x; \lambda) \\
\end{align*}

In other words, it does not matter if you project or evolve first. For $\lambda = 0$ the superscript $c$ actually represents the center subspace, and for small $\lambda$, this is the subspace that the center subspace perturbs to. Using these, we can split the evolution up into evolution on the three subspaces by defining

\begin{align*}
\Phi^s_\pm(y, x; \lambda) &= \Phi(y, x; \lambda)P^s_\pm(x; \lambda) \\
\Phi^u_\pm(y, x; \lambda) &= \Phi(y, x; \lambda)P^u_\pm(x; \lambda) \\
\Phi^c_\pm(y, x; \lambda) &= \Phi(y, x; \lambda)P^c_\pm(x; \lambda) \\
\end{align*}

For the stable and unstable subspaces, we know what the eigenvalues of $\tilde{A}(0, q)$ are. Let $\alpha$ be the smallest real part of the positive eigenvalues of this and $-\alpha$ be the largest real part of the negative eigenvalues of this. (We get the same $\alpha$ both ways by symmetry of the eigenvalues of $\tilde{A}(0, q)$. For small $\lambda$, the spatial eigenvalues will not perturb much, so for stable and unstable subspaces we will still have the bounds

\begin{align*}
|\Phi^s(y, x; \lambda)| \leq C e^{-\alpha(y-x)} \\
|\Phi^u(x, y; \lambda)| \leq C e^{-\alpha(y-x)}
\end{align*}
where $x \leq y$ and $C$ is a constant. Technically we should probably replace $\alpha$ by $\alpha - \delta$ for small $\delta$ to account for the perturbation, but it does not matter for now.\\

For the center subspace, there is a small eigenvalue which is approximately $\nu = \lambda / c$. Thus we should have a $\lambda$-dependent bound of the form

\begin{align*}
|\Phi^c_+(y, x; \lambda)| &\leq C e^{\lambda(y-x)/c} && y \geq x \geq 0 \\
|\Phi^c_-(x, y; \lambda)| &\leq C e^{\lambda(y-x)/c} && x \leq y \leq 0 \\
\end{align*}

indictaing that the (potential) exponential growth rate on this center space is limited by $\lambda$, which we know is small.\\

Now we need to make all of this explicit. Consider the following eigenvalue problem and its adjoint problem.

\begin{align}
V' &= \tilde{A}(\lambda, q)V \label{eig:V} \\
W' &= -\tilde{A}^*(\lambda, q)W \label{eig:W}
\end{align}

We summarize some useful facts about this problem in the following lemma. The proof is either obvious, or if not, I have it scribbled in my notes.

\begin{lemma}\label{eigadjoint}
Consider the eigenvalue problem $U' = A(x)U$ and the corresponding adjoint problem $W' = -A(x)^* W$, where $A$ is an $n \times n$ matrix depending on $x$. Then the following are true.
\begin{enumerate}[(i)]
\item $\frac{d}{dx}\langle U(x), W(x) \rangle = 0$, thus the inner product is constant as $x$ varies.
\item If $\Phi(y, x)$ is the evolution operator for $U' = A(x)U$, then $\Phi(x, y)^*$ is the evolution operator for the adjoint problem $W' = -A(x)^* W$.
\end{enumerate}
\end{lemma}

Let $\nu(\lambda)$ be the small eigenvalue of the asymptotic matrix $\tilde{A}(\lambda,0)$ with corresponding eigenvector $v_0(\lambda)$. Then since $\det(A - \nu I) = 0$ implies $\det(A^* - \overline{\nu}I) = 0$, $-\overline{\nu(\lambda)}$ is the small eigenvalue of $-\tilde{A}(\lambda,0)^*$; let $w_0(\lambda)$ be thecorresponding eigenvector.\\

It would be great if there were a nice relationship between $v_0$ and $w_0$ (like we have with the corresponding eigenvalues), but without additional assumptions on $A$ this is not the case. What we would really like, however, is for $\langle v_0, w_0 \rangle \neq 0$. Even this is too much to ask in the generic case, since if we take

\[
M = \begin{pmatrix}1 & 1 \\ 0 & 1 \end{pmatrix}
\]

$M$ has a single eigenvector $(1, 0)$ and $M^*$ has a single eigenvector $(0, 1)$, both corresponding to the lone eigenvalue 1. These are clearly orthogonal. Since we suspect the problem might be the Jordan block, we will prove the following lemma.

\begin{lemma}\label{perpeigs}
Let $A$ be an $n \times n$ matrix, and suppose $v$ and $w$ are solutions to $Av = \lambda v$ and $A^*w = \overline{\lambda}w$, respectively. Suppose $\lambda$ is a simple eigenvalue, i.e. is has algebraic multiplicity of 1. Then $\langle v, w \rangle \neq 0$.
\begin{proof}
Since $\lambda$ is simple, $\text{span} \{w\} = \ker(A^* - \overline{\lambda}I)$. Suppose $v \perp w$. Then $v \in \ker(A^* - \overline{\lambda I})^\perp = \text{ran}(A - \lambda I)$, where the equality holds since $A$ is finite dimensional, thus has closed range. But this implies $(A - \lambda I)v_1 = v$ for some $v_1$, which cannot be the case since $\lambda$ is simple, so there cannot be such a generalized eigenvector. We conclude that $\langle v, w \rangle \neq 0$
\end{proof}
\end{lemma}

Given this lemma, we make the following hypothesis.

\begin{hypothesis}\label{simplesmalleig}
For sufficiently small $\lambda$, the small eigenvalue $\nu(\lambda)$ of the matrix $\tilde{A}(\lambda, 0)$ is simple.
\end{hypothesis}

I am not sure we even need to state this as a hypothesis, since the eigenvalues of $A(\lambda, 0)$ are analytic in $\lambda$, $A(0, 0)$ has an eigenvalue at 0, and the rest of the eigenvalues of $A(0, 0)$ are large, but we might as well put it here.\\

Given Hypothesis \ref{simplesmalleig} (or the argument above), $\nu(\lambda)$ is a simple eigenvalue of $\tilde{A}(\lambda, 0)$, thus by Lemma \ref{perpeigs}, $\langle v_0, w_0 \rangle \neq 0$. Since eigenvalues are defined up to scalar multiples, we can scale $v_0$ and/or $w_0$ such that

\[
\langle v_0, w_0 \rangle = 1
\]
 
Now we will come up with a formula for the projection and evolution on the center space for $x \geq 0$. Using Lemma \ref{veigproblem}, let $\tilde{v}(x; \lambda)$ and $\tilde{w}(x; \lambda)$ be solutions to the eigenvalue problem \eqref{eig:V} and its adjoint problem \eqref{eig:W} such that

\begin{align*}
\lim_{x \rightarrow \infty} e^{-\nu(\lambda) x} \tilde{v}_+(x) = v_0 \\
\lim_{x \rightarrow \infty} e^{\overline{\nu(\lambda)} x} \tilde{w}_+(x) = w_0 \\
\end{align*}

We would like to scale out the exponential growth/decay factor, so let

\begin{align*}
\tilde{v}_+(x) &= e^{\nu(\lambda) x } v_+(x) \\
\tilde{w}_+(x) &= e^{-\overline{\nu(\lambda)} x } w_+(x) \\
\end{align*}

Then

\begin{align*}
\lim_{x \rightarrow \infty} v_+(x) = v_0 \\
\lim_{x \rightarrow \infty} w_+(x) = w_0 \\
\end{align*}

Taking $x \rightarrow \infty$ in the inner product $\langle \tilde{v}_+(x), \tilde{w}_+(x) \rangle$ we have by the continuity of the inner product

\begin{align*}
\lim_{x \rightarrow \infty} \langle \tilde{v}_+(x), \tilde{w}_+(x) \rangle
&= \lim_{x \rightarrow \infty} \langle e^{\nu(\lambda) x } v_+(x), e^{-\overline{\nu(\lambda)} x} \tilde{w}_+(x) \rangle \\
&= e^{\nu(\lambda) x } e^{-\nu(\lambda) x } \lim_{x \rightarrow \infty} \langle v_+(x), w_+(x) \rangle \\
&= \langle v_0, w_0 \rangle \\
&= 1
\end{align*}

As a consequence of this and Lemma \ref{eigadjoint}, $\langle \tilde{v}_+(x), \tilde{w}_+(x) \rangle = 1$ for all $x \geq 0$. Since $\langle \tilde{v}_+(x), \tilde{w}_+(x) \rangle = \langle v_+(x), w_+(x) \rangle$, it follows that $\langle v_+(x), w_+(x) \rangle = 1$ for all $x \geq 0$.\\

What we would like to do now is write the projection $P^c_+(x)$ for $x \geq 0$ in terms of the adjoint solution $\tilde{w}_+(x)$. To do this, let $R^s_+(x; \lambda)$, $R^u_+(x; \lambda)$, and $R^c(x; \lambda)$ be the ranges of the corresponding projections (stable, unstable, and center ranges)
. The dimensions of these ranges are 2, 2, and 1 (respectively). Note that since $\tilde{v}_+(x)$ is in the center range $R^c(x; \lambda)$ and that space is one-dimensional, $\tilde{v}_+(x)$ is a basis vector for that space. Since we can scale the basis vector by any constant we want, we can divide by $e^{\nu(\lambda) x }$ to see that $v_+(x)$ is a basis vector for $R^c(x; \lambda)$. Therefore, every element in $R^c(x; \lambda)$ is a scalar multiple of $\tilde{v}_+(x)$. \\

We would like to obtain the projection $P^c_+(x)$ by projecting on the adjoint solution $w_+(x)$. First we show that $\tilde{w}(0)$ is perpendicular to $R^s_+(0; \lambda)$. Let $u(0) \in R^s_+(0; \lambda)$. Then $u(x) = \Phi(x, 0)u(0) \in R^s_+(x; \lambda)$ for all $x \geq 0$. Since the inner product $\langle u(x), \tilde{w}_+(x) \rangle$ is constant in $x$, we let $x \rightarrow \infty$ to get

\begin{align*}
\lim_{x \rightarrow \infty} \langle u(x), \tilde{w}_+(x) \rangle &= \lim_{x \rightarrow \infty} e^{-\nu(\lambda) x} \langle u(x), w_+(x) \rangle \\
&= \langle \lim_{x \rightarrow \infty} e^{-\nu(\lambda) x} u(x), w_0 \rangle \\
&= 0
\end{align*}

since $u(x)$ decays exponentially at a faster rate than $|\nu(\lambda)|$. Thus we have $\tilde{w}(0) \perp R^s(0; \lambda)$ and by the same token, $\tilde{w}_+(x) \perp R^s_+(x; \lambda)$ for all $ \geq 0$.\\

Note that we cannot play this same game with $R^u_+(x; \lambda)$, since to get decay to 0 we would have to take $x \rightarrow -\infty$. Since all these only pertain to the dichotomy/trichotomy on $\R^+$, they are only valid for $x \geq 0$, so we cannot take that limit.\\

However, we really want to have $\tilde{w}_+(x) \perp R^u_+(x; \lambda)$. Since $\tilde{w}_+(x)$ is a nonzero scalar multiple of $w_+(x)$, this is equivalent to $w_+(x) \perp R^u_+(x; \lambda)$ (they are the same at $x = 0$). To attain this, let's change coordinates, like we do in the constant coeffient case. The idea is that if we do this at $x = 0$ to get $w(0) \perp R^u_+(0; \lambda)$, the invariance of the inner product in $x$ should take care of the rest. In fact, we can do this for both the stable and unstable ranges so we might as well do that. Let $\{ a^s_1(0), a^s_2(0)\}$ be a basis for $R^s_+(0; \lambda)$ and let $\{a^u_1(0), a^u_2(0)\}$ be a basis for $R^u_+(0; \lambda)$. Then the set $\{ a^s_1(0), a^s_2(0),a^u_1(0), a^u_2(0), w(0) \}$ is linearly independent thus spans $\R^5$ (or $\C^5$). Change coordinates so that $w(0)$ is perpendicular to the span of the other four. Let $a^{s/u}_i(x) = \Phi(x,0)a^{s/u}_i(0)$, i.e. evolve the basis vectors forward. These will remain linearly independent after evolution, so will be a basis for the appropriate projection ranges at $x$. For simplicity, consider one of these, say $a^s_1(x)$. Since $\Phi(x,0) a^s_1(0)$ solves the eigenvalue problem, therefore by the invariance in $x$ of the inner product of solutions to the eigenvalue problem with solutions to the adjoint eigenvalue problem, for $x \geq 0$

\begin{align*}
\langle a^s_1(x), \tilde{w}_+(x) \rangle &= \langle \Phi(x,0) a^s_1(0), \tilde{w}_+(x) \rangle \\
&= \langle a^s_1(0), \tilde{w}(0) \rangle \\
&= \langle a^s_1(0), w(0) \rangle 0
\end{align*}

Since $\tilde{w}_+(x)$ is a scalar multiple of $w_+(x)$, we also have for $x \geq 0$

\[
\langle a^s_1(x), w_+(x) \rangle = 0
\]

Thus a single change of variables at $x = 0$ accomplishes what we want. Since $\tilde{w}_+(x) \in R^c(x; \lambda)$ and is perpendicular to the other two spaces, to get the center range projection $P^c_+(x; \lambda)$, all we have to do is project onto $\tilde{w}_+(x)$. To do this, we take the inner product with $\tilde{w}_+(x)$ to get the component in the direction of the basis vector $\tilde{v}_+(x)$. Thus for $x \geq 0$ and arbitrary $u$ we should have

\begin{align*}
P^c_+(x; \lambda)u &= \langle u, \tilde{w}_+(x) \rangle \tilde{v}_+(x) \\
&= e^{-\nu(\lambda)x} e^{\nu(\lambda) x }\langle u, w_+(x) \rangle v_+(x) \\
&= \langle u, w_+(x) \rangle v_+(x)
\end{align*}

We need to verify that this is in fact a projection. To do this, we show that $P^c_+(x; \lambda)P^c_+(x; \lambda) = P^c_+(x; \lambda)$.

\begin{align*}
P^c_+(x; \lambda)( P^c_+(x; \lambda) u ) &= \langle \langle u, w_+(x) \rangle v_+(x), w_+(x) \rangle v_+(x) \\
&= \langle u, w_+(x) \rangle \langle v_+(x), w_+(x) \rangle v_+(x) \\
&= \langle u, w_+(x) \rangle v_+(x) \\
&= P^c_+(x; \lambda) u 
\end{align*}

where we use the fact (proved above) that $\langle v_+(x), w_+(x) \rangle = 1$ for all $x \geq 0$. Thus this is a projection. From our definition of $P^c_+(x; \lambda)$ and the coordinate change we did above, we have

\begin{align*}
\ker P^c_+(x; \lambda) &= ( \text{span }\{ w_+(x) \})^\perp\\
\text{ran } P^c_+(x; \lambda) &= \text{span }\{ v_+(x) \}
\end{align*}

If this were to be an orthogonal projection, that would mean that $(\ker P^c_+(x; \lambda))^
\perp = \text{ran } P^c_+(x; \lambda)$, i.e. $\text{span }\{ w_+(x) \}) = \text{span }\{ v_+(x) \})$, which would mean that $v_+(x)$ and $w_+(x)$ are scalar multiples of each other. Since $\langle v_+(x), w_+(x) \rangle = 1$ for all $x \geq 0$, this implies $v_+(x) = w_+(x)$, which I do not think is true, thus this is not necessarily an orthogonal projection.\\

In the last line, we have projected onto the one-dimensional center range, which is invariant under the evolution $\Phi$. Since $\tilde{v}_+(x)$ also evolves in that space, we must have $\Phi(x,0) = v_+(x)$.\\

We will also want an expression for the center evolution $\Phi^c(x,y; \lambda)$, so let's do that here. For arbirary $u$, we have for $x, y \geq 0$

\begin{align*}
\Phi^c_+(x,y; \lambda)u &= \Phi(x,y; \lambda) P^c_+(y; \lambda) u \\
&= \Phi(x,y) \langle u, w_+(y) \rangle v_+(y) \\
&= \Phi(x,y) \langle u, w_+(y) \rangle e^{-\nu(\lambda)y} \tilde{v}_+(y) \\
&= \langle u, w_+(y) \rangle e^{-\nu(\lambda)y} \Phi(x,y) \tilde{v}_+(y) \\
&= \langle u, w_+(y) \rangle e^{-\nu(\lambda)y} \tilde{v}_+(x) \\
&= \langle u, w_+(y) \rangle e^{-\nu(\lambda)y} e^{\nu(\lambda)x} v_+(x) \\
&= e^{\nu(\lambda)(x-y)} v_+(x) \langle u, w_+(y) \rangle 
\end{align*}

where we used the fact that $\tilde{v}$ is a solution to the eigenvalue problem, thus under the evolution $\Phi(y, x; \lambda)$ we have $\Phi(y, x; \lambda)\tilde{v}_+(x) = \tilde{v}_+(y)$.\\

We can do the same thing we just did for the trichotomy on $\R^-$, which will give us analogous funcions $\tilde{v}_-(x)$, $v_-(x)$, $\tilde{w}_-(x)$, and $w_-(x)$. The equations for the projection $P^c_-(x)$ and the evolution $\Phi^c_-(x,y)$ will be the same except for the subscripts.\\

At this point, we write down the fixed point equations for the problem. Before we do that, we take a look at where these equations came from. These are very similar to the variation of constants formula, with the primary difference being that we split the solution up into stable, unstable, and center parts, evolve them separately (each with its own IC), and recombine them. So the fixed point equations should look like those in Sandstede (1998) with the addition of a center evolution term together with an IC in the center subspace. Since we are no longer integrating out to $\pm \infty$ the ICs $a_i$ are no longer 0.\\

We can also choose which way to integrate on the ``center'' subspace. Since we need one center initial condition at the end (with the $a^\pm$) and one initial condition at the center (with the $b^\pm$), we will integrate the center part in the forward direction on both pieces. Note that $\nu(\lambda)$ and $\lambda$ have the same sign. Since we need to consider both positive and negative $\lambda$, our estimates will always be for the ``worst-case scenario'' to account for either sign of $\lambda$. \\

The eigenvalue problem we are looking at is, in piecewise form,

\[
(W^\pm)' = \tilde{A}(\lambda, q) W^\pm + G(\lambda)W^\pm + \lambda^2 \tilde{H}
\]

Of course, $W$ is dependent on $\lambda$, but we suppress that dependence in the notation since it is annoying. Thus we get the fixed point problem

\begin{align*}
W^-(x) = \Phi^s_-(&x, -T; \lambda)a^- + \Phi^u_-(x, 0; \lambda)b^- + \Phi^c_-(x, -T; \lambda)a^0 \\
&+ \int_0^x \Phi^u_-(x, y; \lambda)[ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_{-T}^x \Phi^s_-(x, y; \lambda) [ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_{-T}^x \Phi^c_-(x, y; \lambda) [ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ]dy \\
W^+(x) = \Phi^u_+(&x, T; \lambda)a^+ + \Phi^s_+(x, 0; \lambda)b^+ + \Phi^c_+(x, 0; \lambda)b^0 \\
&+ \int_0^x \Phi^s_+(x, y; \lambda) [ G(\lambda)W+(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_T^x \Phi^u_+(x, y; \lambda) [ G(\lambda)W+(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_0^x \Phi^c_+(x, y; \lambda) [ G(\lambda)W+(y) + \lambda^2 \tilde{H}(y) ] dy
\end{align*}

where

\begin{align*}
(a^-, a^+, a^0) &\in E^s \oplus E^u \oplus E^c \\
(b^-, b^+, b^0) &\in R^u_-(0; 0) \oplus R^s_+(0; 0) \oplus R^c(0; 0)
\end{align*}

Note that all these spaces refer to the original, unperturbed problem, i.e. with $\lambda = 0$. The projections onto $E^s$, $E^u$, and $E^c$ are given by $P_0^s$, $P_0^u$, and $P_0^c$.\\

Since we have an actual formula for $\Phi^c_\pm$, we can substitute it in to get

\begin{align*}
W^-(x) = \Phi^s_-(&x, -T; \lambda)a^- + \Phi^u_-(x, 0; \lambda)b^- + e^{\nu(\lambda)(x+T)} v_-(x) \langle a^0, w_-(-T) \rangle \\
&+ \int_0^x \Phi^u_-(x, y; \lambda)[ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_{-T}^x \Phi^s_-(x, y; \lambda) [ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_{-T}^x 
e^{\nu(\lambda)(x-y)} v_-(x) \langle G(\lambda)(y)W^-(y) + \lambda^2 \tilde{H}(y), w_-(y) \rangle dy \\
W^+(x) = \Phi^u_+(&x, T; \lambda)a^+ + \Phi^s_+(x, 0; \lambda)b^+ + e^{\nu(\lambda)x} v_+(x) \langle b^0, w_+(0) \rangle \\
&+ \int_0^x \Phi^s_+(x, y; \lambda) [ G(\lambda)W^+(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_T^x \Phi^u_+(x, y; \lambda) [ G(\lambda)W^+(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_0^x e^{\nu(\lambda)(x-y)} v_+(x) \langle G(\lambda)(y)W^+(y) + \lambda^2 \tilde{H}(y), w_+(y) \rangle dy
\end{align*}

Now we do the same thing we do every night... try to take over the world. Following what was done in Sandstede (1998), we will try to invert this and see what happens. Before we take like 100 pages and do this rigorously (since it might not work), here is a rough list of what needs to happen, together with what the estimates should be. ALSO CAPITAL W AND SMALL w ARE NOT RELATED WHICH GOES AGAINST MY NOTATION CONVENTION BUT WE WILL DEAL WITH THIS LATER IF THIS WORKS.

\begin{enumerate}

\item Linear operator $L_1$ is stuff from the fixed point equations involving $W$.

\begin{align*}
(L_1(\lambda)W)^-(x) &= \int_0^x \Phi^u(x, y; \lambda) G(\lambda)(y)W^-(y) dy \\
&+ \int_{-T}^x \Phi^s(x, y; \lambda) G(\lambda)(y)W^-(y) dy \\
&+ \int_{-T}^x 
e^{\nu(\lambda)(x-y)} v_-(x) \langle G(\lambda)(y)W^-(y), w_-(y) \rangle dy 
\end{align*}

and

\begin{align*}
(L_1(\lambda)W)^+(x) &= \int_0^x \Phi^s_+(x, y; \lambda) G(\lambda)W^+(y) dy \\
&+ \int_T^x \Phi^u_+(x, y; \lambda) G(\lambda)W^+(y) dy \\
&+ \int_0^x e^{\nu(\lambda)(x-y)} v_+(x) \langle G(\lambda)(y)W^+(y), w_+(y) \rangle dy
\end{align*}

The first two terms on the RHS of this are like those from Sanstede (1998). For the third term we have for the negative piece,

\begin{align*}
\Big| \int_{-T}^x &e^{\nu(\lambda)(x-y)} v_-(x) \langle G(\lambda)(y)W^-(y), w_-(y) \rangle dy \Big| \\
&\leq \int_{-T}^x e^{\nu(\lambda)(x-y)} |v_-(x)| |G(\lambda)|||W|||w_-(y)|dy \\
&\leq |G||v||w|||W|| \int_{-T}^x e^{\nu(\lambda)(x-y)} dy \\
&= |G||v||w|||W|| \frac{e^{\nu(\lambda)x} - 1}{\nu(\lambda)} \\
&\leq C(\lambda) e^{\nu(\lambda)T} |G| \: ||W||
\end{align*}

where we used the fact that $x \leq 0$ on the negative piece. Since $v$ and $w$ are bounded and only depend on $\lambda$ (we pulled out the exponential growth/decay in our expressions for $\tilde{v}$ and $\tilde{w}$), we incorporate those bounds into the constant $C$, which depends on $\lambda$. The positive piece has a similar bound. Thus we have

\[
||L_1(\lambda)W|| \leq C(\lambda) e^{\nu(\lambda)T} |G| \: ||W||
\]

Since $|G|$ is of order $e^{-\alpha T}$ and $\nu(\lambda)$ is small, we can choose $T$ sufficiently large that the operator norm of this is less than 1.

\item Linear operator $L_2$ is stuff from fixed point equations not involving $W$.


\begin{align*}
(L_2(\lambda)(a,b))^-(x) &= \Phi^s_-(x, -T; \lambda)a^- + \Phi^u_-(x, 0; \lambda)b^- + e^{\nu(\lambda)(x+T)} v_-(x) \langle a^0, w_-(-T) \rangle \\
&+ \int_0^x \Phi^u_-(x, y; \lambda) \lambda^2 \tilde{H}(y) dy \\
&+ \int_{-T}^x \Phi^s_-(x, y; \lambda) \lambda^2 \tilde{H}(y) dy \\
&+ \int_{-T}^x 
e^{\nu(\lambda)(x-y)} v_-(x) \langle \lambda^2 \tilde{H}(y), w_-(y) \rangle dy \\
\end{align*}

and

\begin{align*}
(L_2(\lambda)(a,b))^+(x) &= \Phi^u_+(x, T; \lambda)a^+ + \Phi^s_+(x, 0; \lambda)b^+ + e^{\nu(\lambda)x} v_+(x) \langle b^0, w_+(0) \rangle \\
&+ \int_0^x \Phi^s_+(x, y; \lambda) \lambda^2 \tilde{H}(y) dy \\
&+ \int_T^x \Phi^u_+(x, y; \lambda) \lambda^2 \tilde{H}(y) dy \\
&+ \int_0^x e^{\nu(\lambda)(x-y)} v_+(x) \langle \lambda^2 \tilde{H}(y), w_+(y) \rangle dy
\end{align*}

Again, most of this is the same as we had before. For the $b^0$ term, we have 

\[
|e^{\nu(\lambda)x} v_+(x) \langle b^0, w_+(0) \rangle| \leq C e^{\nu(\lambda)T}|b^0| 
\]

The $a_0$ term will also have a similar bound. 

\[
e^{\nu(\lambda)(x+T)} v_-(x) \langle a^0, w_-(-T) \rangle \leq C e^{\nu(\lambda)T}|a^0|
\]

The third integrals are similar to the integral in $L_1$, and the rest of the terms are similar to what we had before. Thus the bound for $L_2$ should be

\[
||L_2(\lambda)(a,b)|| \leq C(\lambda) e^{\nu(\lambda)T} (|a| + |b| + |\lambda|^2)
\]

where $a^0$ and $b^0$ are included here with $|a|$ and $|b|$.

\item We can invert the expression $(I - L_1(\lambda))W = L_2(\lambda)(a,b)$ to get $W = W_1(\lambda)(a,b)$, where we have the bound

\[
||W_1(\lambda)(a,b)|| \leq C(\lambda) e^{\nu(\lambda)T} (|a| + |b| + |\lambda|^2)
\]

\item In the non-periodic single-pulse case, $a$ does not exist, i.e. it is 0. In this case, however, since we do not go to $\pm \infty$, $a^\pm$ plays a role. I think what we do here is something similar to the double pulse case, except we solve for $a^\pm$ by enforcing the periodic BCs, i.e. $W^-(-T) = W^+(T)$. Note that since we will need ICs which span the entire space ($\R^5$ in this case), we will use $a^-$, $a^+$, and $a^0$. We have 

\begin{align*}
W^-(-T) &= P^s_-(-T; \lambda)a^- + \Phi^u_-(-T, 0; \lambda)b^- + v_-(-T) \langle a^0, w_-(-T) \rangle \\
&+ \int_0^{-T} \Phi^u_-(-T, y; \lambda)[ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy \\
&= a^- + (P^s_-(-T; \lambda) - P_0^s)a^- + \Phi^u_-(-T, 0; \lambda)b^- + v_-(-T) \langle a^0, w_-(-T) \rangle \\
&+ \int_0^{-T} \Phi^u_-(-T, y; \lambda)[ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy \\
\end{align*}

Similarly,

\begin{align*}
W^+(T) &= P^u_+(T; \lambda)a^+ + \Phi^s_+(T, 0; \lambda)b^+ + e^{\nu(\lambda)T} v_+(T) \langle b^0, w_+(0) \rangle \\
&+ \int_0^T \Phi^s_+(T, y; \lambda) [ G(\lambda)W^+(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_0^T e^{\nu(\lambda)(T-y)} v_+(T) \langle G(\lambda)(y)W^+(y) + \lambda^2 \tilde{H}(y), w_+(y) \rangle dy \\
&= a^+ + (P^u_+(T; \lambda) - P^u_0)a^+ + \Phi^s_+(T, 0; \lambda)b^+ + e^{\nu(\lambda)T} v_+(T) \langle b^0, w_+(0) \rangle \\
&+ \int_0^T \Phi^s_+(T, y; \lambda) [ G(\lambda)W^+(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_0^T e^{\nu(\lambda)(T-y)} v_+(T) \langle G(\lambda)(y)W^+(y) + \lambda^2 \tilde{H}(y), w_+(y) \rangle dy
\end{align*}

What was done in Sandstede (1998) will not work here, since we will not get a good enough estimate to do the inversion. So we will need to try something different. Note that since we have explicit formulas for the center projection, we should be able to solve for $a^0$ in terms of everything else.

\begin{align*}
v_-(-T) \langle a^0, w_-(-T) \rangle &= W^-(-T) - P^s_-(-T; \lambda)a^- - \Phi^u_-(-T, 0; \lambda)b^- \\
&-  \int_0^{-T} \Phi^u_-(-T, y; \lambda)[ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy \\
\langle a^0, w_-(-T) \rangle &= \langle W^-(-T), w^-(-T) \rangle - \langle  P^s_-(-T; \lambda)a^-, w^-(-T) \rangle  - \langle \Phi^u_-(-T, 0; \lambda)b^-, w^-(-T) \rangle  \\
&- \int_0^{-T} \langle \Phi^u_-(-T, y; \lambda)[ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ], w^-(-T) \rangle  dy 
\end{align*}

where in the second line we took the inner product with $w_-(-T)$ and used the fact that the inner product $\langle v_-(x), w_-(x) \rangle = 1$ for all $x \leq 0$. We now would like to solve for $a^0$. Since $a^0 \in E^c$ and $E^c$ is one-dimensional, we can write $a^0 = k^0 e_1$, where $e_1 = (1, 0, 0, 0, 0)$ is the eigenvector of the asymptotic matrix $\tilde{A}(0, 0)$ corresponding to the zero eigenvalue. Thus we need to solve 

\begin{align*}
k^0 \langle e_1, w_-(-T) \rangle &= \langle W^-(-T), w^-(-T) \rangle - \langle  P^s_-(-T; \lambda)a^-, w^-(-T) \rangle  - \langle \Phi^u_-(-T, 0; \lambda)b^-, w^-(-T) \rangle  \\
&- \langle \int_0^{-T} \Phi^u_-(-T, y; \lambda)[ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy, w^-(-T) \rangle \\
&= \langle W^-(-T), w^-(-T) \rangle - \langle \Phi^u_-(-T, 0; \lambda)b^-, w^-(-T) \rangle  \\
&- \langle \int_0^{-T} \Phi^u_-(-T, y; \lambda)[ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy, w^-(-T) \rangle  
\end{align*}

where $\langle P^s_-(-T; \lambda)a^-, w^-(-T) \rangle = 0 $ since we changed coordinates above so that the range of $P^s_-(-T)$ is perpendicular to $w^{-T}$. (ACTUALLY WE DID THIS FOR THE PLUS VERSIONS, BUT LET'S SAY WE DID THIS FOR THE MINUS VERSIONS ALSO. IN ANY CASE EVEN IF WE DON'T D THIS I THINK THE ESTIMATE WILL BE GOOD ENOUGH.)\\

The only way this can go awry is if $\langle e_1, w_-(-T) \rangle = 0$. For now, we will argue that for sufficiently large $T$, $v_-(-T)$ is close to $v_0$ (center eigenvector of $\tilde{A}(\lambda, 0)$) which is close to $e_1$ (center eigenvector of $\tilde{A}(0, 0)$) since $\lambda$ is small. Since $\langle v_(-T), w_-(-T) \rangle = 1$ and things are continuous, we won't have $\langle e_1, w_-(-T) \rangle = 0$. Thus we can divide by $\langle e_1, w_-(-T) \rangle$ to solve for $k^0$.
\\

Note that although there is no explicit dependence on $a^\pm$ in this equation, $a^0$ does depend on $a^\pm$ via $W$. We then have an equation for $a^0$ of the form

\begin{align*}
a^0 = L^0_3(\lambda)(a, b) e_1
\end{align*}

Note that $L^0_3(\lambda)(a, b)$ is a scalar. We have the bound

\begin{align*}
|L^0_3(\lambda)(a, b)| &\leq C( |W^-(-T)| + e^{-\alpha T}|b^\pm| + |G|||W|| + |\lambda^2| )
\end{align*}

Substituting in the expression for $W_1$ into this, we get

\begin{align*}
|L^0_3(\lambda)(a, b)| &\leq C( e^{\nu(\lambda)T}|G|(|a| + |b|) + |\lambda^2| )
\end{align*}

where we ditched the $|W^-(-T)|$ term since it should be order $e^{-(\alpha - \nu(\lambda))T}$, and the other stuff is of that order. \\

Now that we have done this, we should be able to solve for $a^\pm$ by following the usual procedure in Sandstede (1998). To that end, we write

\[
0 = a^+ - a^- + L_3(\lambda)(a^\pm,b)
\] 

Where $L_3(a,b,c)$ is the rest of the stuff you get when you do the subtraction, after substituting $k^0 e_1$ for $a^0$. Note that because of the substitution, $L_3$ no longer depends on $a^0$. Since $a^+$, $a^-$ are linearly independent (based on the eigenspaces they live in) we can do the same thing which was done in Sanstede (1998), i.e. if we solve for $a^+ - a^-$, we are good since by linear independence that uniquely determines $a^\pm$.\\ 

Now we get a bound on $L_3$. As before, let

\[
p(T;\lambda) = \sup_{x \geq T} (|P^u(x;\lambda) - P_0^u| + |P^s(-x;\lambda) - P_0^s|)
\]

which should be order $e^{-\alpha T}$. This gives the following bound on $L_3$.

\begin{align*}
||L_3(\lambda)(a^\pm,b)|| &\leq C(\lambda)(\rho(T; \lambda)|a^\pm| + |W^-(-T)| + e^{-\alpha T}|b^\pm| + e^{\nu(\lambda)T}( |b^0| + |G|||W|| + |\lambda|^2)) )\\
&\leq C(\lambda)(\rho(T; \lambda)|a^\pm| + e^{-\alpha T}|b^\pm| + e^{\nu(\lambda)T}( |b^0| + |G|||W|| + |\lambda|^2)) )
\end{align*}

where we ditched the $|W^-(-T)|$ from the estimate like we did above since it should be order $e^{-(\alpha - \nu(\lambda))T}$ and there's already stuff of that order in the estimate. Substituting in the estimate for $W_1$, we get something like

\[
||L_3(\lambda)(a^\pm, b)|| \leq C(\lambda)((\rho(T; \lambda) + e^{2 \nu(\lambda)T}|G|)|a^\pm| + (e^{-\alpha T}+ e^{2\nu(\lambda)T}|G|)|b| + e^{\nu(\lambda)T}( |b^0| + |\lambda|^2)) )
\]

Now we have

\begin{align*}
0 &= a^+ - a^- + L_3(\lambda)(a^\pm,b) \\
a^+ - a^- + L_3(\lambda)(a^\pm,0) &= - L_3(\lambda)(0,b) \\
\end{align*} 

Applying the projection $P^u_0 + P^s_0$ to both sides above, we get

\begin{align*}
0 &= a^+ - a^- + L_3(\lambda)(a^\pm,b) \\
a^+ - a^- + (P^u_0 + P^s_0) L_3(\lambda)(a^\pm,0) &= -(P^u_0 + P^s_0) L_3(\lambda)(0,b) \\
\end{align*} 

From above, we also have

\begin{align*}
a^0 &= ( L^0_3(\lambda)(a, 0) + L^0_3(\lambda)(0, b) ) e_1 \\
a^0 - L^0_3(\lambda)(a, 0) e_1 &= L^0_3(\lambda)(0, b) ) e_1
\end{align*}

Combining these, we have the following

\begin{align*}
\begin{pmatrix}a^+ - a^- \\ a^0 \end{pmatrix}
+ \begin{pmatrix}(P^u_0 + P^s_0) L_3(\lambda)(a^\pm,0) \\ - L^0_3(\lambda)(a, 0) e_1
\end{pmatrix}
=
\begin{pmatrix}-(P^u_0 + P^s_0) L_3(\lambda)(0,b) \\ L^0_3(\lambda)(0, b) ) e_1
\end{pmatrix}
\end{align*}


Let $J_1 a = (a^+ - a^-, a^0)$, which is an isomorphism on $\C^n$. Let 

\[
\tilde{L_3}(\lambda)(a,b) = \begin{pmatrix}
(P^u_0 + P^s_0) L_3(\lambda)(a^\pm,b) \\
-L^0_3(\lambda)(a, b) ) e_1
\end{pmatrix}
\]

Then this becomes

\begin{align*}
J_1 a + \tilde{L_3}(\lambda)(a,0) &= -\tilde{L_3}(\lambda)(0,b) \\
J_1 (I a + J_1^{-1} \tilde{L_3}(\lambda)(a,0) ) &= -\tilde{L_3}(\lambda)(0,b)
\end{align*}

Define the operator $S_1$ by

\begin{align*}
S_1 a = J_1 (Ia + J_1^{-1} \tilde{L_3}(\lambda)(a,0) )
\end{align*} 

Then this equation is

\begin{align*}
S_1 a &= -\tilde{L_3}(\lambda)(0,b)
\end{align*}

We have the following estimate for $\tilde{L_3}(\lambda)(a,0)$.

\[
||\tilde{L_3}(\lambda)(a,0)|| \leq C(\lambda)((\rho(T; \lambda) + e^{2 \nu(\lambda)T}|G|)|a^\pm| +e^{\nu(\lambda)T} |\lambda|^2) 
\]

For sufficiently small $\lambda$ and sufficiently large $T$, we can make this norm less than 1, thus the operator $S_1$ is invertible, and so we have

\begin{align*}
a &= A_1(\lambda)(b) = -S_1^{-1} \tilde{L_3}(\lambda)(0,b)
\end{align*}

Since we have an estimate for $\tilde{L_3}(\lambda)$, this has bound

\[
|A_1(\lambda)(b)| \leq C ( (e^{-\alpha T}+ e^{2\nu(\lambda)T}|G|)|b| + e^{\nu(\lambda)T}( |b^0| + |\lambda|^2))
\]

Since $e^{2\nu(\lambda)T}|G|$ is higher order than $e^{-\alpha T}$, this becomes

\[
|A_1(\lambda)(b)| \leq C ( e^{2\nu(\lambda)T}|G| |b| + e^{\nu(\lambda)T} |b^0| + e^{\nu(\lambda)T} |\lambda|^2)
\]

Now we substitute this into our expression $W_1$ to get 

\[
W_2(\lambda)(a,b) = W_1(\lambda)(A^1(\lambda)(b),b)
\]

where we have estimate

\begin{align*}
||W_2(\lambda)(b)|| \leq C e^{\nu(\lambda)T} (|b| + e^{\nu(\lambda)T} |b^0| + e^{\nu(\lambda)T} |\lambda^2| )
\end{align*}

\item Now we look at the conditions

\begin{enumerate}[(i)]
\item $W^\pm(0) \in \C \psi(0) \oplus Y^+ \oplus Y^- \oplus Y^0$
\item $W^+(0) - W^-(0) \in \C \psi(0) $ 
\end{enumerate}

Taking $x = 0$ in the fixed point equations gets us

\begin{align*}
W^-(0) = \Phi^s_-(&0, -T; \lambda)a^- + P^u_-(0; \lambda)b^- + e^{\nu(\lambda)(T)} v_-(0) \langle a^0, w_-(-T) \rangle \\
&+ \int_{-T}^0 \Phi^s_-(0, y; \lambda) [ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_{-T}^0 
e^{-\nu(\lambda)y} v_-(0) \langle G(\lambda)(y)W^-(y) + \lambda^2 \tilde{H}(y), w_-(y) \rangle dy \\
W^+(0) = \Phi^u_+(&0, T; \lambda)a^+ + P^s_+(0; \lambda)b^+ + v_+(0) \langle b^0, w_+(0) \rangle \\
&+ \int_T^0 \Phi^u_+(0, y; \lambda) [ G(\lambda)W^+(y) + \lambda^2 \tilde{H}(y) ] dy \\
\end{align*}

Recall that the initial conditions $b$ were chosen from the appropriate spaces when $\lambda = 0$, thus the various projections above do not just disappear. However, we hope they will be near identities. Let

\[
\tilde{\rho}(\lambda) = |P^u_-(0;\lambda) - P^u_-(0; 0)| + |P^s_+(0;\lambda) - P^s_+(0;0)| + |P^c_+(0;\lambda) - P^c_+(0;0)|
\]

We will deal with this later, though it should hopefully scale like $e^{-C/\lambda}$. To use this, we write the above as

\begin{align*}
W^-(0) = \Phi^s_-(&0, -T; \lambda)a^- + b^- + (P^u_-(0;\lambda) - P^u_-(0; 0))b^- + e^{\nu(\lambda)(T)} v_-(0) \langle a^0, w_-(-T) \rangle \\
&+ \int_{-T}^0 \Phi^s_-(0, y; \lambda) [ G(\lambda)W^-(y) + \lambda^2 \tilde{H}(y) ] dy \\
&+ \int_{-T}^0 
e^{-\nu(\lambda)y} v_-(0) \langle G(\lambda)(y)W^-(y) + \lambda^2 \tilde{H}(y), w_-(y) \rangle dy \\
W^+(0) = \Phi^u_+(&0, T; \lambda)a^+ + b^+ + (P^s_+(0;\lambda) - P^s_+(0;0))b^+ + b^0 + (P^c_+(0;\lambda) - P^c_+(0;0))b^0 \\
&+ \int_T^0 \Phi^u_+(0, y; \lambda) [ G(\lambda)W^+(y) + \lambda^2 \tilde{H}(y) ] dy \\
\end{align*}

We can use $W_2$ and $A_1$ from above in this. Since the stable and unstable range spaces at $\lambda = 0$ both contain $\C Q'(0)$, we can decompose $b^\pm$ uniquely as $b^\pm = x^\pm + y^\pm$, where $x^\pm \in \C Q'(0)$ and $y^\pm \in Y^\pm$. We don't have to do this with $b^0$. Then since

\begin{equation}\label{directsum}
\C^n = \C\Psi(0) \oplus \C Q'(0) \oplus Y^+ \oplus Y^- \oplus Y^0
\end{equation}

(each of these is 1D in this case), the conditions above are equivalent to the following projections

\begin{align*}
P(\C Q'(0))W^-(0) &= 0 \\
P(\C Q'(0))W^+(0) &= 0 \\
P(Y^+ \oplus Y^- \oplus Y^0) (W^+(0) - W^-(0) ) &= 0
\end{align*}

where the range of each projection is indicated, and the kernel of each projection is just the other elements of the direct sum \eqref{directsum}. Since the first two equations wipe out any component in $\C Q'(0))$, we don't need to put that in the range of the third projection.\\

If we plug in the fixed point equations into the above set of projections, we get the matrix equation

\[ 
\begin{pmatrix}x_i^- \\ x_i^+ \\ y_i^+ + b^0 - y_i^- \end{pmatrix} + L_4(\lambda)(b) = 0
\]

where $L_4(\lambda)(b)$ is the rest of the terms. Since the third component contain the other ones and we are taking the max over all components, all we need to do is bound the third component of $L_4$. Doing stuff similar to above, we get the bound

\[
|L_4(\lambda)(b)| \leq C( e^{-\alpha T}|a| + \tilde{\rho}(\lambda)|b| + e^{\nu(\lambda)T}(|a^0| + |G|||W|| + |\lambda^2|)
\]

Now substitute in $A_1$ and $W_2$ from above to get

\[
|L_4(\lambda)(b)| \leq C( (e^{3\nu(\lambda)T} + \tilde{\rho}(\lambda))|b| + e^{2\nu(\lambda)T}|b^0| + e^{\nu(\lambda)T} |\lambda^2| )
\]

Everything here is fine except the $b^0$ term, which we cannot make arbitrarily small. Thus we will have to do something like we did above with $a^0$, i.e. solve for it explicitly. We solve the $W^+(0)$ equation for $b^0$ to get

\begin{align*}
b^0 &= W^+(0) - \Phi^u_+(0, T; \lambda)a^+ - b^+ - (P^s_+(0;\lambda) - P^s_+(0;0))b^+ - (P^c_+(0;\lambda) - P^c_+(0;0))b^0 \\
&- \int_T^0 \Phi^u_+(0, y; \lambda) [ G(\lambda)W^+(y) + \lambda^2 \tilde{H}(y) ] dy  
\end{align*}


\end{enumerate}



\end{document}