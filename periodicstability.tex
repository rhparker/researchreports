\documentclass[12pt]{article}
\usepackage[pdfborder={0 0 0.5 [3 2]}]{hyperref}%
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}%
\usepackage[shortalphabetic]{amsrefs}%
\usepackage{amsmath}
\usepackage{enumerate}
% \usepackage{enumitem}
\usepackage{amssymb}                
\usepackage{amsmath}                
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage{float}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{mathtools}
\usepackage{cool}
\usepackage{url}
\usepackage{graphicx,epsfig}
\usepackage{makecell}
\usepackage{array}

\def\noi{\noindent}
\def\T{{\mathbb T}}
\def\R{{\mathbb R}}
\def\N{{\mathbb N}}
\def\C{{\mathbb C}}
\def\Z{{\mathbb Z}}
\def\P{{\mathbb P}}
\def\E{{\mathbb E}}
\def\Q{\mathbb{Q}}
\def\ind{{\mathbb I}}

\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\ran}{ran}

\graphicspath{ {periodic/} }

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{hypothesis}{Hypothesis}

\newtheorem{notation}{Notation}

\usepackage{xr}

\externaldocument{periodicexistence}

\begin{document}

\section{KdV5 with Periodic Boundary Conditions, Stability}

\subsection{Setup of Eigenvalue Problem for KdV5}

In the previous section, we proved the existence of periodic multipulse solutions to KdV5 using Lin's method. In this section, we will examine the spectral stability of the linearization about such solutions.\\

For $n \geq 2$, let $q_{np}(x)$ be an $n-$periodic solution to KdV5 associated with lengths $X_0, \dots, X_{n-1}$. Then by the construction via Lin's method, $q_{np}$ can be written piecewise, using the $2n$ pieces

\begin{align*}
q_i^-(x) &= q^-(0, \beta_i^-)(x) + u_i^-(x) && x \in [-X_{i-1}, 0]\\
q_i^+(x) &= q^+(0, \beta_i^+)(x) + u_i^+(x) && x \in [0, X_i]
\end{align*}

where the subscripts are all $\mod n$, e.g. $X_0 = X_n$. The functions $q^\pm(0, \beta_i^\pm)(x)$ evolve along the stable/unstable manifolds of the equilibrium at 0, and we have bounds on the remainder terms $u_i^\pm$ from the existence problem.\\

To assess the linear stability of such periodic multipulse solutions, we will look at the spectrum of the linearization of KdV5 about $q_{np}(x)$. For the linearization about an arbitrary equilibrium solution $u^*(x)$, the eigenvalue problem is $L(u^*) v(x) = \lambda v(x)$, where

\begin{equation}
L(u^*) = \partial_x^5 - \partial_x^3 + c \partial_x - 2 u^* \partial x - 2 u^*_x = 0
\end{equation}

Note that we can write this as $L = \partial_x H(u^*)$, where $H(u^*)$ is the self-adjoint operator

\begin{equation}
H(u^*) = \partial_x^4 - \partial_x^2 + c - 2 u^*
\end{equation}

First, we write the eigenvalue problem as the first order system

\begin{equation}
V' = A(u^*)V + \lambda B V
\end{equation}

where

\begin{align}
A(u^*) = \begin{pmatrix}0 & 1 & 0 & 0 & 0 \\0 & 0 & 1 & 0 & 0 \\0 & 0 & 0 & 1 & 0 \\0 & 0 & 0 & 0 & 1 \\
2u^*_x(x) & 2u^*(x) - c & 0 & 1 & 0 \end{pmatrix}, &&
B = \begin{pmatrix}0 & 0 & 0 & 0 & 0 \\0 & 0 & 0 & 0 & 0 \\0  & 0 & 0 & 0 & 0 \\0 & 0 & 0 & 0 & 0 \\1 & 0 & 0 & 0 & 0 \end{pmatrix} && 
\end{align}

Before we continue, we note that if we consider $A(0)$, the linearization about 0, for $c > 1/4$ we have eigenvalues $\nu = \{ 0, \pm \alpha \pm \beta i\}$, where $\alpha, \beta > 0$. The equilibrium at 0 is not hyperbolic, so we cannot directly apply the results of San98. The equilibrium at 0 has 2-dimensional stable/unstable manifolds, and a 1-dimensional center manifold. Let $W^{s/u/c}(0)$ be these manifolds.\\

As in the existence problem, we make the following nondegeneracy assumption.

\begin{hypothesis}\label{nondegen}
\[
T_{Q(0)} W^u(0) \cap T_{Q(0)} W_s(0) = \R Q'(0)
\]
\end{hypothesis}

where $Q(x)$ is the single pulse solution on $\R$, written as a vector-valued function in $R^5$ un the usual way. Define the variational equation and adjoint variational equation as follows.

\begin{align}
V' = A(q)V \label{vareq} \\
W' = -A(q)^*W \label{adjvareq}
\end{align}

If $A(0)$ were hyperbolic (as in San98), Hypothesis \ref{nondegen} would be equivalent to the the fact that $Q'(x)$ is the unique bounded solution to the variational equation \eqref{vareq}. This is not the case here, since we are on a periodic domain. This is easiest to see by looking at the adjoint equation $L(q)^* v = 0$. Since $L(q)^* = (\partial_x H(q))^* = -H(q) \partial_x$, we can easily see that there are two bounded solutions to this: $q(x)$ and the constant function $1$. The constant function is periodic, so we have to consider it here.\\

Thus there are two bounded solutions $\Psi_2(x)$ and $\Psi_2(x)$ of \eqref{adjvareq} corresponding to $q(x)$ and 1. We know that $q'(x)$ is a bounded solutions to the variational equation \eqref{vareq}. We will find another below.\\

Next, as in San98, we decompose the tangent space at $Q(0)$ as

\begin{equation}
\R^5 = Z \oplus \R Q'(0) \oplus Y^+ \oplus Y^- \oplus Y^0
\end{equation}

where $Y^+$ and $Y^-$ are chosen so that

\begin{align*}
T_{Q(0)} W^s(0) &= \R Q'(0) \oplus Y^+ \\
T_{Q(0)} W^u(0) &= \R Q'(0) \oplus Y^- \\
\end{align*}

We will deal with $Y^0$ later.\\

Returning to the problem at hand, we next use the piecewise construction of the periodic $n-$pulse to write this in the equivalent piecewise form

\begin{align*}
(V_i^\pm)' &= A( q^\pm(0, \beta_i^\pm) + u_i^\pm) V_i^\pm + \lambda B V_i^\pm \\
V_i^-(0) &= V_i^+(0) \\
V_i^+(X_i) &= V_{i+1}^-(-X_i) 
\end{align*}

for $i = 0, \dots, n-1$. \\

At this point, we make the following hypothesis.

\begin{hypothesis}\label{higherMelnikov}
\begin{equation}\label{higherMelnikovnonzero}
\langle q, q_c \rangle_{L^2(\R)} = \int_{-\infty}^\infty q(x) q_c(x) dx \neq 0
\end{equation}
\end{hypothesis}

This is the higher order Melnikov integral, and numerics suggests that it is in fact nonzero.\\

Before we simplify this further, we note that for the single pulse $q$, $L(q)$ has a 2-dimensional generalized kernel with the following generalized eigenfunctions.

\begin{align}\label{genkernel}
L(q)q_x &= 0 \nonumber \\
L(q)(-q_c) &= q_x
\end{align}

The fact that this generalized kernel is 2-dimensional follows from Hypothesis \ref{higherMelnikov}. If there were another generalized eigenfunction $u$ in the Jordan chain, we would have by the Fredholm alternative

\begin{align*}
L(q) u = -q_c &\iff q_c \in (\ker L(q)^*)^\perp \\
&\iff \langle q, q_c \rangle = 0 
\end{align*} 

This last quantity is nonzero by Hypothesis \ref{higherMelnikov}. It follows that

\begin{align*}
(Q_x)' &= A(q) Q_x \\
(Q_c)' &= A(q) Q_c + B Q_x
\end{align*}

To exploit these, we write $V_i^\pm$ as 

\begin{equation}
V_i^\pm(x) = d_i (Q_{np}'(x) + \lambda (Q_{np})_c(x)) + W_i^\pm 
\end{equation}

where $d_i \in \C$ are arbitrary constants. Substituting this into the piecewise system, using \eqref{genkernel}, and simplifying, we get the system

\begin{align*}
&(W_i^\pm)' = A( q^\pm(0, \beta_i^\pm) ) + u_i^\pm) W_i^\pm + \lambda B W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm \\
&W_i^-(0) = W_i^+(0) \\
&W_i^\pm(0) \in \C \Psi(0) \oplus Y^+ \oplus Y^- \\
&W_i^+(X_i) - W_{i+1}^-(-X_i) = D_i d
\end{align*}

where

\begin{align*}
D_i d &= d_{i+1}(Q_{np}'(-X_i) + \lambda (Q_{np})_c(-X_i))
- d_i ( Q_{np}'(X_i) + \lambda (Q_{np})_c(X_i) ) \\
\tilde{H}_i^\pm &= -B( Q^\pm(0, \beta_i^\pm)_c + (U_i^\pm)_c)  \\
H &= -B Q_c \\
\Delta H_i^\pm &= \tilde{H}_i^\pm - H
\end{align*}

Before we continue, we make a brief note about the condition $W_i^\pm(0) \in \C \Psi(0) \oplus Y^+ \oplus Y^-$. Recall that we are writing our eigenfunction piecewise as $V_i^\pm(x) = d_i(Q_{2p}'(x) + \lambda (Q_{2p})_c(x)) + W_i^\pm $. $Q_{2p}(0)$ and its derivatives have no component in $Y^0$ since they both decay exponentially at both ends. Since we seek eigenfunctions which decay exponentially at both ends, this implies that $W_i^\pm(0)$ cannot have a component in $Y^0$.\\

Finally, we note that the operator $A(u^*)$ is linear in $u^*$ (this is apparent from the definition). Thus the first equation can be written as 

\begin{align*}
(W_i^\pm)' = A(q^\pm(0, \beta_i^\pm)) W_i^\pm + \lambda B W_i^\pm + A(u_i^\pm) W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm
\end{align*}

The advantage of this formulation is that we have bounds on $A(u_i^\pm)$ from the existence problem, and we also know about the decay of $q^\pm$ from the existence problem.\\

Although we could likely use this version of the problem, the drawback is that it contains a term in both $\lambda$ and $\lambda^2$. To eliminate the term in $\lambda$, we use the following idea. As noted above, the matrix $A(0)$ has an eigenvalue at 0, which gives it a center subspace. What we will do is combine the matrices $A(q^\pm(0, \beta_i^\pm))$ and $\lambda B$ to get a new parameter-dependent matrix $A(q^\pm(0, \beta_i^\pm); \lambda)$, i.e. 

\begin{align*}
A(q^\pm(0, \beta_i^\pm); \lambda) &= A(q^\pm(0, \beta_i^\pm)(x)) + \lambda B \\
&= \begin{pmatrix}0 & 1 & 0 & 0 & 0 \\0 & 0 & 1 & 0 & 0 \\0 & 0 & 0 & 1 & 0 \\0 & 0 & 0 & 0 & 1 \\
2 (q^\pm(0, \beta_i^\pm))'(x) + \lambda & 2 q^\pm(0, \beta_i^\pm)(x) - c & 0 & 1 & 0 \end{pmatrix}
\end{align*}

For the $\lambda$-dependent matrix $A(q^\pm(0, \beta_i^\pm); \lambda)$, the eigenvalue at 0 will perturb slightly to a small eigenvalue in a $\lambda$-dependent fashion. The following heuristic argument provides a partial justification for this. Due to the decay properties of $q^\pm$, the matrix $A(q^\pm(0, \beta_i^\pm); \lambda)$ is exponentially asymptotic to $A(0; \lambda)$. We know that $A(0; 0)$ has an eigenvalue at 0. The characteristic polynomial for $A(0; \lambda)$ is $f(\nu; \lambda) = \lambda - c \nu + \nu^3 - \nu^5 = \lambda - c \nu + \mathcal{O}(\nu^3)$. Thus,f for small $\lambda$, this polynomial has a zero at approximately $\nu = \lambda / c$. Numerics shows this is approximation is very close.\\

Thus, the final form of our problem is

\begin{align}
&(W_i^\pm)' = A(q^\pm(0, \beta_i^\pm); \lambda) W_i^\pm + A(u_i^\pm) W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm \\
&W_i^-(0) = W_i^+(0) \\
&W_i^\pm(0) \in \C \Psi(0) \oplus Y^+ \oplus Y^- \\
&W_i^+(X_i) - W_{i+1}^-(-X_i) = D_i d
\end{align}

In the following lemma, we give bounds for terms relevant to this problem.

% lemma : problem bounds

\begin{lemma}\label{problembounds}
We have the following estimates
\begin{align*}
|A(u_i^-(x); \lambda)| &\leq C e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + x) } \\
|A(u_i^+(x); \lambda)| &\leq C e^{-\alpha X_i} e^{-\alpha(X_i - x) } \\
|H(x)|, |\tilde{H}_i^\pm(x)| &\leq C e^{-\alpha |x|} \\
|\Delta H_i^\pm| &\leq C(e^{-\alpha X_i} + e^{-\alpha X_{i-1}} ) \\
D_i d &= ( Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) + \mathcal{O} \left( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right) \\
\end{align*}

\begin{proof}
The first two bounds come from the bounds on the remainder term from the existence problem (the notation $V$ is used for the remainder term there, as opposed to $U$ here), together with the fact that the matrix $A$ is a bounded linear operator. Note that the bound is strongest at $x = 0$ and is weakest at $\pm X_i$. \\

For the third, we first recall that $H = -B Q_c$, and we have shown (somewhere else) using a contraction mapping argument that $q_c$ exists, is exponentially localized, and decays exponentially with rate $\alpha$. An identical proof shows that the same holds for $(q_{2p})_c$, thus for $\tilde{H}$.\\
 
Next, we look at we look at $\Delta H = \tilde{H}_i^\pm - H$. Noting the definition of $B$, we only have to look at 

\[
(q^\pm(0, \beta_i^\pm)(x) - q(x)) + u_i^\pm(x)
\]

and its derivative with respect to $c$. From the existence proof, we recall that $|u_i^+| \leq C e^{-\alpha X_i}$, $|u_i^-| \leq C e^{-\alpha X_{i-1}}$, and $|(\beta_i^+, \beta_i^-)| \leq C( e^{-\alpha X_i} + e^{-\alpha X_{i-1}})$. Since the same bounds hold for derivatives with respect to $c$, we attain the bound given for $|\Delta H_i^\pm|$.\\

For the fourth, we have

\begin{align*}
D_i d &= d_{i+1}(Q_{np}'(-X_i) + \lambda (Q_{np})_c(-X_i)) - d_i ( Q_{np}'(X_i) + \lambda (Q_{np})_c(X_i) ) \\
&= d_{i+1} (Q^-(0; \beta_i^-)'(-X_i) + U_i^-(-X_i)) - d_i (Q^+(0; \beta_i^+)'(X_i) + U_i^+(X_i)) + \mathcal{O}(e^{-\alpha X_i} |\lambda||d|)
\end{align*}

The result follows from Lemma 2.6 in San98, which follows from San93.

\end{proof}
\end{lemma}

Before we continue, we pause briefly to discuss the essential spectrum

\subsection{Essential Spectrum}

Let $X = X_0 + \dots + X_{n-1}$. Then the equilibrium solutions we are considering are periodic on $[-X, X]$. Let $u^*$ be a periodic, equilibrium solution on the interval $[-X, X]$ such that $u^*$ is ``sufficiently localized'', i.e.

\begin{align*}
|u^*(\pm X)| \leq C e^{-\alpha X_{n-1}}
\end{align*}

As long as this is true, the essential spectrum of $L(u^*)$ should be approximately equal to the essential spectrum of the asymptotic operator

\begin{equation}
L_\infty = \partial_x^5 - \partial_x^3 + c \partial_x
\end{equation}

which is independent of $u^*$. The Weyl essential spectrum theorem says that the essential spectra of $L(u^*)$ and $L_\infty$ are equal for the problem on $\R$, but we should be able to get close with our localization assumption.\\

Thus we will look at the essential spectrum of $L_\infty$ on $[-X, X]$. Plugging in the standard ansatz $v = e^{\nu x}$ to $(L_\infty - \lambda I)v = 0$, we get

\begin{align*}
e^{\nu x}(\nu^5 - \nu^3 + c \nu - \lambda) = 0
\end{align*}

$\nu$ is in the essential spectrum of $L_\infty$ whenever we have a solution $\nu = i r$ with $r \in \R$, i.e. a spatial eigenvalue on the imaginary axis. This occurs when

\begin{align*}
\lambda &= i(r^5 + r^3 + c r) && r \in \R
\end{align*}

For the problem on the real line, this tells us what we already know, i.e. that the essential spectrum is the entire imaginary axis. For the periodic problem, we impose the additional requirement that the eigenfunctions $e^{\nu x}$ must be periodic on $[-X, X]$. This implies 

\begin{align*}
r = \pm \frac{n \pi}{X} && n \in \N_0
\end{align*}

In terms of $\lambda$, the essential spectrum of $L_\infty$ is given by

\begin{equation}
\sigma_{\text{ess}} = \left\{ \pm i \left[ \left(\frac{n \pi}{X}\right)^5 
+ \left(\frac{n \pi}{X}\right)^3 + c \left(\frac{n \pi}{X}\right) \right] : n \in \N_0 \right\}
\end{equation}

This is also approximately the essential spectrum of $L(u^*)$. In particular, the essential spectrum is a countable set of isolated points. For $n = 0$, $\lambda = 0$ is in the essential spectrum, which should correspond to $\tilde{q}$ (defined above). For the rest of the essential spectrum, the elements of smallest magnitude are of order $\pm c \pi / X$.


\subsection{General Form}

Consider the general system on $\R^m$, where $m = 2k + 1, k \in \N$

\begin{enumerate}
\item $(W_i^\pm)' = A(q^\pm(0, \beta_i^\pm); \lambda) W_i^\pm + G_i^\pm W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm$
\item $W_i^-(0) = W_i^+(0)$
\item $W_i^\pm(0) \in \C \Psi(0) \oplus Y^+ \oplus Y^- $
\item $W_i^+(X_i) - W_{i+1}^-(-X_i) = D_i d$
\end{enumerate}

for functions $G = (G_i^\pm)$, $\tilde{H} = (\tilde{H})_i^\pm$, matrices $D = (D_i)$, and $\lambda \in \C$ satisfying 

\begin{align}
|G_i^-(x)| &\leq C e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + x) } \\
|G_i^+(x)| &\leq C e^{-\alpha X_i} e^{-\alpha(X_i - x) } \\
||G|| &\leq \delta \\
|H(x)|, |H_i^\pm(x)| &\leq C e^{-\alpha |x|} \\
|\Delta H_i^\pm(x)| &= |\tilde{H}_i^\pm(x) - H(x)| \leq C( e^{-\alpha X_i} + e^{-\alpha X_{i-1}}) \\
|\lambda| &\leq \delta \\
|D_j| &\leq \delta
\end{align}

where $\delta > 0$ is small and $H$ is a smooth, bounded function. We make the following assumptions about the operator $A$.

\begin{hypothesis}\label{Aspectrumhyp}
\begin{enumerate}
	\item The spectrum of $A(0; 0)$ has isolated, simple eigenvalues at $\{ 0, \pm \alpha_0 \pm \beta_0 \}$, where $\alpha_0, \beta_0 > 0$. The real part of any other eigenvalue of $A(0; 0)$ lies outside the interval $[-\alpha_0, \alpha_0]$.
	\item Let $\{\nu_i\}$ be the eigenvalues of $A(0; 0)$. Then the eigenvalues of $A(0; \lambda)$ are given by $\nu(\lambda)_i = \nu_i + \mathcal{O}(|\lambda|)$. In particular, $A(0; \lambda)$ has a simple eigenvalue $\nu(\lambda) = \mathcal{O}(|\lambda|)$.
\end{enumerate}
\end{hypothesis}

Before we continue, we define the following constants

\begin{enumerate}

	\item Let

	\begin{align*}
	X_m &= \min(X_0, \dots, X_{n-1}) \\
	X_M &= \max(X_0, \dots, X_{n-1}) \\
	\end{align*}

	\item Let $n_-$ be the number of eigenvalues of $A(0; 0)$ with negative real part, and $n_+$ be the number of eigenvalues of $A(0; 0)$ with positive real part. Then, by Hypothesis \ref{Aspectrumhyp}, $n_-, n_+ \geq 2$, and $n_- + n_+ + 1 = m$.

	\item Let $\nu(\lambda)$ be the simple, small eigenvalue of $A(0; \lambda)$. By Hypothesis \ref{Aspectrumhyp}, $\nu(0) = 0$, and $\nu(\lambda) = \mathcal{O}(\lambda)$. 

	\item Let $\delta > 0$ be a small. How small will be determined later. We will always take $|\lambda| < \delta$.

	\item Let $\rho > 0$ so that $\rho$ is much smaller than $\alpha_0$. For our analysis, it suffices to take $4 \rho < \alpha_0$. Then, using Hypothesis \ref{Aspectrumhyp}, we can choose $\delta$ sufficiently small so that 

	\begin{enumerate}
		\item $3 |\nu(\lambda)| < \rho$ for all $|\lambda| < \delta$ 
		\item For all $|\lambda| < \delta$, the real part of all other eigenvalues of $A(0; \lambda)$ lies outside the interval $[-\alpha_0 + \rho, \alpha_0 - \rho]$ 
	\end{enumerate}

	\item Let $\alpha = \alpha_0 - 2 \rho$

	\item Let $\tilde{\alpha} = \alpha - \rho > 0$. Note that this implies $3|\nu(\lambda)| < \alpha - \tilde{\alpha}$ for all $|\lambda| < \delta$.

	\item By our choice of $\rho$, we have $|\nu(\lambda)| < \rho < \tilde{\alpha}$ for all $|\lambda| < \delta$

	\item Choose $X_m$ sufficiently large such that

	\begin{equation}
	e^{-\alpha X_m}, ||G||, |\lambda|, ||\Delta H|| < \delta
	\end{equation}

\end{enumerate}

\subsection{Characterization of Center Subspace}

Fix $\beta^+$, $\beta^-$, $\lambda$ with $|\beta^+|, |\beta^-|, |\lambda| < \delta$. We are interested in the following pair of eigenvalue problems together with their adjoint problems.

\begin{align}
V_+' &= A(q^+(0, \beta^+)(x); \lambda) V_+ && x \geq 0 \label{eig:V+} \\
W_+' &= -A(q^+(0, \beta^+)(x); \lambda)^* W_+ && x \geq 0\label{eig:W+} \\
V_-' &= A(q^-(0, \beta^-)(x); \lambda) V_- && x \leq 0 \label{eig:V-} \\
W_-' &= -A(q^-(0, \beta^-)(x); \lambda)^* W_- && x \leq 0 \label{eig:W-}
\end{align}

$V_\pm$ and $W_\pm$ will depend on $\beta^\pm$ and $\lambda$, but for convenience we suppress that notation. Let $\Phi_+(y, x; \beta^+, \lambda)$ be the evolution operator for \eqref{eig:V+} and $\Phi_-(y, x; \beta^-, \lambda)$ be the evolution operator for \eqref{eig:V-}.\\

First, we summarize some useful facts about these eigenvalue problems in the following lemma. For what follows, we define the inner product on $\C^n$ by $\langle x, y \rangle = \sum_i x_i \bar{y_i}$, i.e. the complex conjugation is on the second component.

% lemma : facts about our eigenvalue problem

\begin{lemma}\label{eigadjoint}
Consider the linear ODE $V' = A(x)V$ and the corresponding adjoint problem $W' = -A(x)^* W$, where $A$ is an $n \times n$ matrix depending on $x$. Then the following are true.
\begin{enumerate}[(i)]
\item $\dfrac{d}{dx}\langle V(x), W(x) \rangle = 0$, thus the inner product is constant in $x$.
\item If $\Phi(y, x)$ is the evolution operator for $V' = A(x)V$, then $\Phi(x, y)^*$ is the evolution operator for the adjoint problem $W' = -W(x)^* W$.
\end{enumerate}
\begin{proof}
For (i), take the derivative of the inner product and use the expressions for $V'$ and $W'$. For (ii), take the derivative of the expression $\Phi(y, x)\Phi(x, y) = I$.
\end{proof}
\end{lemma}

Recall that for $|\lambda| < \delta$, the asymptotic matrix $A(0; \lambda)$ has a simple eigenvalue $\nu(\lambda)$ near 0, and $\nu(0) = 0$. Let $v_0(\lambda)$ be the corresponding eigenvector, i.e.

\begin{equation}\label{defv0}
A(0; \lambda) v_0(\lambda) = \nu(\lambda) v_0(\lambda)
\end{equation}

Since $\det(A - \nu I) = 0$ implies $\det(A^* - \overline{\nu}I) = 0$, $-\overline{\nu(\lambda)}$ is the small eigenvalue of $-A(0; \lambda)^*$; let $w_0(\lambda)$ be the corresponding eigenvector, i.e.

\begin{equation}\label{defw0}
-A(0; \lambda)^* w_0(\lambda) = -\overline{\nu(\lambda)} v_0(\lambda)
\end{equation}

Since these are eigenvalues and eigenvectors of the asymptotic matrix $A(0; \lambda)$, $\nu(\lambda)$, $v_0(\lambda)$, and $w_0(\lambda)$ depend on $\lambda$ but not on $\beta^\pm$.\\

It would be convenient if there were a nice relationship between $v_0(\lambda)$ and $w_0(\lambda)$, but without additional assumptions on $A(0; \lambda)$, this is not the case. Failing that, we would settle for knowing $\langle v_0(\lambda), w_0(\lambda) \rangle \neq 0$. Even this is too much to ask in general. As an easy counterexample, if we take

\[
M = \begin{pmatrix}1 & 1 \\ 0 & 1 \end{pmatrix}
\]

$M$ has a single eigenvector $(1, 0)$ and $M^*$ has a single eigenvector $(0, 1)$, both corresponding to the lone eigenvalue 1. These are clearly orthogonal. The problem here is the Jordan block, as we see in the following lemma.

% lemma : v and w cannot be orthogonal

\begin{lemma}\label{perpeigs}
Let $A$ be an $n \times n$ matrix, and suppose $v$ and $w$ are solutions to $Av = \lambda v$ and $A^*w = \overline{\lambda}w$, respectively. Suppose $\lambda$ is a simple eigenvalue, i.e. is has algebraic multiplicity of 1. Then $\langle v, w \rangle \neq 0$.
\begin{proof}
Since $\lambda$ is simple, $\text{span} \{w\} = \ker(A^* - \overline{\lambda}I)$. Suppose $v \perp w$. Then $v \in \ker(A^* - \overline{\lambda I})^\perp = \text{ran}(A - \lambda I)$, where the equality holds since $A$ is finite dimensional, thus has closed range. But this implies $(A - \lambda I)v_1 = v$ for some $v_1$, which cannot be the case since $\lambda$ is simple, so there cannot be such a generalized eigenvector. We conclude that $\langle v, w \rangle \neq 0$
\end{proof}
\end{lemma}

By this lemma, we conclude that for $|\lambda| < \delta$, $\langle v_0(\lambda), w_0(\lambda) \rangle \neq 0$. Since eigenvectors are defined up to scalar multiples, we scale $v_0(\lambda)$ and/or $w_0(\lambda)$ so that

\begin{equation}\label{v0w0IP1}
\langle v_0(\lambda), w_0(\lambda) \rangle = 1
\end{equation}

Next, we will construct solutions to the eigenvalue problem and its adjoint problem which grow/decay with exponential rate $\nu(\lambda)$. The key to doing this the gap lemma, which is based on Zum2018.

% Lemma : Gap Lemma (Zumbrun version)

This is the version from Zum2018.

\begin{lemma}\label{gaplemma}
Let $W \in \C^N$, and consider the family of ODEs on $R^-$

\begin{equation}\label{LambdaEVP}
W(x)' = A(x; \Lambda) W
\end{equation}

where $\Lambda \in \Omega \subset C^m$. Assume that

\begin{enumerate}
	\item The map $\Lambda \mapsto A(\cdot; \Lambda)$ is analytic in $\Lambda$.
	\item $A(x; \Lambda) \rightarrow A_\pm(\lambda)$ (independent of $\Lambda$) as $x \rightarrow \pm \infty$, and for $|\Lambda| < \delta$ we have the uniform exponential decay estimates 
	\begin{align}
	\left| \frac{\partial^k}{\partial x^k} A(x; \Lambda) - A_\pm(\Lambda) \right| 
	&\leq C e^{-\theta |x|} && 0 \leq k \leq K
	\end{align}
	where $\alpha > 0$, $C > 0$, and $K$ is a nonnegative integer,.
\end{enumerate}

Suppose $V^-(\Lambda)$ is an eigenvector of $A_-(\Lambda)$ with corresponding eigenvalue $\mu(\Lambda)$, both analytic in $\Lambda$. Then there exists a solution of \ref{paramEVP} of the form 

\begin{equation}
W(x; \Lambda) = V(x; \Lambda) e^{\mu(\Lambda)x}
\end{equation}

where $V$ is $C^1$ in $x$ and analytic in $\Lambda$ for $|\Lambda| < \delta$, and for any fixed $\tilde{\theta} < \theta$

\begin{align}
V(x; \Lambda) = V^-(\Lambda) + \mathcal{O}(e^{-\tilde{\theta}|x|}|V^-(\Lambda)|) && x < 0
\end{align}

\begin{proof}
This is identical to Zum2018, and is only here for my own edification.\\

Let $W(x; \Lambda) = V(x; \Lambda) e^{\mu(\Lambda) x}$. Substituting this into \eqref{LambdaEVP} and simplifying, we obtain the equivalent ODE

\begin{equation}\label{VEVP}
V(x; \Lambda)' = (A_- - \mu(\Lambda)I)V(x; \Lambda) + \Theta(x; \Lambda) V(x; \Lambda)
\end{equation}

where $\Theta(x; \Lambda) = (A(x; \Lambda) - A_-(\Lambda)) = \mathcal{O}(e^{-\theta|x|})$. Choose any $\tilde{\theta} < \theta_1 < \theta$ such that the real part of the spectrum of $A_-$ lies either to the left or to the right of the vertical line $\text{Re}(\nu) = \text{Re}(\mu(\Lambda) + \theta_1$ in the complex plane. We should be able to make sure this is case for all $|\Lambda| < \delta$ since all the eigenvalues of $A_(\Lambda)$ are analytic in $\Lambda$.\\

Then for $|\Lambda| < \delta$, we can define the spectral projections $P(\Lambda)$ and $Q(\Lambda)$, where $P(\Lambda)$ projects onto the direct sum of all eigenspaces of $A_-(\Lambda)$ corresponding to eigenvalues $\nu$ with $\text{Re}(\nu) < \text{Re}(\mu(\Lambda) + \theta_1$, and $Q(\Lambda)$ projects onto the direct sum of all eigenspaces of $A_-(\Lambda)$ corresponding to eigenvalues $\nu$ with $\text{Re}(\nu) > \text{Re}(\mu(\Lambda) + \theta_1$. $P(\Lambda)$ and $Q(\Lambda)$ are analytic in $\Lambda$ for $|\Lambda| < \delta$, and from our definition of $\theta_1$ we have the estimates

\begin{align*}
\left|e^{(A_-(\Lambda) - \mu(\Lambda)I)x}P \right| &\leq C e^{\theta_1 x} && x \geq 0 \\
\left|e^{(A_-(\Lambda) - \mu(\Lambda)I)x}Q \right| &\leq C e^{\theta_1 x} && x \leq 0
\end{align*}

Note that $P(\Lambda) + Q(\Lambda) = I$. Define the map $T$ on $L^\infty(-\infty, -M]$ by

\begin{align*}
TV(x; \Lambda) &= V^-(\Lambda) 
+ \int_{-\infty}^x e^{(A_-(\Lambda) - \mu(\Lambda)I)(x-y)}P\Theta(y; \Lambda) V(y; \Lambda) dy \\
&- \int_x^{-M} e^{(A_-(\Lambda) - \mu(\Lambda)I)(x-y)}Q\Theta(y; \Lambda) V(y; \Lambda) dy
\end{align*}

Taking the absolute value of both sides, for $x \leq 0$

\begin{align*}
|TV(x; \Lambda)| &\leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]}
\left( \int_{-\infty}^x e^{\theta_1 (x - y)} e^{\theta y} dy + \int_x^{-M} e^{\theta_1 (x - y)} e^{\theta y} dy \right) \\
&\leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{\theta_1 x} \int_{-\infty}^M e^{(\theta - \theta_1) y} dy \\
&= \leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{\theta_1 x} \frac{e^{-(\theta - \theta_1)M}}{\theta - \theta_1}\\
&\leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{\theta_1 x} e^{-(\theta - \theta_1)M} \\
&\leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{-(\theta - \theta_1)M} \\
& < \infty
\end{align*}

Since the RHS is independent of $x$, we have $T: L^\infty(-\infty, -M] \rightarrow L^\infty(-\infty, -M]$. Next, we look at

\begin{align*}
|TV_1(x; \Lambda) - TV_2(x; \Lambda)| &\leq C ||V_1(x; \Lambda) - V_2(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{\theta_1 x} \frac{e^{-(\theta - \theta_1)M}}{\theta - \theta_1}\\
\end{align*}

Since $e^{-(\theta - \theta_1)M} \rightarrow 0$ as $m \rightarrow \infty$, for sufficiently large $M$ we have 

\begin{align*}
|TV_1(x; \Lambda) - TV_2(x; \Lambda)|_{L^\infty(-\infty, -M]} &\leq \frac{1}{2} ||V_1(x; \Lambda) - V_2(x; \Lambda)||_{L^\infty(-\infty, -M]} 
\end{align*}

Thus the map $T$ is a contaction. Since $L^\infty(-\infty, -M]$ is a Banach space, by the Banach fixed point theorem, the map $T$ has a unique fixed point $V = TV$, i.e. we have a function $V \in L^\infty(-\infty, -M]$ such that 

\begin{align*}
V(x; \lambda) &= V^-(\Lambda) 
+ \int_{-\infty}^x e^{(A_-(\Lambda) - \mu(\Lambda)I)x}P\Theta(y; \Lambda) V(y; \Lambda) dy 
- \int_x^{-M} e^{(A_-(\Lambda) - \mu(\Lambda)I)x}Q\Theta(y; \Lambda) V(y; \Lambda) dy
\end{align*}

Differentiating this with respect to $x$, we obtain

\begin{align*}
V'(x; \Lambda) &= P\Theta(x; \Lambda) V(x; \Lambda) +
(A_-(\Lambda) - \mu(\Lambda)I) \int_{-\infty}^x e^{(A_-(\Lambda) - \mu(\Lambda)I)(x-y)}P\Theta(y; \Lambda) V(y; \Lambda) dy \\
&-(-Q\Theta(x; \Lambda) V(x; \Lambda))
-(A_-(\Lambda) - \mu(\Lambda)I) \int_x^{-M} e^{(A_-(\Lambda) - \mu(\Lambda)I)(x-y)}Q\Theta(y; \Lambda) V(y; \Lambda) dy \\
&= P\Theta(x; \Lambda) V(x; \Lambda) + Q\Theta(y; \Lambda) V(x; \Lambda) + (A_-(\Lambda) - \mu(\Lambda)I)(T V(x; \lambda) - V^-(\Lambda) ) \\
&= (P + Q)\Theta(x; \Lambda) V(x; \Lambda) + (A_-(\Lambda) - \mu(\Lambda)I)(V(x; \lambda) - V^-(\Lambda) ) \\
&= (A_-(\Lambda) - \mu(\Lambda)I)V(x; \lambda) + \Theta(x; \Lambda) V(x; \Lambda) - (A_-(\Lambda) - \mu(\Lambda)I)V^-(\Lambda) \\
&= (A_-(\Lambda) - \mu(\Lambda)I)V(x; \lambda) + \Theta(x; \Lambda) V(x; \Lambda)
\end{align*}

where we used the fact that $TV = V$ and $(A_-(\Lambda) - \mu(\Lambda)I)V^-(\Lambda) = 0$. Thus $V(x; \Lambda$ solves \eqref{VEVP}. Since $TV = V$, we let $V_1 = V$ and $V_2 = 0$ in the above to get the estimate

\begin{align*}
|V(x; \Lambda) - V^-(\Lambda)| &= |T(V(x; \Lambda)) - T(0)| \\
&\leq C ||V(x; \Lambda) - 0||_{L^\infty(-\infty, -M]} e^{\theta_1 x} \\
\end{align*}

Similarly, for suffiently large $M$, we have

\begin{align*}
|V(x; \Lambda)| - |V^-(\Lambda)| &\leq | |V(x; \Lambda)| - |V^-(\Lambda)| | \\
&\leq |V(x; \Lambda) - V^-(\Lambda)| \\
&= |T(V(x; \Lambda)) - T(0)| \\
&\leq \frac{1}{2} ||V(x; \Lambda)||_{L^\infty(-\infty, -M]}
\end{align*}

Thus

\begin{align*}
||V(x; \Lambda)||_{L^\infty(-\infty, -M]} \leq 2 |V^-(\Lambda)|
\end{align*}

Combining these, we have

\begin{align*}
|V(x; \Lambda) - V^-(\Lambda)| &\leq C e^{\tilde{\theta} x}|V^-(\Lambda)| \\
\end{align*}

from which we get

\begin{align*}
|V(x; \Lambda) = V^-(\Lambda) + \mathcal{O}( e^{\tilde{\theta} x}|V^-(\Lambda)| )\\
\end{align*}

At the moment, $V(x; \Lambda)$ is only defined for $x < -M$. We extend $V(x; \Lambda)$ to all of $R^-$ using the evolution operator for the system.

\end{proof}
\end{lemma}

% Lemma : Gap Lemma

This is the version we use.

\begin{lemma}\label{gaplemma}
Let $V \in \C^N$, and consider the family of ODEs on $R^-$

\begin{equation}\label{paramEVP}
V(x)' = A(x; \lambda, \beta) V
\end{equation}

where $\lambda \in \C$ and $\beta \in C^m$, and $|\lambda|, |\beta| < \delta$ for some $\delta > 0$. Assume that

\begin{enumerate}
	\item The map $\lambda, \beta \mapsto A(\cdot; \lambda, \beta)$ is analytic in $\lambda$ and $\beta$.
	\item For $|\lambda|, |\beta| < \delta$, $A(x; \lambda, \beta) \rightarrow A_\infty(\lambda)$ (independent of $\beta$) as $x \rightarrow \pm \infty$, and we have the uniform exponential decay estimates 
	\begin{align}
	\left| \frac{\partial^k}{\partial x^k} A(x; \lambda; \beta) - A_\infty(\lambda) \right| 
	&\leq C e^{-\alpha |x|} && 0 \leq k \leq K
	\end{align}
	where $\alpha > 0$, $C > 0$, and $K$ is a nonnegative integer,.
\end{enumerate}

Suppose $P(\lambda)$ is an eigenvector of $A_\infty(\lambda)$ with corresponding eigenvalue $\nu(\lambda)$, both analytic in $\lambda$. Then there exists a solution of \ref{paramEVP} of the form 

\begin{equation}
\tilde{V}(x; \lambda, \beta) = V(x; \lambda, \beta) e^{\nu(\lambda)x}
\end{equation}

where $V$ is $C^1$ in $x$ and analytic in $\lambda$ and $\beta$ for $|\lambda|, |\beta| < \delta$, and for any $\epsilon > 0$

\begin{align}
V(x; \lambda, \beta) = P(\lambda) + \mathcal{O}(e^{-(\alpha - \epsilon)|x|}|P(\lambda)|) && x < 0
\end{align}

\end{lemma}
 
Using Lemma \ref{gaplemma}, let $\tilde{v}_+(x; \beta^+, \lambda)$ and $\tilde{w}_+(x; \beta^+, \lambda)$ be solutions to the eigenvalue problem \eqref{eig:V+} and its adjoint problem \eqref{eig:W+} on $\R^+$ of the form 

\begin{align}
\tilde{v}_+(x; \beta^+, \lambda) &= e^{\nu(\lambda) x } v_+(x; \beta^+, \lambda) \label{tildev+} \\
\tilde{w}_+(x; \beta^+, \lambda) &= e^{-\overline{\nu(\lambda)} x } w_+(x; \beta^+, \lambda) \label{tildew+} 
\end{align}

where

\begin{align*}
v_+(x; \beta^+, \lambda) &= v_0(\lambda) + \mathcal{O}(e^{-(\tilde{\alpha} + |\nu(\lambda)|)|x|}) \\
w_+(x; \beta^+, \lambda) &= w_0(\lambda) + \mathcal{O}(e^{-(\tilde{\alpha} + |\nu(\lambda)|)|x|})\\
\end{align*}

Similarly, let $\tilde{v}_-(x; \beta^-, \lambda)$ and $\tilde{w}_-(x; \beta^-, \lambda)$ be solutions to the eigenvalue problem \eqref{eig:V-} and its adjoint problem \eqref{eig:W-} on $\R^-$ such that

\begin{align}
\tilde{v}_-(x; \beta^-, \lambda) &= e^{\nu(\lambda) x } v_-(x; \beta^-, \lambda) \label{tildev-} \\
\tilde{w}_-(x; \beta^-, \lambda) &= e^{-\overline{\nu(\lambda)} x } w_-(x; \beta^-, \lambda) \label{tildew-} 
\end{align}

where

\begin{align*}
v_-(x; \beta^-, \lambda) &= v_0(\lambda) + \mathcal{O}(e^{-(\tilde{\alpha} + |\nu(\lambda)|)|x|}) \\
w_-(x; \beta^-, \lambda) &= w_0(\lambda) + \mathcal{O}(e^{-(\tilde{\alpha} + |\nu(\lambda)|)|x|})\\
\end{align*}

In the final lemma of this section, we show that $\langle v_\pm(x; \beta^\pm, \lambda), w_\pm(x; \beta^\pm, \lambda) \rangle = 1$ for all $x \geq 0$.

% lemma : IP of v and w is 1

\begin{lemma}\label{vwIP1}

For $\lambda$ sufficiently small and for all $\beta^\pm$, we have

\begin{align}
\langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle = 1 && x \geq 0 \label{vwIP1+} \\
\langle v_-(x; \beta^-, \lambda), w_-(x; \beta^-, \lambda) \rangle = 1 && x \leq 0 \label{vwIP1-}
\end{align}

\begin{proof}
By Lemma \ref{eigadjoint}, $\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle$ is constant for all $x \geq 0$. Using this and the continuity of the inner product, we have for all $x \geq 0$
\begin{equation*}
\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle = \lim_{x \rightarrow \infty} \langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle = \langle v_0(\lambda), w_0(\lambda) \rangle = 1
\end{equation*}
For all $x \geq 0$ we have
\begin{align*}
\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle
&= \langle e^{\nu(\lambda) x } v_+(x; \beta^+, \lambda), e^{-\overline{\nu(\lambda)} x} \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= e^{\nu(\lambda) x } e^{-\nu(\lambda) x } \langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle \\
&= \langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle
\end{align*}
\eqref{vwIP1+} follows from combining these two results. The proof on $\R^-$ is identical.
\end{proof}
\end{lemma}

\subsection{Exponential Trichotomy}

In this section, we will show that $\Phi_\pm$ can be decomposed in an exponential trichotomy with a one-dimensional ``center'' subspace corresponding to the small eigenvalue $\nu(\lambda)$ of the asymptotic matrix $A(0; \lambda)$. We will do this in a series of lemmas. We will only look at $\R^+$. The proofs for $\R^-$ are identical.\\

For simplicity, we write the eigenvalue problem and its adjoint on $\R^+$ as 

\begin{align}
V' &= A(q^+(0, \beta^+); \lambda) V \label{evpsimple}\\
W' &= -A(q^+(0, \beta^+); \lambda) V \label{evpsimpleW}
\end{align}

where $\beta^+$ and $\lambda$ are fixed constants, with $|\lambda| < \delta$. Let $\Phi(y, x; \beta^+, \lambda)$ be the evolution operator for \eqref{evpsimple}. To prove the existence of an exponential trichotomy, we will need to use results from the exponential dichotomy literature, which is only possible if the asymptotic matrix is hyperbolic. To guarantee this is the case and to get uniform bounds, we will use exponentially weighted spaces, with weights $\pm 2 \rho$, where $\rho$ is defined above.\\

Let $U(x) = (U_1(x), \dots, U_m(x)): \R^+ \rightarrow \R^m$. For $\eta \in \R$, define the exponentially weighted $L^2$ norm on $R^+$ by

\[
||U||_\eta^+ = \max_{i = 1, \dots, m} ||e^{\eta x}U_i(x)||_{L_2(\R^+)}
\]

Let $X^+_\eta$ be the space equipped with this norm. This is known to be a Banach space. To recast the eigenvalue problem \eqref{evpsimple} in the exponentially weighted norm, we let $V = e^{-\eta x} V_\eta$. Substituting this into the eigenvalue problem, we obtain the weighted eigenvalue problem

\begin{equation}\label{weightedeq}
V_\eta' = A(q^+(0, \beta^+); \lambda, \eta) V_\eta = (A(q^+(0, \beta^+); \lambda) + \eta I) V_\eta
\end{equation}

Let $\Phi(x, y; \beta^+, \lambda, \eta)$ be the evolution operator for \eqref{weightedeq}. We summarize the relationship between \eqref{evpsimple} and \eqref{weightedeq} in the following lemma.

% lemma : facts about weighted EVP

\begin{lemma}\label{weightfacts}
\begin{enumerate}[(i)]

Let $A(x)$ be a matrix-valued function such that $A(x)$ is exponentially asymptotic to the constant matrix $A$. Consider the eigenvalue problem

\begin{equation}\label{Veq1}
V' = A(x)V
\end{equation}

and the corresponding weighted eigenvalue problem with exponential weight $\eta$

\begin{equation}\label{Veq1eta}
V_\eta' = (A(x) + \eta I)V_\eta
\end{equation}

\item $V(x)$ is a solution to \eqref{Veq1} if and only if $V_\eta(x) = e^{\eta x} V(x)$ is a solution to \eqref{Veq1eta}.

\item The evolution operator $\Phi(x, y; \beta^+, \lambda, \eta)$ of \eqref{weightedeq} is given by
\begin{equation}\label{evolweight}
\Phi(x, y; \beta^+, \lambda, \eta) = e^{\eta(x - y)} \Phi(x, y; \beta^+, \lambda)
\end{equation}

\item $\nu$ is an eigenvalue of the asymptotic matrix $A$ if and only if $\nu + \eta$ is an eigenvalue of $A + \eta I$. In other words, the exponential weight $\eta$ shifts all eigenvalues of the asymptotic matrix by $\eta$.

\end{enumerate}

\begin{proof}

For (i), we have

\begin{align*}
V' = A(x)V &\iff e^{\eta x} V' = A(x) e^{\eta x} V \\
&\iff \frac{d}{dx} (e^{\eta x} V') - \eta e^{\eta x} V = A(x) e^{\eta x} V \\
&\iff \frac{d}{dx} (e^{\eta x} V') = ( A(x) + \eta I)V 
\end{align*}

For (ii), given an initial condition $z \in \R_m$ at y, $u(x) = \Phi(x, y; \beta^+, \lambda) z$ is the unique solution to \eqref{Veq1}. Thus by (i), $u_\eta(x) = e^{\eta x} \Phi(x, y; \beta^+, \lambda) z$ solves \eqref{Veq1eta}. At $x = y$, $u_\eta(y) = e^{\eta y} z$, so $u_\eta(x)$ is the unique solution to \eqref{Veq1eta} with initial condition $e^{\eta y} z$. Thus

\begin{align*}
u_\eta(x) = e^{\eta(x-y)} \Phi(x, y; \beta^+, \lambda) z
\end{align*}

is the the unique solution to \eqref{Veq1eta} with initial condition $z$.\\

For (iii), we note that

\begin{align*}
\det(A - \nu I) = \det( (A + \eta I) - (\nu + \eta) I )
\end{align*}

\end{proof}
\end{lemma}

In the next lemma, we will apply exponential weights of $\pm 2 \rho$ to \eqref{evpsimple} to produce two different exponential dichotomies for \eqref{weightedeq}.

% lemma : weighted dichotomies

\begin{lemma}\label{weightdichotomy}
For the weighted eigenvalue problem \eqref{weightedeq} with weight $2 \rho$, there exist families of projections $P^s(y; \beta^+, \lambda, 2 \rho)$ and $P^s(y; \beta^+, \lambda, 2 \rho)$ parameterized by $y \in \R^+$, such that $P^s(y; \beta^+, \lambda, 2 \rho) + P^s(y; \beta^+, \lambda, 2 \rho) = I$ and

\begin{align*}
|\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\alpha_0 - \rho - \epsilon)(x - y)} && 0 \leq y \leq x \\
|e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\rho - \epsilon)(y - x)} && 0 \leq x \leq y \\
\end{align*}

For these projections, $\dim \ran P^s(y; \beta^+, \lambda, 2 \rho) = n_-$ and $\dim \ran P^s(y; \beta^+, \lambda, 2 \rho) = n_+ + 1$. These projections also satisfy the ``commuting'' relations 

\begin{align*}
\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho) 
&= P^s(x; \beta^+, \lambda, 2 \rho) \Phi(x, y; \beta^+, \lambda) \\
\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho) 
&= P^u(x; \beta^+, \lambda, 2 \rho) \Phi(x, y; \beta^+, \lambda) 
\end{align*}

Similarly, for the weighted eigenvalue problem \eqref{weightedeq} with weight $-2 \rho$, there exist families of projections $P^s(y; \beta^+, \lambda, -2 \rho)$ and $P^s(y; \beta^+, \lambda, -2 \rho)$ parameterized by $y \in \R^+$, such that $P^s(y; \beta^+, \lambda, -2 \rho) + P^s(y; \beta^+, \lambda, -2 \rho) = I$ and

\begin{align*}
|e^{-2 \rho (x - y)}\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\rho - \epsilon)(x - y)} && 0 \leq y \leq x \\
|\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\alpha_0 - \rho - \epsilon)(y - x)} && 0 \leq x \leq y 
\end{align*}

For these projections, $\dim \ran P^s(y; \beta^+, \lambda, -2 \rho) = n_- + 1$ and $\dim \ran P^u(y; \beta^+, \lambda, -2 \rho) = n_+$. The projections $P^s(y; \beta^+, \lambda, -2 \rho)$ and $P^-(y; \beta^+, \lambda, -2 \rho)$ satisfy the same ``commuting'' relations those for the exponential weight $2 \rho$.\\

For the stable projections, we have

\begin{align*}
\ran P^s(y; \beta^+, \lambda, 2 \rho) \subset \ran P^s(y; \beta^+, \lambda, -2 \rho) \\
\end{align*}

Finally, the unstable range at $y = 0$ is not uniquely determined. In particular, we are free to choose $\ran P^u(0; \beta^+, \lambda, -2 \rho)$ to be any complement of $\ran P^s(0; \beta^+, \lambda, -2 \rho)$.

\begin{proof}

First, we use the exponential weight $2 \rho$ in \eqref{weightedeq}. The operator $A(q^+(0, \beta^+); \lambda, 2 \rho)$ is exponentially asymptotic to $A(0; \lambda, 2 \rho)$, and by Lemma \ref{weightfacts}, the spectrum of $A(0; \lambda, 2 \rho)$ lies outside the interval $(-\alpha_0 + 3 \rho, \rho)$. $A(0; \lambda, 2 \rho)$ has $n_-$ eigenvalues with negative real part and $n_+ + 1$ eigenvalues with positive real part. Thus by standard exponential dichotomy theory (e.g. Coppel, Peterhof), for any $0 < \epsilon < \rho$ there exist families of projections $P^s(y; \beta^+, \lambda, 2 \rho)$ and $P^u(y; \beta^+, \lambda, 2 \rho)$ with $P^s(y; \beta^+, \lambda, 2 \rho) + P^s(y; \beta^+, \lambda, 2 \rho) = I$, indexed by $y \in \R^+$, such that

\begin{align*}
|e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\alpha_0 - 3 \rho - \epsilon)(x - y)} && 0 \leq y \leq x \\
|e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\rho - \epsilon)(y - x)} && 0 \leq x \leq y \\
\end{align*}

where we used Lemma \ref{weightfacts} for the form of the evolution operator of \eqref{weightedeq}. We can divide the first equation by $e^{2 \rho (x - y)}$ to get

\begin{align}\label{Ps2rhobound}
|\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\alpha_0 - \rho - \epsilon)(x - y)} && 0 \leq y \leq x
\end{align}

For the ranges of the projections, we have $\dim \ran P^s(y; \beta^+, \lambda, 2 \rho) = n_-$ and $\dim \ran P^s(y; \beta^+, \lambda, 2 \rho) = n_+ + 1$. The projections $P^s(y; \beta^+, \lambda, 2 \rho)$ and $P^-(y; \beta^+, \lambda, 2 \rho)$ also satisfy the ``commuting'' relations

\begin{align*}
e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho) 
&= P^s(x; \beta^+, \lambda, 2 \rho) e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda) \\
e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho) 
&= P^u(x; \beta^+, \lambda, 2 \rho)e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda) 
\end{align*}

We can again divide by $e^{2 \rho (x - y)}$ term to get 

\begin{align*}
\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho) 
&= P^s(x; \beta^+, \lambda, 2 \rho) \Phi(x, y; \beta^+, \lambda) \\
\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho) 
&= P^u(x; \beta^+, \lambda, 2 \rho) \Phi(x, y; \beta^+, \lambda) 
\end{align*}

Similarly, using the exponential weight $-2 \rho$, the spectrum of $A(0; \lambda, -2 \rho)$ lies outside the interval $(-\rho, \alpha_0 - 3 \rho)$. $A(0; \lambda, -2 \rho)$ has $n_- + 1$ eigenvalues with negative real part and $n_+$ eigenvalues with positive real part. Again, using standard exponential dichotomy theory, for the same $\epsilon$ as above there exist families of projections $P^s(y; \beta^+, \lambda, -2 \rho)$ and $P^u(y; \beta^+, \lambda, -2 \rho)$, indexed by $y \in \R^+$, such that

\begin{align*}
|e^{-2 \rho (x - y)}\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\rho - \epsilon)(x - y)} && 0 \leq y \leq x \\
|e^{-2 \rho (x - y)}\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\alpha_0 - 3 \rho - \epsilon)(y - x)} && 0 \leq x \leq y \\
\end{align*}

We can divide the second equation by $e^{-2 \rho (x - y)}$ to get

\begin{align}\label{Pu2-rhobound}
|\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\alpha_0 - \rho - \epsilon)(y - x)} && 0 \leq x \leq y 
\end{align}

For the ranges of the projections, we have $\dim \ran P^s(y; \beta^+, \lambda, -2 \rho) = n_- + 1$ and $\dim \ran P^u(y; \beta^+, \lambda, -2 \rho) = n_+$. The projections $P^s(y; \beta^+, \lambda, -2 \rho)$ and $P^-(y; \beta^+, \lambda, -2 \rho)$ satisfy the same ``commuting'' relations as above.\\

By Pet97, the stable range $\ran P^s(y; \beta^+, \lambda, -2 \rho)$ is uniquely determined. For the unstable range at $x = 0$, however, we are free to choose $\ran P^u(0; \beta^+, \lambda, -2 \rho)$ to be any complement of $\ran P^s(0; \beta^+, \lambda, -2 \rho)$. We will make such a choice later.\\

Finally, let $z \in \ran P^s(y; \beta^+, \lambda, 2 \rho)$. Then for all $x \geq y$

\begin{align*}
|e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)z| &\leq C e^{-(\alpha_0 - 3 \rho - \epsilon)(x - y)} \\
|e^{-2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)z| &\leq C e^{-(\alpha_0 + \rho - \epsilon)(x - y)} \\
&\leq C e^{-(\rho - \epsilon)(x - y)} \\
\end{align*}

Since the stable subspaces of exponential dichotomies are uniquely determined and this has the correct decay properties as $x \rightarrow \infty$, it follows that $z \in \ran P^s(y; \beta^+, \lambda, -2 \rho)$. Thus

\begin{align*}
\ran P^s(y; \beta^+, \lambda, 2 \rho) \subset \ran P^s(y; \beta^+, \lambda, -2 \rho) \\
\end{align*}

\end{proof}
\end{lemma}

In the next lemma, we show that $\tilde{w}_+(x; \beta^+, \lambda)$ is perpendicular to the $\ran P^s_+(x; \beta^+, \lambda, 2 \rho)$, the stable range of the exponential dichotomy for the weighted eigenvalue problem with weight $2 \rho$.

% lemma : adjoint perpendicular to stable range

\begin{lemma}\label{wperpstable}

For the weighted eigenvalue problem \eqref{weightedeq} with weight $2 \rho$,

\begin{equation}
\tilde{w}_+(x; \beta^+, \lambda) \perp \ran P^s_+(x; \beta^+, \lambda, 2 \rho)
\end{equation}

for all $x \geq 0$.

\begin{proof}

Fix $x \in \R^+$ and let $z \in \ran P^s_+(x; \beta^+, \lambda, 2 \rho)$. Then

\begin{align*}
\tilde{u}(y; 2 \rho) &= e^{2 \rho(y - x)} \Phi(y, x; \beta^+, \lambda)z\\
\end{align*}

is a solution to \eqref{weightedeq} with $u(x) = z$, thus

\begin{align*}
u(y) &= \Phi(y, x; \beta^+, \lambda) e^{-2 \rho x} z\\
\end{align*}

is a solution to \eqref{evpsimple} with $u(x) = e^{-2 \rho x} z$. Since $\tilde{w}(y; \beta^+, \lambda)$ is a solution to \eqref{evpsimpleW}, by Lemma \ref{eigadjoint}, the inner product $\langle u(y), \tilde{w}_+(y; \beta^+, \lambda) \rangle$ is constant in $y$. Using this together with the continuity of the inner product, we have

\begin{align*}
e^{-2 \rho x} \langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle &= 
\langle e^{-2 \rho x} z, \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= \langle u(x), \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= \lim_{y \rightarrow \infty} \langle u(y), \tilde{w}_+(y; \beta^+, \lambda) \rangle \\
&= \lim_{y \rightarrow \infty} \langle u(y), e^{-\overline{\nu(\lambda)} y } w_+(y; \beta^+, \lambda) \rangle \\
&= \lim_{y \rightarrow \infty} \langle e^{-{\nu(\lambda)} y } u(y), w_+(y; \beta^+, \lambda) \rangle\\
&= \langle \lim_{y \rightarrow \infty} e^{-{\nu(\lambda)} y } u(y), w_0(\lambda) \rangle \\
&= \langle \lim_{y \rightarrow \infty} e^{-{\nu(\lambda)} y } \Phi(y, x; \beta^+, \lambda) e^{-2 \rho x} z, w_0(\lambda) \rangle \\
&= e^{-2 \rho x} \langle \lim_{y \rightarrow \infty} e^{-{\nu(\lambda)} y } \Phi(y, x; \beta^+, \lambda) P^s_+(x; \beta^+, \lambda, 2 \rho) z, w_0(\lambda) \rangle 
\end{align*}

since $z \in \ran P^s_+(x; \beta^+, \lambda, 2 \rho)$. Thus using \eqref{Ps2rhobound}, by our choices of $\rho$ and $\epsilon$ and since $x$ is fixed, we divide by $e^{-2 \rho x}$ and get

\begin{align*}
|\langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle| 
&\leq \lim_{y \rightarrow \infty} e^{|\nu(\lambda)| y } e^{-(\alpha_0 - \rho - \epsilon)(y - x)} |w_0(\lambda) ||z| \\
&\leq C \lim_{y \rightarrow \infty} e^{|\nu(\lambda)| y } e^{-(\alpha_0 - \rho - \epsilon)y} e^{(\alpha_0 - \rho - \epsilon)x} \\
&\leq C \lim_{y \rightarrow \infty} e^{-(\alpha_0 - 2 \rho - \epsilon)y}  \\
&= 0
\end{align*}

Thus $\langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle = 0$.

\end{proof}
\end{lemma}

In the next lemma, we show that we can choose a complement of $\ran P^s(0; \beta^+, \lambda, -2 \rho)$ for $\ran P^u(0; \beta^+, \lambda, -2 \rho)$ such that $\tilde{w}_+(x; \beta^+, \lambda) \perp \ran P^u_+(x; \beta^+, \lambda, -2 \rho)$ for all $x \geq 0$. 

% lemma : can choose unstable range so that w is perpendicular to it

\begin{lemma}\label{wperpunstable}

We can choose $\ran P^u(0; \beta^+, \lambda, -2 \rho)$ such that 

\begin{align*}
\tilde{w}_+(x; \beta^+, \lambda) \perp \ran P^u_+(x; \beta^+, \lambda, -2 \rho) 
\end{align*}

for all $x \in \R^+$.

\begin{proof}

For convenience, let $R^s(2 \rho) = \ran P^s(0; \beta^+, \lambda, 2 \rho)$ and $R^s(-2 \rho) = \ran P^s(0; \beta^+, \lambda, -2 \rho)$. From Lemma \ref{weightdichotomy}, $R^s(2 \rho) \subset R^s(-2 \rho)$. Let $S = \{ u_1, \dots, u_{n_-} \}$ be a basis for $R^s(2 \rho)$. By our choice of exponential weights, $v_+(0; \beta^+, \lambda) \in R(-2 \rho)$ but $v_+(0; \beta^+, \lambda) \not\in R^s(2 \rho)$. Therefore $\{ u_1, \dots, u_{n_-}, v_+(0; \beta^+, \lambda)\}$ is a basis for $R^s(-2 \rho)$.\\

Let $T = \spn\{ u_1, \dots, u_{n-1} , w_+(0; \beta^+, \lambda) \}^\perp$. We claim that $T$ is a complement of $R^s(-2 \rho)$. Let $t_1, \dots, t_{n^+}$ be a basis for $T$. To prove this, all we have to show is that the set 

\[
S \cup T \cup \{ v_+(0; \beta^+, \lambda) \} =  \{ u_1, \dots, u_{n_-} , v_+(0; \beta^+, \lambda), t_1, \dots, t_{n_+} \}
\]
is linearly independent. By construction, the set $S \cup T = \{ u_1, \dots, u_{n_-}, t_1, \dots, t_{n_+} \}$ is linearly independent. Thus all we have to show is that $v_+(0; \beta^+, \lambda)$ is linearly independent from $S \cup T$. The set $\{ v_+(0; \beta^+, \lambda), u_1, \dots, u_{n_-}\}$ is linearly independent since it is a basis for $R^s(-2 \rho)$. From Lemma \ref{vwIP1}, $\langle v_+(0; \beta^+, \lambda), w_+(0; \beta^+, \lambda) = 1$, thus $v_+(0; \beta^+, \lambda)$ cannot be in $T$, otherwise it would be perpendicular to $w_+(0; \beta^+, \lambda)$. Thus $T$ is a complement of $R^s(-2 \rho)$, so by Pet98, we can choose

\begin{equation}
\ran P^u(0; \beta^+, \lambda, -2 \rho) = \spn\{ u_1, \dots, u_{n-1} , w_+(0; \beta^+, \lambda) \}^\perp
\end{equation}

In particular, $\tilde{w}_+(0; \beta^+, \lambda) \perp \ran P^u(0; \beta^+, \lambda, -2 \rho)$.\\

Next, we show that $\tilde{w}_+(x; \beta^+, \lambda) \perp \ran P^u_+(x; \beta^+, \lambda, -2 \rho)$ for all $x \in \R^+$. Fix $x \geq 0$, and let $z \in \ran P^u(x; \beta^+, \lambda, -2 \rho)$. Then by the invariance of the unstable subspace of the exponential dichotomy,

\begin{align*}
z = e^{-2 \rho x} \Phi(x, 0; \beta^+, \lambda) z_0
\end{align*}

for some $z_0 \in \ran P^u(0; \beta^+, \lambda, -2 \rho)$.

\begin{align*}
\tilde{u}(y; -2 \rho) &= e^{-2 \rho y} \Phi(y, 0; \beta^+, \lambda)z_0
\end{align*}

is a solution to \eqref{weightedeq} with $u(0) = z_0$ and $u(x) = z$, thus

\begin{align*}
u(y) &= \Phi(y, 0; \beta^+, \lambda) z_0 \\
\end{align*}

is a solution to \eqref{evpsimple} with $u(0) = z_0$ and $u(x) = e^{2 \rho x} z$. Since $\tilde{w}(y; \beta^+, \lambda)$ is a solution to \eqref{evpsimpleW}, by Lemma \ref{eigadjoint}, the inner product $\langle u(y), \tilde{w}_+(y; \beta^+, \lambda) \rangle$ is constant in $y$. From our choice of $P^u(0; \beta^+, \lambda, -2 \rho)$, we have

\begin{align*}
0 &= \langle z_0, w_+(0; \beta^+, \lambda) \rangle \\
&= \langle u(0), \tilde{w}_+(0; \beta^+, \lambda) \rangle \\
&= \langle u(x), \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= \langle e^{2 \rho x} z, \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= e^{2 \rho x} \langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle 
\end{align*}

Since $e^{2 \rho x} > 0$, $\langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle = 0$.

\end{proof}
\end{lemma}

We are finally ready to put all of this together. For $x \in \R^+$, we define the stable and unstable projections on $\R^+$ by

\begin{align*}
P^s_+(x; \beta^+, \lambda) &= P^s(x; \beta^+, \lambda, 2 \rho) \\
P^u_+(x; \beta^+, \lambda) &= P^u(x; \beta^+, \lambda, -2 \rho)
\end{align*}

From \eqref{Ps2rhobound} and \eqref{Pu2-rhobound} we have the estimates

\begin{align*}
|\Phi(x, y; \beta^+, \lambda)P_+^s(y; \beta^+, \lambda)| &\leq C e^{-\alpha(x - y)} && 0 \leq y \leq x \\
|\Phi(x, y; \beta^+, \lambda)P_+^u(y; \beta^+, \lambda)| &\leq C e^{-\alpha(y - x)} && 0 \leq x \leq y 
\end{align*}

These estimates are independent of $\beta^+$ and $\lambda$. The ``commuting'' relations for the stable and unstable projections follow from Lemma \ref{weightdichotomy}. The dimensions of the stable and unstable projections are given by $\dim \ran P_+^s(x; \beta^+, \lambda) = n_-$ and $\dim \ran P_+^u(x; \beta^+, \lambda) = n_+$.\\

In the next lemma, we define the center projection $P^c_+(x; \beta^+, \lambda)$.

% lemma : center projection

\begin{lemma}\label{centerproj}

For $x \in \R^+$ and $u \in \R^m$, let

\begin{equation}
P^c_+(x; \beta^+, \lambda)u = \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda)
\end{equation}

Then $P^c_+(x; \beta^+, \lambda)$ is the projection on the center subspace. We also have the ``commuting'' relation

\begin{align*}
\Phi(x, y; \beta^+, \lambda) P^c_+(y; \beta^+, \lambda) 
= P^c_+(x; \beta^+, \lambda) \Phi(x, y; \beta^+, \lambda)
\end{align*}

\begin{proof}

For $|\lambda| < \delta$ and $x \in \R^+$, the center subspace is defined as $\spn \{ v_+(x; \beta^+, \lambda) \}$. From the definition of $P^c_+(x; \beta^+, \lambda)$ we have $\ran P^c_+(x; \beta^+, \lambda) = \spn \{ v_+(x; \beta^+, \lambda) \}$. $P^c_+(x; \beta^+, \lambda)$ also the correct kernel, since $\langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle = 1$ for all $x \geq 0$ (so it does not wipe out anything in the center subspace), and from Lemmas \ref{wperpstable} and \ref{wperpunstable} we have

\begin{align*}
w_+(x; \beta^+, \lambda) \perp \ran P^s_+(x; \beta^+, \lambda) \oplus \ran P^u_+(x; \beta^+, \lambda)
\end{align*}

since $w_+(x; \beta^+, \lambda)$ and $\tilde{w}_+(x; \beta^+, \lambda)$ are scalar multiples of each other.\\

Finally, we need to verify that $P^c_+$ is in fact a projection. To do this, we will show that $P^c_+(x; \beta^+, \lambda)P^c_+(x; \beta^+, \lambda) = P^c_+(x; \beta^+, \lambda)$. For $u \in \R^m$,

\begin{align*}
P^c_+(x; \beta^+, \lambda)( P^c_+(x; \beta^+, \lambda) u ) &= \langle \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(x; \beta^+, \lambda) \rangle \langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= P^c_+(x; \beta^+, \lambda) u 
\end{align*}

since $\langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle = 1$ for all $x \geq 0$ by Lemma \ref{perpeigs}. Thus $P^c_+(x; \beta^+, \lambda)$ is indeed a projection, and is the projection on the center subspace.\\

For the ``commuting'' relation, recall that $\tilde{v}_+(x; \beta^+, \lambda)$ is a solution to \eqref{evpsimple} and $\tilde{w}_+(x; \beta^+, \lambda)$ is a solution to \eqref{evpsimpleW}. Thus for $u \in \R^m$,

\begin{align*}
\Phi(x, y; \beta^+, \lambda) P^c_+(y; \beta^+, \lambda) u 
&= \Phi(x, y; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle v_+(y; \beta^+, \lambda)\\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle \Phi(x, y; \beta^+, \lambda) e^{-\nu(\lambda)y} \tilde{v}_+(y; \beta^+, \lambda)\\
&= \langle u, e^{-\overline{\nu(\lambda)}y}w_+(y; \beta^+, \lambda) \rangle \Phi(x, y; \beta^+, \lambda) \tilde{v}_+(y; \beta^+, \lambda)\\
&= \langle u, \tilde{w}_+(y; \beta^+, \lambda) \rangle \Phi(x, y; \beta^+, \lambda) \tilde{v}_+(y; \beta^+, \lambda)\\
&= \langle u, \Phi(y, x; \beta^+, \lambda)^* \tilde{w}_+(x; \beta^+, \lambda) \rangle \tilde{v}_+(x; \beta^+, \lambda)\\
&= \langle \Phi(x, y; \beta^+, \lambda) u, \tilde{w}_+(x; \beta^+, \lambda) \rangle \tilde{v}_+(x; \beta^+, \lambda)\\
&= P^c_+(x; \beta^+, \lambda) \Phi(x, y; \beta^+, \lambda) u
\end{align*}

\end{proof}
\end{lemma}

Since by the previous lemma we have $\ran P^c_+(x; \beta^+, \lambda) = \spn \{ v_+(x; \beta^+, \lambda) \}$, it follows from Lemma \ref{weightdichotomy} and Lemma \ref{wperpunstable} that for all $x \in \R^m$,

\begin{align*}
\R^m = P^s_+(x; \beta^+, \lambda) \oplus P^u_+(x; \beta^+, \lambda) \oplus P^c_+(x; \beta^+, \lambda)
\end{align*}

Thus for all $x \in \R^m$

\begin{align*}
P^s_+(x; \beta^+, \lambda) + P^u_+(x; \beta^+, \lambda) + P^c_+(x; \beta^+, \lambda) = I
\end{align*}

Finally, we derive an expression for the evolution on the center subspace.

% lemma : center evolution

\begin{lemma}\label{centerevol}

The evolution of \eqref{evpsimple} on the center subspace is given by

\begin{equation}
e^{\nu(\lambda)(x-y)} v_+(x; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle 
\end{equation}

for an initial condition $u \in \R^m$.

\begin{proof}

The center evolution is defined by

\begin{equation*}
\Phi^c_+(x,y; \beta^+, \lambda) = \Phi(x,y; \beta^+, \lambda) P^c_+(y; \beta^+, \lambda)
\end{equation*}

Then for any initial condition $u$, using Lemma \ref{centerproj}, we have

\begin{align*}
\Phi(x,y; \beta^+, \lambda) P^c_+(y; \beta^+, \lambda) u 
&= \Phi(x,y; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle v_+(y; \beta^+, \lambda) \\
&= \Phi(x,y; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} \tilde{v}_+(y; \beta^+, \lambda) \\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} \Phi(x,y; \beta^+, \lambda) \tilde{v}_+(y; \beta^+, \lambda) \\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} \tilde{v}_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} e^{\nu(\lambda)x} v_+(x; \beta^+, \lambda) \\
&= e^{\nu(\lambda)(x-y)} v_+(x; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle 
\end{align*}

where we used the fact that $\tilde{v}_+$ is a solution to the eigenvalue problem \eqref{evpsimple}, thus $\Phi(y, x; \beta^+, \lambda)\tilde{v}_+(x; \beta^+, \lambda) = \tilde{v}_+(y; \beta^+, \lambda)$. 

\end{proof}
\end{lemma}

We combine the results from these lemmas in the following theorem, which demonstrates the exponential trichotomy. 

% theorem : trichotomy 

\begin{theorem}\label{trichotomy}

For $\lambda$ sufficiently small and any $\beta^+, \beta^-$, there exist projections

\begin{align*}
&P_+^s(x; \beta^+, \lambda), P_+^u(x; \beta^+, \lambda), P_+^c(x; \beta^+, \lambda) && x \geq 0 \\
&P_-^s(x; \beta^-, \lambda), P_-^u(x; \beta^-, \lambda), P_-^c(x; \beta^-, \lambda) && x \leq 0 \\
\end{align*}

with

\begin{align*}
&P_+^s(x; \beta^+, \lambda) + P_+^u(x; \beta^+, \lambda) + P_+^c(x; \beta^+, \lambda) = I \\
&P_-^s(x; \beta^-, \lambda) + P_-^u(x; \beta^-, \lambda) + P_-^c(x; \beta^-, \lambda) = I \\
\end{align*}

such that the evolution operators $\Phi_\pm(x, y; \beta^\pm, \lambda)$ can be decomposed as

\begin{align*}
\Phi^s_\pm(x, y; \beta^\pm, \lambda) &= \Phi_\pm(x, y; \beta^\pm, \lambda) P^s_\pm(y; \beta^\pm, \lambda) \\
\Phi^u_\pm(x, y; \beta^\pm, \lambda) &= \Phi_\pm(x, y; \beta^\pm, \lambda) P^u_\pm(y; \beta^\pm, \lambda) \\
\Phi^c_\pm(x, y; \beta^\pm, \lambda) &= \Phi_\pm(x, y; \beta^\pm, \lambda) P^c_\pm(y; \beta^\pm, \lambda) \\
\end{align*}

The projections satisfy the ``commuting'' relations

\begin{align*}
\Phi_\pm(x, y; \beta^\pm, \lambda) P^{s/u/c}_\pm(y; \beta^\pm, \lambda) 
= P^{s/u/c}_\pm(x; \beta^\pm, \lambda) \Phi_\pm(x, y; \beta^\pm, \lambda)
\end{align*}

i.e. it does not matter if we project or evolve first. For $|\lambda| < \delta$, we have the following estimates for the stable and unstable evolutions, which independent of $\lambda$ and $\beta^\pm$.

\begin{align*}
|\Phi^s_+(x, y; \beta^+, \lambda)| &\leq C e^{-\alpha(x - y)} && 0 \leq y \leq x \\
|\Phi^u_+(x, y; \beta^+, \lambda)| &\leq C e^{-\alpha(y - x)} && 0 \leq x \leq y \\
|\Phi^s_-(x, y; \beta^+, \lambda)| &\leq C e^{-\alpha(x - y)} && y \leq x \leq 0 \\
|\Phi^u_-(x, y; \beta^+, \lambda)| &\leq C e^{-\alpha(y - x)} && x \leq y \leq 0 \\
\end{align*}

where $\alpha$ is defined above. The same estimates hold for all derivatives with respect to $\beta^\pm$ and $\lambda$.\\

An explicit form of the center projection is given by

\begin{align}\label{Pc}
P^c_+(x; \beta^+, \lambda)u &= \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) && x \geq 0 \\
P^c_-(x; \beta^-, \lambda)u &= \langle u, w_-(x; \beta^-, \lambda) \rangle v_-(x; \beta^-, \lambda) && x \leq 0
\end{align}

where $v_\pm(x; \beta^\pm, \lambda)$ and $w_\pm(x; \beta^\pm, \lambda)$ are defined above in \eqref{tildev+}, \eqref{tildew+}, \eqref{tildev-}, and \eqref{tildew-}. An explicit form of the center evolution is given by

\begin{align}\label{Phic}
\Phi^c_+(x,y; \beta^+, \lambda) &= e^{\nu(\lambda)(x-y)} v_+(x; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle && x, y \geq 0 \\
\Phi^c_-(x,y; \beta^-, \lambda) &= e^{\nu(\lambda)(x-y)} v_-(x; \beta^-, \lambda) \langle u, w_-(y; \beta^-, \lambda) \rangle && x, y \leq 0
\end{align}

\begin{proof}

This follows from the previous lemmas. The proof for $\R^-$ is identical. The fact that we can use the same estimates for derivatives with respect to the parameters $\beta^\pm$ and $\lambda$ follows from Lemma 3.2 in San98, which follows from San93. In particular, we can perform a Taylor expansion in any of the parameters.

\end{proof}
\end{theorem}

In the work which follows, we will need several estimates based on Theorem \ref{trichotomy}. First, we have bounds involving projections and evolutions on the stable and unstable subspaces. We will show these in the following lemma.

% lemma : various projection bounds

\begin{lemma}\label{projbounds}
Let

\begin{enumerate}
\item
\begin{equation}\label{p1}
p_1(X; \beta^+, \beta^-, \lambda) = \sup_{x \geq X} (|P^u_+(x; \beta^+, \lambda) - P_0^u| + |P^s_-(-x; \beta^-, \lambda) - P_0^s|)
\end{equation}
\item
\begin{equation}\label{p5}
p_5(\beta_i^+, \beta_i^-, \lambda) = |P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0)| + |P^s_+(0; \beta_i^+, \lambda) - P^s_+(0; 0, 0)|
\end{equation}
\item 
\begin{equation}\label{p6}
p_6(y; \beta_i^+, \beta_i^-, \lambda) = |\Phi^u_+(0, y; \beta_i^+, \lambda) - \Phi^u_+(0, y; 0, 0)| + |\Phi^s_-(0, -y; \lambda) - \Phi^s_-(0, -y; 0, 0)| 
\end{equation}

\end{enumerate}

where $P_0^s$ and $P_0^u$ are the projections on the $E^s$ and $E^u$, the stable and unstable eigenspaces of the asymptotic matrix $A(0; 0)$. Then we have bounds

\begin{align}
p_1(X; \beta^+, \beta^-, \lambda) &= \mathcal{O}( e^{-\alpha X } + |\lambda| ) \\
p_5(\beta_i^+, \beta_i^-, \lambda) &= \mathcal{O}(e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} + |\lambda|) \\
p_6(y; \beta_i^+, \beta_i^-, \lambda) &= \mathcal{O}(|\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} ) e^{-\alpha |y|}
\end{align}

\begin{proof}
All these bounds rely on the Taylor theorem. By the previous lemma, we can Taylor expand in $\beta^\pm$ and $\lambda$.\\

For $p_1$, using the triangle inequality, we have

\begin{align*}
|P^u_+(x; \beta^+, \lambda) - P_0^u| 
&\leq |P^u_+(x; \beta^+, \lambda) - P^u_+(x; \beta^+, 0)| + |P^u_+(x; \beta^+, 0) - P_0^u| 
\end{align*}

From Lemma 1.1 in San93, $|P^u_+(x; \beta^+, 0) - P_0^u| = \mathcal{O}(e^{-\alpha x})$. From the Taylor theorem about $\lambda = 0$, we have $|P^u_+(x; \beta^+, \lambda) - P^u_+(x; \beta^+, 0)| = \mathcal{O}(|\lambda|)$. Combining these yields the desired bound.\\

For $p_5$, we use the Taylor theorem on $P^u_-(0; \beta_i^-, \lambda)$ about $(\beta_i^-, \lambda) = (0, 0)$ to get 

\begin{align*}
P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0) &= \mathcal{O}(|\lambda| + |\beta_i^-|) \\
&= \mathcal{O}(|\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})
\end{align*}

where the estimate on $\beta_i^-$ comes from the existence problem. We get the same estimate from using the Taylor theorem on $P^s_+(0; \beta_i^+, \lambda)$.\\

For $p_6$, we use the Taylor theorem on $\Phi^u_+(0, y; \beta_i^+, \lambda)$ at $(\beta_i^+, \lambda) = (0, 0)$ to get 

\begin{align*}
\Phi^u_+(&0, y; \beta_i^+, \lambda) - \Phi^u_+(0, y; 0, 0) \\
&= \frac{\partial}{\partial \beta_i^+}\Phi^u_+(0, y; \beta_i^+, \lambda)\Big|_{(\beta_i^+, \lambda) = (0, 0)} \beta_i^+ + \frac{\partial}{\partial \lambda}\Phi^u_+(0, y; \beta_i^+, \lambda)\Big|_{(\beta_i^+, \lambda) = (0, 0)} \lambda + \mathcal{O}(|\beta_i^+|^2 + |\beta_i^+ \lambda| + |\lambda|^2) \\
&= \mathcal{O}((|\lambda| + |\beta_i^+|)e^{-\alpha |y| }) \\
&= \mathcal{O}((|\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})e^{-\alpha |y| }) \\
\end{align*}

where the derivatives of $\Phi^u_+(0, y; \beta_i^+, \lambda)$ with respect to $\beta_i^+$ and $\lambda$ are $\mathcal{O}(e^{-|\alpha|y}$ by Theorem \ref{trichotomy} and the estimate on $\beta_i^+$ comes from the existence problem. We get the same estimate for $\Phi^s_-(0, -y; \lambda)$.

\end{proof}
\end{lemma}

Finally, we have bounds involving the center subspace.

% lemma : bounds involving center subspace stuff

\begin{lemma}\label{centerbounds}

Let
\begin{enumerate}[(i)]
\item $p_2(X; \lambda) = |v_\pm(\pm X; \beta^\pm, \lambda) - v_0(\lambda)| + |w_\pm(\pm X; \beta^\pm, \lambda) - w_0(\lambda)|$
\item $p_3(\lambda) = |v_0(\lambda) - v_0(0)|$
\item $p_4(X; \lambda) = |v_\pm(\pm X; \beta^\pm, \lambda) - v_\pm(\pm X; 0, 0)| + |w_\pm(\pm X; \beta^\pm, \lambda) - w_\pm(\pm X; 0, 0)|$
\end{enumerate}

Then 

\begin{equation}\label{p2limit}
p_2(X; \lambda) = \mathcal{O}(e^{-\tilde{\alpha} X} )
\end{equation}

\begin{equation}\label{p3bound}
p_3(X; \lambda) = \mathcal{O}(\lambda),
\end{equation}

and

\begin{equation}\label{p3bound}
p_4(X; \lambda) = \mathcal{O}(\lambda + e^{-2 \alpha X} )
\end{equation}

\begin{proof}

The bound on $p_2$ follows from the gap lemma, since

\begin{align*}
v_\pm(X; \beta^\pm, \lambda) &= v_0(\lambda) + \mathcal{O}(e^{-\tilde{\alpha}|X|}) \\
w_\pm(X; \beta^\pm, \lambda) &= w_0(\lambda) + \mathcal{O}(e^{-\tilde{\alpha}|X|})\\
\end{align*}

For $p_3$, we can expand $v_0(\lambda)$ in a Taylor series in $\lambda$ to get

\[
v_0(\lambda) = v_0(0) + \lambda \frac{\partial}{\partial \lambda}v_0(\lambda)\Big|_{\lambda = 0} + \mathcal{O}(\lambda^2)
\]

Since $\frac{\partial}{\partial \lambda}v_0(\lambda)\Big|_{\lambda = 0}$ is a constant, we have the estimate

\[
p_3(X; \lambda) = \mathcal{O}(\lambda) 
\]

For $p_4$, we expand $v_\pm$ and $w_\pm$ in a Taylor series about $(\lambda, \beta^\pm) = (0, 0)$ to get the result.

\end{proof}
\end{lemma}

\subsection{The Inversion}

Define the spaces

\begin{align*}
V_W &= \bigoplus_{i=0}^{n-1} C^0([-X_{i-1}, 0], \C^m) \oplus C^0([0, X_i], \C^m) \\
V_a &= \bigoplus_{i=0}^{n-1} E^u \oplus E^s\\
V_b &= \bigoplus_{i=0}^{n-1} \ran P^u_-(0; 0, 0) \oplus \ran P^s_+(0; 0, 0) \\
V_c^+ &= \bigoplus_{i=0}^{n-1} \spn \{v_0(\lambda)\} \\
V_c^- &= \bigoplus_{i=0}^{n-1} \spn \{v_0(\lambda)\} \\
V_c &= V_c^+ \oplus V_c^- \\
V_\lambda &= B_\delta(0) \subset \C
\end{align*}

where the subscripts are all $\mod n$, as in the existence problem. All the product spaces are endowed with the maximum norm, e.g. for $V_c$, $|c| = \max(|c_0^-|, \dots, |c_{n-1}^-|, |c_0^+|, \dots, |c_{n-1}^+|)$. In addition, we take the following convention: if we eliminate either a subscript or a superscript (or both) in the norm, we are taking the maximum over the eliminated thing. For example,
\begin{enumerate}
	\item $|c_i| = \max(|c_i^+|, |c_i^-|)$ 
	\item $|c^+| = \max(|c_0^+|, \dots, |c_{n-1}^+|)$
\end{enumerate} 

Recall that the eigenspaces $E^s$, $E^u$, and $E^c$ refer to the constant, asymptotic matrix $A(0;, 0)$. The projections onto $E^s$, $E^u$, and $E^c$ are given by $P_0^s$, $P_0^u$, and $P_0^c$. The initial conditions on the stable and unstable subspaces lie in the corresponding spaces for the problem with $\lambda = 0$ and $\beta^\pm = 0$. By contrast, the initial conditions on the center subspace is in the eigenspace for the perturbed problem, which is useful to us since we have derived an equation for the evolution along the center subspace.\\

At this point, we can write down the fixed point equations for the problem. The fixed point equations will look like those in San98 with two main differences. First, we have the addition of a center evolution term and an initial condition in the center subspace. Second, the evolution operators $\Phi^{s/u}_\pm$ depend on both $\beta_i^\pm$ and on $\lambda$.\\

For $i = 0, \dots, n-1$, the fixed point equations are

\begin{align*}
W_i^-(x) = \Phi^s_-(&x, -X_{i-1}; \beta_i^-, \lambda) a_{i-1}^- + \Phi^u_-(x, 0; \beta_i^-, \lambda) b_i^- \\
&+ e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&+ \int_0^x \Phi^u_-(x, y; \beta_i^-, \lambda)[ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ \int_{-X_{i-1}}^x \Phi^s_-(x, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ \int_{-X_{i-1}}^x 
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
W_i^+(x) = \Phi^u_+(&x, X_i; \beta_i^+, \lambda)a_i^+ + \Phi^s_+(x, 0; \beta_i^+, \lambda)b_i^+ \\
&+ e^{\nu(\lambda)(x - X_i)} v_+(x; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&+ \int_0^x \Phi^s_+(x, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ \int_{X_i}^x \Phi^u_+(x, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ \int_{X_i}^x e^{\nu(\lambda)(x-y)} v_+(x; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Before performing the inversion, we will define the following useful constants.

\begin{enumerate}

	\item Let

	\begin{align*}
	X_m &= \min(X_0, \dots, X_{n-1}) \\
	X_M &= \max(X_0, \dots, X_{n-1}) \\
	\end{align*}

	\item Let $\delta > 0$ be a small. How small will be determined later.

	\item Fix a constant $\tilde{\alpha}$, with $0 < \tilde{\alpha} < \alpha$. The idea is that we want $\tilde{\alpha}$ to be close to $\alpha$.

	\item Recall that $\nu(\lambda) = \mathcal{O}(|\lambda|)$. Thus we can choose $\delta$ sufficiently small so that for all $|\lambda| < \delta$, $3|\nu(\lambda)| < \alpha - \tilde{\alpha}$ and $|\nu(\lambda)| < \tilde{\alpha}$.

	\item Choose $|\lambda|$ sufficiently small and $X_m$ sufficiently large such that

	\begin{equation}
	e^{-\alpha X_m}, ||G||, |\lambda|, ||\Delta H|| < \delta
	\end{equation}

\end{enumerate}


Now, as in San98 and the exponentially weighted case, we will perform the inversion of our problem in a series of lemmas. The first step is to solve for $W$ in terms of $(a, b, c, d)$.\\

First, we obtain a bound on the terms from the fixed point equations which involve $W$. 

% Inversion, lemma 1 (L1 bound)

\begin{lemma}\label{L1}

Let $L_1(\lambda): V_W \rightarrow V_W$ be the linear operator defined piecewise by

\begin{align*}
(L_1(\lambda)W)_i^-(x) &= \int_0^x \Phi^u_-(x, y; \beta_i^-, \lambda) G_i^-(y)W_i^-(y) dy + \int_{-X_{i-1}}^x \Phi^s_-(x, y; \beta_i^-, \lambda) G_i^-(y)W_i^-(y) dy \\
&+ \int_{-X_{i-1}}^x 
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
(L_1(\lambda)W)_i^+(x) &= \int_0^x \Phi^s_+(x, y; \beta_i^+, \lambda) G_i^+(y) W_i^+(y) dy + \int_{X_i}^x \Phi^u_+(x, y; \beta_i^+, \lambda) G_i^+(y) W_i^+(y) dy \\
&+ \int_{X_i}^x e^{\nu(\lambda)(x-y)} v_+(x; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Then $L_1(\lambda): V_W \rightarrow V_W$ is a bounded linear operator with uniform bound

\begin{equation}\label{L1bound2}
||L_1(\lambda)W|| \leq C e^{-(\alpha -|\nu(\lambda)|)X_m} ||W||
\end{equation}

Piecewise bounds are

\begin{align*}
||L_1(\lambda)_i^- W_i^-|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ||W_i^-|| \\
||L_1(\lambda)_i^+ W_i^+|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_i} ||W_i^+||
\end{align*}

\begin{proof}
The first two integrals on the RHS of $L_1$ have the same bound as in San98. For the third integral, we will use the piecewise bound for $G_i^\pm(x)$. For $x \leq 0$, we have

\begin{align*}
\Big| \int_{-X_{i-1}}^x &e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \Big| \\
&\leq C ||W_i^-|| \int_{-X_{i-1}}^x e^{\nu(\lambda)(x-y)} e^{-\alpha X_{i-1}}e^{-\alpha(X_{i-1} + y)}dy \\
&\leq C ||W_i^-|| \int_{-X_{i-1}}^x e^{|\nu(\lambda)| (x-y)} e^{-\alpha X_{i-1}}e^{-\alpha(X_{i-1} + y)}dy \\
&= C ||W_i^-|| e^{|\nu(\lambda)| x } e^{-2 \alpha X_{i-1}} \int_{-X_{i-1}}^x e^{-(\alpha + |\nu(\lambda)|) y} dy \\
&= C ||W_i^-|| e^{|\nu(\lambda)| x } e^{-2 \alpha X_{i-1}} \frac{1}{\alpha + |\nu(\lambda)|} \left( e^{-(\alpha + |\nu(\lambda)|)(-X_{i-1})} - e^{-(\alpha + |\nu(\lambda)|)x} \right) \\
&\leq C ||W_i^-|| e^{-2 \alpha X_{i-1}} \left( e^{(\alpha + |\nu(\lambda)|)X_{i-1}} + e^{-\alpha x}  \right) \\
&\leq C ||W_i^-|| e^{-2 \alpha X_{i-1}} \left( e^{\alpha X_{i-1}} e^{|\nu(\lambda)|X_{i-1}} + e^{\alpha X_{i-1}}  \right) \\
&\leq C ||W_i^-|| e^{-\alpha X_{i-1}} \left( e^{|\nu(\lambda)|X_{i-1}} + 1 \right) \\
&\leq C ||W_i^-|| e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} \\
\end{align*}

This can be made arbitrarily small for sufficiently large $X_{i-1}$. The $x \geq 0$ case is similar. Thus we have our piecewise bounds

\begin{align*}
||L_1(\lambda)_i^- W_i^-|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ||W_i^-|| \\
||L_1(\lambda)_i^+ W_i^+|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_i} ||W_i^+||
\end{align*}

For a uniform bound, since $\alpha -|\nu(\lambda)| > 0$, the bound depends on the smallest of the $X_i$, thus we have

\[
||L_1(\lambda)W|| \leq C e^{-(\alpha -|\nu(\lambda)|)X_m}||W||
\]

\end{proof}
\end{lemma}

Next, we obtain a bound on the terms from the fixed point equations which do not involve $W$. 

% inversion, lemma 2 (L2 bound)

\begin{lemma}\label{L2}

Let $L_2(\lambda): V_a \times V_b \times V_c \times V_d \rightarrow V_W$ be the linear operator defined piecewise by

\begin{align*}
L_2(\lambda)&(a,b,c,d)_i^-(x) = \Phi^s_-(x, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- + \Phi^u_-(x, 0; \beta_i^-, \lambda)b_i^- \\
&+ e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&+ \int_0^x \Phi^u_-(x, y; \beta_i^-, \lambda)\lambda^2 d_i \tilde{H}_i^-(y) dy + \int_{-X_{i-1}}^x \Phi^s_-(x, y; \beta_i^-, \lambda) \lambda^2 d_i \tilde{H}_i^-(y) dy \\
&+ \int_{-X_{i-1}}^x
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
L_2(\lambda)&(a,b,c,d)_i^+(x) = \Phi^u_+(x, X_i; \beta_i^+, \lambda)a_i^+ + \Phi^s_+(x, 0; \beta_i^+, \lambda)b_i^+ \\
&+ e^{\nu(\lambda)(x - X_i)} v_+(x; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&+ \int_0^x \Phi^s_+(x, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}_i^+(y) dy + \int_{X_i}^x \Phi^u_+(x, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}_i^+(y) dy \\
&+ \int_{X_i}^x e^{\nu(\lambda)(x-y)} v_+(x; \beta_i^+, \lambda) \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Then $L_2$ is a bounded linear operator with piecewise bounds

\begin{align*}\label{L2bound}
|L_2(\lambda)(a,b,c,d)_i^-| &\leq C \left( |a| + |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + |\lambda|^2 |d| \right) \\
|L_2(\lambda)(a,b,c,d)_i^+| &\leq C \left( |a| + |b| + e^{|\nu(\lambda)|X_i}|c_i| + |\lambda|^2 |d| \right)
\end{align*}

We also have the following piecewise, $x$-dependent bounds for $L_2$.

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^-(x)| &\leq C (e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + |\lambda|^2 |d| ) \\
|L_2(\lambda)(a,b,c,d)_i^+(x)| &\leq C (e^{-\alpha(X_i - x)}|a_i^+| + |b_i^+| + e^{|\nu(\lambda)|(X_i - x)} |c_i^+| + |\lambda|^2 |d| ) 
\end{align*}

\begin{proof}
Most of the bounds on the individual terms are the same as in San98. We will consider the case where $x \leq 0$. The case where $x \geq 0$ is similar. For the $c_{i-1}^-$ term we have

\[
e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \leq C e^{|\nu(\lambda)| X_{i-1} }|c_{i-1}^-|
\]

The first two integral terms are similar to San98. For the third (center) integral terms, we use the following trick involving $\tilde{\alpha}$ to eliminate any potential exponential growth.

\begin{align*}
&\left| \int_{-X_{i-1}}^x 
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \right| \\
&\leq C |\lambda|^2 |d| e^{\tilde{\alpha}x} \int_{-X_{i-1}}^x e^{-\tilde{\alpha}x} e^{\tilde{\alpha}y} e^{\nu(\lambda)(x-y)} |e^{-\tilde{\alpha}y}\tilde{H}_i^-(y)|dy \\
&\leq C |\lambda|^2 |d| e^{\tilde{\alpha}x} \int_{-X_{i-1}}^x e^{-\tilde{\alpha}(x-y)} e^{\nu(\lambda)(x-y)} |e^{-\tilde{\alpha}y}\tilde{H}_i^-(y)| dy \\
&\leq C |\lambda|^2 |d| e^{\tilde{\alpha}x} \int_{-X_{i-1}}^x e^{-(\tilde{\alpha} - |\nu(\lambda)|)(x-y)} dy \\
&\leq C |\lambda|^2 |d|
\end{align*}

where we use the facts that $|e^{-\tilde{\alpha}y}\tilde{H}_i^-(y)|$ is bounded (since $\tilde{H}$ decays exponentially with rate $\alpha$) and that $|\nu(\lambda)| < \tilde{\alpha}$ by our choice of $\tilde{\alpha}$. The other center integral is similar. Thus, we have the bound 

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^-(x)| &\leq C (e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + |\lambda|^2 |d| )
\end{align*}

For the ``positive'' piece, we have

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^+(x)| &\leq C (e^{-\alpha(X_i - x)}|a_i^+| + |b_i^+| + e^{|\nu(\lambda)|(X_i - x)} |c_i^+| + |\lambda|^2 |d| ) 
\end{align*}

For the bounds independent of $x$, we note that $e^{|\nu(\lambda)|(X_i - x)} \leq e^{|\nu(\lambda)|(X_i}$ for $x \in [0, X_i]$, and similarly for the ``negative'' piece.\\

\end{proof}
\end{lemma}

Now that we have these bounds, we can perform the inversion

% inversion lemma 3 - invert to solve for W

\begin{lemma}\label{W1}
There exists a bounded linear operator $W_1: V_\lambda \times V_a \times V_b \times V_c \times V_d \rightarrow V_W$ such that 

\[
W = W_1(\lambda)(a,b,c,d)
\]

This operator is analytic in $\lambda$ and linear in $(a, b, c, d)$. The operator $W_1$ satisfies the piecewise bounds

\begin{align*}
||W_1(\lambda)(a,b,c,d)_i^-|| &\leq C ( |a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + |\lambda|^2 |d| ) \\
||W_1(\lambda)(a,b,c,d)_i^+|| &\leq C ( |a_i^+| + |b_i^+| + e^{|\nu(\lambda)|X_i}|c_i^+| + |\lambda|^2 |d| )
\end{align*}

\begin{proof}
Let the linear operators $L_1$ and $L_2$ be defined as in the previous two lemmas. Then we can rewrite the fixed point equation as

\[
(I - L_1(\lambda))W = L_2(\lambda)(a,b,c,d)
\]

For $L_1$ we have the estimate from Lemma \ref{L1}

\begin{align*}
||L_1(\lambda)W|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_1}||W|| \\
&\leq C e^{-\tilde{\alpha} X_1}||W|| \\
&\leq C \delta ||W||
\end{align*}

Thus if we choose $\delta$ sufficiently small (i.e. smaller than $C$), the operator norm of $L_1$ is less than 1, which implies that the operator $(I - L_1(\lambda))$ is invertible. The inverse $(I - L_1(\lambda))^{-1}$ is analytic in $\lambda$ and has operator norm 

\[
||(I - L_1(\lambda))^{-1}|| \leq \frac{1}{1 - ||L_1||}
\]

We can then write $W$ as
\[
W = W_1(\lambda)(a,b,c,d) = (I - L_1(\lambda))^{-1} L_2(\lambda)(a,b,c,d)
\]

which depends linearly on $(a,b,c,d)$ and analytically on $\lambda$. Since the operator norm of $L_1$ is bounded by a constant (independent of the $X_i$), and we have a piecewise bound on $L_2$ from Lemma \ref{L2}, the piecewise bounds on $||W||$ are obtained by noting which piece of $L_2$ is involved with which piece of $W$.

\end{proof}
\end{lemma}

% lemma : x-dependent bound for W

We can combine the above lemmas to get a piecewise, $x-$dependent bound for $W$.

\begin{lemma}\label{piecewiseW1}
We have the following piecewise, $x-$dependent bounds for $W$.

\begin{align}
|W_i^-(x)| &\leq C ( e^{-\tilde{\alpha}(X_{i-1} + x)}|a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + |\lambda|^2 |d| ) \\
|W_i^+(x)| &\leq C ( e^{-\tilde{\alpha}(X_i - x)}|a_i^+| + |b_i^+| + e^{|\nu(\lambda)|(X_i - x)} |c_i^+| + |\lambda|^2 |d| )
\end{align}

\begin{proof}
Since $W = L_1(\lambda) W + L_2(\lambda)(a,b,c,d)$, we can use the $x-$dependent bound for $L_2$ and the uniform bound for $L_1$ to get for the ``negative'' piece

\begin{align*}
|W_i^-(x)| &\leq C \Big( e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ( |a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + |\lambda|^2 |d| ) + \\
&+ (e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + |\lambda|^2 |d| ) \Big) \\
&\leq C ( e^{-\tilde{\alpha}(X_{i-1} + x)}|a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + |\lambda|^2 |d| )
\end{align*}

The ``positive'' piece is similar.

\end{proof}
\end{lemma}


Before we continue, we need a bound on $P^c_0 D_i d$, since it is going to show up in what follows.

% lemma : estimate for P^0_c D_i d

\begin{lemma}\label{P0cDid}

\begin{equation}
|P^0_c(\lambda) D_i d| \leq C \left( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\end{equation}

where $P^0_c(\lambda)$ is the projection on $v_0(\lambda)$ with kernel $E^s \oplus E^u$.

\begin{proof}
Recall that we have the following expression for $D_i d$.

\[
D_i d = ( Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) + \mathcal{O} \left( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\]

The only terms we have to deal with here are $Q'(X_i)$ and $Q'(-X_i)$. Since $Q'(X_i)$ lies in the tangent space of the stable manifold at $X_i$ and $X_i$ is large, it lies mostly in $E^s$. Specifically, we have

\begin{align*}
Q'(X_i) &= P^s(X_i; 0, 0) Q'(X_i) \\
&= (P^s(X_i; 0, 0) - P^s_0) Q'(X_i) + P^s_0 Q'(X_i)
\end{align*}

The second term is eliminated outright by $P^c_0$. The projection difference should have bound $e^{-\alpha X_i}$ (CHECK THIS!). Thus, using the estimate for $Q'(X_i)$, we should have

\[
| P^0_c Q'(X_i)| \leq C e^{-2 \alpha X_i}
\]

The same estimate holds for $Q'(-X_i)$ using the unstable direction. Thus we have

\[
|P^0_c D_i d| \leq C \left( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\]

\end{proof}
\end{lemma}

The next inversion step solves for the joins at $x = \pm X_i$, i.e. solves the equations

\begin{align*}
W_i^+(X_i) - W_{i+1}^-(-X_i) &= D_i d \\
\end{align*}

% second inversion lemma

\begin{lemma}\label{inv2}

There exist operators

\begin{align*}
A_1: V_\lambda \times V_b \times V_c^- \times V_d \rightarrow V_a \times V_c^+\\
W_2: V_\lambda \times V_b \times V_c^- \times V_d \rightarrow V_W \\
\end{align*}

such that $( (a, c^+) ,W) = ( A_1(\lambda)(b,c^-,d), W_2(\lambda)(b,c^-,d) )$ solves our system. These operators are analytic in $\lambda$ and linear in $(b,c^-,d)$. Piecewise bounds are given by

\begin{align}\label{A1bound}
|A_1&(\lambda)_i(b, c_i^-, d)|
\leq C \Big( e^{-\alpha X_i} |b| + |c_i^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| + |D_i||d| \Big)
\end{align} 

and

\begin{align}
|W_2(\lambda)(b,c^-,d)_i^-|| &\leq C \Big( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| \Big) \\
|W_2(\lambda)(b,c^-,d)_i^+|| 
&\leq C \Big( |b| + e^{|\nu(\lambda)|X_i}|c_i^-| + (|\lambda|^2 + |D_i|)|d| \Big)
\end{align}

In addition, we can write $a_i^\pm$ and $c_i^+$ as 

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_2(\lambda)_i^+(b, c, d) \\
a_i^- &= -P^s_0 D_i d + A_2(\lambda)_i^-(b, c, d) \\
c_i^+ &= c_i^- + A_2(\lambda)_i^c(b, c, d) + \mathcal{O}( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| )
\end{align*}

where $A_2$ is a bounded operator with estimate

\begin{align*}
|A_2&(\lambda)_i(b, c^-, d)| \leq C ( e^{-\alpha X_i} |b| + e^{-(\tilde{\alpha} + |\nu(\lambda)|)X_i} |c_i^-| 
+ e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_i} |\lambda^2| |d| + e^{-(\alpha - |\nu(\lambda)|) X_i}|D_i||d| ) \\
\end{align*}

\begin{proof}

Evaluating the fixed point equations at $\pm X_i$, we have

\begin{align*}
W_i^+(X_i) &- W_{i+1}^-(-X_i) = P^u_+(X_i; \beta_i^+, \lambda) a_i^+ - P^s_-(-X_i; \beta_{i+1}^-, \lambda) a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i-1}^-, \lambda)b_{i+1}^- \\
&+ v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ - v_-(-X_i; \beta_{i-1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy
\end{align*}

We now manipulate this to get it into a form we can use. First, we get the coefficients $a_i^\pm$ and $c_i^\pm$ by themselves by adding and subtracting $P_0^u a_i^+$ and $P_0^s a_i^-$, and $v_0(\lambda)$. Since $a_i^- \in E^u$ and $a_i^+ \in E^s$, this becomes

\begin{align*}
D_i d &= a_i^+ - a_i^- + c_i^+ v_0(\lambda) \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-, \lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda)b_{i+1}^- \\
&+ (v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle - v_0(\lambda) ) c_i^+ \\
&- v_-(-X_i; \beta_{i+1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy
\end{align*}

Note that we are solving for the $c_i^+$ in terms of the $c_i^-$, so we only add and subtract $v_0(\lambda)$ for the $c_i^+$ term. This choice is arbitrary, i.e. we could have just as easily solved for $c_i^-$ in terms of $c_i^+$. Rearranging this, we obtain

\begin{align*}
a_i^- &- a_i^+ + c_i^+ v_0(\lambda) = -D_i d  \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-,\lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda) b_{i+1}^- \\
&+ (v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle - v_0(\lambda) ) c_i^+ \\
&- v_-(-X_i; \beta_{i+1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy
\end{align*}

We write this as

\begin{align*}
a_i^- &- a_i^+ + c_i^+ v_0(\lambda) = -D_i d + L_3(\lambda)_i(a, b, c_i^+, c_i^-, d)
\end{align*}

Where $L_3(\lambda)(a, b, c_i^+, c_i^-, d)_i$ is the rest of the terms on the RHS, i.e. 

\begin{align*}
L_3(\lambda)&(a, b, c_i^+, c_i^-, d)_i = (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-,\lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda) b_{i+1}^- \\
&+ (v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle - v_0(\lambda)) c_i^+ \\
&- v_-(-X_i; \beta_{i+1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy
\end{align*}

For a bound on $L_3$, we have seen most of the terms before. For the bound on the integral term involving $\tilde{H}_i^\pm$, we use the $\tilde{\alpha}$ trick to get a better bound. Anticipating what will come below, we will also give us an extra $|\nu(\lambda)|$ padding, so that we can absorb a factor of $|\nu(\lambda)|$ later. For the ``positive'' piece, this bound is

\begin{align*}
\left| \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) \tilde{H}_i^+(y) dy \right| 
&\leq C \int_0^{X_i} e^{-\alpha (X_i - y)}|\tilde{H}_i^+(y)| dy \\
&= C e^{-(\tilde{\alpha}+|\nu(\lambda)|)X_i} \int_0^{X_i} e^{-\alpha X_i} e^{\alpha y}  e^{(\tilde{\alpha}+|\nu(\lambda)|)X_i} e^{-(\tilde{\alpha}+|\nu(\lambda)|)y} |e^{(\tilde{\alpha}+|\nu(\lambda)|)y} \tilde{H}_i^+(y)| \\
&= C e^{-(\tilde{\alpha}+|\nu(\lambda)|)X_i} \int_0^{X_i} e^{-(\alpha - \tilde{\alpha} - |\nu(\lambda|)(X_i-y)} |e^{\tilde{\alpha}y} \tilde{H}_i^+(y)|\\
&\leq C e^{-(\tilde{\alpha}+|\nu(\lambda)|)X_i} 
\end{align*}

where we again used the fact that $|e^{\tilde{\alpha}y} \tilde{H}_i^+(y)|$ is bounded, since $\tilde{\alpha} < \alpha$ and $\tilde{H}_i^+(y)$ decays with rate $\alpha$. The ``negative'' piece is similar.\\

For the integral term involving $W$, we use the piecewise bound on $W_i^+$ from Lemma \ref{W1}. For the ``positive'' piece, we have

\begin{align*}
&\left| \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) G_i^+(y) W_i^+(y) dy \right| \\
&\leq C \int_0^{X_i} e^{-\alpha(X_i - y)}|G_i^+(y)|(|a_i^+| + |b_i^+| + e^{|\nu(\lambda)|X_i}|c_i^+| + |\lambda|^2 |d| ) dy \\
&\leq C \left( e^{-\alpha X_i} (|a| + |b_i^+| + |\lambda|^2 |d|) + \int_0^{X_i} e^{-\alpha(X_i - y)}|G_i^+(y)|e^{|\nu(\lambda)|X_i}|c_i^+| dy \right) \\
&\leq C \left( e^{-\alpha X_i} (|a| + |b_i^+| + |\lambda|^2 |d|) + \int_0^{X_i} e^{-\alpha(X_i - y)}e^{-\alpha X_i} e^{-\alpha(X_i - y)} e^{|\nu(\lambda)|X_i}|c_i^+| dy \right)\\
&\leq C \left( e^{-\alpha X_i} (|a| + |b_i^+| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i^+| \int_0^{X_i} e^{-2\alpha(X_i - y)} dy \right) \\
&\leq C \left( e^{-\alpha X_i} (|a| + |b_i^+| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i^+| \right)
\end{align*}

where we used the fact that $|\nu(\lambda)| \leq \alpha$. The ``negative'' piece is similar. This works out the way we want, since the ``negative'' piece involves $W_{i+1}$, but the piecewise bound for $W_{i+1}$ involves $c_i^-$.

\begin{align*}
&\left| \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) G_{i+1}^-(y) W_{i+1}^-(y) dy \right| \\
&\leq C \left( e^{-\alpha X_i} (|a| + |b_{i+1}^-| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i^-| \right)
\end{align*}

For the piece involving $c_i^+$, we have

\begin{align*}
|v_+(X_i; &\beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle - v_0(\lambda) | |c_i^+| \\
&= |v_+(X_i; \beta_i^+, \lambda) (\langle v_0(\lambda), w_0(\lambda) \rangle + \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle) - v_0(\lambda) | |c_i^+| \\
&\leq (|v_+(X_i; \beta_i^+, \lambda) - v_0(\lambda)| 
+ |v_+(X_i; \beta_i^+, \lambda)||\langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle|)|c_i^+| \\
&\leq p_2(X_i, \lambda)|c_i^+|
\end{align*}

Thus we have the following bound for $L_3$.

\begin{align*}
L_3(\lambda)&(a, b, c_i^+, c_i^-, d)_i \leq C ( p_1(X_i; \lambda)|a_i|
+ e^{-\alpha X_i}(|b_i^+| + |b_{i+1}^-|) + p_2(X_i; \lambda)|c_i^+| + |c_i^-| \\
&+ e^{-\alpha X_i}(|a| + |b_i^+| + |b_{i+1}^-| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| )
\end{align*}

where $p_1(\lambda)$ is defined in Lemma \ref{projbounds}, and $p_2(X_i; \lambda)$ is defined in Lemma \ref{centerbounds}.\\

Combining terms and simplifying, the final bound for $L_3$ is

\begin{align*}
L_3(\lambda)&(a, b, c_i^+, c_i^-, d)_i \leq C ( (p_1(X_m; \lambda) + e^{-\alpha X_m})|a_i|
+ e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-|) \\
&+ (p_2(X_m; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i})|c_i^+| + |c_i^-| \
+ e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| )
\end{align*}

We use Lemma \ref{projbounds} for a bound on $p_1(X_m; \lambda)$ and Lemma \ref{centerbounds} for a bound on $p_2(X_i; \lambda)$. Taking $X_m$ sufficiently large, we have

\begin{align*}
L_3(\lambda)&(a, b, c^+, c^-, d)\leq C (\delta (|a| + |c^+|) + e^{-\alpha X_i}(|b_i^+| + |b_{i+1}^-|) + |c^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d|)
\end{align*}

Let $J_1: \bigoplus_{j=1}^n (E^s \times E^u \times E^c) \rightarrow \bigoplus_{j=1}^n \rightarrow \C^{2m+1}$ be defined by $(J_1)_i(a_i^+, a_i^-, c_i^+) = (a_i^+ - a_i^-, c_i^+ v_0(0) )$. The map $J_i$ is a linear isomorphism since $E^s \oplus E^u \oplus E^c = \C^{2m + 1}$. Now consider the map

\[
S_1(a, c^+) = J_1 (a, c^+) + L_3(\lambda)(a, 0, c^+, 0, 0) = J_1( I + J_1^{-1} L_3(\lambda)(a, 0, c^+, 0, 0))
\]

For sufficiently small $\delta$, we can get the operator norm $||J_1^{-1} L_3(\lambda)(a, 0, c^+, 0, 0)|| < 1$, thus the operator $S_1(a, c^+)$ is invertible. We can solve for $(a, c^+)$ to get

\[
(a, c^+) = A_1(\lambda)(b, c^-, d) = S_i^{-1}(-D d + L_3(\lambda)(0, b, 0, c^-, d)
\]

Using the bound on $L_3$ and noting which piece we are dealing with, $A_1$ will have piecewise bounds

\begin{align*}
|A_1&(\lambda)_i(b, c_i^-, d)|
\leq C \Big( e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-|) + |c_i^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| + |D_i||d| \Big)
\end{align*} 

A bound which is uniform in $|b|$ is 

\begin{align*}
|A_1&(\lambda)_i(b, c_i^-, d)|
\leq C \Big( e^{-\alpha X_i} |b| + |c_i^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| + |D_i||d| \Big)
\end{align*} 

Recall that $C^{2m+1} = E^s \oplus E^u \oplus \R v_0(\lambda)$. Next, we hit our expression for $D_i d$ with the projections $P^s_0$, $P^u_0$, and $P^c_0(\lambda)$ (the projections on these three components) to eliminate some of the terms. This time we add and subtract $v_0(\lambda)$ for both of the $c_i^\pm$ terms so we can get $(c_i^+ - c_i^-)v_0(\lambda)$ on the LHS.

\begin{align*}
a_i^- &- a_i^+ + (c_i^+ - c_i^-)v_0(\lambda) = -D_i d  \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-,\lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda) b_{i+1}^- \\
&+ (v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle - v_0(\lambda) ) c_i^+ \\
&- (v_-(-X_i; \beta_{i+1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle - v_0(\lambda) ) c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy
\end{align*}

Let $\tilde{L}_3(\lambda)_i(a, b, c_i^+, c_i^-, d)$ be everything on the RHS of this except for the $D_i d$ term.  We take projections $P^s_0$, $P^u_0$, and $P^c_0(\lambda)$ individually. This becomes

\begin{align*}
a_i^+ &= P^u_0 D_i d - P^u_0 \tilde{L}_3(\lambda)_i(a, b, c_i^+, c_i^-, d) \\
a_i^- &= -P^s_0 D_i d + P^s_0 \tilde{L}_3(\lambda)_i(a, b, c_i^+, c_i^-, d) \\
(c_i^+ - c_i^-)v_0(0) &= -P^c_0(\lambda) D_i d + P^c_0(\lambda) \tilde{L}_3(\lambda)_i(a, b, c_i^+, c_i^-, d) \\
\end{align*}

Define $A_2$ to be all the stuff on the RHS other than the $D_i d$ term. Using the bound for $P^c_0 D_i d$ from Lemma \ref{P0cDid}, we have

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_2(\lambda)_i^+(b, c^-, d) \\
a_i^- &= -P^s_0 D_i d + A_2(\lambda)_i^-(b, c^-, d) \\
c_i^+ &= c_i^- + A_2(\lambda)_i^c(b, c^-, d) + \mathcal{O}( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| )
\end{align*}

We can come up with a bound for $A_2$ using the bound for $A_1$ and the estimates we have already done. Plugging in $A_1$ for $a_i^\pm$ and $c_i^+$ and using the bounds for $p_1$ from Lemma \ref{projbounds} and $p_3$ from Lemma \ref{centerbounds}, we have

\begin{align*}
|A_2&(\lambda)_i(b, c^-, d)| \leq C ( (p_1(X_i; \lambda) + e^{-\alpha X_i})|A_1(\lambda)_i(b, c_i^-, d)| + e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-|) \\
&+ (p_2(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i})|A_1(\lambda)_i(b, c_i^-, d)|
+ (p_2(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i})|c_i^-| \\
&+ e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_i} |\lambda^2| |d| ) \\
&\leq C ( (p_1(X_i; \lambda) + p_2(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i})( e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-|) + |c_i^-| + e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_i} |\lambda^2| |d| + |D_i||d|) \\
&+ e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-|) + (p_2(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i})|c_i^-| \
+ e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_i} |\lambda^2| |d| ) \\
&\leq C ( e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-|) + (e^{-(\tilde{\alpha} + |\nu(\lambda)|)X_i} + e^{-(\alpha - |\nu(\lambda)|)X_i})|c_i^-| \
+ e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_i} |\lambda^2| |d| + e^{-(\alpha - |\nu(\lambda)|) X_i}|D_i||d| ) \\
&\leq C ( e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-|) + e^{-(\tilde{\alpha} + |\nu(\lambda)|)X_i} |c_i^-| 
+ e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_i} |\lambda^2| |d| + e^{-(\alpha - |\nu(\lambda)|) X_i}|D_i||d| ) \\
\end{align*}

Alternatively, we can make this uniform in $|b|$.

\begin{align*}
|A_2&(\lambda)_i(b, c^-, d)| \leq C ( e^{-\alpha X_i} |b| + e^{-(\tilde{\alpha} + |\nu(\lambda)|)X_i} |c_i^-| 
+ e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_i} |\lambda^2| |d| + e^{-(\alpha - |\nu(\lambda)|) X_i}|D_i||d| ) \\
\end{align*}

Finally, we plug in $A_1$ for $a_i^\pm$ and $c_i^+ = c_i^- + A_2(\lambda)_i^c(b, c^-, d) + \mathcal{O}( e^{-\alpha X_i} (|\lambda| +  e^{-\alpha X_i} ) |d| )$ in our expression for $W_1$ to get $W_2(\lambda)$, which has piecewise bounds

\begin{align*}
|W_2(\lambda)(b,c^-,d)_i^-|| &\leq C \Big( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| \Big) \\
|W_2(\lambda)(b,c^-,d)_i^+|| 
&\leq C \Big( |b| + e^{|\nu(\lambda)|X_i}|c_i^-| + (|\lambda|^2 + |D_i|)|d| \Big)
\end{align*}

We can do the same thing for the piecewise, $x-$dependent bounds.

\begin{align*}
|W_i^-(x)| &\leq C ( |b| + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + e^{-\tilde{\alpha}(X_{i-1} + x)}|D_{i-1}||d| + |\lambda|^2 |d| ) \\
|W_i^+(x)| &\leq C ( |b| + e^{|\nu(\lambda)|(X_i - x)} |c_i^-| + e^{-\tilde{\alpha}(X_i - x)}|D_i||d| + |\lambda|^2 |d| )
\end{align*}

\end{proof}
\end{lemma}

Up to now, things have not been too complicated, and we have actually been able to get piecewise bounds. Going forward, that will be more difficult as things ``mix''.\\

The final step is to satisfy the conditions

\begin{align*}
W_i^\pm(0) &\in \C \Psi(0) \oplus Y^0 \oplus Y^+ \oplus Y^- \\
W_i^+(0) - W_i^-(0) &\in \C \Psi(0)
\end{align*}

In other words, we allow the remainder terms $W_i^\pm(0)$ to perturb in any direction other than along $Q'(0)$, but we require the jump to only be in the direction of $\Psi(0)$.

Recall that

\[
\C^m = \C \Psi(0) \oplus \C Q'(0) \oplus Y^0 \oplus Y^+ \oplus Y^- 
\]

This condition is equivalent to the three projections

\begin{align*}
P(\C Q'(0))W_i^-(0) &= 0 \\
P(\C Q'(0))W_i^+(0) &= 0 \\
P(Y^+ \oplus Y^- \oplus Y^0) ( W_i^+(0) - W_i^-(0) ) &= 0
\end{align*}

where the kernel of each projection is the remaining spaces in the direct sum. We can ignore $\C Q'(0)$ in the third equation since we ditched any component in it in the first two equations. Splitting up the third projection, this is equivalent to the four projections

\begin{align*}
P(\C Q'(0))W_i^-(0) &= 0 \\
P(\C Q'(0))W_i^+(0) &= 0 \\
P(Y^+ \oplus Y^-) ( W_i^+(0) - W_i^-(0) ) &= 0 \\
P(Y^0) ( W_i^+(0) - W_i^-(0) ) &= 0
\end{align*}

Since the stable and unstable range spaces at $\lambda = 0$ both contain $\C Q'(0)$, we can decompose $b^\pm$ uniquely as $b^\pm = x^\pm + y^\pm$, where $x^\pm \in \C Q'(0)$ and $y^\pm \in Y^\pm$.\\

In the following lemma, we will solve the first three of these, i.e. 

\begin{align*}
P(\C Q'(0))W_i^-(0) &= 0 \\
P(\C Q'(0))W_i^+(0) &= 0 \\
P(Y^+ \oplus Y^-) ( W_i^+(0) - W_i^-(0) ) &= 0 \\
\end{align*}

This will give us $b_i$ in terms of the $c_i$ and $d$.\\

% inversion 3

\begin{lemma}\label{inv3}
There exists operators

\begin{align*}
B_1: V_\lambda \times V_c^- \times V_d \rightarrow V_b \\
A_3: V_\lambda \times V_c^- \times V_d \times V_d \rightarrow V_a \\
W_3: V_\lambda \times V_c^- \times V_d \times V_d \rightarrow V_W \\
\end{align*}

such that $( (a, c^+) , b, W) = ( A_3(\lambda)(c^-,d), B_1(\lambda)(c^-, d), W_3(\lambda)(c^-,d) )$ solves our system. These operators are analytic in $\lambda$ and linear in $(c^-,d)$. Uniform bounds for $B_1$ and $A_3$ are given by

\begin{align}
|B_1(\lambda)(c, d)| &\leq C \Big( e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2 |d| \Big) \\
|A_3(\lambda)_i(b, c^-, d)| &\leq C \Big( e^{-\alpha X_m} |c^-| + |c_i^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| + |D||d| \Big)
\end{align} 

Piecewise bounds for $W_3$ are given by

\begin{align}
|W_3(\lambda)(b,c^-,d)_i^-|| &\leq C \Big( e^{-\alpha X_m} |c^-| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + (|\lambda|^2 + |D|)|d| \Big) \\
|W_3(\lambda)(b,c^-,d)_i^+|| 
&\leq C \Big( e^{-\alpha X_m} |c^-| + e^{|\nu(\lambda)|X_i}|c_i^-| + (|\lambda|^2 + |D|)|d| \Big)
\end{align}

Again, we can write

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_4(\lambda)_i^+(c^-, d) \\
a_i^- &= -P^s_0 D_i d + A_4(\lambda)_i^-(c^-, d) \\
c_i^+ &= c_i^- + A_4(\lambda)_i^c(c^-, d) + \mathcal{O}( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| )
\end{align*}

where $A_4(\lambda)(c^-, d)$ is analytic in $\lambda$ and linear in $c^-, d$ and has bound

\begin{align}
|A_4&(\lambda)_i(c^-, d)| \leq C e^{-(\tilde{\alpha} + |\nu(\lambda)|)X_i} ( |c^-| + |\lambda^2| |d| + |D||d| )
\end{align}

\begin{proof}

At $x = 0$, the fixed point equations become

\begin{align*}
W_i^-(0) = \Phi^s_-(&0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- + x_i^- + y_i^- + (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \\
&+ v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \\
&+ \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
W_i^+(0) = \Phi^u_+(&0, X_i; \beta_i^+, \lambda)a_i^+ + x_i^+ + y_i^+ + (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ \\
&+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle e^{-\nu(\lambda) X_i} c_i^+ \\
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

where we have added and subtracted $P^s_-(0; 0, 0))b_i^+ = b_i^+$ and $P^u_-(0; 0, 0))b_i^- = b_i^-$ and substituted $b_i^\pm = x_i^\pm + y_i^\pm$. Since one of the projections is on $Y^0 = v_+(0; 0, 0 = v_-(0; 0, 0)$, we need to manipulate things to make that happen. For the ``negative'' piece, we have

\begin{align*}
v_-(0; \beta_i^-, \lambda) &\langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle
= v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_0(\lambda)) \rangle
+ v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) - w_0(\lambda) \rangle \\
&= v_-(0; \beta_i^-, \lambda)
+ v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) - w_0(\lambda) \rangle \\
&= v_-(0; 0, 0) + (v_-(0; \beta_i^-, \lambda) - v_-(0; 0, 0))
+ v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) - w_0(\lambda) \rangle
\end{align*}

Similarly

\begin{align*}
v_+(0; \beta_i^+, \lambda)
&= v_+(0; 0, 0) + (v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0))
+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle
\end{align*}

Substituting these in, and adding/subtracting $v_\pm(0; 0, 0)$ in the ``center'' integral terms, we get

\begin{align*}
W_i^-(0) = \Phi^s_-(&0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- + x_i^- + y_i^- + (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- + v_-(0; 0, 0) e^{\nu(\lambda)X_{i-1}} c_{i-1}^-\\
&+ ((v_-(0; \beta_i^-, \lambda) - v_-(0; 0, 0))
+ v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) - w_0(\lambda) \rangle) e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \\
&+ \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ v_-(0; 0; 0) \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
&+ (v_-(0; \beta_i^-, \lambda) - v_-(0; 0; 0) )\int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
W_i^+(0) = \Phi^u_+(&0, X_i; \beta_i^+, \lambda)a_i^+ + x_i^+ + y_i^+ + (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ + v_+(0; 0, 0) e^{-\nu(\lambda) X_i} c_i^+\\
&+ ((v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0))
+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle) e^{-\nu(\lambda) X_i} c_i^+ \\
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ v_+(0; 0, 0) \int_{X_i}^0 e^{\nu(\lambda)y} \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&+ (v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0)) \int_{X_i}^0 e^{\nu(\lambda)y}  \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Plug these expressions for $W_i^\pm(0)$ into the above set of projections. We get the matrix equation

\[
\begin{pmatrix}x_i^- \\ x_i^+ \\ 
y_i^+ - y_i^- \end{pmatrix} + L_4(\lambda)_i(b, c, d) = 0
\]

The $L_4(\lambda)_i(b, c^-, d)$ term contains the terms that don't get eliminated outright by the projections. $L_4(\lambda)$ does not depend on $a$, $c_+$, or $W$ since we already solved for them in the previous lemmas and will make the appropriate substitutions.\\

Now we estimate the terms one by one. First we look at the noncenter integrals involving $W$. For the ``negative'' piece, we have

\begin{align*}
&\left| \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) G_i^-(y)W_i^-(y) dy \right| \\
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} |W_i^-(y)| dy \\
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha X_{i-1}} e^{-(\tilde{\alpha} + |\nu(\lambda)|)(X_{i-1} + y)} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| ) dy \\
&\leq C e^{-\alpha X_{i-1} } e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_{i-1}}( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| ) \int_{-X_{i-1}}^0 e^{(\alpha - \tilde{\alpha} - |\nu(\lambda)|)y} dy \\
&\leq C e^{-(\alpha + \tilde{\alpha}) X_{i-1}}( |b| + |c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| )
\end{align*}

Similarly, for the ``positive'' piece,

\begin{align*}
&\left| \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) G_i^+(y)W_i^+(y) dy \right| \\
&\leq C e^{-(\alpha + \tilde{\alpha}) X_i}( |b| + |c_i^-| + (|\lambda|^2 + |D_i|)|d| )
\end{align*}

For the noncenter integrals not involving $W$,

\begin{align*}
&\left| \int_{-X_{i-1}}^0
\Phi^s_-(0, y; \beta_i^-, \lambda) \lambda^2 d_i \tilde{H}_i^-(y) dy \right| \\
&\leq C |\lambda|^2 |d_i| \int_{-X_{i-1}}^0 e^{\alpha y} e^{\alpha y} dy \\
&\leq C |\lambda|^2 |d| 
\end{align*}

The other piece is similar. Next, we look at the center integrals. For the integrals involving $W$, we have for the ``negative'' piece,

\begin{align*}
&\left| \int_{-X_{i-1}}^0 \langle G_i^-(y) W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \right| \\
&\leq C \int_{-X_{i-1}}^0 e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} |W_i^-(y)| dy \\
&\leq C \int_{-X_{i-1}}^0 e^{-\alpha X_{i-1}} e^{-(\tilde{\alpha} + |\nu(\lambda)|)(X_{i-1} + y)} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| ) dy \\
&\leq C e^{-\alpha X_{i-1}} \int_{-X_{i-1}}^0  e^{-\tilde{\alpha}(X_{i-1} + y)} ( |b| + |c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| ) dy \\
&\leq C e^{-\alpha X_{i-1}} ( |b| + |c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| )
\end{align*}

Similarly, for the ``positive'' piece

\begin{align*}
&\left| \int_{X_i}^0 \langle G_i^+(y) W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \right| 
&\leq C e^{-\alpha X_i}  ( |b| + |c_i^-| + (|\lambda|^2 + |D_i|)|d| )
\end{align*}

For the center integrals not involving $W$, we have

\begin{align*}
&\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \right| \\
&\leq C |\lambda|^2 |d| \int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y}e^{\alpha y} dy \\
&\leq C |\lambda|^2 |d| \int_{-X_{i-1}}^0 e^{(\alpha -|\nu(\lambda)|) y} dy \\
&\leq C |\lambda|^2 |d| 
\end{align*}

Thus we have the following bound on $L_4(\lambda)$. Recall that all the terms involving $v_\pm(0; 0, 0)$ are eliminated outright by these projections.

\begin{align*}
|L_4&(\lambda)_i(b, c^-, d)|\\ 
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + p_5(\beta_i^+, \beta_i^-, \lambda) |b_i| \\
&+ p_4(\beta_i, \lambda)( |e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| + |e^{-\nu(\lambda)X_i} c_i^+|) \\
&+ (e^{-(\alpha + \tilde{\alpha}) X_{i-1}} + e^{-\alpha X_{i-1}} p_4(\beta_i, \lambda))( |b| + |c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| ) \\
&+ (e^{-(\alpha + \tilde{\alpha}) X_i} + e^{-\alpha X_i} p_4(\beta_i, \lambda))( |b| + |c_i^-| + (|\lambda|^2 + |D_i|)|d| ) \\
&+ |\lambda|^2 |d|  \Big)
\end{align*}

where $p_5(X; \lambda)$ is defined in Lemma \ref{projbounds} and $p_4(\beta_i, \lambda)$ is defined in Lemma \ref{centerbounds}. The one remaining thing to do before simplifying is to swap out $c_i^+$ for $c_i^-$ using the previous lemma. From there, we have

\[
c_i^+ = c_i^- + A_2(\lambda)_i^c(b, c^-, d) + \mathcal{O}( e^{-\alpha X_i} (|\lambda| +  e^{-\alpha X_i} ) |d| )
\]

Substituting the bound for $A_2$ from Lemma \ref{inv2}, we have

\begin{align*}
e^{-\nu(\lambda)X_i} c_i^+ &= e^{-\nu(\lambda)X_i} c_i^- + \mathcal{O}( e^{-\tilde{\alpha} X_i} |b| + e^{-\tilde{\alpha} X_i} |c_i^-| + e^{-\tilde{\alpha} X_i} |\lambda^2| |d| + e^{-\tilde{\alpha} X_i}|D_i||d| + e^{-\tilde{\alpha} X_i} (|\lambda| +  e^{-\alpha X_i} ) |d| ) \\
&= e^{-\nu(\lambda)X_i} c_i^- + \mathcal{O}\Big( e^{-\tilde{\alpha} X_i}(|b| + |c_i^-| + (|\lambda| + |D_i|)|d| ) \Big)
\end{align*}

Substituting this into the bound for $L_4$, we have

\begin{align*}
|L_4&(\lambda)_i(b, c^-, d)|\\ 
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + p_5(\beta_i^+, \beta_i^-, \lambda) |b_i| \\
&+ p_4(\beta_i, \lambda)( |e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| + |e^{-\nu(\lambda)X_i} c_i^-|) \\
&+ p_4(\beta_i, \lambda)e^{-\tilde{\alpha} X_i}(|b| + |c_i^-| + (|\lambda| + |D_i|)|d| ) \\
&+ (e^{-(\alpha + \tilde{\alpha}) X_{i-1}} + e^{-\alpha X_{i-1}} p_4(\beta_i, \lambda))( |b| + |c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| ) \\
&+ (e^{-(\alpha + \tilde{\alpha}) X_i} + e^{-\alpha X_i} p_4(\beta_i, \lambda))( |b| + |c_i^-| + (|\lambda|^2 + |D_i|)|d| ) \\
&+ |\lambda|^2 |d|  \Big)
\end{align*}

Substituting the bound for $p_4$ and $p_5$, this becomes

\begin{align*}
|L_4&(\lambda)_i(b, c^-, d)|\\ 
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + (|\lambda| + e^{-2 \alpha X_m}) |b_i| \\
&+ (|\lambda| + e^{-2 \alpha X_m})( |e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| + |e^{-\nu(\lambda)X_i} c_i^-|) \\
&+ (|\lambda| + e^{-2 \alpha X_m})e^{-\tilde{\alpha} X_i}(|b| + |c_i^-| + (|\lambda| + |D_i|)|d| ) \\
&+ (e^{-(\alpha + \tilde{\alpha}) X_{i-1}} + e^{-\alpha X_{i-1}} (|\lambda| + e^{-2 \alpha X_m}))( |b| + |c_{i-1}^-| + (|\lambda|^2 + |D_{i-1}|)|d| ) \\
&+ (e^{-(\alpha + \tilde{\alpha}) X_i} + e^{-\alpha X_i} (|\lambda| + e^{-2 \alpha X_m}))( |b| + |c_i^-| + (|\lambda|^2 + |D_i|)|d| ) \\
&+ |\lambda|^2 |d|  \Big)
\end{align*}

simplifying and eliminating higher order terms, this becomes

\begin{align*}
|L_4&(\lambda)_i(b, c^-, d)|\\ 
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + (|\lambda| + e^{-(\alpha + \tilde{\alpha}) X_m})|b| \\
&+ (|\lambda| + e^{-2 \alpha X_m})( |e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| + |e^{-\nu(\lambda)X_i} c_i^-|) \\
&+ e^{-\alpha X_{i-1}}( e^{-\tilde{\alpha} X_{i-1}} + |\lambda|)( |c_{i-1}^-| + |D_{i-1}||d| ) \\
&+ e^{-\alpha X_i}( e^{-\tilde{\alpha} X_i} + |\lambda|)( |c_i^-| + |D_i||d| ) \\
&+ |\lambda|^2 |d|  \Big)
\end{align*}

To finish the bound, we plug in $A_1$ for $|a|$ to get

\begin{align*}
|L_4&(\lambda)_i(b, c^-, d)|\\ 
&\leq C \Big( e^{-\alpha X_i} ( e^{-\alpha X_i} |b| + |c_i^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| + |D_i||d| ) \\
&+  e^{-\alpha X_{i-1}} ( e^{-\alpha X_{i-1}} |b| + |c_{i-1}^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_{i-1}} |\lambda^2| |d| + |D_{i-1}||d| ) \\
&+ (|\lambda| + e^{-(\alpha + \tilde{\alpha}) X_m})|b| \\
&+ (|\lambda| + e^{-2 \alpha X_m})( |e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| + |e^{-\nu(\lambda)X_i} c_i^-|) \\
&+ e^{-\alpha X_{i-1}}( e^{-\tilde{\alpha} X_{i-1}} + |\lambda|)( |c_{i-1}^-| + |D_{i-1}||d| ) \\
&+ e^{-\alpha X_i}( e^{-\tilde{\alpha} X_i} + |\lambda|)( |c_i^-| + |D_i||d| ) \\
&+ |\lambda|^2 |d|  \Big) \\
&\leq C \Big( 
(|\lambda| + e^{-(\alpha + \tilde{\alpha}) X_m})|b| \\
&+ (|\lambda| + e^{-2 \alpha X_m})( |e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| + |e^{-\nu(\lambda)X_i} c_i^-|) \\
&+ e^{-\alpha X_{i-1}}( |c_{i-1}^-| + |D_{i-1}||d| ) \\
&+ e^{-\alpha X_i}( |c_i^-| + |D_i||d| ) \\
&+ |\lambda|^2 |d|  \Big)
\end{align*}

To do the inversion, we take $X_m$ sufficiently large and $|\lambda|$ sufficiently small, so that we have

\begin{align*}
|L_4&(\lambda)_i(b, c^-, d)| \leq C \Big( 
\delta |b| + (|\lambda| + e^{-2 \alpha X_m})( |e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| + |e^{-\nu(\lambda)X_i} c_i^-|) \\
&+ e^{-\alpha X_{i-1}}(|c_{i-1}^-| + |D_{i-1}||d| ) + e^{-\alpha X_i}( |c_i^-| + |D_i||d| ) + |\lambda|^2 |d|  \Big)
\end{align*}

which is a uniform bound in $|b|$. Thus for sufficiently small $\delta$, we can perform the inversion, as in the previous two lemmas. Recall that $\R^{2m} = \R Q'(0) \oplus Y^+ \oplus Y^-$. As in San98, define the map

\[
J_2: \left( \bigoplus_{j=1}^n \C Q'(0) \oplus \C Q'(0) \right) \oplus
\left( \bigoplus_{j=1}^n Y^+ \oplus Y^- \right) 
\rightarrow \bigoplus_{j=1}^n \C Q'(0) \oplus \C Q'(0) \oplus (Y^+ \oplus Y^-)
\]

by 

\[
J_2( (x_i^+, x_i^-),(y_i^+, y_i^-))_i = ( x_i^+, x_i^-, y_i^+ - y_i^- )
\]

Then $J_2$ is an isomorphism. We can write our problem as 

\[
J_2( (x_i^+, x_i^-),(y_i^+, y_i^-))_i 
+ L_4(\lambda)_i(b_i, 0, 0) + L_4(\lambda)_i(0, c, d) = 0
\]

Recalling that $b_i = (x_i^- + y_i^-, x_i^+ + y_i^+)$, let

\begin{align*}
S_2(b)_i &= J_2( (x_i^+, x_i^-),(y_i^+, y_i^-))_i 
+ L_4(\lambda)_i(b_i, 0, 0) 
\end{align*}

Substituting this in, we have

\begin{align*}
S_2(b) &= -L_4(\lambda)(0, c, d)
\end{align*}

For sufficiently small $\delta$, the operator $S_2$ is invertible, thus we have

\begin{align}
b = B_1(\lambda)(c,d) 
= -S_2^{-1} ( J_2(0, 0,L_4(\lambda)(0, c, d)
\end{align}

The bound on $B_1$ is given by the bound on $L_4$, where we note which piece is involved.

\begin{align*}
|B_1(\lambda)_i(c, d)| &\leq C \Big( 
(|\lambda| + e^{-2 \alpha X_m})( |e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| + |e^{-\nu(\lambda)X_i} c_i^-|) \\
&+ e^{-\alpha X_{i-1}}( |c_{i-1}^-| + |D_{i-1}||d| ) 
+ e^{-\alpha X_i}( |c_i^-| + |D_i||d| ) 
+ |\lambda|^2 |d| \Big)
\end{align*}

Putting this in terms of $X_m$ (where appropriate), this becomes

\begin{align*}
|B_1(\lambda)_i(c, d)| &\leq C \Big( (|\lambda| + e^{-2 \alpha X_m})( |e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| + |e^{-\nu(\lambda)X_i} c_i^-|)
+ e^{-\alpha X_m} ( |c^-| + |D||d| )
+ |\lambda|^2 |d| \Big)
\end{align*}

Finally, we plug this in $A_1$, $A_2$, and $W_2$ from Lemma \ref{inv2}. As we can see, this will quickly become a mess, due to all the terms of the form $|e^{\pm \nu(\lambda)X_i} c_i^-|$ which will result. In an attempt to make things simpler, we will define

\[
\tilde{c}_i^\pm = e^{\pm \nu(\lambda)X_i} c_i^-
\]

where we note that the $\pm$ on the $\tilde{c}_i^\pm$ indicates the sign in front of $\nu(\lambda)$ in the exponent. Thus we have

\begin{align*}
|B_1(\lambda)_i(c, d)| &\leq C \Big( (|\lambda| + e^{-2 \alpha X_m})( |\tilde{c}_{i-1}^-| + |\tilde{c}_i^+|)
+ e^{-\alpha X_m} ( |c^-| + |D||d| )
+ |\lambda|^2 |d| \Big)
\end{align*}

For now, we will use a uniform bound

\begin{align*}
|B_1(\lambda)_i(c, d)| &\leq C \Big( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| 
+ e^{-\alpha X_m} ( |c^-| + |D||d| )
+ |\lambda|^2 |d| \Big)
\end{align*}

Plugging this into $A_1$, we get $A_3$, which has uniform bound

\begin{align*}
|A_3&(\lambda)(b, c^-, d)|
\leq C \Big( e^{-\alpha X_i} ((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| 
+ e^{-\alpha X_m} ( |c^-| + |D||d| )
+ |\lambda|^2 |d) \\
&+ |c_i^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| + |D_i||d| \Big) \\
&\leq C \Big( e^{-\alpha X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| 
+ |c^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| + |D||d| \Big)
\end{align*} 

Plug this into $W_2$ to get $W_3(\lambda)$, which has piecewise bounds

\begin{align*}
||W_3(\lambda)(b,c^-,d)_i^-|| &\leq C \Big( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} |c^-| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + (|\lambda|^2 + |D|)|d| \Big) \\
||W_3(\lambda)(b,c^-,d)_i^+|| 
&\leq C \Big( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} |c^-| + e^{|\nu(\lambda)|X_i}|c_i^-| + (|\lambda|^2 + |D|)|d| \Big)
\end{align*}

We can do the same thing for the piecewise, $x-$dependent bounds.

\begin{align*}
|W_i^-(x)| &\leq C ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + e^{-\tilde{\alpha}(X_{i-1} + x)}|D_{i-1}||d| + |\lambda|^2 |d| ) \\
|W_i^+(x)| &\leq C ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + e^{|\nu(\lambda)|(X_i - x)} |c_i^-| + e^{-\tilde{\alpha}(X_i - x)}|D_i||d| + |\lambda|^2 |d| )
\end{align*}

Finally, we plug $B_1$ into $A_2$ to get $A_4$.

\begin{align*}
|A_4&(\lambda)_i(c^-, d)| \leq C ( e^{-\alpha X_i} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\tilde{\alpha} + |\nu(\lambda)|)X_i} |c^-| 
+ e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_i} |\lambda^2| |d| + e^{-(\alpha - |\nu(\lambda)|) X_i}|D||d| ) \\
\end{align*}

\end{proof}
\end{lemma}

\subsection{Jump Conditions}

We have jump equations in two directions: $Y_0$ and $\Psi(0)$. We will look at the jumps in the two directions separately, then combine them.

\subsubsection{Jump in Center Direction}

In the next lemma, we look at jump in the $Y_0$ direction, i.e. the equation

\[
\xi^c_i = P(Y^0) ( W_i^+(0) - W_i^-(0) ) = 0
\]

which is the jump condition in the center direction $Y_0$.

\begin{lemma}

The jumps in the $Y_0$ direction are given by 

\begin{equation}
\xi^c_i 
= e^{-\nu(\lambda)X_i} c_i^- - e^{\nu(\lambda)X_{i-1}} c_{i-1}^- - \lambda^2 d_i \int_{-\infty}^\infty e^{\nu(\lambda)y}  \langle H(y), w(y; 0, 0) \rangle dy + R^c_i(c^-,d)
\end{equation}

for $i = 1, \dots, n$. The remainder term $R^c_i(c^-,d)$ has bound

\begin{align}
|R^c_i&(c^-,d)| \leq C \Big( e^{-\tilde{\alpha} X_m} |c^-| + ((|\lambda| + e^{-\tilde{\alpha} X_m})|\lambda|^2 + e^{-\tilde{\alpha} X_m}|D| + e^{-\tilde{\alpha} X_m} |\lambda| ) |d| \Big)
\end{align}

We can write the $n$ center jump conditions in matrix form as

\begin{equation}
K(\lambda)c^- -\lambda^2 M(\lambda) I d + R^c(\lambda)(c^-,d) = 0
\end{equation}

where $c^- = (c_1^-, \dots, c_{n-1}^-, c_0^-)$, $d = (d_1, \dots, d_n)$, 

\begin{equation}
K(\lambda) = 
\begin{pmatrix}
e^{-\nu(\lambda)X_1} & & & & & -e^{\nu(\lambda)X_0} \\
-e^{\nu(\lambda)X_1} & e^{-\nu(\lambda)X_2} \\
& -e^{\nu(\lambda)X_2} & e^{-\nu(\lambda)X_3} \\
\vdots & & \vdots & &&  \vdots \\
& & & & -e^{\nu(\lambda)X_{n-1}} & e^{-\nu(\lambda)X_0} 
\end{pmatrix}
\end{equation}

and

\begin{equation}
M(\lambda) = \int_{-\infty}^\infty e^{-\nu(\lambda)y} \langle H(y), w(y; 0, 0) \rangle dy
\end{equation}

\begin{proof}

Evaluating the fixed point equations at $x = 0$, we have the following expression for $W_i^+(0) - W_i^-(0)$.

\begin{align*}
W_i^+(0) &- W_i^-(0) = x_i^+ + y_i^+ - x_i^- - y_i^- + v_+(0; 0, 0) e^{-\nu(\lambda) X_i} c_i^+ - v_-(0; 0, 0) e^{\nu(\lambda)X_{i-1}} c_{i-1}^-\\
&+ \Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- \\
&+ (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ -  (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- + \\
&+ ((v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0))
+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle) e^{-\nu(\lambda) X_i} c_i^+ \\
&- ((v_-(0; \beta_i^-, \lambda) - v_-(0; 0, 0))
+ v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) - w_0(\lambda) \rangle) e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \\
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&- \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ v_+(0; \beta_i^+, \lambda) \int_{X_i}^0 e^{\nu(\lambda)y}  \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&- v_-(0; \beta_i^-, \lambda) \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy
\end{align*}

The projection $P(Y_0)$ will eliminate the $x_i^\pm$ and $y_i^\pm$ terms outright.\\

First, to we write this in terms of $c_i^-$, we use $c_i^+ = c_i^- + A_4(\lambda)_i^c(c^-, d) + \mathcal{O}( e^{-\alpha X_i} (|\lambda| +  e^{-\alpha X_i} ) |d| )$. Since 

\begin{align*}
|e^{-\nu(\lambda)X_i} &A_4(\lambda)_i^c(c^-, d)| \leq e^{-|\nu(\lambda)|X_i} |A_4(\lambda)_i^c(c^-, d)| \\
&\leq C e^{-|\nu(\lambda)|X_i} ( e^{-\alpha X_i} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\tilde{\alpha} + |\nu(\lambda)|)X_i} |c^-| 
+ e^{-(\tilde{\alpha} + |\nu(\lambda)|) X_i} |\lambda^2| |d| + e^{-(\alpha - |\nu(\lambda)|) X_i}|D||d| ) \\
&\leq C e^{-\tilde{\alpha} X_i} ((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + |c^-| 
+ |\lambda^2| |d| + |D||d| )
\end{align*}

we have

\begin{align*}
e^{-\nu(\lambda)X_i} c_i^+ &= e^{-\nu(\lambda)X_i} c_i^- + \mathcal{O}(e^{-\tilde{\alpha} X_i} ((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + |c^-| 
+ |\lambda^2| |d| + |D||d| ) + e^{-\tilde{\alpha} X_i} (|\lambda| +  e^{-\alpha X_i} ) |d| ) \\
&= e^{-\nu(\lambda)X_i} c_i^- + \mathcal{O}\Big(e^{-\tilde{\alpha} X_i} ((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + |c^-| 
+ |\lambda| |d| + |D||d| )\Big)\\
\end{align*}

Now we estimate the remaining terms involved in $P(Y_0)(W_i^+(0) - W_i^-(0)$. For the terms involving $a_i^\pm$, we use the bound $A_3$ from Lemma \ref{inv3}.

\begin{align*}
|\Phi^u_+&(0, X_i; \beta_i^+, \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^-|
\leq C e^{-\alpha X_m} ( e^{-\alpha X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| 
+ |c^-| + e^{-(\tilde{\alpha}+|\nu(\lambda)|) X_i} |\lambda^2| |d| + |D||d| ) \\
&\leq C e^{-\alpha X_m} ( e^{-\alpha X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| 
+ |c^-| + e^{-\tilde{\alpha} X_i} |\lambda^2| |d| + |D||d| )
\end{align*}

For the terms involving $b_i^\pm$, we use the bound $B_1$ from Lemma \ref{inv3}.

\begin{align*}
|(P^s_+&(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ - (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^-| \leq C p_5(\beta_i^+, \beta_i^-, \lambda)\Big( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| \\
&+ e^{-\alpha X_m} ( |c^-| + |D||d| )
+ |\lambda|^2 |d| \Big) \\
&\leq C(|\lambda| + e^{-2 \alpha X_m})( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2 |d| )
\end{align*}

Finally, we look at the integral terms.

\begin{enumerate}

\item First we do the ``noncenter'' integrals. For the ``positive'' piece, we have

\begin{align*}
P(Y^0) &\int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&= ( P^c_+(0; 0, 0) - P^c_+(0; \beta_i^+, \lambda)) \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ \int_{X_i}^0 P^c_+(0; \beta_i^+, \lambda) P^u_+(0; \beta_i^+, \lambda) \Phi(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&= ( P^c_+(0; 0, 0) - P^c_+(0; \beta_i^+, \lambda)) \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy
\end{align*}

since by Theorem \ref{trichotomy}, $P^c_+(0; \beta_i^+, \lambda) P^u_+(0; \beta_i^+, \lambda) = 0$. We split this into two integrals and evaluate them separately. For the first integral involving $W$, we use the piecewise, $x-$dependent bound on $W$ from Lemma \ref{inv3}. For the ``positive'' piece, we have

\begin{align*}
\Big| &\int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) G_i^+(y)W_i^+(y) dy \Big| \\
&\leq C \int_{X_i}^0 e^{-\alpha y} e^{-\alpha X_i} e^{-\alpha (X_i - y)} ( e^{|\nu(\lambda)|(X_i - y)} |c_i^-| + e^{-\tilde{\alpha}(X_i - y)}|D||d| \\
&+ ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d| ) + |\lambda|^2) |d|) dy
\end{align*}

This will give us three integrals. The first one has bound

\begin{align*}
\int_0^{X_i} &e^{-\alpha y} e^{-\alpha X_i} e^{-\alpha (X_i - y)} e^{|\nu(\lambda)|(X_i - y)} |c_i^-| dy \leq |c| \int_0^{X_i} e^{-\alpha y} e^{-\alpha X_i} e^{-(\alpha - |\nu(\lambda)|) (X_i - y)} dy \\ 
&\leq |c^-| \int_0^{X_i} e^{-\alpha y} e^{-\alpha X_i} e^{-\tilde{\alpha}(X_i - y)} dy \\
&\leq e^{-(\alpha + \tilde{\alpha}) X_m} |c^-| \int_0^{X_i} e^{-(\alpha - \tilde{\alpha}) y} dy \\
&\leq C e^{-(\alpha + \tilde{\alpha}) X_m} |c^-|
\end{align*}

The second one has bound

\begin{align*}
\int_0^{X_i} &e^{-\alpha y} e^{-\alpha X_i} e^{-\alpha (X_i - y)} e^{-\tilde{\alpha}(X_i - y)}|D||d|  dy \leq |D| |d| e^{-(\alpha + \tilde{\alpha})X_m } \int_0^{X_i} e^{-(\alpha - \tilde{\alpha})y } dy \\
&\leq C e^{-(\alpha + \tilde{\alpha}) X_m } |D||d|
\end{align*}

The last one has bound

\begin{align*}
( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| &+ e^{-\alpha X_m}( |c^-| + |D||d| ) + |\lambda|^2) |d| \int_0^{X_i} e^{-\alpha y} e^{-\alpha X_i} e^{-\alpha (X_i - y)} dy \\
&\leq ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2) |d| \int_0^{X_i} e^{-\alpha y} e^{-\alpha X_i} e^{-\tilde{\alpha} (X_i - y)} dy \\
&\leq e^{-(\alpha + \tilde{\alpha})X_m } ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2) |d| \int_0^{X_i} e^{-(\alpha - \tilde{\alpha})y } dy \\
&\leq C e^{-(\alpha + \tilde{\alpha})X_m } ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D| |d|) + |\lambda|^2) |d|
\end{align*}

The ``negative'' piece is similar. For the second integral involving $\tilde{H}$, we have bound

\begin{align*}
\Big| \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}_i^+(y) dy \Big| \leq C |\lambda|^2 |d|
\end{align*}

Putting all of this together, we have bound

\begin{align*}
\Big| P(Y^0) &\int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \Big| \\
&\leq C p_4(0; \lambda)(e^{-(\alpha + \tilde{\alpha}) X_m} |c^-| + e^{-(\alpha + \tilde{\alpha}) X_m } |D||d| + e^{-(\alpha + \tilde{\alpha})X_m } ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d| ) + |\lambda|^2) |d| +  |\lambda|^2 |d|)\\
&\leq C (|\lambda| + e^{-2\alpha X_m})( e^{-(\alpha + \tilde{\alpha})X_m } (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha}) X_m} |c^-| + e^{-(\alpha + \tilde{\alpha}) X_m } |D||d| + |\lambda|^2 |d|)\\
\end{align*}

Note that this bound will be subsumed by the one for the center integral terms (to follow).

\item The center integral involving $W$ is similar to the noncenter integral involving $W$. Using the piecewise bounds on $W$ from Lemma \ref{inv3} 

\begin{align*}
\Big| P(Y^0) &\int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \Big| \\
&\leq C \int_{X_i}^0 e^{|\nu(\lambda)|y} e^{-\alpha X_i} e^{-\alpha (X_i - y)} ( e^{|\nu(\lambda)|(X_i - y)} |c_i^-| + e^{-\tilde{\alpha}(X_i - y)}|D||d| \\
&+ (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| +  ( e^{-\alpha X_m}( |c^-| + |D||d| ) + |\lambda|^2) |d|) dy
\end{align*}

Again, we have three integrals to evaluate. The first one has bound

\begin{align*}
\int_0^{X_i} & e^{|\nu(\lambda)|y} e^{-\alpha X_i} e^{-\alpha (X_i - y)} e^{|\nu(\lambda)|(X_i - y)} |c_i^-| dy \leq |c^-| \int_0^{X_i} e^{-(\alpha - |\nu(\lambda)|) X_i} e^{-(\alpha - |\nu(\lambda)|) (X_i - y)} dy \\ 
&\leq C e^{-\tilde{\alpha} X_m} |c^-|
\end{align*}

The second one has bound

\begin{align*}
\int_0^{X_i} &e^{|\nu(\lambda)|y} e^{-\alpha X_i} e^{-\alpha (X_i - y)} e^{-\tilde{\alpha}(X_i - y)}|D||d|  dy \leq |D| |d| e^{-\alpha X_m } \int_0^{X_i} e^{-(\alpha + \tilde{\alpha})(X_i - y) } dy \\
&\leq C e^{-\alpha X_m } |D||d|
\end{align*}

The last one has bound

\begin{align*}
( (|\lambda| + e^{-2 \alpha X_m}) &|\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D| |d| ) + |\lambda|^2) |d| \int_0^{X_i} e^{|\nu(\lambda)|y} e^{-\alpha X_i} e^{-\alpha (X_i - y)} dy \\
&\leq C e^{-\tilde{\alpha} X_m } ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D| ) + |\lambda|^2) |d|
\end{align*}

All together, the bound is

\begin{align*}
\Big| P(Y^0) &\int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \Big| \\
&\leq C ( e^{-\tilde{\alpha} X_m } (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} ( |c^-| + |\lambda|^2|d| + |D| |d| ))
\end{align*}

The ``negative'' piece is similar.

\item For the center integral involving $\tilde{H}$, we have

\begin{align*}
P(Y^0) &\int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&= ( P^c_+(0; 0, 0) - P^c_+(0; \beta_i^+, \lambda) \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&+ P^c_+(0; \beta_i^+, \lambda) \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy 
\end{align*}

We are going to need to evaluate the $\tilde{H}$ integral, so let's do that now. Using the decay rate of $\tilde{H}$, we have

\begin{align*}
\Big| \int_{X_i}^0 e^{\nu(\lambda)y} \tilde{H}_i^+(y) dy \Big| 
&\leq C \int_0^{X_i} e^{-\alpha y} e^{|\nu(\lambda)| y} dy \leq C
\end{align*}

Thus we have, using this and the bound for $p_4(0; \lambda)$ from Lemma \ref{centerbounds}

\begin{align*}
P(Y^0) &\int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&= P^c_+(0; \beta_i^+, \lambda) \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy + \mathcal{O}((|\lambda| + e^{-2 \alpha X_m})|\lambda|^2||d| ) \\
&= \lambda^2 d_i \int_{X_i}^0 e^{\nu(\lambda)y}  \langle \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy + \mathcal{O}((|\lambda| + e^{-2 \alpha X_m})|\lambda|^2||d| )\\
&= \lambda^2 d_i \int_{X_i}^0 e^{\nu(\lambda)y}  \langle H(y), w_+(y; \beta_i^+, \lambda) \rangle dy + \lambda^2 d_i \int_{X_i}^0 e^{\nu(\lambda)y}  \langle \Delta H_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy + \mathcal{O}((|\lambda| + e^{-2 \alpha X_m})|\lambda|^2||d| ) )
\end{align*}

Since $|\Delta H_i^+(y)| \leq C(e^{-\alpha X_i}) e^{-\alpha (X_i - y)}$, the second integral becomes

\begin{align*}
\Big| \int_{X_i}^0 e^{\nu(\lambda)y} \langle \Delta H_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \Big| &\leq C e^{-\alpha X_i} \int_0^{X_i} e^{|\nu(\lambda)y|} e^{-\alpha (X_i - y)} dy \\
&\leq C e^{-(\alpha - |\nu(\lambda)|) X_i} \int_0^{X_i} e^{-\alpha (X_i - y)} dy \\
&\leq C e^{-\tilde{\alpha} X_m}
\end{align*}

For the first integral, since $w_+(y; \beta_i^+, \lambda) = w_+(y; 0, 0) + \mathcal{O}(|\lambda| + e^{-2 \alpha X_m}$ from Lemma \ref{centerbounds}

\begin{align*}
\lambda^2 d_i &\int_{X_i}^0 e^{\nu(\lambda)y}  \langle H(y), w_+(y; \beta_i^+, \lambda) \rangle dy = \lambda^2 d_i \int_{X_i}^0 e^{\nu(\lambda)y}  \langle H(y), w(y; 0, 0) \rangle dy + \mathcal{O}((|\lambda| + e^{-2 \alpha X_m})|\lambda|^2|d| ) \\
&= \lambda^2 d_i \int_\infty^0 e^{\nu(\lambda)y}  \langle H(y), w(y; 0, 0) \rangle dy 
- \lambda^2 d_i \int_\infty^{X_i} e^{\nu(\lambda)y}  \langle H(y), w(y; 0, 0) \rangle dy
+ \mathcal{O}((|\lambda| + e^{-2 \alpha X_m})|\lambda|^2|d| ) \\
&= -\lambda^2 d_i \int_0^\infty e^{\nu(\lambda)y}  \langle H(y), w(y; 0, 0) \rangle dy 
+ \mathcal{O}((|\lambda| + e^{-\tilde{\alpha} X_m})|\lambda|^2 |d| ) 
\end{align*}

Thus we have

\begin{align*}
P(Y^0) &\int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&= -\lambda^2 d_i \int_0^\infty e^{\nu(\lambda)y}  \langle H(y), w(y; 0, 0) \rangle dy 
+ \mathcal{O}((|\lambda| + e^{-\tilde{\alpha} X_m})|\lambda|^2 |d| )  
\end{align*}

Similarly,

\begin{align*}
P(Y^0) &\int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
&= \lambda^2 d_i \int_{-\infty}^0 e^{\nu(\lambda)y}  \langle H(y), w(y; 0, 0) \rangle dy 
+ \mathcal{O}((|\lambda| + e^{-\tilde{\alpha} X_m})|\lambda|^2 |d| ) 
\end{align*}

\end{enumerate}

Now that we have estimates on all the things, we can plug them all into the expression above to get the $n$ equations ($i = 1, \dots, n$)

\begin{align*}
P(Y^0)&(W_i^+(0) - W_i^-(0)) 
= e^{-\nu(\lambda)X_i} c_i^- - e^{\nu(\lambda)X_{i-1}} c_{i-1}^- - \lambda^2 d_i \int_{-\infty}^\infty e^{\nu(\lambda)y}  \langle H(y), w(y; 0, 0) \rangle dy + R^c_i(c^-,d)
\end{align*}

The remainder term $R^c_i(c^-,d)$ has bound

\begin{align*}
|R^c_i&(c^-,d)| \leq C \Big( e^{-\alpha X_m} ( e^{-\alpha X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + |c^-| + e^{-\tilde{\alpha} X_m} |\lambda^2| |d| + |D||d| ) \\
&+ (|\lambda| + e^{-2 \alpha X_m})( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2 |d| ) \\
&+ e^{-\tilde{\alpha} X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\tilde{\alpha} X_m} |c^-| + e^{-\tilde{\alpha} X_m}( |\lambda| + |D| ) |d| \\
&+ e^{-\tilde{\alpha} X_m } (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} ( |c^-| + |\lambda|^2|d| + |D| |d| )
\Big) \\
&\leq C \Big( (|\lambda| + e^{-\tilde{\alpha} X_m})(|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\tilde{\alpha} X_m} |c^-| + ((|\lambda| + e^{-\tilde{\alpha} X_m})|\lambda|^2 + e^{-\tilde{\alpha} X_m}|D| + e^{-\tilde{\alpha} X_m} |\lambda| ) |d| \Big) \\
&\leq C \Big( (|\lambda| + e^{-\tilde{\alpha} X_m})(|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\tilde{\alpha} X_m} |c^-| + (|\lambda|^3 + e^{-\tilde{\alpha} X_m}|D| + e^{-\tilde{\alpha} X_m} |\lambda| ) |d| \Big)
\end{align*}

We can write this in matrix form as

\begin{align*}
K(\lambda) c^- &= 
\begin{pmatrix}
e^{-\nu(\lambda)X_1} & & & & & -e^{\nu(\lambda)X_0} \\
-e^{\nu(\lambda)X_1} & e^{-\nu(\lambda)X_2} \\
& -e^{\nu(\lambda)X_2} & e^{-\nu(\lambda)X_3} \\
\vdots & & \vdots & &&  \vdots \\
& & & & -e^{\nu(\lambda)X_{n-1}} & e^{-\nu(\lambda)X_0} 
\end{pmatrix}
\begin{pmatrix}
c_1^- \\ \vdots \\ c_{n-1}^- \\ c_0^-
\end{pmatrix} \\
&= \lambda^2 M(\lambda) \begin{pmatrix}
d_1 \\ \dots \\ d_n
\end{pmatrix} - R^c(\lambda)(c^-,d)
\end{align*}

i.e.

\begin{equation}
K(\lambda)c^- -\lambda^2 M(\lambda) I d + R^c(\lambda)(c^-,d) = 0
\end{equation}

where

\[
M(\lambda) = \int_{-\infty}^\infty e^{-\nu(\lambda)y} \langle H(y), w(y; 0, 0) \rangle dy
\]

\end{proof}
\end{lemma}

Since we will need to take the determinant of the matrix $K(\lambda)$ above, the following lemma gives us an expression for that determinant.

\begin{lemma}
Let $A$ be the ``periodic'' bi-diagonal matrix
\begin{equation}
A = \begin{pmatrix}
a_1 & & & & & & b_n \\
b_1 & a_2 \\
& b_2 & a_3 \\
\vdots & & & \vdots & &&  \vdots \\
& & & & b_{n-2} & a_{n-1} \\
& & & & & b_{n-1} & a_n
\end{pmatrix}
\end{equation}

Then 

\begin{equation}
\det{A} = \prod_{k = 1}^n a_k + (-1)^n \prod_{k = 1}^{n-1} b_k
\end{equation}

\begin{proof}
Expanding by minors using the last column, we have
\begin{align*}
\det A &= a_n \det
\begin{pmatrix}
a_1 \\
b_1 & a_2 \\
& b_2 & a_3 \\
\vdots & & & & \vdots \\
& & & & b_{n-2} & a_{n-1}
\end{pmatrix}
+ (-1)^{n-1} \det
\begin{pmatrix}
b_1 & a_2 \\
& b_2 & a_3 \\
\vdots & & & & \vdots \\
& & & & & b_{n-2} & a_{n-1} \\
& & & & & & b_{n-1}
\end{pmatrix} \\
&= \prod_{k = 1}^n a_k + (-1)^{n-1} \prod_{k = 1}^n b_k
\end{align*}
since both of the matrices on the RHS are triangular.
\end{proof}
\end{lemma}

Using this to evaluate the $\det K(\lambda)$, we have

\begin{align*}
\det K(\lambda) &= \prod_{k = 0}^{n-1} e^{-\nu(\lambda)X_k} + (-1)^{n-1} \prod_{k = 0}^{n-1} (-e^{\nu(\lambda)X_k}) \\
&= e^{-\nu(\lambda) X} - e^{\nu(\lambda) X}
\end{align*}

where $X = X_0 + \dots + X_{n-1}$ is half the length of the domain. Note that the determinant depends on the domain length only, not on the individual pulse distances. Thus we have

\[
\det K(\lambda) = 0 \iff \nu(\lambda) = i \frac{n \pi}{X}, n \in \Z
\]

\subsubsection{Jump in Adjoint Direction}

For our final step, we estimate the jumps along the adjoint solution.

\begin{equation}
\xi_i = \langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle 
\end{equation}

for $i = 1, \dots, n$. Recall that $\Psi(0)$ is the adjoint solution for the unperturbed problem linearized about the single pulse $q(x)$, i.e. with $\lambda = 0$ and $\beta_i^\pm = 0$. The equations for $W$ contain the evolution operator $\Phi^{(s/u)}_\pm(x, y; \beta_i^\pm, \lambda)$, for which we have $\lambda \neq 0$ and with ICs $\beta_i^\pm$.\\

For the adjoint solution $\Psi(x)$, we have estimate 

\begin{equation}
|\Psi(x)| \leq C e^{-\alpha|x|}
\end{equation}

which holds since we know exactly what $\Psi$ is (it involves only the single pulse $q(x)$ and its derivatives, all of which decay with rate $\alpha$). Note as well that $\Psi(0)$ is just a fixed constant. For the difference $W_i^+(0) - W_i^-(0)$, we have, as in the previous lemma

\begin{align*}
W_i^+(0) &- W_i^-(0) = b_i^+ - b_i^- + v_+(0; 0, 0) e^{-\nu(\lambda) X_i} c_i^+ - v_-(0; 0, 0) e^{\nu(\lambda)X_{i-1}} c_{i-1}^-\\
&+ \Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- \\
&+ (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ -  (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- + \\
&+ ((v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0))
+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle) e^{-\nu(\lambda) X_i} c_i^+ \\
&- ((v_-(0; \beta_i^-, \lambda) - v_-(0; 0, 0))
+ v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) - w_0(\lambda) \rangle) e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \\
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&- \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ v_+(0; 0, 0) \int_{X_i}^0 e^{\nu(\lambda)y}  \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&+ (v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0)) \int_{X_i}^0 e^{\nu(\lambda)y}  \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&- v_-(0; 0, 0) \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
&- (v_-(0; \beta_i^-, \lambda) - v_-(0; 0, 0) \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy
\end{align*}

We will evaluate (or estimate) each term in the jump equation in a series of lemmas. Note that the projection on $\Psi(0)$ eliminates the terms $b_i^\pm$ and those in the direction of $v_\pm(0; 0, 0) = Y^-$.

% lemma : a terms in jump

\begin{lemma}\label{jumpa}
For the terms involving $a$ in the jump $\xi_i$, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle \\
&+ \mathcal{O}\Big( e^{-(\alpha + \tilde{\alpha}) X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha})X_m} |c^-| 
+ e^{-(\alpha + \tilde{\alpha})X_m}(|\lambda|^2 + |D| )|d| \Big)
\end{align*}

\begin{proof}

Recall the following expressions for $a_i^\pm$ from Lemma \ref{inv2}.

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_4(\lambda)_i^+(c^-, d)\\
a_i^- &= -P^s_0 D_i d + A_4(\lambda)_i^-(c^-, d)
\end{align*}

For the ``positive'' piece, $\langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ \rangle$, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle = \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda) P^u_0 D_i d \rangle + \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda) A_4(\lambda)_i^+(b, c, d) \rangle \\
\end{align*} 

Note that $\Psi(0)$ is the adjoint solution unperturbed by $\lambda$ and with $\beta_i^\pm = 0$, whereas the evolution $\Phi^u_+(0, X_i; \lambda)$ is perturbed by $\lambda$ and has $\beta_i^\pm \neq 0$. To get around this, we add and subtract $\Phi^u_+(0, X_i; 0, 0)$ to get

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle \\
&= \langle \Psi(0), \Phi^u_+(0, X_i; 0, 0) P^u_0 D_i d \rangle + \langle \Psi(0), (\Phi^u_+(0, X_i; \beta_i^+, \lambda) - \Phi^u_+(0, X_i; 0, 0)) P^u_0 D_i d \rangle \\
&+ \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda) A_4(\lambda)_i^+(c^-,d) \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle 
+ \mathcal{O}((|\lambda| + e^{-\alpha X_1} + e^{-\alpha X_2} ) e^{-\alpha X_i}|D_i||d|) + \langle \Psi(0), \Phi^u_+(0, X_i; \lambda) A_4(\lambda)_i^+(c^-,d) \rangle 
\end{align*}

We look at the terms on the RHS one at a time. For the second term, we have

\begin{align*}
|\langle \Psi(0), (\Phi^u_+(0, X_i; \beta_i^+, \lambda) &- \Phi^u_+(0, X_i; 0, 0)) P^u_0 D_i d \rangle| \leq p_6(X_i; \beta_i^+, \beta_i^-, \lambda)|D||d| \\
&\leq C( ( |\lambda| + e^{-2 \alpha X_m} ) e^{-\alpha X_m})(e^{-\alpha X_m})|d| \\
&=C e^{-2 \alpha X_m}(|\lambda| + e^{-2 \alpha X_m})|d|
\end{align*}

For the third term, we use the estimate for $A_4$ to get

\begin{align*}
|\langle \Psi(0), \Phi^u_+(0, X_i; \lambda) A_4(\lambda)_i^+(b,c,d) \rangle| 
\leq C e^{-\alpha X_m}\Big( e^{-\tilde{\alpha}X_m}( e^{-\alpha X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + |c^-| + |\lambda|^2 |d| + |D||d| ) \Big)
\end{align*}

The first term on the RHS is what we want.

\begin{align*}
\langle \Psi(0), \Phi^u_+(0, X_i; 0, 0) P^u_0 D_i d \rangle &= \langle \Psi(0), \Phi(0, X_i; 0, 0) P^u_+(X_i; 0, 0) P^u_0 D_i d \rangle \\
&= \langle \Psi(X_i), P^u_+(X_i; 0, 0) P^u_0 D_i d \rangle \\
&= \langle \Psi(X_i), P^u_0 P^u_0 D_i d \rangle + \langle \Psi(X_i), (P^u_+(X_i; 0, 0) - P^u_0) P^u_0 D_i d \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \mathcal{O}(e^{-3 \alpha X_i}|d|)
\end{align*}

WHERE WE HAVE ASSUMED THAT $P^u_+(X; 0, 0) - P^u_0 = \mathcal{O}(e^{-\alpha X})$. WE SHOULD SHOW THIS AT SOME POINT, SHOULD NOT BE HARD. THIS IS USED IN San98. Thus we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \mathcal{O}\Big( e^{-(\alpha + \tilde{\alpha}) X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha})X_m} |c^-| 
+ e^{-(\alpha + \tilde{\alpha})X_m}(|\lambda|^2 + |D| )|d| \Big)
\end{align*}

Similarly we have

\begin{align*}
\langle \Psi(0), &\Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= -\langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle
+ \mathcal{O}\Big( e^{-(\alpha + \tilde{\alpha}) X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha})X_m} |c^-| 
+ e^{-(\alpha + \tilde{\alpha})X_m}(|\lambda|^2 + |D| )|d| \Big)
\end{align*}

Putting everything together, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle \\
&+ \mathcal{O}\Big( e^{-(\alpha + \tilde{\alpha}) X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha})X_m} |c^-| 
+ e^{-(\alpha + \tilde{\alpha})X_m}(|\lambda|^2 + |D| )|d| \Big)
\end{align*}

\end{proof}
\end{lemma}

Next, we look at the terms involving $b$. Note that the terms involving $b^\pm$ by themselves will vanish, since they are in the spaces $R^u_-(0; 0) \oplus R^s_+(0; 0)$ which are perpendicular to $\Psi(0)$. For the other terms involving $b$, we have the following lemma.

% lemma : b terms in jump

\begin{lemma}\label{jumpb}

For the terms involving $b$ in the jump $\xi_i$, we have

\begin{align*}
\langle \Psi(0), (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ \rangle
&\leq C (|\lambda| + e^{-2 \alpha X_m})((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}|c^-| + (e^{-\alpha X_m}|D|+ |\lambda|^2 )|d|)  \\
\langle \Psi(0), (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \rangle
&\leq C (|\lambda| + e^{-2 \alpha X_m})((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}|c^-| + (e^{-\alpha X_m}|D|+ |\lambda|^2 )|d|)
\end{align*}

\begin{proof}

Using the bound for $B_1$ from Lemma \ref{inv3}, we have for the ``negative'' piece

\begin{align*}
|\langle \Psi(0), &(P^u_-(0; \lambda) - P^u_-(0; 0))b_i^- \rangle|
\leq |\Psi(0)| p_5(\beta_i^+, \beta_i^-, \lambda)|b_i^-| \\
&\leq |\Psi(0)| p_5(\beta_i^+, \beta_i^-, \lambda)|B_1(\lambda)(d)| \\
&\leq C p_5(\beta_i^+, \beta_i^-, \lambda)  \Big( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| +
e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2 |d| \Big) \\
&\leq C (|\lambda| + e^{-2 \alpha X_m})((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}|c^-| + (e^{-\alpha X_m}|D|+ |\lambda|^2 )|d|)
\end{align*}

\end{proof}
\end{lemma}

Next, we look at the terms in the jump involving $c$. Since $\langle \Psi(0), v_+(0; 0, 0) \rangle = 0$ and we have changed coordinates so that $v_\pm(0; \beta_i^\pm, \lambda)$ and $v_\pm(0; 0, 0)$ are in the same direction, these terms are 0. THE ONLY ONE OF THESE THAT ACTUALLY MATTERS IS THE PERTURBATION IN $\lambda$, SO IT WOULD BE ENOUGH TO CHANGE COORDINATES ONLY REGARDING $\lambda$.

% lemma : c terms in jump

\begin{lemma}\label{jumpc}
For the terms involving $c$ in the jump $\xi_i$, we have bounds

\begin{align*}
|\langle &\Psi(0), ((v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0))
+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle) e^{-\nu(\lambda) X_i} c_i^+ \rangle| \\
&\leq C (|\lambda| + e^{-2 \alpha X_m})( |\tilde{c}| + e^{-\tilde{\alpha} X_m} ( |c^-| 
+ |\lambda| |d| + |D||d| )) \\
|\langle &\Psi(0), ((v_-(0; \beta_i^-, \lambda) - v_-(0; 0, 0))
+ v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) - w_0(\lambda) \rangle) e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \rangle | \\
&\leq C (|\lambda| + e^{-2 \alpha X_m})|\tilde{c}|
\end{align*}

\begin{proof}
Looking at the ``plus'' term, we have

\begin{align*}
|\langle &\Psi(0), ((v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0))
+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle) e^{-\nu(\lambda) X_i} c_i^+ \rangle| \\
&\leq |\langle \Psi(0), v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0) \rangle 
+ \langle \Psi(0), v_+(0; \beta_i^+, \lambda) \rangle \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle | |e^{-\nu(\lambda) X_i} c_i^+ | \\
&\leq C |\langle \Psi(0), v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0) \rangle 
+ \langle \Psi(0), v_+(0; \beta_i^+, \lambda) \rangle \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle | |e^{-\nu(\lambda) X_i} c_i^+ | \\
&\leq C p_4(0; \lambda) |e^{-\nu(\lambda) X_i} c_i^+ | \\
&\leq C (|\lambda| + e^{-2 \alpha X_m})|e^{-\nu(\lambda) X_i} c_i^+ |
\end{align*}

From a previous lemma, we have 
\begin{align*}
e^{-\nu(\lambda)X_i} c_i^+ &= e^{-\nu(\lambda)X_i} c_i^- + \mathcal{O}\Big(e^{-\tilde{\alpha} X_i} ((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + |c^-| 
+ |\lambda| |d| + |D||d| )\Big)\\
\end{align*}

Combining these, 

\begin{align*}
|\langle &\Psi(0), ((v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0))
+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) - w_0(\lambda) \rangle) e^{-\nu(\lambda) X_i} c_i^+ \rangle| \\
&\leq C (|\lambda| + e^{-2 \alpha X_m})( |e^{-\nu(\lambda) X_i} c_i^-| + e^{-\tilde{\alpha} X_i} ((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + |c^-| 
+ |\lambda| |d| + |D||d| )) \\
&\leq C (|\lambda| + e^{-2 \alpha X_m})( |\tilde{c}| + e^{-\tilde{\alpha} X_m} ( |c^-| 
+ |\lambda| |d| + |D||d| )) \\
\end{align*}
 
The ``negative'' piece similar, except we do not have to substitute for $c_i^+$.

\begin{align*}
|\langle &\Psi(0), ((v_-(0; \beta_i^-, \lambda) - v_-(0; 0, 0))
+ v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) - w_0(\lambda) \rangle) e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \rangle | \\
&\leq C (|\lambda| + e^{-2 \alpha X_m})|\tilde{c}|
\end{align*}

\end{proof} 
\end{lemma}

Next, we look at the integral terms in the jump $\xi_i$. First, we look at the ``noncenter'' integral terms. We divide these into ones involving $W$ and ones not involving $W$. First, we estimate the noncenter integrals which involve $W$.

\begin{lemma}\label{noncenterW}

\begin{align*}
&\left| \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; \lambda) G_i^-(y) W_i^-(y) \rangle dy \right| \\
&\leq C\Big( e^{-(\alpha + \tilde{\alpha}) X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha}) X_m} |c^-| + e^{-2 \alpha X_m} |D||d| + e^{-(\tilde{\alpha} + \alpha) X_m} |\lambda|^2 |d| \Big) \\
&\left| \int_{X_i}^0 \langle \Psi(0), \Phi^u_-(0, y; \lambda) G_i^+(y) W_i^+(y) \rangle dy \right| \\
&\leq C\Big( e^{-(\alpha + \tilde{\alpha}) X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha}) X_m} |c^-| + e^{-2 \alpha X_m} |D||d| + e^{-(\tilde{\alpha} + \alpha) X_m} |\lambda|^2 |d| \Big) 
\end{align*}

\begin{proof}

\begin{align*}
|W_i^-(x)| &\leq C ( e^{-\alpha X_m}( |c^-| + |D||d|) + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + e^{-\tilde{\alpha}(X_{i-1} + x)}|D_{i-1}||d| + |\lambda|^2 |d| ) \\
|W_i^+(x)| &\leq C ( e^{-\alpha X_m}( |c^-| + |D||d|) + e^{|\nu(\lambda)|(X_i - x)} |c_i^-| + e^{-\tilde{\alpha}(X_i - x)}|D_i||d| + |\lambda|^2 |d| )
\end{align*}

We do the ``minus'' integral here. Substituting in our pointwise bound for $G_i^-(y)$, the piecewise bound for $W_i^-(y)$, and using Theorem \ref{trichotomy}

\begin{align*}
&\left| \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; \lambda) G_i^-(y) W_i^-(y) \rangle dy \right| \\
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} |G_i^-(y)| ||W_i^-(y)|| dy \\
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} \Big( e^{|\nu(\lambda)|(X_{i-1} + y)} |c_{i-1}^-| + e^{-\tilde{\alpha}(X_{i-1} + y)}|D_{i-1}||d| \\
&+ (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2 |d| \Big) dy \\
\end{align*}

We have three integrals to evaluate. For the first integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 &e^{\alpha y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} e^{|\nu(\lambda)|(X_{i-1} + y)} |c_{i-1}^-| dy \leq C |c^-| e^{-\alpha X_{i-1}} \int_{-X_{i-1}}^0 e^{\alpha y} e^{-\tilde{\alpha}(X_{i-1} + y)} dy \\
&\leq C |c^-| e^{-(\alpha + \tilde{\alpha}) X_{i-1}} \int_{-X_{i-1}}^0 e^{(\alpha - \tilde{\alpha}) y} dy \\
&\leq C e^{-(\alpha + \tilde{\alpha}) X_m} |c^-|
\end{align*}

For the second integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 &e^{\alpha y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} e^{-\tilde{\alpha}(X_{i-1} + y)}|D_{i-1}||d|  dy \leq C |D||d| e^{-\alpha X_{i-1}} \int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha(X_{i-1} + y)} e^{-\tilde{\alpha}(X_{i-1} + y)} dy \\
&\leq C |D||d| e^{-2 \alpha X_{i-1}} \int_{-X_{i-1}}^0 e^{-\tilde{\alpha}(X_{i-1} + y)} dy \\
&\leq C  e^{-2 \alpha X_m} |D||d|
\end{align*}

For the third integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 &e^{\alpha y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)}( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2 |d| ) dy \\
&\leq C e^{-\alpha X_{i-1}} ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2 |d| ) \int_{-X_{i-1}}^0 e^{\alpha y}  e^{-\tilde{\alpha}(X_{i-1} + y)} dy \\
&\leq C e^{-(\tilde{\alpha} + \alpha) X_m} ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}( |c^-| + |D||d|) + |\lambda|^2 |d| ) \int_{-X_{i-1}}^0 e^{(\alpha - \tilde{\alpha}) y} dy \\
&\leq C e^{-(\tilde{\alpha} + \alpha) X_m} ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} |c^-| + (e^{-\alpha X_m}|D| + |\lambda|^2) |d| )
\end{align*}

Putting this all together, we have

\begin{align*}
&\left| \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; \lambda) G_i^-(y) W_i^-(y) \rangle dy \right| \\
&\leq C \Big( e^{-(\alpha + \tilde{\alpha}) X_m} |c^-| + e^{-2 \alpha X_m} |D||d| + e^{-(\tilde{\alpha} + \alpha) X_m} ( (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} |c^-| + (e^{-\alpha X_m}|D| + |\lambda|^2) |d| ) \Big) \\
&\leq C \Big( e^{-(\alpha + \tilde{\alpha}) X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha}) X_m} |c^-| + e^{-2 \alpha X_m} |D||d| + e^{-(\tilde{\alpha} + \alpha) X_m} |\lambda|^2 |d| \Big)
\end{align*}

The ``plus'' integral has the same bound.

\end{proof}
\end{lemma}

Next, we look at the ``noncenter'' integrals involving $\tilde{H}$. These will give us our higher order Melnikov integral.

% lemma : noncenter integrals involving H

\begin{lemma}\label{noncenterH}

\begin{align*}
\langle \Psi(0), &\int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}_i^+(y) dy - \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) \lambda^2 d_i \tilde{H}_i^-(y) dy \rangle \\ 
&= -d_i \lambda^2 \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy + \mathcal{O}\left( (|\lambda| + e^{-\alpha X_m} ) |\lambda|^2 |d| \right)
\end{align*}

\begin{proof}

Looking at the ``negative'' integral (which is multiplied by $d_i \lambda^2$), we write it as

\begin{align*}
\langle \Psi(0)&, \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) \tilde{H}_i^-(y) dy \rangle \\ 
&= \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; 0, 0) \tilde{H}_i^-(y) \rangle dy + 
\int_{-X_{i-1}}^0 \langle \Psi(0), (\Phi^s_-(0, y; \beta_i^-, \lambda) - \Phi^s_-(0, y; 0, 0)) \tilde{H}_i^-(y) \rangle dy
\end{align*}

where we use this trick in order to get the Melnikov term we want. For the second integral, we have

\begin{align*}
\Big| \int_{-X_{i-1}}^0 \langle &\Psi(0), (\Phi^s_-(0, y; \beta_i^-, \lambda) - \Phi^s_-(0, y; 0, 0)) \tilde{H}_i^-(y) \rangle dy \Big| \\
&\leq C \int_{-X_{i-1}}^0 |\Phi^s_-(0, y; \beta_i^-, \lambda) - \Phi^s_-(0, y; 0, 0)| |\tilde{H}_i^-(y)| dy \\
&\leq C \int_{-X_{i-1}}^0 p_6(y; \beta_i^+, \beta_i^-, \lambda) dy \\
&\leq C ( |\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})\int_{-X_{i-1}}^0 e^{\alpha y} dy \\
&\leq C ( |\lambda| + e^{-2 \alpha X_m}) \\
\end{align*}

where we used the estimate for $p_6$ from Lemma \ref{projbounds} and the fact that $\tilde{H}_i^\pm$ is bounded.\\

For the first integral, we manipulate things to bring the limits out to $\pm \infty$ (to get the higher order Melnikov integral) and to replace $\tilde{H}_i^\pm$ by $H$ (so that the Melnikov integral only involves the single pulse).

\begin{align*}
\int_{-X_{i-1}}^0 &\langle \Psi(0), \Phi^s_-(0, y; 0, 0) \tilde{H}_i^-(y) \rangle dy = 
\int_{-X_{i-1}}^0 \langle \Psi(y), H(y) \rangle dy + \int_{-X_{i-1}}^0 \langle \Psi(y), \Delta H(y) \rangle dy \\
&= \int_{-\infty}^0 \langle \Psi(y), H(y) \rangle dy - \int_{-\infty}^{-X_{i-1}} \langle \Psi(y), H(y) \rangle dy + \int_{-X_{i-1}}^0 \langle \Psi(y), \Delta H(y) \rangle dy 
\end{align*}

The first integral on the RHS is the left half of our higher order Melnikov integral. The second integral is order $e^{-\alpha X_{i-1}}$, since $H$ decays exponentially with order $\alpha$ and $\Psi$ is bounded. The third integral is order $e^{-\alpha X_m}$, which is the order of $\Delta H$. When we do the ``plus'' piece, the first integral is the other half of the Melnikov integral; the second integral is order $e^{-\alpha X_i}$; and the third integral is the same order. Combining all of these gives us our result.

\end{proof}
\end{lemma}

Because of our change of coordinates, the center integral terms will vanish when projected on the adjoint $\Psi(0)$ (just like the center terms did above).

Finally, we look at the ``center'' integral terms.

% lemma : center integrals 

\begin{lemma}\label{centerint}

\begin{align*}
&\Big| (v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0)) \int_{X_i}^0 e^{\nu(\lambda)y}  \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \Big| \\
&\leq (|\lambda| + e^{-2 \alpha X_m})( e^{-\tilde{\alpha} X_m } (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} |c^-| + e^{-\alpha X_m} |D| |d| + |\lambda|^2 |d| ) \\
&\Big| (v_-(0; \beta_i^-, \lambda) - v_-(0; 0, 0) \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \Big| \\
&\leq (|\lambda| + e^{-2 \alpha X_m})( e^{-\tilde{\alpha} X_m } (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} |c^-| + e^{-\alpha X_m} |D| |d| + |\lambda|^2 |d| )
\end{align*}

\begin{proof}

Luckily, we have already evaluated most of these in a previous lemma. For the integrals involving $W$, we have for the ``positive'' piece,

\begin{align*}
\Big| &\int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \Big| \\
&\leq C ( e^{-\tilde{\alpha} X_m } (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} ( |c^-| + |\lambda|^2|d| + |D| |d| ))
\end{align*}

For the integrals not involving $W$, for the ``positive'' piece, we have

\begin{align*}
\Big| \int_{X_i}^0 e^{\nu(\lambda)y} \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \Big| &\leq C |\lambda|^2 |d| \int_0^{X_i} e^{-(\alpha - |\nu(\lambda)|)y} dy \\
&\leq C |\lambda|^2 |d|
\end{align*}

Combining these and using the bound for $p_4$, we have

\begin{align*}
&\Big| (v_+(0; \beta_i^+, \lambda) - v_+(0; 0, 0)) \int_{X_i}^0 e^{\nu(\lambda)y}  \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \Big| \\
&\leq C p_4(\lambda) \Big( e^{-\tilde{\alpha} X_m } (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} ( |c^-| + |\lambda|^2|d| + |D| |d| ) + |\lambda|^2 |d| \Big) \\
&\leq (|\lambda| + e^{-2 \alpha X_m})( e^{-\tilde{\alpha} X_m } (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} |c^-| + e^{-\alpha X_m} |D| |d| + |\lambda|^2 |d| )
\end{align*}

\end{proof}
\end{lemma}

\begin{lemma}\label{jump}

For the jumps in the direction of the adjoint $\Psi(0)$

\[
\xi_i = \langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle
\]

we have the following expression

\begin{equation}\label{jumpexp}
\xi_i = \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^u_0 D_{i-1} d \rangle - d_i \lambda^2 \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy + R_i(c^-, d)
\end{equation}

where the remainder term $R(\lambda)_i(d)$ has bound

\begin{align}\label{remainder1}
|R_i(c^-, d)| \leq C \Big( e^{-\alpha X_m}(|\lambda| + e^{-\tilde{\alpha} X_m} )|c^-| + 
(|\lambda| + e^{-\tilde{\alpha} X_m} )( e^{-\alpha X_m} |D| + |\lambda|^2)|d| \Big)
\end{align}

\begin{proof}
Using the fixed point equations at $x = 0$, we evaluate $\langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle$. The first two terms on the RHS of \eqref{jumpexp} come from Lemma \ref{jumpa}. The higher order Melnikov integral term comes from Lemma \ref{noncenterH}. For the remainder term, we use all the other jump estimation lemmas above to get the estimate

\begin{align*}
|R&(\lambda)(c^-, d)_i| \leq C \Big( e^{-(\alpha + \tilde{\alpha}) X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha})X_m} |c^-| + e^{-(\alpha + \tilde{\alpha})X_m}(|\lambda|^2 + |D| )|d| \\
&+ (|\lambda| + e^{-2 \alpha X_m})((|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m}|c^-| + (e^{-\alpha X_m}|D|+ |\lambda|^2 )|d|) \\
&+ (|\lambda| + e^{-2 \alpha X_m})( |\tilde{c}| + e^{-\tilde{\alpha} X_m} ( |c^-| 
+ |\lambda| |d| + |D||d| ) \\
&+ e^{-(\alpha + \tilde{\alpha}) X_m} (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-(\alpha + \tilde{\alpha}) X_m} |c^-| + e^{-2 \alpha X_m} |D||d| + e^{-(\tilde{\alpha} + \alpha) X_m} |\lambda|^2 |d| \\
&+ (|\lambda| + e^{-\alpha X_m} ) |\lambda|^2 |d| \\
&+ (|\lambda| + e^{-2 \alpha X_m})( e^{-\tilde{\alpha} X_m } (|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\alpha X_m} |c^-| + e^{-\alpha X_m} |D| |d| + |\lambda|^2 |d| )
\Big)
\end{align*}

Simplifying and dropping higher order terms, this becomes

\begin{align*}
|R&(\lambda)(c^-, d)_i| \leq C \Big( (|\lambda| + e^{-2 \alpha X_m})|\tilde{c}| + e^{-\alpha X_m}(|\lambda| + e^{-\tilde{\alpha} X_m} )|c^-| + 
(|\lambda| + e^{-\tilde{\alpha} X_m} )( e^{-\alpha X_m} |D| + |\lambda|^2)|d| \Big)
\end{align*}

\end{proof}
\end{lemma}

We write the jump conditions for the jump in the adjoint direction in matrix form in the following lemma.

% lemma : adjoint jump condition in matrix form 

\begin{lemma}\label{evpsol}

The $n$ jump conditions in the adjoint direction can be written in matrix form as

\begin{equation}\label{adjmatrix}
A - \lambda^2 MI + R(\lambda)(c^-, d) = 0
\end{equation}

where $M$ is the higher order Melnikov integral 

\begin{equation}
M =  \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy
\end{equation}

and $A$ is the $n \times n$ matrix defined by

\begin{align*}
A &= \begin{pmatrix}
-a_0 + \tilde{a}_1 & a_0 - \tilde{a}_1 \\
-\tilde{a}_0 + a_1 & \tilde{a}_0 - a_1
\end{pmatrix} && n = 2 \\
A &= \begin{pmatrix}
\tilde{a}_{n-1} - a_0 & a_0 & & & \dots & -\tilde{a}_{n-1}\\
-\tilde{a}_0 & \tilde{a}_0 - a_1 &  a_1 \\
& -\tilde{a}_1 & \tilde{a}_1 - a_2 &  a_2 \\
& & \vdots & & \vdots \\
a_{n-1} & & & & -\tilde{a}_{n-2} & \tilde{a}_{n-2} - a_{n-1} \\
\end{pmatrix} && n > 2
\end{align*}

where

\begin{align*}
a_i &= \langle \Psi(X_i), Q'(-X_i) \rangle \\
\tilde{a}_i &= \langle \Psi(-X_i), Q'(X_i) \rangle
\end{align*}

The remainder $R(\lambda)(c^-, d)$ is analytic in $\lambda$ and has bound

\begin{align*}
|R&(\lambda)(c^-, d)_i| \leq C \Big( (|\lambda| + e^{-2 \alpha X_m})|\tilde{c}| + e^{-\alpha X_m}(|\lambda| + e^{-\tilde{\alpha} X_m} )|c^-| + 
(|\lambda| + e^{-\tilde{\alpha} X_m} )( e^{-2 \alpha X_m} + |\lambda|^2)|d| \Big)
\end{align*}

\begin{proof}

First, we plug in $D_i d$ and $D_{i-1} d$ into \eqref{jumpexp} from the previous lemma. 
Recall that we have the following expression for $D_id $ from Lemma \ref{problembounds}.

\[
D_i d = ( Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) + \mathcal{O} \left( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\]

Substituting this into $\langle \Psi(X_i), P^u_0 D_i d \rangle$ and using the fact that $\Psi(\pm X_i)$ is order $e^{-\alpha X_i}$, we have

\begin{align*}
\langle \Psi(X_i), P^u_0 D_i d \rangle &= \langle \Psi(X_i), P^u_0 (Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) \rangle + \mathcal{O} \left( e^{-2 \alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\end{align*}

Now we deal with $P^u_0 Q'(X_i)$ and $P^u_0 Q'(-X_i)$. For the first, we have

\begin{align*}
P^u_0 Q'(X_i) &= P^u_0( (P^s_+(X_i; 0, 0) - P^s_0) Q'(X_i) + P^s_0 Q'(X_i) ) \\
&= P^u_0( (P^s_+(X_i; 0, 0) - P^s_0) Q'(X_i) \\
&= \mathcal{O}(e^{-2\alpha X_i})
\end{align*}

where we use the UNPROVEN ASSUMPTION that $P^s_+(X; 0, 0) - P^s_0) = \mathcal{O}(e^{-\alpha X})$. Similarly, 

\begin{align*}
P^u_0 Q'(-X_i) &= (P^u_0 - P^u_-(-X_i; 0, 0))Q'(-X_i) + P^u_-(-X_i; 0, 0)Q'(-X_i) \\
&= Q'(-X_i) + \mathcal{O}(e^{-2\alpha X_i})
\end{align*}

The terms involving $P^s_0$ are similar. Thus the jumps are given by

\begin{equation}\label{jumpexp2}
\xi_i = \langle \Psi(X_i), Q'(-X_i) \rangle (d_{i+1} - d_i ) + \langle \Psi(-X_{i-1}), Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) - d_i \lambda^2 \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy + R_i(c^-, d)
\end{equation}

where we have incorporated the two $\mathcal{O}(e^{-3\alpha X_i})$ terms into the remainder. Since $D = \mathcal{O}(e^{-\alpha X_m})$, we substitute this into the remainder bound from the previous lemma to get

\begin{align*}
|R&(\lambda)(c^-, d)_i| \leq C \Big( (|\lambda| + e^{-2 \alpha X_m})|\tilde{c}| + e^{-\alpha X_m}(|\lambda| + e^{-\tilde{\alpha} X_m} )|c^-| + 
(|\lambda| + e^{-\tilde{\alpha} X_m} )( e^{-2 \alpha X_m} + |\lambda|^2)|d| \Big)
\end{align*}

Let 

\begin{equation*}
M =  \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy
\end{equation*}

be the higher order Melnikov integral defined above. As in San98, we let

\begin{align*}
a_i &= \langle \Psi(X_i), Q'(-X_i) \rangle \\
\tilde{a}_i &= \langle \Psi(-X_i), Q'(X_i) \rangle
\end{align*}

where $i = 0, \dots, n-1$. Then the jumps are given by 

\begin{align*}
\xi_i &= a_i (d_{i+1} - d_i ) + \tilde{a}_{i-1} (d_i - d_{i-1} ) - \lambda^2 d_i M + R(\lambda)(d)_i
\end{align*}

We can thus write the jump conditions in matrix form as 

\begin{align*}
(A - \lambda^2 MI)d + R(\lambda)(c^-,d) = 0
\end{align*}

where $A$ is the following $n \times n$ matrix, which is a ``periodic analogue'' of the tridiagonal matrix $A$ in San98. For $n = 2$, we have

\[
A = 
\begin{pmatrix}
-a_0 + \tilde{a}_1 & a_0 - \tilde{a}_1 \\
-\tilde{a}_0 + a_1 & \tilde{a}_0 - a_1
\end{pmatrix}
\]

and for $n > 2$, we have

\[
A = 
\begin{pmatrix}
\tilde{a}_{n-1} - a_0 & a_0 & & & \dots & -\tilde{a}_{n-1}\\
-\tilde{a}_0 & \tilde{a}_0 - a_1 &  a_1 \\
& -\tilde{a}_1 & \tilde{a}_1 - a_2 &  a_2 \\
& & \vdots & & \vdots \\
a_{n-1} & & & & -\tilde{a}_{n-2} & \tilde{a}_{n-2} - a_{n-1} \\
\end{pmatrix}
\]

\end{proof}
\end{lemma}

\subsubsection{Solution Condition}

Now we are ready to put the two jump conditions together. From the previous two sections, we need to solve simultaneously

\begin{align*}
(A - \lambda^2 MI)d + R(\lambda)(c^-,d) &= 0 \\
K(\lambda)c^- -\lambda^2 M(\lambda) I d + R^c(\lambda)(c^-,d) &= 0
\end{align*}

We combine these in the following theorem.

\begin{theorem}\label{blockmatrixform}

The jump conditions can be written as the block diagonal matrix equation 

\begin{equation}
\begin{pmatrix}
K(\lambda) & -\lambda^2 M(\lambda) I  \\
0 & A - \lambda^2 MI 
\end{pmatrix}
\begin{pmatrix}c^- \\ d \end{pmatrix} 
+ \begin{pmatrix}
R^c(\lambda)(c^-, d) \\
R(\lambda)(c^-, d)
\end{pmatrix}
= 0
\end{equation}

where we have remainder bounds

\begin{align*}
| R^c(\lambda)(c^-, d)_i| &\leq C \Big( (|\lambda| + e^{-\tilde{\alpha} X_m})(|\lambda| + e^{-2 \alpha X_m}) |\tilde{c}| + e^{-\tilde{\alpha} X_m} |c^-| + (|\lambda|^3 + e^{-(\alpha + \tilde{\alpha}) X_m} + e^{-\tilde{\alpha} X_m} |\lambda| ) |d| \Big) \\
|R(\lambda)(c^-, d)_i| &\leq C \Big( (|\lambda| + e^{-2 \alpha X_m})|\tilde{c}| + e^{-\alpha X_m}(|\lambda| + e^{-\tilde{\alpha} X_m} )|c^-| + 
(|\lambda| + e^{-\tilde{\alpha} X_m} )( e^{-2 \alpha X_m} + |\lambda|^2)|d| \Big)
\end{align*}

and

\begin{enumerate}
\item $c^- = (c_1^-, \dots, c_{n-1}^-, c_0^-)$
\item $\tilde{c}_i^\pm = e^{\pm \nu(\lambda) X_i} c_i^-$
\item $|\tilde{c}| = \max_i{| e^{\pm \nu(\lambda) X_i} c_i^- | }$
\item $d = (d_1, \dots, d_n)$
\item $M$ is the higher order Melnikov integral

\begin{equation}
M =  \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy
\end{equation}

For this specific problem,

\begin{equation*}
M =  \int_{-\infty}^\infty q(y) q_c(y) dy
\end{equation*}

\item $M(\lambda)$ is given by

\begin{equation}
M(\lambda) = \int_{-\infty}^\infty e^{-\nu(\lambda)y} \langle H(y), w(y; 0, 0) \rangle dy
\end{equation}

where $w(y; 0, 0)$ is a bounded (but not exponentially decaying) solution to the (unperturbed) adjoint variational equation. If we assume that the constant solution $1$ is the only such solution, this would become

\begin{equation*}
M(0) =  \int_{-\infty}^\infty q_c(y) dy
\end{equation*}

\item The matrix $K(\lambda)$ is given by

\begin{equation}\label{blockdiag}
K(\lambda) = 
\begin{pmatrix}
e^{-\nu(\lambda)X_1} & & & & & -e^{\nu(\lambda)X_0} \\
-e^{\nu(\lambda)X_1} & e^{-\nu(\lambda)X_2} \\
& -e^{\nu(\lambda)X_2} & e^{-\nu(\lambda)X_3} \\
\vdots & & \vdots & &&  \vdots \\
& & & & -e^{\nu(\lambda)X_{n-1}} & e^{-\nu(\lambda)X_0} 
\end{pmatrix}
\end{equation}

where $\nu(\lambda)$ is the small eigenvalue of the asympotic matrix $A(0; \lambda)$.

\item The matrix $A$ is given by

\begin{align*}
A &= \begin{pmatrix}
-a_0 + \tilde{a}_1 & a_0 - \tilde{a}_1 \\
-\tilde{a}_0 + a_1 & \tilde{a}_0 - a_1
\end{pmatrix} && n = 2 \\
A &= \begin{pmatrix}
\tilde{a}_{n-1} - a_0 & a_0 & & & \dots & -\tilde{a}_{n-1}\\
-\tilde{a}_0 & \tilde{a}_0 - a_1 &  a_1 \\
& -\tilde{a}_1 & \tilde{a}_1 - a_2 &  a_2 \\
& & \vdots & & \vdots \\
a_{n-1} & & & & -\tilde{a}_{n-2} & \tilde{a}_{n-2} - a_{n-1} \\
\end{pmatrix} && n > 2
\end{align*}

where

\begin{align*}
a_i &= \langle \Psi(X_i), Q'(-X_i) \rangle \\
\tilde{a}_i &= \langle \Psi(-X_i), Q'(X_i) \rangle
\end{align*}

\end{enumerate}

To leading order, equation \eqref{blockdiag} is given by
\begin{equation}
\begin{pmatrix}
K(\lambda) & -\lambda^2 M(\lambda) I  \\
0 & A - \lambda^2 MI 
\end{pmatrix}
\begin{pmatrix}c^- \\ d \end{pmatrix} = 0
\end{equation}

Thus, to leading order, the eigenvalue problem has a nontrivial solution if either of the following conditions holds.

\begin{enumerate}[(i)]
\item $\nu(\lambda) = i \frac{n \pi}{X}, n \in \Z$ 
\item $\det(A - \lambda^2 MI) = 0$
\end{enumerate}

where $X = X_0 + \dots + X_{n-1}$ is half the length of the domain. Note that $M(\lambda)$ does not appear in these conditions.\\

\begin{proof}

Using the above lemmas, we can write the two jump conditions in matrix form as the block matrix equation

\[
\begin{pmatrix}
K(\lambda) & -\lambda^2 M(\lambda) I \\
0 & A - \lambda^2 MI
\end{pmatrix}
\begin{pmatrix}c^- \\ d \end{pmatrix} +
\begin{pmatrix} R(\lambda)(c^-,d) \\ R^c( \lambda)(c^-,d) \end{pmatrix}  = 0
\]

To leading order, this has a nontrivial solution if and only if the block diagonal matrix is singular, i.e. if and only if its determinant is 0. Since this is a triangular block diagonal matrix, its determinant is given by 

\begin{align*}
\det \begin{pmatrix}
K(\lambda) & -\lambda^2 M(\lambda) I \\
0 & A - \lambda^2 MI
\end{pmatrix} &= \det K(\lambda) \det(A - \lambda^2 MI)\\
&= ( e^{-\nu(\lambda) X} - e^{\nu(\lambda) X} ) \det(A - \lambda^2 MI)
\end{align*}

where $X = X_0 + \dots + X_{n-1}$ is half the length of the domain. We computed the determinant of $K(\lambda)$ above. Thus we have a nontrivial solution to the jump equations if and only if 

\[
\nu(\lambda) = i \frac{n \pi}{X}, n \in \Z
\]

or 

\[
\det(A - \lambda^2 MI) = 0
\]

\end{proof}
\end{theorem}

% look at it for 2-pulse

\subsubsection{2-pulse}

Let's look at this for the periodic 2-pulse. For now, we take $C_1 = D_1 = D_2 = 0$, so we have the block diagonal matrix equation

\begin{equation}
\tilde{A}\begin{pmatrix}c^- \\ d \end{pmatrix} = \begin{pmatrix}
K(\lambda) & -\lambda^2 M(\lambda) I  \\
C_2 & A - \lambda^2 MI
\end{pmatrix}
\begin{pmatrix}c^- \\ d \end{pmatrix} = 0
\end{equation}

Note that

\[
\tilde{a}_i = \langle \Psi(-X_i), Q'(X_i) \rangle = -\langle \Psi(X_i), Q'(-X_i) \rangle = -a_i
\]

Thus we have

\begin{align*}
A &== \begin{pmatrix}
-a_0 - a_1 & a_0 + a_1 \\
a_0 + a_1 & -a_0 - a_1
\end{pmatrix} \\
&= (a_0 + a_1)
\begin{pmatrix}
-1 & 1 \\
1 & -1
\end{pmatrix}
\end{align*}

We can take $a_i = e^{-2 \alpha X_i}$ (which is its order of magnitude). Then this becomes

\[
A = (e^{-2 \alpha X_0} + e^{-2 \alpha X_1})
\begin{pmatrix}
-1 & 1 \\
1 & -1
\end{pmatrix}
\]

Or, letting $a = e^{-2 \alpha X_0} + e^{-2 \alpha X_1}$, we have

\[
A =
\begin{pmatrix}
-a & a \\
a & -a
\end{pmatrix}
\]

Take $c_2 = e^{-\alpha X_m}(|\lambda| + e^{-\alpha X_m})$, i.e. ditch the tilde for convenience, and suppose $C_2$ is just a 4x4 block composed of $c_2$. Then $\tilde{A}$ is the 4x4 matrix

\[
\tilde{A} = 
\begin{pmatrix}
e^{-\nu(\lambda)X_1} & -e^{\nu(\lambda)X_0} & -\lambda^2 M(\lambda) & 0 \\
-e^{\nu(\lambda)X_1} & e^{-\nu(\lambda)X_0} & 0 & -\lambda^2 M(\lambda) \\
c_2 & c_2 & -a - \lambda^2 M & a \\
c_2 & c_2 & a & -a - \lambda^2 M
\end{pmatrix}
\]

This looks terrible. Since life is too short to take 4x4 determinants by hand, we will ask Stephen Wolfram, i.e. Mathematica, for help. Doing \texttt{ Det[$\tilde{A}$]//Simplify} gives us

\begin{align*}
\det{\tilde{A}} &= 
-e^{-\nu(\lambda)(X_0 + X_1)} (e^{\nu(\lambda)(X_0 + X_1)} + 1) 
\lambda^2 (2 a + \lambda^2 M) \Big( 
(e^{\nu(\lambda)(X_0 + X_1)} - 1) M + c_2 M(\lambda)(e^{\nu(\lambda) X_0} + e^{\nu(\lambda) X_1})  \Big) \\
&= -(e^{-\nu(\lambda)(X_0 + X_1)} + 1) 
\lambda^2 (2 a + \lambda^2 M) M \left( 
(e^{\nu(\lambda)(X_0 + X_1)} - 1) + c_2 \frac{M(\lambda)}{M}(e^{\nu(\lambda) X_0} + e^{\nu(\lambda) X_1})  \right) \\
&= -(e^{-\nu(\lambda)X} + 1) 
\lambda^2 M (2 a + \lambda^2 M) \left( 
(e^{\nu(\lambda)X} - 1) + c_2 \frac{M(\lambda)}{M}(e^{\nu(\lambda) X_0} + e^{\nu(\lambda) X_1})  \right) 
\end{align*}

This actually looks promising. In fact, $\det (A - \lambda^2 M) = \lambda^2 (2 a + \lambda^2 M)$ is part of this product, which is great, and $c_2$ only appears in one place. In fact, this is zero if either $\det (A - \lambda^2 M) = 0$ or $\nu(\lambda) = i n \pi / X$ for $n$ odd. (We don't have this for $n$ even). Next, we multiply the term out front inside the rightmost term to get

\begin{align*}
\det{\tilde{A}}
&= \lambda^2 M (2 a + \lambda^2 M) \left( 
(e^{\nu(\lambda)X} - e^{-\nu(\lambda)X}) + c_2 \frac{M(\lambda)}{M}(e^{-\nu(\lambda)(X_0 + X_1)} + 1) (e^{\nu(\lambda) X_0} + e^{\nu(\lambda) X_1})  \right) \\
&= \lambda^2 M (2 a + \lambda^2 M) \left( 
(e^{\nu(\lambda)X} - e^{-\nu(\lambda)X}) + c_2 \frac{M(\lambda)}{M}((e^{\nu(\lambda)X_0} + e^{\nu(\lambda)X_1}) + (e^{-\nu(\lambda) X_0} + e^{-\nu(\lambda) X_1}) \right) 
\end{align*}

Let's look at the remainder term. Regardless of the sign of $\nu(\lambda)$, we will have

\begin{align*}
|(e^{\nu(\lambda)X_0} + e^{\nu(\lambda)X_1}) + (e^{-\nu(\lambda) X_0} + e^{-\nu(\lambda) X_1})| &\leq C |e^{\nu(\lambda)(X_0 + X_1)} - e^{-\nu(\lambda)(X_0 + X_1)}| \\
&= C |e^{\nu(\lambda)X} - e^{-\nu(\lambda)X}|
\end{align*}

Since $M$ and $M(\lambda)$ are constants, using the order of $c_2$, this becomes

\begin{align*}
\det{\tilde{A}}
&= \lambda^2 M (2 a + \lambda^2 M) 
(e^{\nu(\lambda)X} - e^{-\nu(\lambda)X})\Big(1 + \mathcal{O}(e^{-\alpha X_m}(|\lambda| + e^{-\alpha X_m}) \Big)
\end{align*}

In terms of the determinants of the matrices we care about, this is

\begin{align}\label{tildeA2}
\det{\tilde{A}}
&= \det(A - \lambda^2 M) \det(K(\lambda))\Big(1 + \mathcal{O}(e^{-\alpha X_m}(|\lambda| + e^{-\alpha X_m}) \Big)
\end{align}

This actually looks really good. If $c_2 = 0$, this reduces to the product of determinants of $K(\lambda)$ and $A - \lambda^2 M$, since in that case we have

\begin{align*}
\det{\tilde{A}} 
&= \lambda^2 M (2 a + \lambda^2 M)(e^{\nu(\lambda)X} - e^{-\nu(\lambda)X})
\end{align*}

\subsubsection{n-pulse}

Now comes the fun part where we generalize this to the $n-$pulse, which will be a $2n \times 2n$ matrix. Stephen will not be of much use here (in fact, if you do the 3-pulse in Mathematica, it looks terrible), so we will need to figure something else out. Let

\[
\tilde{A} = 
\begin{pmatrix}
K(\lambda) & -\lambda^2 M(\lambda) I  \\
C_2 & A - \lambda^2 MI
\end{pmatrix}
\]

First, we swap the rows, since we can just as easily write the system that way.

\[
\tilde{A} = 
\begin{pmatrix}
C_2 & A - \lambda^2 MI \\
K(\lambda) & -\lambda^2  M(\lambda) I  \\
\end{pmatrix}
\]

Here, we are lucky, since the matrices in the bottom row commute ($-\lambda^2  M(\lambda) I$ is a scalar multiple of the identity). Thus, using the Wikipedia article on the determinant, we have


\begin{align*}
\det \tilde{A} &= \det \Big( 
-\lambda^2  M(\lambda) I C_2 - 
K(\lambda)(A -\lambda^2  MI) \Big) \\
&= \det \Big( K(\lambda)(A -\lambda^2  MI) + 
\lambda^2 M(\lambda) C_2 
 \Big) \\
\end{align*}

(Since this matrix is $2n \times 2n$, we can ditch the negative sign, not that it matters.) So this is now the determinant of what we want plus something small. We could easily do an expansion if $K(\lambda)(A -\lambda^2  MI)$ were invertible, but of course we cannot assume that! Writing the remainder term as $R(\lambda)$, we have

\begin{align}\label{tildeAn}
\det \tilde{A} &= \det \Big( 
-\lambda^2  M(\lambda) I C_2 - 
K(\lambda)(A -\lambda^2  MI) \Big) \\
&= \det \Big( K(\lambda)(A -\lambda^2  MI) + 
R(\lambda)
 \Big) \\
\end{align}

where

\[
R(\lambda) = \mathcal{O}(e^{-\alpha X_m}|\lambda^2|(|\lambda| + e^{-\alpha X_m}) )
\]

We might be able do a perturbation analysis on this. Or we can leave it in the form, which resembles Theorem 2 in San98. If we take $\lambda = \mathcal{O}(e^{-\alpha X_m})$, then the remainder term is order $\mathcal{O}(e^{-4\alpha X_m})$ and the higher order terms are at most order $\mathcal{O}(e^{-2 \alpha X_m})$, so this should be good. 1`	`''


% As a corollary, for the 2-periodic pulse in KdV5, we can compute the eigenvalues exactly.

% % corrolary : eigenvalues for 2-per pulse

% \begin{corollary}
% The nonzero eigenvalues are given, to leading order, by

% \begin{equation}
% \lambda = \pm \sqrt{-2a/M}
% \end{equation}

% where $M$ is the higher order Melnikov integral defined in Theorem \ref{evpsol} and 

% \begin{equation}
% a = \langle \Psi (X_1), Q'(-X_1) \rangle + \langle \Psi (X_2), Q'(-X_2) \rangle 
% \end{equation}

% For $M a < 0$, the eigenvalues lie on the real axis and for $M a > 0$ the eigenvalues lie on the imaginary axis.

% \begin{proof}

% For KdV5, we know the form of $\Psi(x)$ (we showed this for the exponentially weighted version on the real line), thus it is not hard to show that

% \[
% \tilde{a}_i = \langle \Psi(-X_i), Q'(X_i) \rangle = -\langle \Psi(X_i), Q'(-X_i) \rangle = -a_i
% \]

% Thus the matrix $A$ from Theorem \ref{evpsol} becomes

% \begin{align*}
% A = 
% \begin{pmatrix}
% -a_0 - a_1 & a_0 + a_1 \\
% a_0 + a_1 & -a_0 - a_1
% \end{pmatrix}
% = a \begin{pmatrix}
% -1 & 1 \\
% 1 & -1
% \end{pmatrix}
% \end{align*}

% where $a = a_1 + a_2$. Using Theorem \ref{evpsol}, the eigenvalues are given, to leading order, by 

% \begin{align*}
% \det \left[ a \begin{pmatrix}
% -1 & 1 \\
% 1 & -1
% \end{pmatrix}
% - \lambda^2 MI \right] = 
% \det \begin{pmatrix}
% -a - \lambda^2 M & a \\
% a & -a - \lambda^2 M
% \end{pmatrix}
%  = 0
% \end{align*}

% Solving this for $\lambda$, the eigenvalues are given, to leading order, by

% \begin{align*}
% 0 &= (-a - \lambda^2 M)^2 - a^2 \\
% &= a^2 + 2 a \lambda^2 M + \lambda^4 M^2 - a^2 \\
% &= 2 a \lambda^2 M + \lambda^4 M^2 \\
% &= \lambda^2 M (2a + M \lambda^2 )
% \end{align*}

% This has two roots at 0 (corresponding to the 2-dimensional generalized kernel) as well as two roots at $\pm \sqrt{-2a/M}$. To leading order, these will be purely imaginary or real depending on the sign of $a$. By Theorem \ref{evpsol} these are the only four small eigenvalues. By symmetry we know that if there is an eigenvalue in the first quadrant of the complex plane, i.e. $\lambda = \alpha + \beta i$ with $\alpha, \beta > 0$, we must have a quartet of eigenvalues. This is not possible here, since there must be two eigenvalues at 0 and there are only 4 total eigenvalues. Thus the only possibilities are that the eigenvalues lie on the real axis (for $M a < 0$) or on the imaginary axis for $M a > 0$.

% % \end{proof}
% \end{corollary}

\end{document}