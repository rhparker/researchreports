\documentclass[12pt]{article}
\usepackage[pdfborder={0 0 0.5 [3 2]}]{hyperref}%
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}%
\usepackage[shortalphabetic]{amsrefs}%
\usepackage{amsmath}
\usepackage{enumerate}
% \usepackage{enumitem}
\usepackage{amssymb}                
\usepackage{amsmath}                
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage{float}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{mathtools}
\usepackage{cool}
\usepackage{url}
\usepackage{graphicx,epsfig}
\usepackage{makecell}
\usepackage{array}

\def\noi{\noindent}
\def\T{{\mathbb T}}
\def\R{{\mathbb R}}
\def\N{{\mathbb N}}
\def\C{{\mathbb C}}
\def\Z{{\mathbb Z}}
\def\P{{\mathbb P}}
\def\E{{\mathbb E}}
\def\Q{\mathbb{Q}}
\def\ind{{\mathbb I}}

\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\ran}{ran}

\graphicspath{ {periodic/} }

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{hypothesis}{Hypothesis}

\newtheorem{notation}{Notation}

\usepackage{xr}
\externaldocument{periodicexistence}

\begin{document}

\section{KdV5 with Periodic Boundary Conditions, Stability}

\subsection{Setup of Eigenvalue Problem for KdV5}

In the previous section, we proved the existence of periodic multipulse solutions to KdV5 using Lin's method. In this section, we will examine the spectral stability of the linearization about such solutions.\\

For $n \geq 2$, let $q_{np}(x)$ be an $n-$periodic solution to KdV5 associated with lengths $X_0, \dots, X_{n-1}$. Then by the construction via Lin's method, $q_{np}$ can be written piecewise, using the $2n$ pieces

\begin{align*}
q_i^-(x) &= q^-(0, \beta_i^-)(x) + u_i^-(x) && x \in [-X_{i-1}, 0]\\
q_i^+(x) &= q^+(0, \beta_i^+)(x) + u_i^+(x) && x \in [0, X_i]
\end{align*}

where the subscripts are all $\mod n$, e.g. $X_0 = X_n$. The functions $q^\pm(0, \beta_i^\pm)(x)$ evolve along the stable/unstable manifolds of the equilibrium at 0, and we have bounds on the remainder terms $u_i^\pm$ from the existence problem.\\

To assess the linear stability of such periodic multipulse solutions, we will look at the spectrum of the linearization of KdV5 about $q_{np}(x)$. For the linearization about an arbitrary equilibrium solution $u^*(x)$, the eigenvalue problem is $L(u^*) v(x) = \lambda v(x)$, where

\begin{equation}
L(u^*) = \partial_x^5 - \partial_x^3 + c \partial_x - 2 u^* \partial x - 2 u^*_x = 0
\end{equation}

First, we write the eigenvalue problem as the first order system

\begin{equation}
V' = A(u^*)V + \lambda B V
\end{equation}

where

\begin{align}
A(u^*) = \begin{pmatrix}0 & 1 & 0 & 0 & 0 \\0 & 0 & 1 & 0 & 0 \\0 & 0 & 0 & 1 & 0 \\0 & 0 & 0 & 0 & 1 \\
2u^*_x(x) & 2u^*(x) - c & 0 & 1 & 0 \end{pmatrix}, &&
B = \begin{pmatrix}0 & 0 & 0 & 0 & 0 \\0 & 0 & 0 & 0 & 0 \\0  & 0 & 0 & 0 & 0 \\0 & 0 & 0 & 0 & 0 \\1 & 0 & 0 & 0 & 0 \end{pmatrix} && 
\end{align}

Before we continue, we note that if we consider $A(0)$, the linearization about 0, for $c > 1/4$ we have eigenvalues $\nu = \{ 0, \pm \alpha \pm \beta i\}$, where $\alpha, \beta > 0$. The equilibrium at 0 is not hyperbolic, so we cannot directly apply the results of San98. The equilibrium at 0 has 2-dimensional stable/unstable manifolds, and a 1-dimensional center manifold. Let $W^{s/u/c}(0)$ be these manifolds.\\

As in the existence problem, we make the following nondegeneracy assumption.

\begin{hypothesis}
\[
T_{Q(0)} W^u(0) \cap T_{Q(0)} W_s(0) = \R Q'(0)
\]
\end{hypothesis}

where $Q(x)$ is the single pulse solution on $\R$. This is equivalent to the the fact that $Q'(x)$ is the unique bounded solution to the variational equation

\begin{equation}
V' = A(q)V
\end{equation}

It follows from San93 that the adjoint variational equation

\begin{equation}
W' = -A(q)^*W
\end{equation}

has a unique bounded solution $\Psi$. Next, as in San98, we decompose the tangent space at $Q(0)$ as

\begin{equation}
\R^5 = Z \oplus \R Q'(0) \oplus Y^+ \oplus Y^- \oplus Y^0
\end{equation}

where $Z = \R \Psi(0)$, and $Y^+$ and $Y^-$ are chosen so that

\begin{align*}
T_{Q(0)} W^s(0) &= \R Q'(0) \oplus Y^+ \\
T_{Q(0)} W^u(0) &= \R Q'(0) \oplus Y^- \\
\end{align*}

We have not yet looked at $Y^0$, but this space will correspond in some sense to the center manifold of $A(0)$. For now, we can say nothing about this space, but since it is one-dimensional, we will be able to fully characterize it in a later section.\\

Returning to the problem at hand, we next use the piecewise construction of the periodic $n-$pulse to write this in the equivalent piecewise form

\begin{align*}
(V_i^\pm)' &= A( q^\pm(0, \beta_i^\pm) + u_i^\pm) V_i^\pm + \lambda B V_i^\pm \\
V_i^-(0) &= V_i^+(0) \\
V_i^+(X_i) &= V_{i+1}^-(-X_i) 
\end{align*}

for $i = 0, \dots, n-1$. \\

At this point, we make the following hypothesis.

\begin{hypothesis}\label{higherMelnikov}
\begin{equation}\label{higherMelnikovnonzero}
\langle q, q_c \rangle_{L^2(\R)} = \int_{-\infty}^\infty q(x) q_c(x) dx \neq 0
\end{equation}
\end{hypothesis}

This is the higher order Melnikov integral, and numerics suggests that it is in fact nonzero.\\

Before we simplify this further, we note that for the single pulse $q$, $L(q)$ has a 2-dimensional generalized kernel with the following generalized eigenfunctions.

\begin{align}\label{genkernel}
L(q)q_x &= 0 \nonumber \\
L(q)(-q_c) &= q_x
\end{align}

The fact that this generalized kernel is 2-dimensional follows from Hypothesis \ref{higherMelnikov}. If there were another generalized eigenfunction $u$ in the Jordan chain, we would have by the Fredholm alternative

\begin{align*}
L(q) u = -q_c &\iff q_c \in (\ker L(q)^*)^\perp \\
&\iff \langle q, q_c \rangle = 0 
\end{align*} 

This last quantity is nonzero by Hypothesis \ref{higherMelnikov}. It follows that

\begin{align*}
(Q_x)' &= A(q) Q_x \\
(Q_c)' &= A(q) Q_c + B Q_x
\end{align*}

To exploit these, we write $V_i^\pm$ as 

\begin{equation}
V_i^\pm(x) = d_i (Q_{np}'(x) + \lambda (Q_{np})_c(x)) + W_i^\pm 
\end{equation}

where $d_i \in \C$ are arbitrary constants. Substituting this into the piecewise system, using \eqref{genkernel}, and simplifying, we get the system

\begin{align*}
&(W_i^\pm)' = A( q^\pm(0, \beta_i^\pm) ) + u_i^\pm) W_i^\pm + \lambda B W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm \\
&W_i^-(0) = W_i^+(0) \\
&W_i^\pm(0) \in \C \Psi(0) \oplus Y^+ \oplus Y^- \\
&W_i^+(X_i) - W_{i+1}^-(-X_i) = D_i d
\end{align*}

where

\begin{align*}
D_i d &= d_{i+1}(Q_{np}'(-X_i) + \lambda (Q_{np})_c(-X_i))
- d_i ( Q_{np}'(X_i) + \lambda (Q_{np})_c(X_i) ) \\
\tilde{H}_i^\pm &= -B( Q^\pm(0, \beta_i^\pm)_c + (U_i^\pm)_c)  \\
H &= -B Q_c \\
\Delta H_i^\pm &= \tilde{H}_i^\pm - H
\end{align*}

Before we continue, we make a brief note about the condition $W_i^\pm(0) \in \C \Psi(0) \oplus Y^+ \oplus Y^-$. Recall that we are writing our eigenfunction piecewise as $V_i^\pm(x) = d_i(Q_{2p}'(x) + \lambda (Q_{2p})_c(x)) + W_i^\pm $. $Q_{2p}(0)$ and its derivatives have no component in $Y^0$ since they both decay exponentially at both ends. Since we seek eigenfunctions which decay exponentially at both ends, this implies that $W_i^\pm(0)$ cannot have a component in $Y^0$.\\

Finally, we note that the operator $A(u^*)$ is linear in $u^*$ (this is apparent from the definition). Thus the first equation can be written as 

\begin{align*}
(W_i^\pm)' = A(q^\pm(0, \beta_i^\pm)) W_i^\pm + \lambda B W_i^\pm + A(u_i^\pm) W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm
\end{align*}

The advantage of this formulation is that we have bounds on $A(u_i^\pm)$ from the existence problem, and we also know about the decay of $q^\pm$ from the existence problem.\\

Although we could likely use this version of the problem, the drawback is that it contains a term in both $\lambda$ and $\lambda^2$. To eliminate the term in $\lambda$, we use the following idea. As noted above, the matrix $A(0)$ has an eigenvalue at 0, which gives it a center subspace. What we will do is combine the matrices $A(q^\pm(0, \beta_i^\pm))$ and $\lambda B$ to get a new parameter-dependent matrix $A(q^\pm(0, \beta_i^\pm); \lambda)$, i.e. 

\begin{align*}
A(q^\pm(0, \beta_i^\pm); \lambda) &= A(q^\pm(0, \beta_i^\pm)(x)) + \lambda B \\
&= \begin{pmatrix}0 & 1 & 0 & 0 & 0 \\0 & 0 & 1 & 0 & 0 \\0 & 0 & 0 & 1 & 0 \\0 & 0 & 0 & 0 & 1 \\
2 (q^\pm(0, \beta_i^\pm))'(x) + \lambda & 2 q^\pm(0, \beta_i^\pm)(x) - c & 0 & 1 & 0 \end{pmatrix}
\end{align*}

For the $\lambda$-dependent matrix $A(q^\pm(0, \beta_i^\pm); \lambda)$, the eigenvalue at 0 will perturb slightly to a small eigenvalue in a $\lambda$-dependent fashion. The following heuristic argument provides a partial justification for this. Due to the decay properties of $q^\pm$, the matrix $A(q^\pm(0, \beta_i^\pm); \lambda)$ is exponentially asymptotic to $A(0; \lambda)$. We know that $A(0; 0)$ has an eigenvalue at 0. The characteristic polynomial for $A(0; \lambda)$ is $f(\nu; \lambda) = \lambda - c \nu + \nu^3 - \nu^5 = \lambda - c \nu + \mathcal{O}(\nu^3)$. Thus,f for small $\lambda$, this polynomial has a zero at approximately $\nu = \lambda / c$. Numerics shows this is approximation is very close.\\

Thus, the final form of our problem is

\begin{align}
&(W_i^\pm)' = A(q^\pm(0, \beta_i^\pm); \lambda) W_i^\pm + A(u_i^\pm) W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm \\
&W_i^-(0) = W_i^+(0) \\
&W_i^\pm(0) \in \C \Psi(0) \oplus Y^+ \oplus Y^- \\
&W_i^+(X_i) - W_{i+1}^-(-X_i) = D_i d
\end{align}

In the following lemma, we give bounds for terms relevant to this problem.

% lemma : problem bounds

\begin{lemma}\label{problembounds}
We have the following estimates
\begin{align*}
|A(u_i^-(x); \lambda)| &\leq C e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + x) } \\
|A(u_i^+(x); \lambda)| &\leq C e^{-\alpha X_i} e^{-\alpha(X_i - x) } \\
|H(x)|, |\tilde{H}_i^\pm(x)| &\leq C e^{-\alpha |x|} \\
|\Delta H_i^\pm| &\leq C(e^{-\alpha X_i} + e^{-\alpha X_{i-1}} ) \\
D_i d &= ( Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) + \mathcal{O} \left( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right) \\
\end{align*}

\begin{proof}
The first two bounds come from the bounds on the remainder term from the existence problem (the notation $V$ is used for the remainder term there, as opposed to $U$ here), together with the fact that the matrix $A$ is a bounded linear operator. Note that the bound is strongest at $x = 0$ and is weakest at $\pm X_i$. \\

For the third, we first recall that $H = -B Q_c$, and we have shown (somewhere else) using a contraction mapping argument that $q_c$ exists, is exponentially localized, and decays exponentially with rate $\alpha$. An identical proof shows that the same holds for $(q_{2p})_c$, thus for $\tilde{H}$.\\
 
Next, we look at we look at $\Delta H = \tilde{H}_i^\pm - H$. Noting the definition of $B$, we only have to look at 

\[
(q^\pm(0, \beta_i^\pm)(x) - q(x)) + u_i^\pm(x)
\]

and its derivative with respect to $c$. From the existence proof, we recall that $|u_i^+| \leq C e^{-\alpha X_i}$, $|u_i^-| \leq C e^{-\alpha X_{i-1}}$, and $|(\beta_i^+, \beta_i^-)| \leq C( e^{-\alpha X_i} + e^{-\alpha X_{i-1}})$. Since the same bounds hold for derivatives with respect to $c$, we attain the bound given for $|\Delta H_i^\pm|$.\\

For the fourth, we have

\begin{align*}
D_i d &= d_{i+1}(Q_{np}'(-X_i) + \lambda (Q_{np})_c(-X_i)) - d_i ( Q_{np}'(X_i) + \lambda (Q_{np})_c(X_i) ) \\
&= d_{i+1} (Q^-(0; \beta_i^-)'(-X_i) + U_i^-(-X_i)) - d_i (Q^+(0; \beta_i^+)'(X_i) + U_i^+(X_i)) + \mathcal{O}(e^{-\alpha X_i} |\lambda||d|)
\end{align*}

The result follows from Lemma 2.6 in San98, which follows from San93.

\end{proof}
\end{lemma}

\subsection{General Form}

Consider the general system on $\R^m$, where $m = 2k + 1, k \in \N$

\begin{enumerate}
\item $(W_i^\pm)' = A(q^\pm(0, \beta_i^\pm); \lambda) W_i^\pm + G_i^\pm W_i^\pm + \lambda^2 d_i \tilde{H}_i^\pm$
\item $W_i^-(0) = W_i^+(0)$
\item $W_i^\pm(0) \in \C \Psi(0) \oplus Y^+ \oplus Y^- $
\item $W_i^+(X_i) - W_{i+1}^-(-X_i) = D_i d$
\end{enumerate}

for functions $G = (G_i^\pm)$, $\tilde{H} = (\tilde{H})_i^\pm$, matrices $D = (D_i)$, and $\lambda \in \C$ satisfying 

\begin{align}
|G_i^-(x)| &\leq C e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + x) } \\
|G_i^+(x)| &\leq C e^{-\alpha X_i} e^{-\alpha(X_i - x) } \\
||G|| &\leq \delta \\
|H(x)|, |H_i^\pm(x)| &\leq C e^{-\alpha |x|} \\
|\Delta H_i^\pm(x)| &= |\tilde{H}_i^\pm(x) - H(x)| \leq C( e^{-\alpha X_i} + e^{-\alpha X_{i-1}}) \\
|\lambda| &\leq \delta \\
|D_j| &\leq \delta
\end{align}

where $\delta > 0$ is small and $H$ is a smooth, bounded function. We make the following assumptions about the operator $A$.

\begin{hypothesis}\label{Aspectrumhyp}
\begin{enumerate}
	\item The spectrum of $A(0; 0)$ has isolated, simple eigenvalues at $\{ 0, \pm \alpha_0 \pm \beta_0 \}$, where $\alpha_0, \beta_0 > 0$. The real part of any other eigenvalue of $A(0; 0)$ lies outside the interval $[-\alpha_0, \alpha_0]$.
	\item Let $\{\nu_i\}$ be the eigenvalues of $A(0; 0)$. Then the eigenvalues of $A(0; \lambda)$ are given by $\nu(\lambda)_i = \nu_i + \mathcal{O}(|\lambda|)$. In particular, $A(0; \lambda)$ has a simple eigenvalue $\nu(\lambda) = \mathcal{O}(|\lambda|)$.
\end{enumerate}
\end{hypothesis}

Before we continue, we define the following constants

\begin{enumerate}

	\item Let

	\begin{align*}
	X_m &= \min(X_0, \dots, X_{n-1}) \\
	X_M &= \max(X_0, \dots, X_{n-1}) \\
	\end{align*}

	\item Let $n_-$ be the number of eigenvalues of $A(0; 0)$ with negative real part, and $n_+$ be the number of eigenvalues of $A(0; 0)$ with positive real part. Then, by Hypothesis \ref{Aspectrumhyp}, $n_-, n_+ \geq 2$, and $n_- + n_+ + 1 = m$.

	\item Let $\nu(\lambda)$ be the simple, small eigenvalue of $A(0; \lambda)$. By Hypothesis \ref{Aspectrumhyp}, $\nu(0) = 0$, and $\nu(\lambda) = \mathcal{O}(\lambda)$. 

	\item Let $\delta > 0$ be a small. How small will be determined later. We will always take $|\lambda| < \delta$.

	\item Let $\rho > 0$ so that $\rho$ is much smaller than $\alpha_0$. For our analysis, it suffices to take $4 \rho < \alpha_0$. Then, using Hypothesis \ref{Aspectrumhyp}, we can choose $\delta$ sufficiently small so that 

	\begin{enumerate}
		\item $3 |\nu(\lambda)| < \rho$ for all $|\lambda| < \delta$ 
		\item For all $|\lambda| < \delta$, the real part of all other eigenvalues of $A(0; \lambda)$ lies outside the interval $[-\alpha_0 + \rho, \alpha_0 - \rho]$ 
	\end{enumerate}

	\item Let $\alpha = \alpha_0 - 2 \rho$

	\item Let $\tilde{\alpha} = \alpha - \rho > 0$. Note that this implies $3|\nu(\lambda)| < \alpha - \tilde{\alpha}$ for all $|\lambda| < \delta$.

	\item By our choice of $\rho$, we have $|\nu(\lambda)| < \rho < \tilde{\alpha}$ for all $|\lambda| < \delta$

	\item Choose $X_m$ sufficiently large such that

	\begin{equation}
	e^{-\alpha X_m}, ||G||, |\lambda|, ||\Delta H|| < \delta
	\end{equation}

\end{enumerate}

\subsection{Characterization of Center Subspace}

Consider the family of equations

\begin{equation}\label{varparam}
(V^\pm)' = A(q^\pm(0, \beta^\pm); \lambda) V^\pm
\end{equation}

parameterized by $\beta^\pm$ and $\lambda$, where $V^+$ is defined on $\R^+$ and $V^-$ is defined on $\R^-$, and the functions $q^\pm(0, \beta^\pm)(x)$ are defined in the existence problem. Let $\Phi_\pm(x, y; \beta^\pm, \lambda)$ be the family of evolution operators associated with \eqref{varparam}, where $\Phi_+$ is defined for $x, y \in \R^+$ and $\Phi_-$ is defined for $x, y \in \R^-$. Recall that the asymptotic matrix $A(0; \lambda)$ has a small eigenvalue $\nu(\lambda)$ with $|3 \nu(\lambda)| < \rho$ for all $|\lambda| < \delta$. In this section, we will construct a solution to \eqref{varparam} and its adjoint problem which grows/decays with exponential rate $\nu(\lambda)$.\\

We start by proving the following lemma, based on Exercise 29 on p. 104 of Coddington and Levinson (1955).

% lemma : 1d evolution of EVP on R^+

\begin{lemma}\label{1devolpos}
Consider the eigenvalue problem on $\R^+$

\begin{equation}\label{veigproblem}
V(x)' = AV(x) + R(x)V(x)
\end{equation}

where $V(x) \in R^n$, $A$ is a constant, diagonalizable $n \times n$ matrix, and $R(x): \R \rightarrow \R^n$ is an integrable function which is globally Lipschitz continuous in $x$. Let $\nu$ be any eigenvalue of $A$ with corresponding eigenvector $p$, i.e. $A p = \nu p$. Then there is a unique solution $\phi(x)$ to \eqref{veigproblem} such that 

\[
\lim_{x\rightarrow\infty} \phi(x) e^{-\nu x} = p
\]

In other words, for large $x$, the solution $\phi(x)$ resembles that of the constant coefficient eigenvalue problem $V(x)' = AV(x)$.

\begin{proof}
Let $\sigma = \text{Re} \nu$. Let $\nu_1, \dots, \nu_n$ be the $n$ eigenvalues of $A$ with corresponding eigenvectors $p_1, \dots, p_n$. Since we are assuming that $A$ is diagonalizable, we have a complete set of $n$ of these. Order the eigenvalues by increasing real part; if more than one eigenvalue has the same real part, any order is fine, as long as we make sure that any eigenvalue besides $\nu$ with real part $\sigma$ occurs after $\nu$ in the list. Then $\nu = \nu_k$ for some $k$, $\text{Re} \nu_j < \sigma$ for $j < k$ (as long as $k \neq 1$), and $\text{Re} \nu_j \geq \sigma$ for $j \geq k$. \\

Let $e^{Ax}$ be the fundamental matrix solution for $U' = A U$, and split $e^{Ax}$ up into
\[
e^{Ax} = Y_1(x) + Y_2(x)
\]

where $Y_1$ involves only eigenvectors corresponding to eigenvalues $\nu_1, \dots, \nu_{k-1}$ and $Y_2$ involves only eigenvectors corresponding to eigenvalues $\nu_{k}, \dots, \nu_n$. Since $A$ is a constant-coefficient matrix, we can write down an explicit formula for $Y_1$ and $Y_2$. Essentially, all we need to do is change coordinates to the eigenbasis, evolve along the appropriate eigenvectors, and zero out the other ones. To be specific, let P be the $n \times n$ matrix with columns $p_1, \dots, p_n$. Since we are assuming $A$ is diagonalizable, this matrix is invertible, and $D = P^{-1}AP$ is diagonal with eigenvalues $\nu_1, \dots, \nu_n$ on the diagonal. Recall that the matrix exponential is given by $e^{Ax} = P^{-1}e^{Dx}P$. Starting with the matrix $D$, form the matrix $D_1$ by keeping only the eigenvalues $\nu_1, \dots, \nu_{k-1}$ on the diagonal, and form the matrix $D_2$ by keeping only the eigenvalues $\nu_{k}, \dots, \nu_n$ on the diagonal. Then we have

\begin{align*}
Y_1(x) &= P^{-1}e^{D_1x}P \\
Y_1(x) &= P^{-1}e^{D_2x}P \\
\end{align*}
 
Choose $\delta$ such that $0 < \delta < \sigma - \text{Re} \nu_{k-1}$, i.e. smaller than the spectral gap between $\nu$ and the eigenvalue with the next smallest real part. (If $k = 1$, $Y_1 = 0$, $Y_2 = e^{Ax}$, and we don't care about $\delta$). Then we can find a constant $C$ such that

\begin{align*} 
|Y_1(x)| &\leq Ce^{(\sigma - \delta)x} && x \geq 0 \\
|Y_2(x)| &\leq Ce^{\sigma x} && x \leq 0 
\end{align*}

Define the exponentially weighted function space with weight $\sigma$

\[
B_{\sigma, a} = \{ f \in C^0([a, \infty), \R^n) : \sup_{x \in [a, \infty)} |e^{-\sigma x} f(x)| < \infty 
\]

where $a$ will be chosen later. The norm on this space is given by

\[
||f||_{\sigma, a} = \sup_{x \in [a, \infty)} |e^{-\sigma x} f(x)|
\]

In other words, we allow functions in $B_{\sigma, a}$ to grow exponentially as $x \rightarrow \infty$ at a rate of $\sigma$ or slower. It is known that $B_{\sigma, a}$ is a Banach space. Define the operator $F$ on $B_{\sigma, a}$ by

\begin{align*}
F(\phi)(x) = e^{\nu x} p + \int_a^x Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2(x - y)R(y)\phi(y)dy
\end{align*}

where the $a$ in the integral is the same as in $B_{\sigma, a}$ and will be chosen later. First we show that $F: B_{\sigma, a} \rightarrow B_{\sigma, a}$. Let $\phi \in B_{\sigma, a}$. For $x \geq a$ we have

\begin{align*}
|e^{-\sigma x} &F(\phi)(x)| \leq e^{(\nu - \sigma) x} |p| + \int_a^x |Y_1(x - y)||R(y)||\phi(y)| dy + \int_x^\infty |Y_2(x - y)||R(y)||\phi(y)|dy \\
&\leq |p| + C \left( e^{-\sigma x}  \int_a^x e^{(\sigma - \delta)(x - y)}|R(y)||\phi(y)| dy + e^{-\sigma x}  \int_x^\infty e^{\sigma(x - y)}|R(y)||\phi(y)|dy \right) \\
&\leq |p| +  C \left( \int_a^x e^{-\delta(x - y)}|R(y)||e^{-\sigma y}\phi(y)| dy + \int_x^\infty |R(y)||e^{-\sigma y} \phi(y)|dy \right) \\
&\leq |p| + C ||\phi||_{\sigma, a}\left( \int_a^x e^{-\delta(x - y)}|R(y)| dy + \int_x^\infty |R(y)|dy \right) \\
&\leq |p| + C ||\phi||_{\sigma, a} \int_a^\infty |R(y)| dy 
\end{align*}

Since $R$ is integrable, the RHS is finite, thus the map $F: B_{\sigma, a} \rightarrow B_{\sigma, a}$ is well defined. Now we show the map $F$ is a contraction. Let $\phi, \psi \in B_{\sigma, a}$. For $x \geq a$ we have

\begin{align*}
|e^{-\sigma x}( &F(\phi)(x) - F(\psi)(x))| \leq \int_a^x |Y_1(x - y)||R(y)||\phi(y) - \psi(y)| dy + \int_x^\infty |Y_2(x - y)||R(y)||\phi(y) - \psi(y)|dy \\
&\leq C \left( e^{-\sigma x}  \int_a^x e^{(\sigma - \delta)(x - y)}|R(y)||\phi(y) - \psi(y)| dy + e^{-\sigma x}  \int_x^\infty e^{\sigma(x - y)}|R(y)||\phi(y) - \psi(y)|dy \right) \\
&\leq C \left( \int_a^x e^{-\delta(x - y)}|R(y)||e^{-\sigma y}(\phi(y) - \psi(y))| dy + \int_x^\infty |R(y)||e^{-\sigma y} (\phi(y) - \psi(y))|dy \right) \\
&\leq C ||\phi - \psi ||_{\sigma, a}\left( \int_a^x e^{-\delta(x - y)}|R(y)| dy + \int_x^\infty |R(y)|dy \right) \\
&\leq C ||\phi - \psi ||_{\sigma, a} \int_a^\infty |R(y)| dy 
\end{align*}

Since $R$ is integrable, we can choose $a$ sufficiently large so that

\[
\int_a^\infty |R(y)| dy < \frac{1}{2C}
\]

from which we conclude that

\[
||F(\phi) - F(\psi) ||_{\sigma, a} \leq \frac{1}{2} ||\phi - \psi ||_{\sigma, a}
\]

Since $F$ is a contraction on the Banach space $B_{\sigma, a}$, by the Banach Fixed Point Theorem the map $F$ has a unique fixed point, i.e. a unique $\phi(x) \in B_{\sigma, a}$ such that $F(\phi) = \phi$. Note that by the fixed point theorem and definition of $B_{\sigma, a}$, we only have $\phi(x)$ defined for $\phi \geq a$. However, choosing the initial condition $\phi(a)$ at $x = a$, by the existence and uniqueness of solutions to \eqref{veigproblem} and the global Lipschitz condition placed on $R(x)$ (which guarantees global existence of solutions), we can extend $\phi(x)$ uniquely to all of $\R$. This extension of $\phi(x)$ to $\R$ is given by the same formula we have for $\phi(x)$ when $x \geq a$.

\begin{equation}\label{fpphi}
\phi(x) = e^{\nu x} p + \int_a^x Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2(x - y)R(y)\phi(y)dy
\end{equation}

To see this, all we need to do is show that it satisfies the ODE \eqref{veigproblem}. Differentiating \eqref{fpphi}, we get

\begin{align*}
\phi'(x) &= \nu e^{\nu x} p + (Y_1(0) + Y_2(0))R(x)\phi(x) + \int_a^x Y_1'(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2'(x - y)R(y)\phi(y)dy \\
&= e^{\nu x} A p + e^{0A}R(x)\phi(x) + \int_a^x A Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x A Y_2(x - y)R(y)\phi(y)dy \\
&= A \left( e^{\nu x} p + \int_a^x Y_1(x - y)R(y)\phi(y)dy + \int_\infty^x Y_2(x - y)R(y)\phi(y)dy \right) + R(x) \phi(x) \\
&= A \phi(x) + R(x) \phi(x)
\end{align*}

Thus $\phi(x)$ defined in \eqref{fpphi} is the unique extension that we seek. All that remains is to show what happens when $x \rightarrow \infty$. Since we are interested in end behavior, we only need to consider what happens when $x \geq a$. Since $\phi(x) \in B_{\lambda, a}$, $||\phi||_{\sigma, a}$ is finite and independent of $x$. Thus for $x \geq a$, using what we did above, 

\begin{align*}
|e^{-\sigma x} &(\phi(x) - e^{\nu x} p)| \leq C ||\phi||_{\sigma, a}\left( \int_a^x e^{-\delta(x - y)}|R(y)| dy + \int_x^\infty |R(y)|dy \right) \\
&\leq C ||\phi||_{\sigma, a}\left( \int_a^{x/2} e^{-\delta(x - y)}|R(y)| dy + \int_{x/2}^x |R(y)|+ \int_x^\infty |R(y)|dy \right)\\
&\leq C ||\phi||_{\sigma, a}\left( e^{-\delta(x/2)} \int_a^{x/2} e^{-\delta(x/2 - y)}|R(y)| dy + \int_{x/2}^\infty |R(y)|dy \right)\\
&\leq C ||\phi||_{\sigma, a}\left( e^{-\delta(x/2)} \int_a^{\infty} |R(y)| dy + \int_{x/2}^\infty |R(y)|dy \right)\\
&\leq ||\phi||_{\sigma, a}\left(\frac{1}{2} e^{-\delta(x/2)} + \int_{x/2}^\infty |R(y)|dy \right)
\end{align*}

Since $\delta > 0$, $R(x)$ is integrable, and $||\phi||_{\sigma, a}$ is constant, both terms on the RHS go to 0 as $x \rightarrow \infty$. Thus we conclude that

\[
\lim_{x \rightarrow \infty} |e^{-\sigma x} (\phi(x) - e^{\nu x} p)| = 0
\]

Pulling out a factor of $e^{\nu x}$, this becomes 

\[
\lim_{x \rightarrow \infty} |e^{(\nu - \sigma) x}||\phi(x) e^{-\nu x} - p)| = 0
\]

since $\text{Re} \phi = \nu$, $|e^{(\nu - \sigma) x} = 1$ for all $x$. Thus we conclude that

\[
\lim_{x \rightarrow \infty} |\phi(x) e^{-\nu x} - p)| = 0
\]  

from which it follows that

\[
\lim_{x\rightarrow\infty} \phi(x) e^{-\nu x} = p
\]

\end{proof}
\end{lemma}

We have the same result on $R^-$, as shown in the following corollary

% corrolary : same result on R^-

\begin{corollary}\label{1devolneg}
The same result holds on $(-\infty, 0]$ if we take $x \rightarrow -\infty$, i.e. there is a unique solution $\tilde{\phi}(x)$ to \eqref{veigproblem} such that 

\[
\lim_{x\rightarrow -\infty} \tilde{\phi}(x) e^{-\nu x} = p
\]

This function in general will not be the same as $\phi(x)$ in Lemma \ref{1devolpos}.

\begin{proof}
First we replace $x$ with $-x$ in \eqref{veigproblem}

\begin{align*}
V'(-x) = A V(-x) + R(-x)V(-x)
\end{align*}

Let $\tilde{V}(x) = V(-x)$ and $\tilde{R}(x) = -R(-x)$. Then since $\tilde{V}'(x) = -V'(-x)$, we get

\begin{align*}
\tilde{V}'(x) = -A \tilde{V}(x) + \tilde{R}(x)\tilde{V}(x)
\end{align*}

Now we use Lemma \ref{1devolpos} on $\tilde{V}$ (for $x \geq 0$). Since $-A$ has an eigenvector $p$ with corresponding eigenvalue $-\nu$, by the above lemma we can find a unique solution $\psi(x)$ such that 

\[
\lim_{x\rightarrow \infty} \psi(x) e^{(-\nu)(-x)} = p
\]

Let $\tilde{\phi(x)} = \psi(-x)$. Then $\tilde{\phi(x)}$ solves the original problem, and

\[
\lim_{x\rightarrow -\infty} \tilde{\phi}(x) e^{-\nu x } = p
\]

\end{proof}
\end{corollary}

We will now use these lemmas to characterize the ``center'' subspace. Fix $\beta^+$, $\beta^-$, and $
\lambda$ with $|\lambda| < \delta$. We are interested in the following pair of eigenvalue problems together with their adjoint problems.

\begin{align}
V_+' &= A(q^+(0, \beta^+)(x); \lambda) V_+ && x \geq 0 \label{eig:V+} \\
W_+' &= -A(q^+(0, \beta^+)(x); \lambda)^* W_+ && x \geq 0\label{eig:W+} \\
V_-' &= A(q^-(0, \beta^-)(x); \lambda) V_- && x \leq 0 \label{eig:V-} \\
W_-' &= -A(q^-(0, \beta^-)(x); \lambda)^* W_- && x \leq 0 \label{eig:W-}
\end{align}

$V_\pm$ and $W_\pm$ will depend on $\beta^\pm$ and $\lambda$, but for convenience we suppress that notation. Let $\Phi_+(y, x; \beta^+, \lambda)$ be the evolution operator for \eqref{eig:V+} and $\Phi_-(y, x; \beta^-, \lambda)$ be the evolution operator for \eqref{eig:V-}.\\

First, we summarize some useful facts about these eigenvalue problems in the following lemma. For what follows, we define the inner product on $\C^n$ by $\langle x, y \rangle = \sum_i x_i \bar{y_i}$, i.e. the complex conjugation is on the second component.

% lemma : facts about our eigenvalue problem

\begin{lemma}\label{eigadjoint}
Consider the linear ODE $V' = A(x)V$ and the corresponding adjoint problem $W' = -A(x)^* W$, where $A$ is an $n \times n$ matrix depending on $x$. Then the following are true.
\begin{enumerate}[(i)]
\item $\dfrac{d}{dx}\langle V(x), W(x) \rangle = 0$, thus the inner product is constant in $x$.
\item If $\Phi(y, x)$ is the evolution operator for $V' = A(x)V$, then $\Phi(x, y)^*$ is the evolution operator for the adjoint problem $W' = -W(x)^* W$.
\end{enumerate}
\begin{proof}
For (i), take the derivative of the inner product and use the expressions for $V'$ and $W'$. For (ii), take the derivative of the expression $\Phi(y, x)\Phi(x, y) = I$.
\end{proof}
\end{lemma}

Recall that for $|\lambda| < \delta$, the asymptotic matrix $A(0; \lambda)$ has a simple eigenvalue $\nu(\lambda)$ near 0, and $\nu(0) = 0$. Let $v_0(\lambda)$ be the corresponding eigenvector, i.e.

\begin{equation}\label{defv0}
A(0; \lambda) v_0(\lambda) = \nu(\lambda) v_0(\lambda)
\end{equation}

Since $\det(A - \nu I) = 0$ implies $\det(A^* - \overline{\nu}I) = 0$, $-\overline{\nu(\lambda)}$ is the small eigenvalue of $-A(0; \lambda)^*$; let $w_0(\lambda)$ be the corresponding eigenvector, i.e.

\begin{equation}\label{defw0}
-A(0; \lambda)^* w_0(\lambda) = -\overline{\nu(\lambda)} v_0(\lambda)
\end{equation}

Since these are eigenvalues and eigenvectors of the asymptotic matrix $A(0; \lambda)$, $\nu(\lambda)$, $v_0(\lambda)$, and $w_0(\lambda)$ depend on $\lambda$ but not on $\beta^\pm$.\\

It would be convenient if there were a nice relationship between $v_0(\lambda)$ and $w_0(\lambda)$, but without additional assumptions on $A(0; \lambda)$, this is not the case. Failing that, we would settle for knowing $\langle v_0(\lambda), w_0(\lambda) \rangle \neq 0$. Even this is too much to ask in general. As an easy counterexample, if we take

\[
M = \begin{pmatrix}1 & 1 \\ 0 & 1 \end{pmatrix}
\]

$M$ has a single eigenvector $(1, 0)$ and $M^*$ has a single eigenvector $(0, 1)$, both corresponding to the lone eigenvalue 1. These are clearly orthogonal. The problem here is the Jordan block, as we see in the following lemma.

% lemma : v and w cannot be orthogonal

\begin{lemma}\label{perpeigs}
Let $A$ be an $n \times n$ matrix, and suppose $v$ and $w$ are solutions to $Av = \lambda v$ and $A^*w = \overline{\lambda}w$, respectively. Suppose $\lambda$ is a simple eigenvalue, i.e. is has algebraic multiplicity of 1. Then $\langle v, w \rangle \neq 0$.
\begin{proof}
Since $\lambda$ is simple, $\text{span} \{w\} = \ker(A^* - \overline{\lambda}I)$. Suppose $v \perp w$. Then $v \in \ker(A^* - \overline{\lambda I})^\perp = \text{ran}(A - \lambda I)$, where the equality holds since $A$ is finite dimensional, thus has closed range. But this implies $(A - \lambda I)v_1 = v$ for some $v_1$, which cannot be the case since $\lambda$ is simple, so there cannot be such a generalized eigenvector. We conclude that $\langle v, w \rangle \neq 0$
\end{proof}
\end{lemma}

By this lemma, we conclude that for $|\lambda| < \delta$, $\langle v_0(\lambda), w_0(\lambda) \rangle \neq 0$. Since eigenvectors are defined up to scalar multiples, we scale $v_0(\lambda)$ and/or $w_0(\lambda)$ so that

\begin{equation}\label{v0w0IP1}
\langle v_0(\lambda), w_0(\lambda) \rangle = 1
\end{equation}
 
Using Lemma \ref{veigproblem}, let $\tilde{v}_+(x; \beta^+, \lambda)$ and $\tilde{w}_+(x; \beta^+, \lambda)$ be solutions to the eigenvalue problem \eqref{eig:V+} and its adjoint problem \eqref{eig:W+} on $\R^+$ such that

\begin{align*}
\lim_{x \rightarrow \infty} e^{-\nu(\lambda) x} \tilde{v}_+(x; \beta^+, \lambda) = v_0(\lambda) \\
\lim_{x \rightarrow \infty} e^{\overline{\nu(\lambda)} x} \tilde{w}_+(x; \beta^+, \lambda) = w_0(\lambda) \\
\end{align*}

To scale out the exponential term, let

\begin{align}
\tilde{v}_+(x; \beta^+, \lambda) &= e^{\nu(\lambda) x } v_+(x; \beta^+, \lambda) \label{tildev+} \\
\tilde{w}_+(x; \beta^+, \lambda) &= e^{-\overline{\nu(\lambda)} x } w_+(x; \beta^+, \lambda) \label{tildew+} 
\end{align}

Then we have

\begin{align*}
\lim_{x \rightarrow \infty} v_+(x; \beta^+, \lambda) = v_0(\lambda) \\
\lim_{x \rightarrow \infty} w_+(x; \beta^+, \lambda) = w_0(\lambda) \\
\end{align*}

We know that this limit exists, but since we scaled out the exponential term, we do not have a decay rate for $|v_+(x; \beta^+, \lambda) - v_0(\lambda)|$ or $|w_+(x; \beta^+, \lambda) - w_0(\lambda)|$.\\

Similarly, using Corollary \ref{1devolneg}, let $\tilde{v}_-(x; \beta^-, \lambda)$ and $\tilde{w}_-(x; \beta^-, \lambda)$ be solutions to the eigenvalue problem \eqref{eig:V-} and its adjoint problem \eqref{eig:W-} on $\R^-$ such that

\begin{align*}
\lim_{x \rightarrow -\infty} e^{-\nu(\lambda) x} \tilde{v}_-(x; \beta^-, \lambda) = v_0(\lambda) \\
\lim_{x \rightarrow -\infty} e^{\overline{\nu(\lambda)} x} \tilde{w}_-(x; \beta^-, \lambda) = w_0(\lambda) \\
\end{align*}

Then we define

\begin{align}
\tilde{v}_-(x; \beta^-, \lambda) &= e^{\nu(\lambda) x } v_-(x; \beta^-, \lambda) \label{tildev-} \\
\tilde{w}_-(x; \beta^-, \lambda) &= e^{-\overline{\nu(\lambda)} x } w_-(x; \beta^-, \lambda) \label{tildew-} 
\end{align}

These have the same properties as the corresponding functions on $\R^+$ since the asymptotic matrix $A(0; \lambda)$ is the same for $x \rightarrow -\infty$ as $x \rightarrow \infty$.\\

In the final lemma of this section, we show that $\langle v_\pm(x; \beta^\pm, \lambda), w_\pm(x; \beta^\pm, \lambda) \rangle = 1$ for all $x \geq 0$.

% lemma : IP of v and w is 1

\begin{lemma}\label{vwIP1}

For $\lambda$ sufficiently small and for all $\beta^\pm$, we have

\begin{align}
\langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle = 1 && x \geq 0 \label{vwIP1+} \\
\langle v_-(x; \beta^-, \lambda), w_-(x; \beta^-, \lambda) \rangle = 1 && x \leq 0 \label{vwIP1-}
\end{align}

\begin{proof}
By Lemma \ref{eigadjoint}, $\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle$ is constant for all $x \geq 0$. Using this and the continuity of the inner product, we have for all $x \geq 0$
\begin{equation*}
\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle = \lim_{x \rightarrow \infty} \langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle = \langle v_0(\lambda), w_0(\lambda) \rangle = 1
\end{equation*}
For all $x \geq 0$ we have
\begin{align*}
\langle \tilde{v}_+(x; \beta^+, \lambda), \tilde{w}_+(x; \beta^+, \lambda) \rangle
&= \langle e^{\nu(\lambda) x } v_+(x; \beta^+, \lambda), e^{-\overline{\nu(\lambda)} x} \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= e^{\nu(\lambda) x } e^{-\nu(\lambda) x } \langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle \\
&= \langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle
\end{align*}
\eqref{vwIP1+} follows from combining these two results. The proof on $\R^-$ is identical.
\end{proof}
\end{lemma}

\subsection{Exponential Trichotomy}

In this section, we will show that $\Phi_\pm$ can be decomposed in an exponential trichotomy with a one-dimensional ``center'' subspace corresponding to the small eigenvalue $\nu(\lambda)$ of the asymptotic matrix $A(0; \lambda)$. We will do this in a series of lemmas. We will only look at $\R^+$. The proofs for $\R^-$ are identical.\\

For simplicity, we write the eigenvalue problem and its adjoint on $\R^+$ as 

\begin{align}
V' &= A(q^+(0, \beta^+); \lambda) V \label{evpsimple}\\
W' &= -A(q^+(0, \beta^+); \lambda) V \label{evpsimpleW}
\end{align}

where $\beta^+$ and $\lambda$ are fixed constants, with $|\lambda| < \delta$. Let $\Phi(y, x; \beta^+, \lambda)$ be the evolution operator for \eqref{evpsimple}. To prove the existence of an exponential trichotomy, we will need to use results from the exponential dichotomy literature, which is only possible if the asymptotic matrix is hyperbolic. To guarantee this is the case and to get uniform bounds, we will use exponentially weighted spaces, with weights $\pm 2 \rho$, where $\rho$ is defined above.\\

Let $U(x) = (U_1(x), \dots, U_m(x)): \R^+ \rightarrow \R^m$. For $\eta \in \R$, define the exponentially weighted $L^2$ norm on $R^+$ by

\[
||U||_\eta^+ = \max_{i = 1, \dots, m} ||e^{\eta x}U_i(x)||_{L_2(\R^+)}
\]

Let $X^+_\eta$ be the space equipped with this norm. This is known to be a Banach space. To recast the eigenvalue problem \eqref{evpsimple} in the exponentially weighted norm, we let $V = e^{-\eta x} V_\eta$. Substituting this into the eigenvalue problem, we obtain the weighted eigenvalue problem

\begin{equation}\label{weightedeq}
V_\eta' = A(q^+(0, \beta^+); \lambda, \eta) V_\eta = (A(q^+(0, \beta^+); \lambda) + \eta I) V_\eta
\end{equation}

Let $\Phi(x, y; \beta^+, \lambda, \eta)$ be the evolution operator for \eqref{weightedeq}. We summarize the relationship between \eqref{evpsimple} and \eqref{weightedeq} in the following lemma.

% lemma : facts about weighted EVP

\begin{lemma}\label{weightfacts}
\begin{enumerate}[(i)]

Let $A(x)$ be a matrix-valued function such that $A(x)$ is exponentially asymptotic to the constant matrix $A$. Consider the eigenvalue problem

\begin{equation}\label{Veq1}
V' = A(x)V
\end{equation}

and the corresponding weighted eigenvalue problem with exponential weight $\eta$

\begin{equation}\label{Veq1eta}
V_\eta' = (A(x) + \eta I)V_\eta
\end{equation}

\item $V(x)$ is a solution to \eqref{Veq1} if and only if $V_\eta(x) = e^{\eta x} V(x)$ is a solution to \eqref{Veq1eta}.

\item The evolution operator $\Phi(x, y; \beta^+, \lambda, \eta)$ of \eqref{weightedeq} is given by
\begin{equation}\label{evolweight}
\Phi(x, y; \beta^+, \lambda, \eta) = e^{\eta(x - y)} \Phi(x, y; \beta^+, \lambda)
\end{equation}

\item $\nu$ is an eigenvalue of the asymptotic matrix $A$ if and only if $\nu + \eta$ is an eigenvalue of $A + \eta I$. In other words, the exponential weight $\eta$ shifts all eigenvalues of the asymptotic matrix by $\eta$.

\end{enumerate}

\begin{proof}

For (i), we have

\begin{align*}
V' = A(x)V &\iff e^{\eta x} V' = A(x) e^{\eta x} V \\
&\iff \frac{d}{dx} (e^{\eta x} V') - \eta e^{\eta x} V = A(x) e^{\eta x} V \\
&\iff \frac{d}{dx} (e^{\eta x} V') = ( A(x) + \eta I)V 
\end{align*}

For (ii), given an initial condition $z \in \R_m$ at y, $u(x) = \Phi(x, y; \beta^+, \lambda) z$ is the unique solution to \eqref{Veq1}. Thus by (i), $u_\eta(x) = e^{\eta x} \Phi(x, y; \beta^+, \lambda) z$ solves \eqref{Veq1eta}. At $x = y$, $u_\eta(y) = e^{\eta y} z$, so $u_\eta(x)$ is the unique solution to \eqref{Veq1eta} with initial condition $e^{\eta y} z$. Thus

\begin{align*}
u_\eta(x) = e^{\eta(x-y)} \Phi(x, y; \beta^+, \lambda) z
\end{align*}

is the the unique solution to \eqref{Veq1eta} with initial condition $z$.\\

For (iii), we note that

\begin{align*}
\det(A - \nu I) = \det( (A + \eta I) - (\nu + \eta) I )
\end{align*}

\end{proof}
\end{lemma}

In the next lemma, we will apply exponential weights of $\pm 2 \rho$ to \eqref{evpsimple} to produce two different exponential dichotomies for \eqref{weightedeq}.

% lemma : weighted dichotomies

\begin{lemma}\label{weightdichotomy}
For the weighted eigenvalue problem \eqref{weightedeq} with weight $2 \rho$, there exist families of projections $P^s(y; \beta^+, \lambda, 2 \rho)$ and $P^s(y; \beta^+, \lambda, 2 \rho)$ parameterized by $y \in \R^+$, such that $P^s(y; \beta^+, \lambda, 2 \rho) + P^s(y; \beta^+, \lambda, 2 \rho) = I$ and

\begin{align*}
|\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\alpha_0 - \rho - \epsilon)(x - y)} && 0 \leq y \leq x \\
|e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\rho - \epsilon)(y - x)} && 0 \leq x \leq y \\
\end{align*}

For these projections, $\dim \ran P^s(y; \beta^+, \lambda, 2 \rho) = n_-$ and $\dim \ran P^s(y; \beta^+, \lambda, 2 \rho) = n_+ + 1$. These projections also satisfy the ``commuting'' relations 

\begin{align*}
\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho) 
&= P^s(x; \beta^+, \lambda, 2 \rho) \Phi(x, y; \beta^+, \lambda) \\
\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho) 
&= P^u(x; \beta^+, \lambda, 2 \rho) \Phi(x, y; \beta^+, \lambda) 
\end{align*}

Similarly, for the weighted eigenvalue problem \eqref{weightedeq} with weight $-2 \rho$, there exist families of projections $P^s(y; \beta^+, \lambda, -2 \rho)$ and $P^s(y; \beta^+, \lambda, -2 \rho)$ parameterized by $y \in \R^+$, such that $P^s(y; \beta^+, \lambda, -2 \rho) + P^s(y; \beta^+, \lambda, -2 \rho) = I$ and

\begin{align*}
|e^{-2 \rho (x - y)}\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\rho - \epsilon)(x - y)} && 0 \leq y \leq x \\
|\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\alpha_0 - \rho - \epsilon)(y - x)} && 0 \leq x \leq y 
\end{align*}

For these projections, $\dim \ran P^s(y; \beta^+, \lambda, -2 \rho) = n_- + 1$ and $\dim \ran P^u(y; \beta^+, \lambda, -2 \rho) = n_+$. The projections $P^s(y; \beta^+, \lambda, -2 \rho)$ and $P^-(y; \beta^+, \lambda, -2 \rho)$ satisfy the same ``commuting'' relations those for the exponential weight $2 \rho$.\\

For the stable projections, we have

\begin{align*}
\ran P^s(y; \beta^+, \lambda, 2 \rho) \subset \ran P^s(y; \beta^+, \lambda, -2 \rho) \\
\end{align*}

Finally, the unstable range at $y = 0$ is not uniquely determined. In particular, we are free to choose $\ran P^u(0; \beta^+, \lambda, -2 \rho)$ to be any complement of $\ran P^s(0; \beta^+, \lambda, -2 \rho)$.

\begin{proof}

First, we use the exponential weight $2 \rho$ in \eqref{weightedeq}. The operator $A(q^+(0, \beta^+); \lambda, 2 \rho)$ is exponentially asymptotic to $A(0; \lambda, 2 \rho)$, and by Lemma \ref{weightfacts}, the spectrum of $A(0; \lambda, 2 \rho)$ lies outside the interval $(-\alpha_0 + 3 \rho, \rho)$. $A(0; \lambda, 2 \rho)$ has $n_-$ eigenvalues with negative real part and $n_+ + 1$ eigenvalues with positive real part. Thus by standard exponential dichotomy theory (e.g. Coppel, Peterhof), for any $0 < \epsilon < \rho$ there exist families of projections $P^s(y; \beta^+, \lambda, 2 \rho)$ and $P^u(y; \beta^+, \lambda, 2 \rho)$ with $P^s(y; \beta^+, \lambda, 2 \rho) + P^s(y; \beta^+, \lambda, 2 \rho) = I$, indexed by $y \in \R^+$, such that

\begin{align*}
|e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\alpha_0 - 3 \rho - \epsilon)(x - y)} && 0 \leq y \leq x \\
|e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\rho - \epsilon)(y - x)} && 0 \leq x \leq y \\
\end{align*}

where we used Lemma \ref{weightfacts} for the form of the evolution operator of \eqref{weightedeq}. We can divide the first equation by $e^{2 \rho (x - y)}$ to get

\begin{align}\label{Ps2rhobound}
|\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho)| &\leq C e^{-(\alpha_0 - \rho - \epsilon)(x - y)} && 0 \leq y \leq x
\end{align}

For the ranges of the projections, we have $\dim \ran P^s(y; \beta^+, \lambda, 2 \rho) = n_-$ and $\dim \ran P^s(y; \beta^+, \lambda, 2 \rho) = n_+ + 1$. The projections $P^s(y; \beta^+, \lambda, 2 \rho)$ and $P^-(y; \beta^+, \lambda, 2 \rho)$ also satisfy the ``commuting'' relations

\begin{align*}
e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho) 
&= P^s(x; \beta^+, \lambda, 2 \rho) e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda) \\
e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho) 
&= P^u(x; \beta^+, \lambda, 2 \rho)e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda) 
\end{align*}

We can again divide by $e^{2 \rho (x - y)}$ term to get 

\begin{align*}
\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, 2 \rho) 
&= P^s(x; \beta^+, \lambda, 2 \rho) \Phi(x, y; \beta^+, \lambda) \\
\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, 2 \rho) 
&= P^u(x; \beta^+, \lambda, 2 \rho) \Phi(x, y; \beta^+, \lambda) 
\end{align*}

Similarly, using the exponential weight $-2 \rho$, the spectrum of $A(0; \lambda, -2 \rho)$ lies outside the interval $(-\rho, \alpha_0 - 3 \rho)$. $A(0; \lambda, -2 \rho)$ has $n_- + 1$ eigenvalues with negative real part and $n_+$ eigenvalues with positive real part. Again, using standard exponential dichotomy theory, for the same $\epsilon$ as above there exist families of projections $P^s(y; \beta^+, \lambda, -2 \rho)$ and $P^u(y; \beta^+, \lambda, -2 \rho)$, indexed by $y \in \R^+$, such that

\begin{align*}
|e^{-2 \rho (x - y)}\Phi(x, y; \beta^+, \lambda)P^s(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\rho - \epsilon)(x - y)} && 0 \leq y \leq x \\
|e^{-2 \rho (x - y)}\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\alpha_0 - 3 \rho - \epsilon)(y - x)} && 0 \leq x \leq y \\
\end{align*}

We can divide the second equation by $e^{-2 \rho (x - y)}$ to get

\begin{align}\label{Pu2-rhobound}
|\Phi(x, y; \beta^+, \lambda)P^u(y; \beta^+, \lambda, -2 \rho)| &\leq C e^{-(\alpha_0 - \rho - \epsilon)(y - x)} && 0 \leq x \leq y 
\end{align}

For the ranges of the projections, we have $\dim \ran P^s(y; \beta^+, \lambda, -2 \rho) = n_- + 1$ and $\dim \ran P^u(y; \beta^+, \lambda, -2 \rho) = n_+$. The projections $P^s(y; \beta^+, \lambda, -2 \rho)$ and $P^-(y; \beta^+, \lambda, -2 \rho)$ satisfy the same ``commuting'' relations as above.\\

By Pet97, the stable range $\ran P^s(y; \beta^+, \lambda, -2 \rho)$ is uniquely determined. For the unstable range at $x = 0$, however, we are free to choose $\ran P^u(0; \beta^+, \lambda, -2 \rho)$ to be any complement of $\ran P^s(0; \beta^+, \lambda, -2 \rho)$. We will make such a choice later.\\

Finally, let $z \in \ran P^s(y; \beta^+, \lambda, 2 \rho)$. Then for all $x \geq y$

\begin{align*}
|e^{2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)z| &\leq C e^{-(\alpha_0 - 3 \rho - \epsilon)(x - y)} \\
|e^{-2 \rho (x - y)} \Phi(x, y; \beta^+, \lambda)z| &\leq C e^{-(\alpha_0 + \rho - \epsilon)(x - y)} \\
&\leq C e^{-(\rho - \epsilon)(x - y)} \\
\end{align*}

Since the stable subspaces of exponential dichotomies are uniquely determined and this has the correct decay properties as $x \rightarrow \infty$, it follows that $z \in \ran P^s(y; \beta^+, \lambda, -2 \rho)$. Thus

\begin{align*}
\ran P^s(y; \beta^+, \lambda, 2 \rho) \subset \ran P^s(y; \beta^+, \lambda, -2 \rho) \\
\end{align*}

\end{proof}
\end{lemma}

In the next lemma, we show that $\tilde{w}_+(x; \beta^+, \lambda)$ is perpendicular to the $\ran P^s_+(x; \beta^+, \lambda, 2 \rho)$, the stable range of the exponential dichotomy for the weighted eigenvalue problem with weight $2 \rho$.

% lemma : adjoint perpendicular to stable range

\begin{lemma}\label{wperpstable}

For the weighted eigenvalue problem \eqref{weightedeq} with weight $2 \rho$,

\begin{equation}
\tilde{w}_+(x; \beta^+, \lambda) \perp \ran P^s_+(x; \beta^+, \lambda, 2 \rho)
\end{equation}

for all $x \geq 0$.

\begin{proof}

Fix $x \in \R^+$ and let $z \in \ran P^s_+(x; \beta^+, \lambda, 2 \rho)$. Then

\begin{align*}
\tilde{u}(y; 2 \rho) &= e^{2 \rho(y - x)} \Phi(y, x; \beta^+, \lambda)z\\
\end{align*}

is a solution to \eqref{weightedeq} with $u(x) = z$, thus

\begin{align*}
u(y) &= \Phi(y, x; \beta^+, \lambda) e^{-2 \rho x} z\\
\end{align*}

is a solution to \eqref{evpsimple} with $u(x) = e^{-2 \rho x} z$. Since $\tilde{w}(y; \beta^+, \lambda)$ is a solution to \eqref{evpsimpleW}, by Lemma \ref{eigadjoint}, the inner product $\langle u(y), \tilde{w}_+(y; \beta^+, \lambda) \rangle$ is constant in $y$. Using this together with the continuity of the inner product, we have

\begin{align*}
e^{-2 \rho x} \langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle &= 
\langle e^{-2 \rho x} z, \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= \langle u(x), \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= \lim_{y \rightarrow \infty} \langle u(y), \tilde{w}_+(y; \beta^+, \lambda) \rangle \\
&= \lim_{y \rightarrow \infty} \langle u(y), e^{-\overline{\nu(\lambda)} y } w_+(y; \beta^+, \lambda) \rangle \\
&= \lim_{y \rightarrow \infty} \langle e^{-{\nu(\lambda)} y } u(y), w_+(y; \beta^+, \lambda) \rangle\\
&= \langle \lim_{y \rightarrow \infty} e^{-{\nu(\lambda)} y } u(y), w_0(\lambda) \rangle \\
&= \langle \lim_{y \rightarrow \infty} e^{-{\nu(\lambda)} y } \Phi(y, x; \beta^+, \lambda) e^{-2 \rho x} z, w_0(\lambda) \rangle \\
&= e^{-2 \rho x} \langle \lim_{y \rightarrow \infty} e^{-{\nu(\lambda)} y } \Phi(y, x; \beta^+, \lambda) P^s_+(x; \beta^+, \lambda, 2 \rho) z, w_0(\lambda) \rangle 
\end{align*}

since $z \in \ran P^s_+(x; \beta^+, \lambda, 2 \rho)$. Thus using \eqref{Ps2rhobound}, by our choices of $\rho$ and $\epsilon$ and since $x$ is fixed, we divide by $e^{-2 \rho x}$ and get

\begin{align*}
|\langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle| 
&\leq \lim_{y \rightarrow \infty} e^{|\nu(\lambda)| y } e^{-(\alpha_0 - \rho - \epsilon)(y - x)} |w_0(\lambda) ||z| \\
&\leq C \lim_{y \rightarrow \infty} e^{|\nu(\lambda)| y } e^{-(\alpha_0 - \rho - \epsilon)y} e^{(\alpha_0 - \rho - \epsilon)x} \\
&\leq C \lim_{y \rightarrow \infty} e^{-(\alpha_0 - 2 \rho - \epsilon)y}  \\
&= 0
\end{align*}

Thus $\langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle = 0$.

\end{proof}
\end{lemma}

In the next lemma, we show that we can choose a complement of $\ran P^s(0; \beta^+, \lambda, -2 \rho)$ for $\ran P^u(0; \beta^+, \lambda, -2 \rho)$ such that $\tilde{w}_+(x; \beta^+, \lambda) \perp \ran P^u_+(x; \beta^+, \lambda, -2 \rho)$ for all $x \geq 0$. 

% lemma : can choose unstable range so that w is perpendicular to it

\begin{lemma}\label{wperpunstable}

We can choose $\ran P^u(0; \beta^+, \lambda, -2 \rho)$ such that 

\begin{align*}
\tilde{w}_+(x; \beta^+, \lambda) \perp \ran P^u_+(x; \beta^+, \lambda, -2 \rho) 
\end{align*}

for all $x \in \R^+$.

\begin{proof}

For convenience, let $R^s(2 \rho) = \ran P^s(0; \beta^+, \lambda, 2 \rho)$ and $R^s(-2 \rho) = \ran P^s(0; \beta^+, \lambda, -2 \rho)$. From Lemma \ref{weightdichotomy}, $R^s(2 \rho) \subset R^s(-2 \rho)$. Let $S = \{ u_1, \dots, u_{n_-} \}$ be a basis for $R^s(2 \rho)$. By our choice of exponential weights, $v_+(0; \beta^+, \lambda) \in R(-2 \rho)$ but $v_+(0; \beta^+, \lambda) \not\in R^s(2 \rho)$. Therefore $\{ u_1, \dots, u_{n_-}, v_+(0; \beta^+, \lambda)\}$ is a basis for $R^s(-2 \rho)$.\\

Let $T = \spn\{ u_1, \dots, u_{n-1} , w_+(0; \beta^+, \lambda) \}^\perp$. We claim that $T$ is a complement of $R^s(-2 \rho)$. Let $t_1, \dots, t_{n^+}$ be a basis for $T$. To prove this, all we have to show is that the set 

\[
S \cup T \cup \{ v_+(0; \beta^+, \lambda) \} =  \{ u_1, \dots, u_{n_-} , v_+(0; \beta^+, \lambda), t_1, \dots, t_{n_+} \}
\]
is linearly independent. By construction, the set $S \cup T = \{ u_1, \dots, u_{n_-}, t_1, \dots, t_{n_+} \}$ is linearly independent. Thus all we have to show is that $v_+(0; \beta^+, \lambda)$ is linearly independent from $S \cup T$. The set $\{ v_+(0; \beta^+, \lambda), u_1, \dots, u_{n_-}\}$ is linearly independent since it is a basis for $R^s(-2 \rho)$. From Lemma \ref{vwIP1}, $\langle v_+(0; \beta^+, \lambda), w_+(0; \beta^+, \lambda) = 1$, thus $v_+(0; \beta^+, \lambda)$ cannot be in $T$, otherwise it would be perpendicular to $w_+(0; \beta^+, \lambda)$. Thus $T$ is a complement of $R^s(-2 \rho)$, so by Pet98, we can choose

\begin{equation}
\ran P^u(0; \beta^+, \lambda, -2 \rho) = \spn\{ u_1, \dots, u_{n-1} , w_+(0; \beta^+, \lambda) \}^\perp
\end{equation}

In particular, $\tilde{w}_+(0; \beta^+, \lambda) \perp \ran P^u(0; \beta^+, \lambda, -2 \rho)$.\\

Next, we show that $\tilde{w}_+(x; \beta^+, \lambda) \perp \ran P^u_+(x; \beta^+, \lambda, -2 \rho)$ for all $x \in \R^+$. Fix $x \geq 0$, and let $z \in \ran P^u(x; \beta^+, \lambda, -2 \rho)$. Then by the invariance of the unstable subspace of the exponential dichotomy,

\begin{align*}
z = e^{-2 \rho x} \Phi(x, 0; \beta^+, \lambda) z_0
\end{align*}

for some $z_0 \in \ran P^u(0; \beta^+, \lambda, -2 \rho)$.

\begin{align*}
\tilde{u}(y; -2 \rho) &= e^{-2 \rho y} \Phi(y, 0; \beta^+, \lambda)z_0
\end{align*}

is a solution to \eqref{weightedeq} with $u(0) = z_0$ and $u(x) = z$, thus

\begin{align*}
u(y) &= \Phi(y, 0; \beta^+, \lambda) z_0 \\
\end{align*}

is a solution to \eqref{evpsimple} with $u(0) = z_0$ and $u(x) = e^{2 \rho x} z$. Since $\tilde{w}(y; \beta^+, \lambda)$ is a solution to \eqref{evpsimpleW}, by Lemma \ref{eigadjoint}, the inner product $\langle u(y), \tilde{w}_+(y; \beta^+, \lambda) \rangle$ is constant in $y$. From our choice of $P^u(0; \beta^+, \lambda, -2 \rho)$, we have

\begin{align*}
0 &= \langle z_0, w_+(0; \beta^+, \lambda) \rangle \\
&= \langle u(0), \tilde{w}_+(0; \beta^+, \lambda) \rangle \\
&= \langle u(x), \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= \langle e^{2 \rho x} z, \tilde{w}_+(x; \beta^+, \lambda) \rangle \\
&= e^{2 \rho x} \langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle 
\end{align*}

Since $e^{2 \rho x} > 0$, $\langle z, \tilde{w}_+(x; \beta^+, \lambda) \rangle = 0$.

\end{proof}
\end{lemma}

We are finally ready to put all of this together. For $x \in \R^+$, we define the stable and unstable projections on $\R^+$ by

\begin{align*}
P^s_+(x; \beta^+, \lambda) &= P^s(x; \beta^+, \lambda, 2 \rho) \\
P^u_+(x; \beta^+, \lambda) &= P^u(x; \beta^+, \lambda, -2 \rho)
\end{align*}

From \eqref{Ps2rhobound} and \eqref{Pu2-rhobound} we have the estimates

\begin{align*}
|\Phi(x, y; \beta^+, \lambda)P_+^s(y; \beta^+, \lambda)| &\leq C e^{-\alpha(x - y)} && 0 \leq y \leq x \\
|\Phi(x, y; \beta^+, \lambda)P_+^u(y; \beta^+, \lambda)| &\leq C e^{-\alpha(y - x)} && 0 \leq x \leq y 
\end{align*}

These estimates are independent of $\beta^+$ and $\lambda$. The ``commuting'' relations for the stable and unstable projections follow from Lemma \ref{weightdichotomy}. The dimensions of the stable and unstable projections are given by $\dim \ran P_+^s(x; \beta^+, \lambda) = n_-$ and $\dim \ran P_+^u(x; \beta^+, \lambda) = n_+$.\\

In the next lemma, we define the center projection $P^c_+(x; \beta^+, \lambda)$.

% lemma : center projection

\begin{lemma}\label{centerproj}

For $x \in \R^+$ and $u \in \R^m$, let

\begin{equation}
P^c_+(x; \beta^+, \lambda)u = \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda)
\end{equation}

Then $P^c_+(x; \beta^+, \lambda)$ is the projection on the center subspace. We also have the ``commuting'' relation

\begin{align*}
\Phi(x, y; \beta^+, \lambda) P^c_+(y; \beta^+, \lambda) 
= P^c_+(x; \beta^+, \lambda) \Phi(x, y; \beta^+, \lambda)
\end{align*}

\begin{proof}

For $|\lambda| < \delta$ and $x \in \R^+$, the center subspace is defined as $\spn \{ v_+(x; \beta^+, \lambda) \}$. From the definition of $P^c_+(x; \beta^+, \lambda)$ we have $\ran P^c_+(x; \beta^+, \lambda) = \spn \{ v_+(x; \beta^+, \lambda) \}$. $P^c_+(x; \beta^+, \lambda)$ also the correct kernel, since $\langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle = 1$ for all $x \geq 0$ (so it does not wipe out anything in the center subspace), and from Lemmas \ref{wperpstable} and \ref{wperpunstable} we have

\begin{align*}
w_+(x; \beta^+, \lambda) \perp \ran P^s_+(x; \beta^+, \lambda) \oplus \ran P^u_+(x; \beta^+, \lambda)
\end{align*}

since $w_+(x; \beta^+, \lambda)$ and $\tilde{w}_+(x; \beta^+, \lambda)$ are scalar multiples of each other.\\

Finally, we need to verify that $P^c_+$ is in fact a projection. To do this, we will show that $P^c_+(x; \beta^+, \lambda)P^c_+(x; \beta^+, \lambda) = P^c_+(x; \beta^+, \lambda)$. For $u \in \R^m$,

\begin{align*}
P^c_+(x; \beta^+, \lambda)( P^c_+(x; \beta^+, \lambda) u ) &= \langle \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(x; \beta^+, \lambda) \rangle \langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) \\
&= P^c_+(x; \beta^+, \lambda) u 
\end{align*}

since $\langle v_+(x; \beta^+, \lambda), w_+(x; \beta^+, \lambda) \rangle = 1$ for all $x \geq 0$ by Lemma \ref{perpeigs}. Thus $P^c_+(x; \beta^+, \lambda)$ is indeed a projection, and is the projection on the center subspace.\\

For the ``commuting'' relation, recall that $\tilde{v}_+(x; \beta^+, \lambda)$ is a solution to \eqref{evpsimple} and $\tilde{w}_+(x; \beta^+, \lambda)$ is a solution to \eqref{evpsimpleW}. Thus for $u \in \R^m$,

\begin{align*}
\Phi(x, y; \beta^+, \lambda) P^c_+(y; \beta^+, \lambda) u 
&= \Phi(x, y; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle v_+(y; \beta^+, \lambda)\\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle \Phi(x, y; \beta^+, \lambda) e^{-\nu(\lambda)y} \tilde{v}_+(y; \beta^+, \lambda)\\
&= \langle u, e^{-\overline{\nu(\lambda)}y}w_+(y; \beta^+, \lambda) \rangle \Phi(x, y; \beta^+, \lambda) \tilde{v}_+(y; \beta^+, \lambda)\\
&= \langle u, \tilde{w}_+(y; \beta^+, \lambda) \rangle \Phi(x, y; \beta^+, \lambda) \tilde{v}_+(y; \beta^+, \lambda)\\
&= \langle u, \Phi(y, x; \beta^+, \lambda)^* \tilde{w}_+(x; \beta^+, \lambda) \rangle \tilde{v}_+(x; \beta^+, \lambda)\\
&= \langle \Phi(x, y; \beta^+, \lambda) u, \tilde{w}_+(x; \beta^+, \lambda) \rangle \tilde{v}_+(x; \beta^+, \lambda)\\
&= P^c_+(x; \beta^+, \lambda) \Phi(x, y; \beta^+, \lambda) u
\end{align*}

\end{proof}
\end{lemma}

Since by the previous lemma we have $\ran P^c_+(x; \beta^+, \lambda) = \spn \{ v_+(x; \beta^+, \lambda) \}$, it follows from Lemma \ref{weightdichotomy} and Lemma \ref{wperpunstable} that for all $x \in \R^m$,

\begin{align*}
\R^m = P^s_+(x; \beta^+, \lambda) \oplus P^u_+(x; \beta^+, \lambda) \oplus P^c_+(x; \beta^+, \lambda)
\end{align*}

Thus for all $x \in \R^m$

\begin{align*}
P^s_+(x; \beta^+, \lambda) + P^u_+(x; \beta^+, \lambda) + P^c_+(x; \beta^+, \lambda) = I
\end{align*}

Finally, we derive an expression for the evolution on the center subspace.

% lemma : center evolution

\begin{lemma}\label{centerevol}

The evolution of \eqref{evpsimple} on the center subspace is given by

\begin{equation}
e^{\nu(\lambda)(x-y)} v_+(x; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle 
\end{equation}

for an initial condition $u \in \R^m$.

\begin{proof}

The center evolution is defined by

\begin{equation*}
\Phi^c_+(x,y; \beta^+, \lambda) = \Phi(x,y; \beta^+, \lambda) P^c_+(y; \beta^+, \lambda)
\end{equation*}

Then for any initial condition $u$, using Lemma \ref{centerproj}, we have

\begin{align*}
\Phi(x,y; \beta^+, \lambda) P^c_+(y; \beta^+, \lambda) u 
&= \Phi(x,y; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle v_+(y; \beta^+, \lambda) \\
&= \Phi(x,y; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} \tilde{v}_+(y; \beta^+, \lambda) \\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} \Phi(x,y; \beta^+, \lambda) \tilde{v}_+(y; \beta^+, \lambda) \\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} \tilde{v}_+(x; \beta^+, \lambda) \\
&= \langle u, w_+(y; \beta^+, \lambda) \rangle e^{-\nu(\lambda)y} e^{\nu(\lambda)x} v_+(x; \beta^+, \lambda) \\
&= e^{\nu(\lambda)(x-y)} v_+(x; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle 
\end{align*}

where we used the fact that $\tilde{v}_+$ is a solution to the eigenvalue problem \eqref{evpsimple}, thus $\Phi(y, x; \beta^+, \lambda)\tilde{v}_+(x; \beta^+, \lambda) = \tilde{v}_+(y; \beta^+, \lambda)$. 

\end{proof}
\end{lemma}

We combine the results from these lemmas in the following theorem, which demonstrates the exponential trichotomy. 

% theorem : trichotomy 

\begin{theorem}\label{trichotomy}

For $\lambda$ sufficiently small and any $\beta^+, \beta^-$, there exist projections

\begin{align*}
&P_+^s(x; \beta^+, \lambda), P_+^u(x; \beta^+, \lambda), P_+^c(x; \beta^+, \lambda) && x \geq 0 \\
&P_-^s(x; \beta^-, \lambda), P_-^u(x; \beta^-, \lambda), P_-^c(x; \beta^-, \lambda) && x \leq 0 \\
\end{align*}

with

\begin{align*}
&P_+^s(x; \beta^+, \lambda) + P_+^u(x; \beta^+, \lambda) + P_+^c(x; \beta^+, \lambda) = I \\
&P_-^s(x; \beta^-, \lambda) + P_-^u(x; \beta^-, \lambda) + P_-^c(x; \beta^-, \lambda) = I \\
\end{align*}

such that the evolution operators $\Phi_\pm(x, y; \beta^\pm, \lambda)$ can be decomposed as

\begin{align*}
\Phi^s_\pm(x, y; \beta^\pm, \lambda) &= \Phi_\pm(x, y; \beta^\pm, \lambda) P^s_\pm(y; \beta^\pm, \lambda) \\
\Phi^u_\pm(x, y; \beta^\pm, \lambda) &= \Phi_\pm(x, y; \beta^\pm, \lambda) P^u_\pm(y; \beta^\pm, \lambda) \\
\Phi^c_\pm(x, y; \beta^\pm, \lambda) &= \Phi_\pm(x, y; \beta^\pm, \lambda) P^c_\pm(y; \beta^\pm, \lambda) \\
\end{align*}

The projections satisfy the ``commuting'' relations

\begin{align*}
\Phi_\pm(x, y; \beta^\pm, \lambda) P^{s/u/c}_\pm(y; \beta^\pm, \lambda) 
= P^{s/u/c}_\pm(x; \beta^\pm, \lambda) \Phi_\pm(x, y; \beta^\pm, \lambda)
\end{align*}

i.e. it does not matter if we project or evolve first. For $|\lambda| < \delta$, we have the following estimates for the stable and unstable evolutions, which independent of $\lambda$ and $\beta^\pm$.

\begin{align*}
|\Phi^s_+(x, y; \beta^+, \lambda)| &\leq C e^{-\alpha(x - y)} && 0 \leq y \leq x \\
|\Phi^u_+(x, y; \beta^+, \lambda)| &\leq C e^{-\alpha(y - x)} && 0 \leq x \leq y \\
|\Phi^s_-(x, y; \beta^+, \lambda)| &\leq C e^{-\alpha(x - y)} && y \leq x \leq 0 \\
|\Phi^u_-(x, y; \beta^+, \lambda)| &\leq C e^{-\alpha(y - x)} && x \leq y \leq 0 \\
\end{align*}

where $\alpha$ is defined above. The same estimates hold for all derivatives with respect to $\beta^\pm$ and $\lambda$.\\

An explicit form of the center projection is given by

\begin{align}\label{Pc}
P^c_+(x; \beta^+, \lambda)u &= \langle u, w_+(x; \beta^+, \lambda) \rangle v_+(x; \beta^+, \lambda) && x \geq 0 \\
P^c_-(x; \beta^-, \lambda)u &= \langle u, w_-(x; \beta^-, \lambda) \rangle v_-(x; \beta^-, \lambda) && x \leq 0
\end{align}

where $v_\pm(x; \beta^\pm, \lambda)$ and $w_\pm(x; \beta^\pm, \lambda)$ are defined above in \eqref{tildev+}, \eqref{tildew+}, \eqref{tildev-}, and \eqref{tildew-}. An explicit form of the center evolution is given by

\begin{align}\label{Phic}
\Phi^c_+(x,y; \beta^+, \lambda) &= e^{\nu(\lambda)(x-y)} v_+(x; \beta^+, \lambda) \langle u, w_+(y; \beta^+, \lambda) \rangle && x, y \geq 0 \\
\Phi^c_-(x,y; \beta^-, \lambda) &= e^{\nu(\lambda)(x-y)} v_-(x; \beta^-, \lambda) \langle u, w_-(y; \beta^-, \lambda) \rangle && x, y \leq 0
\end{align}

\begin{proof}

This follows from the previous lemmas. The proof for $\R^-$ is identical. The fact that we can use the same estimates for derivatives with respect to the parameters $\beta^\pm$ and $\lambda$ follows from Lemma 3.2 in San98, which follows from San93. In particular, we can perform a Taylor expansion in any of the parameters.

\end{proof}
\end{theorem}

In the work which follows, we will need several estimates based on Theorem \ref{trichotomy}. First, we have bounds involving projections and evolutions on the stable and unstable subspaces. We will show these in the following lemma.

% lemma : various projection bounds

\begin{lemma}\label{projbounds}
Let

\begin{enumerate}
\item
\begin{equation}\label{p1}
p_1(X; \beta^+, \beta^-, \lambda) = \sup_{x \geq X} (|P^u_+(x; \beta^+, \lambda) - P_0^u| + |P^s_-(-x; \beta^-, \lambda) - P_0^s|)
\end{equation}
\item
\begin{equation}\label{p5}
p_5(\beta_i^+, \beta_i^-, \lambda) = |P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0)| + |P^s_+(0; \beta_i^+, \lambda) - P^s_+(0; 0, 0)|
\end{equation}
\item 
\begin{equation}\label{p6}
p_6(y; \beta_i^+, \beta_i^-, \lambda) = |\Phi^u_+(0, y; \beta_i^+, \lambda) - \Phi^u_+(0, y; 0, 0)| + |\Phi^s_-(0, -y; \lambda) - \Phi^s_-(0, -y; 0, 0)| 
\end{equation}

\end{enumerate}

where $P_0^s$ and $P_0^u$ are the projections on the $E^s$ and $E^u$, the stable and unstable eigenspaces of the asymptotic matrix $A(0; 0)$. Then we have bounds

\begin{align}
p_1(X; \beta^+, \beta^-, \lambda) &= \mathcal{O}( e^{-\alpha X } + |\lambda| ) \\
p_5(\beta_i^+, \beta_i^-, \lambda) &= \mathcal{O}(e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} + |\lambda|) \\
p_6(y; \beta_i^+, \beta_i^-, \lambda) &= \mathcal{O}(|\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} ) e^{-\alpha |y|}
\end{align}

\begin{proof}
All these bounds rely on the Taylor theorem. By the previous lemma, we can Taylor expand in $\beta^\pm$ and $\lambda$.\\

For $p_1$, using the triangle inequality, we have

\begin{align*}
|P^u_+(x; \beta^+, \lambda) - P_0^u| 
&\leq |P^u_+(x; \beta^+, \lambda) - P^u_+(x; \beta^+, 0)| + |P^u_+(x; \beta^+, 0) - P_0^u| 
\end{align*}

From Lemma 1.1 in San93, $|P^u_+(x; \beta^+, 0) - P_0^u| = \mathcal{O}(e^{-\alpha x})$. From the Taylor theorem about $\lambda = 0$, we have $|P^u_+(x; \beta^+, \lambda) - P^u_+(x; \beta^+, 0)| = \mathcal{O}(|\lambda|)$. Combining these yields the desired bound.\\

For $p_5$, we use the Taylor theorem on $P^u_-(0; \beta_i^-, \lambda)$ about $(\beta_i^-, \lambda) = (0, 0)$ to get 

\begin{align*}
P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0) &= \mathcal{O}(|\lambda| + |\beta_i^-|) \\
&= \mathcal{O}(|\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})
\end{align*}

where the estimate on $\beta_i^-$ comes from the existence problem. We get the same estimate from using the Taylor theorem on $P^s_+(0; \beta_i^+, \lambda)$.\\

For $p_6$, we use the Taylor theorem on $\Phi^u_+(0, y; \beta_i^+, \lambda)$ at $(\beta_i^+, \lambda) = (0, 0)$ to get 

\begin{align*}
\Phi^u_+(&0, y; \beta_i^+, \lambda) - \Phi^u_+(0, y; 0, 0) \\
&= \frac{\partial}{\partial \beta_i^+}\Phi^u_+(0, y; \beta_i^+, \lambda)\Big|_{(\beta_i^+, \lambda) = (0, 0)} \beta_i^+ + \frac{\partial}{\partial \lambda}\Phi^u_+(0, y; \beta_i^+, \lambda)\Big|_{(\beta_i^+, \lambda) = (0, 0)} \lambda + \mathcal{O}(|\beta_i^+|^2 + |\beta_i^+ \lambda| + |\lambda|^2) \\
&= \mathcal{O}((|\lambda| + |\beta_i^+|)e^{-\alpha |y| }) \\
&= \mathcal{O}((|\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})e^{-\alpha |y| }) \\
\end{align*}

where the derivatives of $\Phi^u_+(0, y; \beta_i^+, \lambda)$ with respect to $\beta_i^+$ and $\lambda$ are $\mathcal{O}(e^{-|\alpha|y}$ by Theorem \ref{trichotomy} and the estimate on $\beta_i^+$ comes from the existence problem. We get the same estimate for $\Phi^s_-(0, -y; \lambda)$.

\end{proof}
\end{lemma}

Finally, we have bounds involving the center subspace.

% lemma : bounds involving center subspace stuff

\begin{lemma}\label{centerbounds}

Let
\begin{enumerate}[(i)]
\item $p_2(X; \lambda) = |v_\pm(\pm X; \beta^\pm, \lambda) - v_0(\lambda)| + |w_\pm(\pm X; \beta^\pm, \lambda) - w_0(\lambda)|$
\item $p_3(\lambda) = |v_0(\lambda) - v_0(0)|$
\end{enumerate}

Then 

\begin{equation}\label{p2limit}
p_2(X; \lambda) \rightarrow 0 \text{ as } |X| \rightarrow \infty
\end{equation}

and

\begin{equation}\label{p3bound}
p_3(X; \lambda) = \mathcal{O}(\lambda)  
\end{equation}

\begin{proof}

For $p_2$, since $v_\pm(\pm x; \beta^\pm, \lambda) \rightarrow v_0(\lambda)$ and $w_\pm(\pm x; \beta^\pm, \lambda) \rightarrow w_0(\lambda)$ as $|x| \rightarrow \infty$, $p_2(X; \lambda) \rightarrow 0$ as $|X| \rightarrow \infty$. Since we scaled out the exponential factor, we do not have a rate of convergence for this, thus cannot get an actual estimate. Fortunately, this will not matter.\\

For $p_3$, we can expand $v_0(\lambda)$ in a Taylor series in $\lambda$ to get

\[
v_0(\lambda) = v_0(0) + \lambda \frac{\partial}{\partial \lambda}v_0(\lambda)\Big|_{\lambda = 0} + \mathcal{O}(\lambda^2)
\]

Since $\frac{\partial}{\partial \lambda}v_0(\lambda)\Big|_{\lambda = 0}$ is a constant, we have the estimate

\[
p_3(X; \lambda) = \mathcal{O}(\lambda) 
\]

\end{proof}
\end{lemma}

\subsection{The Inversion}

Define the spaces

\begin{align*}
V_W &= \bigoplus_{i=0}^{n-1} C^0([-X_{i-1}, 0], \C^m) \oplus C^0([0, X_i], \C^m) \\
V_a &= \bigoplus_{i=0}^{n-1} E^u \oplus E^s\\
V_b &= \bigoplus_{i=0}^{n-1} \ran P^u_-(0; 0, 0) \oplus \ran P^s_+(0; 0, 0) \\
V_c &= \bigoplus_{i=0}^{n-1} \spn \{v_0(\lambda)\} \oplus \spn \{v_0(\lambda)\} \\
V_\lambda &= B_\delta(0) \subset \C
\end{align*}

where the subscripts are all $\mod n$, as in the existence problem. All the product spaces are endowed with the maximum norm, e.g. for $V_c$, $|c| = \max(|c_0^-|, \dots, |c_{n-1}^-|, |c_0^+|, \dots, |c_{n-1}^+|)$. In addition, we take the following convention: if we eliminate either a subscript or a superscript (or both) in the norm, we are taking the maximum over the eliminated thing. For example,
\begin{enumerate}
	\item $|c_i| = \max(|c_i^+|, |c_i^-|)$ 
	\item $|c^+| = \max(|c_0^+|, \dots, |c_{n-1}^+|)$
\end{enumerate} 

Recall that the eigenspaces $E^s$, $E^u$, and $E^c$ refer to the constant, asymptotic matrix $A(0;, 0)$. The projections onto $E^s$, $E^u$, and $E^c$ are given by $P_0^s$, $P_0^u$, and $P_0^c$. The initial conditions on the stable and unstable subspaces lie in the corresponding spaces for the problem with $\lambda = 0$ and $\beta^\pm = 0$. By contrast, the initial conditions on the center subspace is in the eigenspace for the perturbed problem, which is useful to us since we have derived an equation for the evolution along the center subspace.\\

Finally, for convenience, we define

\begin{align*}
\tilde{c}_i^- &= e^{\nu(\lambda)X_i} c_i^- \\
\tilde{c}_i^+ &= e^{-\nu(\lambda)X_i} c_i^+
\end{align*}

At this point, we can write down the fixed point equations for the problem. The fixed point equations will look like those in San98 with two main differences. First, we have the addition of a center evolution term and an initial condition in the center subspace. Second, the evolution operators $\Phi^{s/u}_\pm$ depend on both $\beta_i^\pm$ and on $\lambda$.\\

For $i = 0, \dots, n-1$, the fixed point equations are

\begin{align*}
W_i^-(x) = \Phi^s_-(&x, -X_{i-1}; \beta_i^-, \lambda) a_{i-1}^- + \Phi^u_-(x, 0; \beta_i^-, \lambda) b_i^- \\
&+ e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&+ \int_0^x \Phi^u_-(x, y; \beta_i^-, \lambda)[ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ \int_{-X_{i-1}}^x \Phi^s_-(x, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ \int_{-X_{i-1}}^x 
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
W_i^+(x) = \Phi^u_+(&x, X_i; \beta_i^+, \lambda)a_i^+ + \Phi^s_+(x, 0; \beta_i^+, \lambda)b_i^+ \\
&+ e^{\nu(\lambda)(x - X_i)} v_+(x; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&+ \int_0^x \Phi^s_+(x, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ \int_{X_i}^x \Phi^u_+(x, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ \int_{X_i}^x e^{\nu(\lambda)(x-y)} v_+(x; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Before performing the inversion, we will define the following useful constants.

\begin{enumerate}

	\item Let

	\begin{align*}
	X_m &= \min(X_0, \dots, X_{n-1}) \\
	X_M &= \max(X_0, \dots, X_{n-1}) \\
	\end{align*}

	\item Let $\delta > 0$ be a small. How small will be determined later.

	\item Fix a constant $\tilde{\alpha}$, with $0 < \tilde{\alpha} < \alpha$. The idea is that we want $\tilde{\alpha}$ to be close to $\alpha$.

	\item Recall that $\nu(\lambda) = \mathcal{O}(|\lambda|)$. Thus we can choose $\delta$ sufficiently small so that for all $|\lambda| < \delta$, $3|\nu(\lambda)| < \alpha - \tilde{\alpha}$ and $|\nu(\lambda)| < \tilde{\alpha}$.

	\item Choose $|\lambda|$ sufficiently small and $X_m$ sufficiently large such that

	\begin{equation}
	e^{-\alpha X_m}, ||G||, |\lambda|, ||\Delta H|| < \delta
	\end{equation}

\end{enumerate}


Now, as in San98 and the exponentially weighted case, we will perform the inversion of our problem in a series of lemmas. The first step is to solve for $W$ in terms of $(a, b, c, d)$.\\

First, we obtain a bound on the terms from the fixed point equations which involve $W$. 

% Inversion, lemma 1 (L1 bound)

\begin{lemma}\label{L1}

Let $L_1(\lambda): V_W \rightarrow V_W$ be the linear operator defined piecewise by

\begin{align*}
(L_1(\lambda)W)_i^-(x) &= \int_0^x \Phi^u_-(x, y; \beta_i^-, \lambda) G_i^-(y)W_i^-(y) dy + \int_{-X_{i-1}}^x \Phi^s_-(x, y; \beta_i^-, \lambda) G_i^-(y)W_i^-(y) dy \\
&+ \int_{-X_{i-1}}^x 
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
(L_1(\lambda)W)_i^+(x) &= \int_0^x \Phi^s_+(x, y; \beta_i^+, \lambda) G_i^+(y) W_i^+(y) dy + \int_{X_i}^x \Phi^u_+(x, y; \beta_i^+, \lambda) G_i^+(y) W_i^+(y) dy \\
&+ \int_{X_i}^x e^{\nu(\lambda)(x-y)} v_+(x; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Then $L_1(\lambda): V_W \rightarrow V_W$ is a bounded linear operator with uniform bound

\begin{equation}\label{L1bound2}
||L_1(\lambda)W|| \leq C e^{-(\alpha -|\nu(\lambda)|)X_m} ||W||
\end{equation}

Piecewise bounds are

\begin{align*}
||L_1(\lambda)_i^- W_i^-|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ||W_i^-|| \\
||L_1(\lambda)_i^+ W_i^+|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_i} ||W_i^+||
\end{align*}

\begin{proof}
The first two integrals on the RHS of $L_1$ have the same bound as in San98. For the third integral, we will use the piecewise bound for $G_i^\pm(x)$. For $x \leq 0$, we have

\begin{align*}
\Big| \int_{-X_{i-1}}^x &e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \Big| \\
&\leq C ||W_i^-|| \int_{-X_{i-1}}^x e^{\nu(\lambda)(x-y)} e^{-\alpha X_{i-1}}e^{-\alpha(X_{i-1} + y)}dy \\
&\leq C ||W_i^-|| \int_{-X_{i-1}}^x e^{|\nu(\lambda)| (x-y)} e^{-\alpha X_{i-1}}e^{-\alpha(X_{i-1} + y)}dy \\
&= C ||W_i^-|| e^{|\nu(\lambda)| x } e^{-2 \alpha X_{i-1}} \int_{-X_{i-1}}^x e^{-(\alpha + |\nu(\lambda)|) y} dy \\
&= C ||W_i^-|| e^{|\nu(\lambda)| x } e^{-2 \alpha X_{i-1}} \frac{1}{\alpha + |\nu(\lambda)|} \left( e^{-(\alpha + |\nu(\lambda)|)(-X_{i-1})} - e^{-(\alpha + |\nu(\lambda)|)x} \right) \\
&\leq C ||W_i^-|| e^{-2 \alpha X_{i-1}} \left( e^{(\alpha + |\nu(\lambda)|)X_{i-1}} + e^{-\alpha x}  \right) \\
&\leq C ||W_i^-|| e^{-2 \alpha X_{i-1}} \left( e^{\alpha X_{i-1}} e^{|\nu(\lambda)|X_{i-1}} + e^{\alpha X_{i-1}}  \right) \\
&\leq C ||W_i^-|| e^{-\alpha X_{i-1}} \left( e^{|\nu(\lambda)|X_{i-1}} + 1 \right) \\
&\leq C ||W_i^-|| e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} \\
\end{align*}

This can be made arbitrarily small for sufficiently large $X_{i-1}$. The $x \geq 0$ case is similar. Thus we have our piecewise bounds

\begin{align*}
||L_1(\lambda)_i^- W_i^-|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ||W_i^-|| \\
||L_1(\lambda)_i^+ W_i^+|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_i} ||W_i^+||
\end{align*}

For a uniform bound, since $\alpha -|\nu(\lambda)| > 0$, the bound depends on the smallest of the $X_i$, thus we have

\[
||L_1(\lambda)W|| \leq C e^{-(\alpha -|\nu(\lambda)|)X_m}||W||
\]

\end{proof}
\end{lemma}

Next, we obtain a bound on the terms from the fixed point equations which do not involve $W$. 

% inversion, lemma 2 (L2 bound)

\begin{lemma}\label{L2}

Let $L_2(\lambda): V_a \times V_b \times V_c \times V_d \rightarrow V_W$ be the linear operator defined piecewise by

\begin{align*}
L_2(\lambda)&(a,b,c,d)_i^-(x) = \Phi^s_-(x, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- + \Phi^u_-(x, 0; \beta_i^-, \lambda)b_i^- \\
&+ e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&+ \int_0^x \Phi^u_-(x, y; \beta_i^-, \lambda)\lambda^2 d_i \tilde{H}_i^-(y) dy + \int_{-X_{i-1}}^x \Phi^s_-(x, y; \beta_i^-, \lambda) \lambda^2 d_i \tilde{H}_i^-(y) dy \\
&+ \int_{-X_{i-1}}^x
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
L_2(\lambda)&(a,b,c,d)_i^+(x) = \Phi^u_+(x, X_i; \beta_i^+, \lambda)a_i^+ + \Phi^s_+(x, 0; \beta_i^+, \lambda)b_i^+ \\
&+ e^{\nu(\lambda)(x - X_i)} v_+(x; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&+ \int_0^x \Phi^s_+(x, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}_i^+(y) dy + \int_{X_i}^x \Phi^u_+(x, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}_i^+(y) dy \\
&+ \int_{X_i}^x e^{\nu(\lambda)(x-y)} v_+(x; \beta_i^+, \lambda) \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Then $L_2$ is a bounded linear operator with piecewise bounds

\begin{align*}\label{L2bound}
|L_2(\lambda)(a,b,c,d)_i^-| &\leq C \left( |a| + |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + |\lambda|^2 |d| \right) \\
|L_2(\lambda)(a,b,c,d)_i^+| &\leq C \left( |a| + |b| + e^{|\nu(\lambda)|X_i}|c_i| + |\lambda|^2 |d| \right)
\end{align*}

We also have the following piecewise, $x$-dependent bounds for $L_2$.

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^-(x)| &\leq C (e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + |\lambda|^2 |d| ) \\
|L_2(\lambda)(a,b,c,d)_i^+(x)| &\leq C (e^{-\alpha(X_i - x)}|a_i^+| + |b_i^+| + e^{|\nu(\lambda)|(X_i - x)} |c_i^+| + |\lambda|^2 |d| ) 
\end{align*}

\begin{proof}
Most of the bounds on the individual terms are the same as in San98. We will consider the case where $x \leq 0$. The case where $x \geq 0$ is similar. For the $c_{i-1}^-$ term we have

\[
e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \leq C e^{|\nu(\lambda)| X_{i-1} }|c_{i-1}^-|
\]

The first two integral terms are similar to San98. For the third (center) integral terms, we use the following trick involving $\tilde{\alpha}$ to eliminate any potential exponential growth.

\begin{align*}
&\left| \int_{-X_{i-1}}^x 
e^{\nu(\lambda)(x-y)} v_-(x; \beta_i^-, \lambda) \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \right| \\
&\leq C |\lambda|^2 |d| e^{\tilde{\alpha}x} \int_{-X_{i-1}}^x e^{-\tilde{\alpha}x} e^{\tilde{\alpha}y} e^{\nu(\lambda)(x-y)} |e^{-\tilde{\alpha}y}\tilde{H}_i^-(y)|dy \\
&\leq C |\lambda|^2 |d| e^{\tilde{\alpha}x} \int_{-X_{i-1}}^x e^{-\tilde{\alpha}(x-y)} e^{\nu(\lambda)(x-y)} |e^{-\tilde{\alpha}y}\tilde{H}_i^-(y)| dy \\
&\leq C |\lambda|^2 |d| e^{\tilde{\alpha}x} \int_{-X_{i-1}}^x e^{-(\tilde{\alpha} - |\nu(\lambda)|)(x-y)} dy \\
&\leq C |\lambda|^2 |d|
\end{align*}

where we use the facts that $|e^{-\tilde{\alpha}y}\tilde{H}_i^-(y)|$ is bounded (since $\tilde{H}$ decays exponentially with rate $\alpha$) and that $|\nu(\lambda)| < \tilde{\alpha}$ by our choice of $\tilde{\alpha}$. The other center integral is similar. Thus, we have the bound 

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^-(x)| &\leq C (e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|(X_{i-1} + x)} |c_{i-1}^-| + |\lambda|^2 |d| )
\end{align*}

For the ``positive'' piece, we have

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^+(x)| &\leq C (e^{-\alpha(X_i - x)}|a_i^+| + |b_i^+| + e^{|\nu(\lambda)|(X_i - x)} |c_i^+| + |\lambda|^2 |d| ) 
\end{align*}

For the bounds independent of $x$, we note that $e^{|\nu(\lambda)|(X_i - x)} \leq e^{|\nu(\lambda)|(X_i}$ for $x \in [0, X_i]$, and similarly for the ``negative'' piece

\end{proof}
\end{lemma}

Now that we have these bounds, we can perform the inversion

% inversion lemma 3 - invert to solve for W

\begin{lemma}\label{W1}
There exists a bounded linear operator $W_1: V_\lambda \times V_a \times V_b \times V_c \times V_d \rightarrow V_W$ such that 

\[
W = W_1(\lambda)(a,b,c,d)
\]

This operator is analytic in $\lambda$ and linear in $(a, b, c, d)$. The operator $W_1$ satisfies the piecewise bounds

\begin{align*}
||W_1(\lambda)(a,b,c,d)_i^-|| &\leq C ( |a_{i-1}^-| + |b_i^-| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}^-| + |\lambda|^2 |d| ) \\
||W_1(\lambda)(a,b,c,d)_i^+|| &\leq C ( |a_i^+| + |b_i^+| + e^{|\nu(\lambda)|X_i}|c_i^+| + |\lambda|^2 |d| )
\end{align*}

\begin{proof}
Let the linear operators $L_1$ and $L_2$ be defined as in the previous two lemmas. Then we can rewrite the fixed point equation as

\[
(I - L_1(\lambda))W = L_2(\lambda)(a,b,c,d)
\]

For $L_1$ we have the estimate from Lemma \ref{L1}

\begin{align*}
||L_1(\lambda)W|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_1}||W|| \\
&\leq C e^{-\tilde{\alpha} X_1}||W|| \\
&\leq C \delta ||W||
\end{align*}

Thus if we choose $\delta$ sufficiently small (i.e. smaller than $C$), the operator norm of $L_1$ is less than 1, which implies that the operator $(I - L_1(\lambda))$ is invertible. The inverse $(I - L_1(\lambda))^{-1}$ is analytic in $\lambda$ and has operator norm 

\[
||(I - L_1(\lambda))^{-1}|| \leq \frac{1}{1 - ||L_1||}
\]

We can then write $W$ as
\[
W = W_1(\lambda)(a,b,c,d) = (I - L_1(\lambda))^{-1} L_2(\lambda)(a,b,c,d)
\]

which depends linearly on $(a,b,c,d)$ and analytically on $\lambda$. Since the operator norm of $L_1$ is bounded by a constant (independent of the $X_i$), and we have a piecewise bound on $L_2$ from Lemma \ref{L2}, the piecewise bounds on $||W||$ are obtained by noting which piece of $L_2$ is involved with which piece of $W$.

\end{proof}
\end{lemma}

The next inversion step solves for the joins at $x = \pm X_i$, i.e. solves the equations

\begin{align*}
W_i^+(X_i) - W_{i+1}^-(-X_i) &= D_i d \\
\end{align*}

% second inversion lemma

\begin{lemma}\label{inv2}
There exist operators

\begin{align*}
A_1: V_\lambda \times V_b \times V_c \times V_d \rightarrow V_a \\
W_2: V_\lambda \times V_b \times V_c \times V_d \rightarrow V_W \\
\end{align*}

such that $(a,W) = ( A_1(\lambda)(b,c,d), W_2(\lambda)(b,c,d) )$ solves our system. These operators are analytic in $\lambda$ and linear in $(b,c,d)$. Piecewise bounds for them are given by

\begin{align*}
|A_1(\lambda)_i&(b, c, d)| \\
&\leq C \Big( (e^{-\alpha X_i} + ||G||) |b| + ( p_2(X_i; \lambda) + p_3(\lambda)  + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i|
+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d| \Big)
\end{align*} 

and

\begin{align}
|W_2(\lambda)(b,c,d)_i^-|| &\leq C \Big( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| \Big) \\
|W_2(\lambda)(b,c,d)_i^+|| 
&\leq C \Big( |b| + e^{|\nu(\lambda)|X_i}|c_i| + (|\lambda|^2 + |D_i|)|d| \Big)
\end{align} 

Furthermore, we can write $a_i^\pm$ as 

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_2(\lambda)_i^+(b, c, d) \\
a_i^- &= -P^s_0 D_i d + A_2(\lambda)_i^-(b, c, d)
\end{align*}

where $A_2$ is a bounded operator with estimate

\begin{align*}
|A_2&(\lambda)_i(b, c, d)| \\
&\leq C \Big( (e^{-\alpha X_i} + ||G||)|b| + ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + (p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big)
\end{align*}

$p_1(X_i; \lambda)$ is defined in Lemma \ref{projbounds}, and $p_2(X_i; \lambda)$ and $p_3(\lambda)$ are defined in Lemma \ref{centerbounds}. 

\begin{proof}

Evaluating the fixed point equations at $\pm X_i$, we have

\begin{align*}
W_i^+(X_i) &- W_{i+1}^-(-X_i) = P^u_+(X_i; \beta_i^+, \lambda) a_i^+ - P^s_-(-X_i; \beta_{i+1}^-, \lambda) a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i-1}^-, \lambda)b_{i+1}^- \\
&+ v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ - v_-(-X_i; \beta_{i-1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i-1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy
\end{align*}

We now manipulate this to get it into a form we can use. First, we get the coefficients $a_i^\pm$ by themselves by adding and subtracting $P_0^u a_i^+$ and $P_0^s a_i^-$. Since $a_i^- \in E^u$ and $a_i^+ \in E^s$, 

\begin{align*}
D_i d &= a_i^+ - a_i^- \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-, \lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda)b_{i+1}^- \\
&+ v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ - v_-(-X_i; \beta_{i+1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy
\end{align*}

Next we rearrange the above to get $a_i^- - a_i^+$ by itself on the LHS.

\begin{align*}
a_i^- - a_i^+ &= -D_i d  \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-,\lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda) b_{i+1}^- \\
&+ v_+(X_i; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ - v_-(-X_i; \beta_{i+1}^-, \lambda) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy
\end{align*}

Since $a_i^- - a_i^+ \in E^+ \oplus E^-$, the RHS must lie in $E^+ \oplus E^-$ as well. Since $\C^m = E^+ \oplus E^- \oplus E^0$, the RHS must have no component in the (unperturbed) center space. The vectors $v_+(X_i; \beta_i^+, \lambda)$ and $v_-(-X_i; \beta_{i+1}^-, \lambda)$ are close to $v_0(\lambda)$, which is close to $v_0(0) \in E^0$. Adding and subtracting $v_0(0)$ in both of the $c_i$ terms, we rewrite $a_i^- - a_i^+$ as

\begin{align*}
a_i^- &- a_i^+ = -D_i d + (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-, \lambda) - P_0^s)a_i^- \\
&+ v_0(0) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ 
- v_0(0) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda)b_{i+1}^- \\
&+ (v_0(0) - v_+(X_i; \beta_i^+, \lambda)) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&- (v_0(0) - v_-(-X_i; \beta_{i+1}^-, \lambda)) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy
\end{align*}

Let $P_0^\pm$ be the projection on $E^s \oplus E^u$. When we apply the projection, the $v_0(0)$ terms disappear, which leaves us with

\begin{align*}
a_i^- &- a_i^+ = P_0^\pm \Big(-D_i d \\
&+(v_+(X_i; \beta_i^+, \lambda) - v_0(0)) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&- (v_-(-X_i; \beta_{i+1}^-,\lambda) - v_0(0)) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-, \lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda)b_{i+1}^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy \Big)
\end{align*}

Thus we have

\begin{align*}
a_i^- - a_i^+ = -P_0^\pm D_i d + L_3(\lambda)_i(a, b, c, d)
\end{align*}

Where $L_3(\lambda)(a, b, c, d)_i$ is the rest of the terms on the RHS.

\begin{align*}
L_3(\lambda)&(a, b, c, d)_i = P_0^\pm \Big( \\
&(v_+(X_i; \beta_i^+, \lambda) - v_0(0)) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&- (v_-(-X_i; \beta_{i+1}^-, \lambda) - v_0(0)) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-, \lambda) - P_0^s)a_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda)b_{i+1}^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy \Big)
\end{align*}

For a bound on $L_3$, we have seen most of the terms before. For the bound on the integral term involving $\tilde{H}_i^\pm$, we use the $\tilde{\alpha}$ trick to get a better bound. For the ``positive'' piece, this bound is

\begin{align*}
\left| \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) \tilde{H}_i^+(y) dy \right| 
&\leq C \int_0^{X_i} e^{-\alpha (X_i - y)}|\tilde{H}_i^+(y)| dy \\
&= C e^{-\tilde{\alpha}X_i} \int_0^{X_i} e^{-\alpha X_i} e^{\alpha y}  e^{\tilde{\alpha}X_i} e^{-\tilde{\alpha}y} |e^{\tilde{\alpha}y} \tilde{H}_i^+(y)| \\
&= C e^{-\tilde{\alpha}X_i} \int_0^{X_i} e^{-(\alpha - \tilde{\alpha})(X_i-y)} |e^{\tilde{\alpha}y} \tilde{H}_i^+(y)|\\
&\leq C e^{-\tilde{\alpha}X_i} 
\end{align*}

where we again used the fact that $|e^{\tilde{\alpha}y} \tilde{H}_i^+(y)|$ is bounded, since $\tilde{\alpha} < \alpha$ and $\tilde{H}_i^+(y)$ decays with rate $\alpha$. The ``negative'' piece is similar.\\

For the integral term involving $W$, we use the piecewise bound on $W_i^+$ from Lemma \ref{W1}. For the ``positive'' piece, we have

\begin{align*}
&\left| \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) G_i^+(y) W_i^+(y) \right| \\
&\leq C \int_0^{X_i} e^{-\alpha(X_i - y)}|G_i^+(y)|(|a_i^+| + |b_i^+| + e^{|\nu(\lambda)|X_i}|c_i^+| + |\lambda|^2 |d| ) dy \\
&\leq C \left( ||G||(|a| + |b| + |\lambda|^2 |d|) + \int_0^{X_i} e^{-\alpha(X_i - y)}|G_i^+(y)|e^{|\nu(\lambda)|X_i}|c_i^+| dy \right) \\
&\leq C \left( ||G||(|a| + |b| + |\lambda|^2 |d|) + \int_0^{X_i} e^{-\alpha(X_i - y)}e^{-\alpha X_i} e^{-\alpha(X_i - y)} e^{|\nu(\lambda)|X_i}|c_i^+| dy \right)\\
&\leq C \left( ||G||(|a| + |b| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i^+| \int_0^{X_i} e^{-2\alpha(X_i - y)} dy \right) \\
&\leq C \left( ||G||(|a| + |b| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i^+| \right)
\end{align*}

where we used the fact that $|\nu(\lambda)| \leq \alpha$.  

The ``negative'' piece is similar. This works out the way we want, since the ``negative'' piece involves $W_{i+1}$, but the piecewise bound for $W_{i+1}$ involves $c_i^-$.\\

Thus we have the following bound for $L_3$.

\begin{align*}
L_3(\lambda)&(a, b, c, d)_i \leq C ( p_1(X_i; \lambda)|a_i|
+ e^{-\alpha X_i}|b| + (p_2(X_i; \lambda) + p_3(\lambda))|c_i| \\
&+ ||G||(|a| + |b| + |\lambda|^2 |d|) + e^{-(\alpha - |\nu(\lambda)|)X_i} |c_i| + e^{-\tilde{\alpha} X_i} |\lambda^2| |d| )
\end{align*}

where $p_1(\lambda)$ is defined in Lemma \ref{projbounds}, and $p_2(X_i; \lambda)$ and $p_3(\lambda)$ are defined in Lemma \ref{centerbounds}.\\

Combining terms and simplifying, the final bound for $L_3$ is

\begin{align*}
L_3(\lambda)&(a, b, c, d)_i \leq C \Big( (p_1(X_i; \lambda) + ||G|| )|a_i|
+ (e^{-\alpha X_i} + ||G||)|b| + ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| \Big)
\end{align*}

We use Lemma \ref{projbounds} for a bound on $p_1(X_i; \lambda)$. Using Lemma \ref{centerbounds} and recalling that $X_m = \min_i \{ X_i \}$, we take $X_m$ sufficiently large so that $p_2(X_i; \lambda) < \delta$ for all $i$. Using Lemma \ref{centerbounds} again, $p_3(\lambda)$ is order $|\lambda|$. Thus we have

\begin{align*}
L_3(\lambda)&(a, b, c, d)_i \leq C \delta (|a_i| + |b| + |c_i| + |d|)
\end{align*}

Let $J_1: V_a \rightarrow \C^{2n}$ be defined by $J_i(a_i) = (a_i^+ - a_i^-)$. The map $J_i$ is a linear isomorphism since $E^s \oplus E^u = \C^{m-1}$. Now consider the map

\[
S_i(a_i) = J_i (a_i) + L_3(\lambda)_i(a_i, 0, 0, 0) = J_i( I + J_i^{-1} L_3(\lambda)_i(a_i, 0, 0, 0))
\]

For sufficiently small $\delta$ we can get the operator norm 

\[
||J_i^{-1} L_3(\lambda)_i(\cdot, 0, 0, 0)|| < 1
\]

thus the map $a_i \rightarrow I + J_1^{-1} L_3(\lambda)_i(a_i, 0, 0, 0)$ is invertible, and so the operator $S_i$ is invertible.\\

We can thus solve for $a_i$ to get

\[
a_i = A_1(\lambda)_i(b, c, d) = S_i^{-1}(-D_i d - L_3(\lambda)_i(0, b, c, d))
\]

Using the bound on $L_3$, $A_1$ will have the bound

\begin{align*}
|A_1&(\lambda)_i(b, c, d)| \\
&\leq C \Big( (e^{-\alpha X_i} + ||G||) |b| + ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i|
+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d| \Big)
\end{align*} 

We can plug this into our expression for $W_1$ to get $W_2(\lambda)$, which has piecewise bounds

\begin{align*}
|W_2(\lambda)(b,c,d)_i^-|| &\leq C \Big( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| \Big) \\
|W_2(\lambda)(b,c,d)_i^+|| 
&\leq C \Big( |b| + e^{|\nu(\lambda)|X_i}|c_i| + (|\lambda|^2 + |D_i|)|d| \Big)
\end{align*}

With a multipulse, we will need an analogue of (3.25) in San98. The idea here is that we hit our expression for $D_i d$ with projections $P^s_0$ and $P^u_0$ to eliminate some of the terms. We start with

\begin{align*}
a_i^- &- a_i^+ = -D_i d + (P^u_+(X_i; \beta_i^+, \lambda) - P_0^u)a_i^+ - (P^s_-(-X_i; \beta_{i+1}^-, \lambda) - P_0^s)a_i^- \\
&+ v_0(0) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ 
- v_0(0) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ \Phi^s_+(X_i, 0; \beta_i^+, \lambda)b_i^+ - \Phi^u_-(-X_i, 0; \beta_{i+1}^-, \lambda)b_{i+1}^- \\
&+ (v_0(0) - v_+(X_i; \beta_i^+, \lambda)) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&- (v_0(0) - v_-(-X_i; \beta_{i+1}^-, \lambda)) \langle v_0(\lambda), w_-(-X_i; \beta_{i+1}^-, \lambda) \rangle c_i^- \\
&+ \int_0^{X_i} \Phi^s_+(X_i, y; \beta_i^+, \lambda) [ G_i^+(y) W_i^+(y) + d_i \lambda^2 \tilde{H}_i^+(y) ] dy \\
&- \int_0^{-X_i} \Phi^u_-(-X_i, y; \beta_{i+1}^-, \lambda) [ G_{i+1}^-(y) W_{i+1}^-(y) + d_{i+1} \lambda^2 \tilde{H}_i^-(y) ] dy 
\end{align*}

This time, we take projections $P^s_0$ and $P^u_0$ individually. Recalling where the $a_i^\pm$ and $v_0(0)$ live and that $v_0(0)$ is wiped out by both projections, this becomes 

\begin{align*}
a_i^+ &= P^u_0 D_i d - P^u_0 L_3(\lambda)_i(a, b, c, d) \\
a_i^- &= -P^s_0 D_i d + P^s_0 L_3(\lambda)_i(a, b, c, d)
\end{align*}

Define $A_2$ to be all the stuff on the RHS other than the $D_i d$ term. Thus we have 

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_2(\lambda)_i^+(b, c, d) \\
a_i^- &= -P^s_0 D_i d + A_2(\lambda)_i^-(b, c, d)
\end{align*}

We then can come up with a bound for $A_2$ using the bound for $L_3$ and the bound for $A_1$.

\begin{align*}
|A_2&(\lambda)_i(b, c, d)| \\
&\leq C |L_3(\lambda)_i(a, b, c, d)| \\
&\leq C \Big( (p_1(X_i; \lambda) + ||G|| )|A_1(\lambda)_i(b, c, d)| \\
&+ (e^{-\alpha X_i} + ||G||)|b| + ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| + (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| \Big) \\
&\leq C \Big( (p_1(X_i; \lambda) + ||G|| )( (e^{-\alpha X_i} + ||G||)|b| + ( p_2(X_i; \lambda) + p_3(\lambda) + ||G|| )|c_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d|)  \\
&+ (e^{-\alpha X_i} + ||G||)|b| + ( p_2(X_i; \lambda) + p_3(\lambda) + ||G|| )|c_i| + (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| \Big) \\
&\leq C \Big( (p_1(X_i; \lambda) + ||G|| + 1)((e^{-\alpha X_i} + ||G||)|b| 
+ ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| \\
&+(e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big)
\end{align*}

Simplifying this expression and eliminating higher order terms, we attain our bound for $A_2$.

\begin{align*}
|A_2&(\lambda)_i(b, c, d)| \\
&\leq C \Big( (e^{-\alpha X_i} + ||G||)|b| + ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big)
\end{align*}

\end{proof}
\end{lemma}

Finally, we want to satisfy the conditions

\begin{align*}
P(\C Q'(0))W_i^-(0) &= 0 \\
P(\C Q'(0))W_i^+(0) &= 0 \\
P(Y^+ \oplus Y^- \oplus Y^0) ( W_i^+(0) - W_i^-(0) ) &= 0
\end{align*}

Since the stable and unstable range spaces at $\lambda = 0$ both contain $\C Q'(0)$, we decompose $b^\pm$ uniquely as $b^\pm = x^\pm + y^\pm$, where $x^\pm \in \C Q'(0)$ and $y^\pm \in Y^\pm$. Then since

\begin{equation}\label{directsum}
\C^m = \C\Psi(0) \oplus \C Q'(0) \oplus Y^+ \oplus Y^- \oplus Y^0
\end{equation}

the conditions above are equivalent to the following projections

\begin{align*}
P(\C Q'(0) \oplus Y^0 )W_i^-(0) &= 0 \\
P(\C Q'(0) \oplus Y^0 )W_i^+(0) &= 0 \\
P(Y^+ \oplus Y^-) (W_i^+(0) - W_i^-(0) ) &= 0
\end{align*}

where the range of each projection is indicated, and the kernel of each projection is the other elements of the direct sum \eqref{directsum}. Since the first two equations wipe out any component in $\C Q'(0) \oplus Y^0$, we don't need to put that in the range of the third projection. \\

Let $y_0 = v_\pm(0; 0, 0)$ be a unit vector for $Y^0$ (note that $v_+(0; 0, 0) = v_-(0, 0, 0)$ here). Expanding $v_+(0; 0, \lambda)$ in a Taylor series about $\lambda = 0$, we have (ASSUMING WE CAN DO THIS)

\begin{align*}
v_+(0; &0, \lambda) = v_+(0; 0, 0) 
+ \lambda \frac{\partial}{\partial \lambda}v_+(0; 0, \lambda)\Big|_{\lambda = 0} 
+ \mathcal{O}(|\lambda|^2) \\
&= y_0 + \mathcal{O}(|\lambda|)
\end{align*}

since $\frac{\partial}{\partial \lambda}v_+(0; 0, \lambda)\Big|_{\lambda = 0}$ is a constant. The same is true for $v_-(0; 0, \lambda)$. Thus since there is only a small $\mathcal{O}(|\lambda|)$ perturbation when we go from $y_0$ to $v_\pm(0; 0, \lambda)$ we can replace $Y_0$ with either $\spn \{v_+(0; 0, \lambda) \}$ or $\spn \{v_-(0; 0, \lambda) \}$ in \eqref{directsum}. In other words, we have the following two direct sum decompositions

\begin{align*}\label{directsum2}
\C^m = \C\Psi(0) \oplus \C Q'(0) \oplus Y^+ \oplus Y^- \oplus \C v_+(0; 0, \lambda) \\
\C^m = \C\Psi(0) \oplus \C Q'(0) \oplus Y^+ \oplus Y^- \oplus \C v_-(0; 0, \lambda) \\
\end{align*}

Thus we can use the following projections instead

\begin{align*}
P(\C Q'(0) \oplus \C v_-(0; \lambda) )W_i^-(0) &= 0 \\
P(\C Q'(0) \oplus \C v_+(0; \lambda) )W_i^+(0) &= 0 \\
P(Y^+ \oplus Y^-) (W_i^+(0) - W_i^-(0) ) &= 0
\end{align*}

To separate out the coefficients nicely, we write this as five projections

\begin{align*}
P(\C Q'(0) )W_i^-(0) &= 0 \\
P(\C Q'(0) )W_i^+(0) &= 0 \\
P(\C v_-(0; 0, \lambda))W_i^-(0) &= 0 \\
P(\C v_+(0; 0, \lambda))W_i^+(0) &= 0 \\
P(Y^+ \oplus Y^-) (W_i^+(0) - W_i^-(0) ) &= 0
\end{align*}

This is the system we will solve in the next lemma.

% inversion 3

\begin{lemma}\label{inv3}
There exists an operator

\begin{align*}
B_1(\lambda): V_\lambda \times V_d \rightarrow V_b \times V_c \\
\end{align*}

such that 
\[
(b, \tilde{c}) = B_1(\lambda)d
\]

where

\begin{align*}
\tilde{c}_i^- &= e^{\nu(\lambda)X_i} c_i^- \\
\tilde{c}_i^+ &= e^{-\nu(\lambda)X_i} c_i^+
\end{align*}

and

\begin{align*}
(a,b,&\tilde{c}, W) 
= (A_1(\lambda)(B_1(\lambda)d, d), B_1(\lambda)d, W_2(\lambda)(B_1(\lambda)d, d))
\end{align*}

solves our system. The operator $B_1(\lambda)$ is analytic in $\lambda$ and linear in $d$ and has piecewise bound

\begin{align*}
|B_1(\lambda)_i(d)| &\leq C ( (e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} ) |D| + |\lambda|^2 )|d|
\end{align*}

It also has uniform bound

\begin{equation}
|B_1(\lambda)(d)| \leq C ( e^{-(\alpha - |\nu(\lambda)|) X_m} |D| + |\lambda|^2 )|d|
\end{equation}

\begin{proof}

At $x = 0$, the fixed point equations become

\begin{align*}
W_i^-(0) = \Phi^s_-(&0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- + b_i^- + (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \\
&+ e^{\nu(\lambda)X_{i-1}} v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&+ \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
W_i^+(0) = \Phi^u_+(&0, X_i; \beta_i^+, \lambda)a_i^+ + b_i^+ + (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ \\
&+ e^{-\nu(\lambda) X_i} v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

where we have added and subtracted $P^s_-(0; 0, 0))b_i^+ = b_i^+$ and $P^u_-(0; 0, 0))b_i^- = b_i^-$ since we want the $b_i^\pm$ to disappear when we take the projections. Before we start hitting things with all sorts of projections, we need to get the $c_i^\pm$ term into a useful form.

\begin{align*}
e^{\nu(\lambda)X_{i-1}} &v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&= e^{\nu(\lambda)X_{i-1}} v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_0(\lambda) \rangle c_{i-1}^- \\
&+ e^{\nu(\lambda)X_{i-1}} v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), \Delta w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&= e^{\nu(\lambda)X_{i-1}} c_{i-1}^- v_-(0; \lambda) + e^{\nu(\lambda)X_{i-1}} c_{i-1}^- v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), \Delta w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle 
\end{align*}

where 

\begin{align*}
\Delta v_\pm(X; \beta^\pm, \lambda) &= v_\pm(\pm X; \beta^\pm, \lambda) - v_0(\lambda) \\
\Delta w_\pm(X; \beta^\pm, \lambda) &= w_\pm(\pm X; \beta^\pm, \lambda) - w_0(\lambda) 
\end{align*}

and $\langle v_0(\lambda), w_0(\lambda) \rangle = 1$. Similarly, we have

\begin{align*}
e^{-\nu(\lambda)X_i} &v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&= e^{-\nu(\lambda)X_i} v_-(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_0(\lambda) \rangle c_i^- + e^{-\nu(\lambda)X_i} v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), \Delta w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&= e^{-\nu(\lambda)X_i} c_i^+ v_+(0; \beta_i^+, \lambda) + e^{-\nu(\lambda)X_i} c_i^+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), \Delta w_+(X_i; \beta_i^+, \lambda) \rangle 
\end{align*}

Next, we let

\begin{align*}
\tilde{c}_i^- &= e^{\nu(\lambda)X_i} c_i^- \\
\tilde{c}_i^+ &= e^{-\nu(\lambda)X_i} c_i^+
\end{align*}

Then these equations become

\begin{align*}
e^{\nu(\lambda)X_{i-1}} &v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^- \\
&= \tilde{c}_{i-1}^- v_-(0; \beta_i^-, \lambda) + \tilde{c}_{i-1}^- v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), \Delta w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle \\
e^{-\nu(\lambda)X_i} &v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle c_i^+ \\
&= \tilde{c}_i^+ v_+(0; \beta_i^+, \lambda) + \tilde{c}_i^+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), \Delta w_+(X_i; \beta_i^+, \lambda) \rangle 
\end{align*}

Substituting these into the fixed point equations evaluated at $x = 0$, we have the following expressions for $W_i^\pm(0)$.

\begin{align*}
W_i^-(0) &= x_i^- + y_i^- + v_-(0; \beta_i^-, \lambda) \tilde{c}_{i-1}^- v_-(0; \beta_i^-, \lambda) \\
&+\Phi^s_-(0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- + (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \\
&+ \tilde{c}_{i-1}^- v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), \Delta w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle \\
&+ \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&+ \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
W_i^+(0) &= x_i^+ + y_i^+ + v_+(0; \beta_i^+, \lambda) \tilde{c}_i^+ v_+(0; \beta_i^+, \lambda) \\
&+\Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ + (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ \\
&+ \tilde{c}_i^+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), \Delta w_+(X_i; \beta_i^+, \lambda) \rangle \\  
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy
\end{align*}

Plugging these expressions for $W_i^\pm(0)$ into the above set of projections, we get the matrix equation

\[
\begin{pmatrix}x_i^- \\ x_i^+ \\ 
\tilde{c}_{i-1}^- v_-(0; \lambda) \\
\tilde{c}_i^+ v_+(0; \lambda) \\
y_i^+ - y_i^- \end{pmatrix} + L_4(\lambda)(b, \tilde{c}) = 0
\]

where $L_4(\lambda)(b, \tilde{c})$ contains the terms that don't get eliminated outright by the projections. Note that so far we have written $L_4$ entirely in terms of $\tilde{c}$. We will make sure this remains the case when we perform the substitutions for $W$ and $a$.\\

For the bound on $L_4$, we need to get bounds on the integral terms involving $W$ in a similar fashion to what we did in the previous lemmas. First, we find a bound for the center integral involving $W$ on the ``minus'' piece.\\

\begin{align*}
&\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle \right| \\
&\leq C \int_{-X_{i-1}}^0 e^{|\nu(\lambda)|y} |G_i^-(y)| |W_i^-(y)| dy \\
&\leq C \int_{-X_{i-1}}^0 e^{|\nu(\lambda)|y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} |W_i^-(y)| dy
\end{align*}

Substituting the piecewise bound $W_2$ for $W_i^-$ from Lemma \ref{inv2}, we have

\begin{align*}
&\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle \right| \\
&\leq C \int_{-X_{i-1}}^0 e^{|\nu(\lambda)|y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + D_{i-1})|d| )dy \\
&\leq C e^{-\alpha X_{i-1}} \int_{-X_{i-1}}^0 e^{|\nu(\lambda)|X_{i-1}} e^{-\alpha(X_{i-1} + y)} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + D_{i-1})|d| )dy \\
&\leq C e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + D_{i-1})|d| ) \int_{-X_{i-1}}^0 e^{-\alpha(X_{i-1} + y)} dy \\
&\leq C e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + D_{i-1})|d| ) \\
&\leq C ( e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} |b| + e^{-(\alpha - 2 |\nu(\lambda)|) X_{i-1}}|c_{i-1}| + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} (|\lambda|^2 + D_{i-1})|d| )
\end{align*}

We can also use this bound on the noncenter integral on the ``minus'' piece, since that integral does not contain the $e^{\nu(\lambda)y}$ term, which only makes things worse. (In fact, we can get a better bound, but it does not matter in this case.)\\

Similarly, for the center integral involving $W$ on the the ``plus'' piece, we have a bound

\begin{align*}
&\left| \int_{X_i}^0 e^{\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \right| \\
&\leq C ( e^{-(\alpha - |\nu(\lambda)|) X_i} |b| + e^{-(\alpha - 2 |\nu(\lambda)|) X_{i-1}}|c_i| + e^{-(\alpha - |\nu(\lambda)|) X_i} (|\lambda|^2 + D_i)|d| )
\end{align*}

The integrals not involving $W$ can be evaluated using the $\tilde{\alpha}$ trick, as we have done before. Thus we have the following bound on $L_4(\lambda)$. 

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\ 
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + p_5(\beta_i^+, \beta_i^-, \lambda) |b_i| \\
&+ p_2(X_{i-1}; \lambda) |\tilde{c}_{i-1}| + p_2(X_i; \lambda) |\tilde{c}_i| \\
&+ ( e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} |b| + e^{-(\alpha - 2 |\nu(\lambda)|) X_{i-1}}|c_{i-1}| + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} (|\lambda|^2 + D_{i-1})|d| ) \\
&+ ( e^{-(\alpha - |\nu(\lambda)|) X_i} |b| + e^{-(\alpha - 2 |\nu(\lambda)|) X_{i-1}}|c_i| + e^{-(\alpha - |\nu(\lambda)|) X_i} (|\lambda|^2 + D_i)|d| )  \\
&+ |\lambda|^2 |d| \Big)\\
\end{align*}

where $p_2(X; \lambda)$ is defined in Lemma \ref{centerbounds} and $p_5(\beta_i^+, \beta_i^-, \lambda)$ is defined in Lemma \ref{projbounds}. Luckily, $p_2(X; \lambda)$ does not enter into the final bound, since we do not have a decay rate for it, but we know that its limit is 0 as $|X| \rightarrow \infty$, which is all we need.\\

Before we continue, we need to get everything we have so far on the RHS in terms of the $\tilde{c}$. Fortunately, this is not hard to do since we can absorb another $|\nu(\lambda)|X_i$ using $\alpha$. This gives us

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + p_5(\beta_i^+, \beta_i^-, \lambda) |b_i| \\
&+ p_2(X_{i-1}; \lambda) |\tilde{c}_{i-1}| + p_2(X_i; \lambda) |\tilde{c}_i| \\
&+ ( e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} |b| + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}|\tilde{c}_{i-1}| + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}} (|\lambda|^2 + D_{i-1})|d| ) \\
&+ ( e^{-(\alpha - |\nu(\lambda)|) X_i} |b| + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}|\tilde{c}_i| + e^{-(\alpha - |\nu(\lambda)|) X_i} (|\lambda|^2 + D_i)|d| )  \\
&+ |\lambda|^2 |d| \Big)\\
&\leq C \Big( e^{-\alpha X_i} |a_i^+| +  e^{-\alpha X_{i-1}} |a_{i-1}^-| + (p_5(\beta_i^+, \beta_i^-, \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}) |\tilde{c}_{i-1}| + (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i})|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}})|D||d| + |\lambda|^2|d|
\Big)
\end{align*}

To finish the bound, we plug in $A_1$ for $|a|$

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\
&\leq C \Big( e^{-\alpha X_i} |A_1(\lambda)_i(b, c, d)| \\
&+  e^{-\alpha X_{i-1}} |A_1(\lambda)_{i-1}(b, c, d)| \\
&+ (p_5(\beta_i^+, \beta_i^-, \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}) |\tilde{c}_{i-1}| + (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i})|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}})|D||d| + |\lambda|^2|d|
\Big) \\
&\leq C \Big( e^{-\alpha X_i} ( (e^{-\alpha X_i} + ||G||) |b| + ( p_4(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d| ) \\
&+ e^{-\alpha X_{i-1}} ( (e^{-\alpha X_{i-1}} + ||G||) |b| + ( p_4(X_{i-1}; \lambda) + e^{-(\alpha - |\nu(\lambda)|)X_{i-1}} )|c_{i-1}| \\
&+ (e^{-\tilde{\alpha} X_{i-1}} + ||G||) |\lambda^2| |d| + |D_{i-1}||d| ) \\
&+ (p_5(\beta_i^+, \beta_i^-, \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}) |\tilde{c}_{i-1}| + (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i})|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}})|D||d| + |\lambda|^2|d|
\Big) \\
\end{align*}

where, for convenience, we take

\begin{equation}
p_4(X; \lambda) = p_2(X; \lambda) + p_3(\lambda)
\end{equation}

We can do the same thing we did above to get this in terms of the $\tilde{c}$.

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\
&\leq C \Big( e^{-\alpha X_i} ( (e^{-\alpha X_i} + ||G||) |b| + ( p_4(X_i; \lambda) + e^{-(\alpha - 2|\nu(\lambda)|)X_i} )|\tilde{c}_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| + |D_i||d| ) \\
&+ e^{-\alpha X_{i-1}} ( (e^{-\alpha X_{i-1}} + ||G||) |b| + ( p_4(X_{i-1}; \lambda) + e^{-(\alpha - 2 |\nu(\lambda)|)X_{i-1}} )|\tilde{c}_{i-1}| \\
&+ (e^{-\tilde{\alpha} X_{i-1}} + ||G||) |\lambda^2| |d| + |D_{i-1}||d| ) \\
&+ (p_5(\beta_i^+, \beta_i^-, \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}}) |\tilde{c}_{i-1}| + (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i})|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}})|D||d| + |\lambda|^2|d|
\Big) \\
\end{align*}

Simplifying and eliminating higher order terms, this becomes

\begin{align*}
|L_4&(\lambda)_i(b, c, d)|\\
&\leq C \Big(
(p_5(\beta_i^+, \beta_i^-, \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1}) |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}} + e^{-\alpha X_{i-1}} p_4(X_{i-1}; \lambda) ) |\tilde{c}_{i-1}| \\
&+ (p_2(X_i; \lambda) + e^{-(\alpha - 3 |\nu(\lambda)|) X_i} + e^{-\alpha X_i} p_4(X_i; \lambda) )|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}})|D||d|+ |\lambda|^2|d|
\Big)
\end{align*}

Since $p_4(X, \lambda) = p_2(X, \lambda) + \mathcal{O}(|\lambda|)$ and $\alpha - 3 |\nu(\lambda)| > \tilde{\alpha}$, we can further eliminate higher order terms and simplify this to

\begin{align*}
&\leq C \Big(
(p_5(\beta_i^+, \beta_i^-, \lambda) + e^{-\tilde{\alpha} X_1}  |b| \\
&+ (p_2(X_{i-1}; \lambda) + e^{-\tilde{\alpha} X_{i-1}})|\tilde{c}_{i-1}| 
+ (p_2(X_i; \lambda) + e^{-\tilde{\alpha} X_i} )|\tilde{c}_i| \\
&+ (e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}})|D||d| + |\lambda|^2|d|
\Big)
\end{align*}

To do the inversion, we use Lemma \ref{projbounds} for the estimate of $p_5(\beta_i^+, \beta_i^-, \lambda)$ and note that in the previous lemma we chose $X_m$ sufficiently large so that $p_2(X_1; \lambda) < \delta$. Thus we have

\begin{align*}
|L_4&(\lambda)_i(b, c, d)| \leq C \delta (|b| + |\tilde{c}|) + C ( (e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}})|D| + |\lambda|^2)|d|
\end{align*}

Thus for sufficiently small $\delta$, we can perform the inversion, as in the previous two lemmas.\\

Since the map $J_2$ defined by
\[
J_2( (x_i^+, x_i^-),(y_i^+, y_i^-), \tilde{c}_{i-1}^-, \tilde{c}_i^+ ) \rightarrow ( x_i^+, x_i^-, \tilde{c}_{i-1}^-, \tilde{c}_i^+, y_i^+ -  y_i^- )
\]

is an isomorphism, the operator

\[
S_2(x,y, \tilde{c}) = J_2(x+y, \tilde{c}) + L_4(\lambda)(x+y,\tilde{c}, 0)
\]

is invertible. Thus we have

\begin{equation}
(b,\tilde{c}) = B_1(\lambda)(d) = -S_2^{-1} L_4(\lambda)(0, 0, d)
\end{equation}

where we have the following bound on $B_1$

\begin{align*}
|B_1(\lambda)_i(d)| &\leq C ( (e^{-(\alpha - |\nu(\lambda)|) X_i} + e^{-(\alpha - |\nu(\lambda)|) X_{i-1}})|D| + |\lambda|^2 )|d|
\end{align*}

The uniform bound depends only on $X_m$. 

\begin{align*}
|B_1(\lambda)(d)| &\leq C ( e^{-(\alpha - |\nu(\lambda)|) X_m} |D| + |\lambda|^2 )|d|
\end{align*}

 
\end{proof}
\end{lemma}

\subsection{Jump Equations}

For our final step, we estimate the jumps

\begin{equation}
\xi_i = \langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle 
\end{equation}

for $i = 0, \dots, n-1$. Recall that $\Psi(0)$ is the adjoint solution for the unperturbed problem linearized about the single pulse $q(x)$, i.e. with $\lambda = 0$ and $\beta_i^\pm = 0$. The equations for $W$ contain the evolution operator $\Phi^{(s/u)}_\pm(x, y; \beta_i^\pm, \lambda)$, for which we have $\lambda \neq 0$ and with ICs $\beta_i^\pm$.\\

For the adjoint solution $\Psi(x)$, we have estimate 

\begin{equation}
|\Psi(x)| \leq C e^{-\alpha|x|}
\end{equation}

which holds since we know exactly what $\Psi$ is (it involves only the single pulse $q(x)$ and its derivatives, all of which decay with rate $\alpha$). Note as well that $\Psi(0)$ is just a fixed constant. For the difference $W_i^+(0) - W_i^-(0)$, we have

\begin{align*}
W_i^+(0) - W_i^-(0) &= b_i^+ - b_i^- \\
&+ \Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \beta_i^-, \lambda)a_{i-1}^- \\
&+(P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+  - (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \\
&+ v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+, \lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \\
&- v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \\
&+ \int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) [ G_i^+(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y) ] dy \\
&+ \int_{X_i}^0 e^{-\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)(y)W_i^+(y) + \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy \\
&- \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) [ G_i^-(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y) ] dy \\
&- \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)(y)W_i^-(y) + \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \\
\end{align*}

We will evaluate (or estimate) each term in the jump equation in a series of lemmas.

% lemma : a terms in jump

\begin{lemma}\label{jumpa}
For the terms involving $a$ in the jump $\xi_i$, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle
+ \mathcal{O}\Big(e^{-\alpha X_m} \Big( |\lambda|^2  + (e^{-\tilde{\alpha} X_m} + |\lambda|)|D| \Big)|d| \Big)
\end{align*}

\begin{proof}

Recall the following expressions for $a_i^\pm$ from Lemma \ref{inv2}.

\begin{align*}
a_i^+ &= P^u_0 D_i d + A_2(\lambda)_i^+(b, c, d)\\
a_i^- &= -P^s_0 D_i d + A_2(\lambda)_i^-(b, c, d)
\end{align*}

For the ``positive'' piece $\langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda)a_i^+ \rangle$, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle = \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda) P^u_0 D_i d \rangle + \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b, c, d) \rangle \\
\end{align*} 

Note that $\Psi(0)$ is the adjoint solution unperturbed by $\lambda$ and with $\beta_i^\pm = 0$, whereas the evolution $\Phi^u_+(0, X_i; \lambda)$ is perturbed by $\lambda$ and has $\beta_i^\pm \neq 0$. To get around this, we add and subtract $\Phi^u_+(0, X_i; 0, 0)$ to get

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle \\
&= \langle \Psi(0), \Phi^u_+(0, X_i; 0, 0) P^u_0 D_i d \rangle + \langle \Psi(0), (\Phi^u_+(0, X_i; \beta_i^+, \lambda) - \Phi^u_+(0, X_i; 0, 0)) P^u_0 D_i d \rangle \\
&+ \langle \Psi(0), \Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle 
+ \mathcal{O}((|\lambda| + e^{-\alpha X_1} + e^{-\alpha X_2} ) e^{-\alpha X_i}|D_i||d|) + \langle \Psi(0), \Phi^u_+(0, X_i; \lambda) A_2(\lambda)_i^+(b,c,d) \rangle 
\end{align*}

Using the bound for $p_5$ from Lemma \ref{projbounds}, we have

\begin{align*}
\langle \Psi(0), (\Phi^u_+(0, X_i; \beta_i^+, \lambda) &- \Phi^u_+(0, X_i; 0, 0)) P^u_0 D_i d \rangle = \mathcal{O}(p_5(X_i; \beta_i^+, \beta_i^-, \lambda)) \\
&= \mathcal{O}((|\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} ) e^{-\alpha X_i}) \\
&= \mathcal{O}((|\lambda| + e^{-2 \alpha X_m}) e^{-\alpha X_m})
\end{align*}

Thus we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle 
+ \langle \Psi(0), \Phi^u_+(0, X_i; \lambda) A_2(\lambda)_i^+(b,c,d) \rangle 
+ \mathcal{O}((|\lambda| + e^{-2 \alpha X_m}) e^{-\alpha X_m}|D||d|)
\end{align*}

The first term on the RHS is what we want. Using the bound for $A_2$ from Lemma \ref{inv2}, the second term on the RHS has bound

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&\leq C e^{-\alpha X_i} |A_2(\lambda)_i(b,c,d)| \\
&\leq C e^{-\alpha X_i}  \Big( (e^{-\alpha X_i} + ||G||)|b| + ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - |\nu(\lambda)|)X_i} )|c_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big)
\end{align*}

We want to plug in the $B_1$ bound here, but first we need to get this in terms of the $\tilde{c}$. This is not hard to do, as we can easily absorb another $|\nu(\lambda)|$.

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&\leq C e^{-\alpha X_i} ( (e^{-\alpha X_i} + ||G||)|b| + ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - 2|\nu(\lambda)|)X_i} )|\tilde{c}_i| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|))
\end{align*}

Substituting $B_1$ for $b$ and $\tilde{c}$ and using the uniform $B_1$ bound, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&\leq C e^{-\alpha X_i}  \Big( (e^{-\alpha X_i} + ||G||)|B_1(\lambda)(d)| \\
&+ ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - 2|\nu(\lambda)|)X_i} )|B_1(\lambda)(d)| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big) \\
&\leq C e^{-\alpha X_i}  \Big( (e^{-\alpha X_i} + ||G||)( e^{-(\alpha - |\nu(\lambda)|) X_m} |D| + |\lambda|^2 )|d| \\
&+ ( p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - 2|\nu(\lambda)|)X_i} )( e^{-(\alpha - |\nu(\lambda)|) X_m} |D| + |\lambda|^2 )|d| \\
&+ (e^{-\tilde{\alpha} X_i} + ||G||) |\lambda^2| |d| +(p_1(X_i; \lambda) + ||G|| )|D_i||d|) \Big) 
\end{align*}

Collecting like terms and dropping higher order terms, this becomes

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) A_2(\lambda)_i^+(b,c,d) \rangle \\
&\leq C e^{-\alpha X_i} \Big( (e^{-\alpha X_i} + ||G|| + p_2(X_i; \lambda) + p_3(\lambda) + e^{-(\alpha - |2 \nu(\lambda)|)X_i} ) |\lambda|^2 ) \\
&+ (p_1(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_1} + |G|| )|D| \Big)|d| \\
&\leq C \Big( e^{-(\alpha - \nu(\lambda)) X_i} |\lambda|^2 
+ e^{-(\alpha - \nu(\lambda)) X_i}( e^{-\alpha X_1} + ||G|| + p_1(X_i; \lambda))|D| )|d| \Big) \\
&\leq e^{-\alpha X_i} \Big( |\lambda|^2  + (p_1(X_i; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_m} + ||G|| )|D| \Big)|d| \\
&\leq e^{-\alpha X_m} \Big( |\lambda|^2  + (p_1(X_m; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_m} + ||G|| )|D| \Big)|d| 
\end{align*}

Thus, we conclude

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \beta_i^+, \lambda) a_i^+ \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \mathcal{O}\Big(e^{-\alpha X_m} \Big( |\lambda|^2  + (p_1(X_m; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_m} \\
&+ |\lambda| + e^{-2 \alpha X_m} + ||G|| )|D| \Big)|d|  \Big) \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \mathcal{O}\Big(e^{-\alpha X_m} \Big( |\lambda|^2  + (p_1(X_m; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_m} + |\lambda| + ||G|| )|D| \Big)|d| \Big)
\end{align*}


Similarly we have

\begin{align*}
\langle \Psi(0), &\Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= -\langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle
+ \mathcal{O}\Big(e^{-\alpha X_m} \Big( |\lambda|^2  + (p_1(X_m; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_m} + |\lambda| + ||G|| )|D| \Big)|d| \Big)
\end{align*}

Putting everything together, we have

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle \\
&+ \mathcal{O}\Big(e^{-\alpha X_m} \Big( |\lambda|^2  + (p_1(X_m; \lambda) + e^{-(\alpha - |\nu(\lambda)|) X_m} + |\lambda| + ||G|| )|D| \Big)|d| \Big)
\end{align*}

Using the estimate for $p_1$ from Lemma \ref{projbounds}, the bound for $||G||$, and the fact that $\tilde{\alpha} < \alpha - |\nu(\lambda)|$, this can be simplified to

\begin{align*}
\langle \Psi(0), &\Phi^u_+(0, X_i; \lambda)a_i^+ - \Phi^s_-(0, -X_{i-1}; \lambda)a_{i-1}^- \rangle \\
&= \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^s_0 D_{i-1} d \rangle \\
&+ \mathcal{O}\Big(e^{-\alpha X_m} \Big( |\lambda|^2  + (e^{-\tilde{\alpha} X_m} + |\lambda|)|D| \Big)|d| \Big)
\end{align*}

\end{proof}
\end{lemma}

Next, we look at the terms involving $b$. Note that the terms involving $b^\pm$ by themselves will vanish, since they are in the spaces $R^u_-(0; 0) \oplus R^s_+(0; 0)$ which are perpendicular to $\Psi(0)$. For the other terms involving $b$, we have the following lemma.

% lemma : b terms in jump

\begin{lemma}\label{jumpb}

For the terms involving $b$ in the jump $\xi_i$, we have

\begin{align*}
\langle \Psi(0), (P^s_+(0; \beta_i^+, \lambda) - P^s_-(0; 0, 0))b_i^+ \rangle
&\leq C p_5(\beta_i^+, \beta_i^-, \lambda) \Big( e^{-\tilde{\alpha} X_m} |D| + |\lambda|^2 \Big)|d|  \\
\langle \Psi(0), (P^u_-(0; \beta_i^-, \lambda) - P^u_-(0; 0, 0))b_i^- \rangle
&\leq C p_5(\beta_i^+, \beta_i^-, \lambda) \Big( e^{-\tilde{\alpha} X_m} |D| + |\lambda|^2 \Big)|d|
\end{align*}

where $p_5(\beta_i^+, \beta_i^-, \lambda)$ is defined in Lemma \ref{projbounds}.

\begin{proof}

Using the bound for $B_1$ from Lemma \ref{inv3}, we have for the ``negative'' piece

\begin{align*}
|\langle \Psi(0), &(P^u_-(0; \lambda) - P^u_-(0; 0))b_i^- \rangle|
\leq |\Psi(0)| p_5(\beta_i^+, \beta_i^-, \lambda)|b_i^-| \\
&\leq |\Psi(0)| p_5(\beta_i^+, \beta_i^-, \lambda)|B_1(\lambda)(d)| \\
&\leq C p_5(\beta_i^+, \beta_i^-, \lambda) \Big( e^{-(\alpha - |\nu(\lambda)|) X_m} |D| 
+ |\lambda|^2 \Big)|d|\\
\end{align*}

Since $\alpha - |\nu(\lambda)| > \tilde{\alpha}$, this bound becomes

\begin{align*}
|\langle \Psi(0), &(P^u_-(0; \lambda) - P^u_-(0; 0))b_i^- \rangle|
\leq C p_5(\beta_i^+, \beta_i^-, \lambda) \Big( e^{-\tilde{\alpha} X_m} |D| + |\lambda|^2 \Big)|d|\\
\end{align*}

The ``positive'' piece is similar.

\end{proof}
\end{lemma}

Next, we look at the terms in the jump involving $c$.

% lemma : c terms in jump

\begin{lemma}\label{jumpc}
For the terms involving $c$ in the jump $\xi_i$, we have bounds

\begin{align*}
|\langle \Psi(0), &v_+(0; \beta_i^+, \lambda) \langle v_0(\lambda), w_+(X_i; \beta_i^+,\lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \rangle| \\
&\leq C ( |\lambda| + e^{-2 \alpha X_m} )( e^{-\tilde{\alpha} X_m} |D| + |\lambda|^2 )|d|  \\
|\langle \Psi(0), &v_-(0; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle e^{\nu(\lambda)X_{i-1}} c_{i-1}^- \rangle | \\
&\leq C ( |\lambda| + e^{-2 \alpha X_m} )( e^{-\tilde{\alpha} X_m} |D| + |\lambda|^2 )|d|  \\
\end{align*}

\begin{proof}
Looking at the ``plus'' term, we have

\begin{align*}
\langle \Psi(0), v_+(0; \lambda) \langle v_0(\lambda), w_+(X_i; \lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \rangle &= \langle \Psi(0), v_+(0; \lambda) \rangle \langle v_0(\lambda), w_+(X_i; \lambda) \rangle \tilde{c}_i^+
\end{align*}

To get our bound, we will expand $v_+(0; \beta_i^+, \lambda)$ in a Taylor series about $(\beta_i^+, \lambda) = (0, 0)$.

\begin{align*}
v_+(0; &\beta_i^+, \lambda) = v_+(0; 0, 0) 
+ \lambda \frac{\partial}{\partial \lambda}v_+(0; \beta_i^+, \lambda)\Big|_{\lambda, \beta_i^+ = (0, 0)} 
+ \beta_i^+ \frac{\partial}{\partial \beta_i^+}v_+(0; \beta_i^+, \lambda)\Big|_{\lambda, \beta_i^+ = (0, 0)} \\
&+ \mathcal{O}(|\lambda|^2 + |\beta_i^+||\lambda| + |\beta_i^+|^2)
\end{align*}

When we take the inner product with $\Psi(0)$, the first term will vanish since 
$\langle \Psi(0), v_+(0; 0, 0) \rangle = 0$. Since the two derivatives in the expression above are constants, we have

\begin{align*}
\langle \Psi(0), v_+(0; \beta_i^+, \lambda) \rangle &\leq C ( |\lambda| + |\beta_i^+| ) \\
&\leq C ( |\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} )
\end{align*}

The inner product $\langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle$, i.e. we have

\begin{equation}\label{vpsiIP}
\langle \Psi(0), v_\pm(0; \beta_i^\pm, \lambda) \rangle \leq C ( |\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} )
\end{equation}

Plugging this in, together with the bound for $B_1$ (which is a bound for $\tilde{c}_i^+ = e^{-\nu(\lambda)X_i} c_i^+$), we have

\begin{align*}
|\langle \Psi(0), &v_+(0; \lambda) \langle v_0(\lambda), w_+(X_i; \lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \rangle| \\ 
&\leq C ( |\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} ) |B_1(\lambda)(d)| \\
&\leq C ( |\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}} )
( e^{-(\alpha - |\nu(\lambda)|) X_m} |D| + |\lambda|^2 )|d| \\
&\leq C ( |\lambda| + e^{-2 \alpha X_m} )
( e^{-(\alpha - |\nu(\lambda)|) X_m} |D| + |\lambda|^2 )|d| \\
\end{align*}

Since $\alpha - |\nu(\lambda)| > \tilde{\alpha}$, this becomes 

\begin{align*}
|\langle \Psi(0), &v_+(0; \lambda) \langle v_0(\lambda), w_+(X_i; \lambda) \rangle e^{-\nu(\lambda)X_i} c_i^+ \rangle| \\
&\leq C ( |\lambda| + e^{-2 \alpha X_m} )
( e^{-\tilde{\alpha} X_m} |D| + |\lambda|^2 )|d| 
\end{align*}
 
The ``minus'' piece similar.\\

\end{proof} 
\end{lemma}

Next, we look at the integral terms in the jump $\xi_i$. First, we look at the ``noncenter'' integral terms. We divide these into ones involving $W$ and ones not involving $W$. Before we can do that, we will need an improved estimate for $|W_i^\pm|$.

\begin{lemma}\label{Wboundimproved}
We have the following improved, piecewise, $x$-dependent estimate for $|W_i^\pm(x)$

\begin{align*}
| W_i^-(x)| &\leq C \Big(e^{-\alpha(X_{i-1} + x)}( |\lambda|^2 + |D|)
+ e^{-2|\nu(\lambda)|x}( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) \Big)|d| && x \leq 0 \\
| W_i^+(x)| &\leq C \Big(e^{-\alpha(X_{i-1} + x)}( |\lambda|^2 + |D|)
+ e^{2|\nu(\lambda)|x}( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) \Big)|d| && x \geq 0
\end{align*}

\begin{proof}

From Lemma \ref{L1} and Lemma \ref{L2} we have
\[
W_i^\pm = L_1(\lambda)W_i^\pm + L_2(\lambda)W_i^\pm 
\]

We will do the ''negative'' piece here. The ''positive'' piece is similar. From Lemma \ref{L1}, we have the piecewise bound

\[
||L_1(\lambda)_i^- W|| \leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ||W_i^-||
\]

Plugging in the piecewise bound for $W_2$ from Lemma \ref{inv2} for $W_i^-$, we have

\begin{align*}
||L_1(\lambda)_i^- W|| &\leq C e^{-(\alpha -|\nu(\lambda)|)X_{i-1}} ( |b| + e^{|\nu(\lambda)|X_{i-1}}|c_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| ) \\
&\leq C e^{-(\alpha - 3|\nu(\lambda)|)X_{i-1}} ( |b| + |\tilde{c}_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| ) 
\end{align*}

We can get an improved bound for $L_2(\lambda)$ in the following way. For the $c_{i-1}^-$ term from $L_2(\lambda)$, we can get the $x-$dependent estimate

\begin{align*}
|e^{\nu(\lambda)(x+X_{i-1})} v_-(x; \beta_i^-, \lambda) \langle v_0(\lambda), w_-(-X_{i-1}; \beta_i^-, \lambda) \rangle c_{i-1}^-| &\leq C e^{-|\nu(\lambda)| x }| e^{\nu(\lambda)X_{i-1}} c_{i-1}^-| \\
&= C e^{-|\nu(\lambda)| x }| \tilde{c}_{i-1}^-|
\end{align*}

where $x \leq 0$. Thus, using Lemma \ref{L2} for the remaining terms, we have the following estimate for $L_2(\lambda)_i^-$.

\begin{align*}
|L_2(\lambda)(a,b,c,d)_i^-(x)| &\leq C (e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{-|\nu(\lambda)|x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| )
\end{align*}

Combining these, we have

\begin{align*}
| &W_i^-(x)| \leq C \Big(e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{-|\nu(\lambda)|x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| \\
&+ e^{-(\alpha - 3|\nu(\lambda)|)X_{i-1}} ( |b| + |\tilde{c}_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| ) \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{-|\nu(\lambda)|x} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| \\
&+ e^{-\tilde{\alpha} X_{i-1}} ( |b| + |\tilde{c}_{i-1}| + (|\lambda|^2 + |D_{i-1}|)|d| ) \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}|a_{i-1}^-| + |b| + e^{-|\nu(\lambda)|x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
\end{align*}

where we recall that $3|\nu(\lambda)| \leq \alpha - \tilde{\alpha}$.\\

At this point, we substitute in $A_1(\lambda)$ from Lemma \ref{inv2} and $B_1(\lambda)$ from Lemma \ref{inv3}. First, we substitute $A_1(\lambda)$.

\begin{align*}
| &W_i^-(x)| \leq C \Big(e^{-\alpha(X_{i-1} + x)}|A_1(\lambda)_{i-1}(b, c, d)| \\
&+ |b| + e^{-|\nu(\lambda)|x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}( (e^{-\alpha X_{i-1}} + ||G||) |b| + ( p_2(X_{i-1}; \lambda) + p_3(\lambda) + e^{-(\alpha - |\nu(\lambda)|)X_{i-1}} )|c_{i-1}| \\
&+ (e^{-\tilde{\alpha} X_{i-1}} + ||G||) |\lambda^2| |d| + |D_{i-1}||d| ) \\
&+ |b| + e^{-|\nu(\lambda)|x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}( e^{|\nu(\lambda)|X_{i-1}} |\tilde{c}_{i-1}| + |D_{i-1}||d| ) \\
&+ |b| + e^{-|\nu(\lambda)|x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
&\leq C \Big(e^{-(\alpha - |\nu(\lambda)|)(X_{i-1} + x)}( |\tilde{c}_{i-1}| + |D_{i-1}||d| ) \\
&+ |b| + e^{-2 |\nu(\lambda)|x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
&\leq C \Big(e^{-\tilde{\alpha}(X_{i-1} + x)}( |\tilde{c}_{i-1}| + |D_{i-1}||d| ) \\
&+ |b| + e^{-2 |\nu(\lambda)|x} |\tilde{c}_{i-1}^-| + e^{-\tilde{\alpha} X_{i-1}} |\tilde{c}_{i-1}^-| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
\end{align*}

Finally, we substitute $|B_1(\lambda)(d)$ for $|b|$ and $\tilde{c}$.

\begin{align*}
| &W_i^-(x)| \leq C \Big(e^{-\tilde{\alpha}(X_{i-1} + x)}(( e^{-(\alpha - |\nu(\lambda)|) X_m} |D| + |\lambda|^2 )|d| + |D_{i-1}||d| ) \\
&+ e^{-2|\nu(\lambda)|x} ( e^{-(\alpha - |\nu(\lambda)|) X_m}|D| + |\lambda|^2 )|d| \\ 
&+ ( e^{-(\alpha - |\nu(\lambda)|) X_m} |D| + |\lambda|^2 )|d| + |\lambda|^2 |d| + e^{-\tilde{\alpha} X_{i-1}} |D_{i-1}||d| \Big) \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}( |\lambda|^2 + |D|)
+ e^{-2|\nu(\lambda)|x} ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) + (|\lambda|^2 + e^{-\tilde{\alpha} X_m} |D| ) \Big)|d| \\
&= C \Big(e^{-\alpha(X_{i-1} + x)}( |\lambda|^2 + |D|)
+ (1 + e^{-2|\nu(\lambda)|x} )( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) \Big)|d| \\
&\leq C \Big(e^{-\alpha(X_{i-1} + x)}( |\lambda|^2 + |D|)
+ e^{-2|\nu(\lambda)|x}( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) \Big)|d| \\
\end{align*}

Similarly, for $x \geq 0$,

\begin{align*}
| &W_i^+(x)| \leq C \Big(e^{-\alpha(X_{i-1} + x)}( |\lambda|^2 + |D|)
+ e^{2|\nu(\lambda)|x}( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) \Big)|d| 
\end{align*}

\end{proof}
\end{lemma}

We can now estimate the noncenter integrals which involve $W$.

\begin{lemma}\label{noncenterW}

\begin{align*}
\left| \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; \lambda) G_i^-(y) W_i^-(y) \rangle dy \right| &\leq C \Big( e^{-\alpha X_m} |\lambda|^2 + e^{-(\alpha + \tilde{\alpha}) X_m} |D| \Big) |d| \\
\left| \int_{X_i}^0 \langle \Psi(0), \Phi^u_-(0, y; \lambda) G_i^+(y) W_i^+(y) \rangle dy \right| &\leq C \Big( e^{-\alpha X_m} |\lambda|^2 + e^{-(\alpha + \tilde{\alpha}) X_m} |D| \Big) |d|
\end{align*}

\begin{proof}

We do the ``minus'' integral here. Substituting in our pointwise bound for $G_i^-(y)$, the improved bound for $W_i^-(y)$ from the previous lemma, and using Theorem \ref{trichotomy}

\begin{align*}
&\left| \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; \lambda) G_i^-(y) W_i^-(y) \rangle dy \right| \\
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} |G_i^-(y)| ||W_i^-(y)|| dy \\
&\leq C \int_{-X_{i-1}}^0 e^{\alpha y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} \Big(e^{-\alpha(X_{i-1} + y)}( |\lambda|^2 + |D|)
+ e^{-2|\nu(\lambda)|y}( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) \Big) |d| dy \\
\end{align*}

We have two integrals to evaluate. For the first integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 &e^{\alpha y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} e^{-\alpha(X_{i-1} + y)}( |\lambda|^2 + |D|) |d| dy \\
&= e^{-2 \alpha X_{i-1}} ( |\lambda|^2 + |D|) |d| \int_{-X_{i-1}}^0 e^{-\alpha(X_{i-1} + y)} dy \\
&\leq C e^{-2 \alpha X_{i-1}} ( |\lambda|^2 + |D|) |d| \\
&\leq C e^{-2 \alpha X_m}( |\lambda|^2 + |D|) |d|
\end{align*}

For the second integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 &e^{\alpha y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} e^{-2|\nu(\lambda)|y}( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)|d| dy \\
&= e^{-\alpha X_{i-1}} ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)|d| \int_{-X_{i-1}}^0 e^{(\alpha - 2 |\nu(\lambda)|) y}  e^{-\alpha(X_{i-1} + y)} dy \\
&\leq e^{-\alpha X_{i-1}} ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)|d| \int_{-X_{i-1}}^0 e^{\tilde{\alpha} y}  e^{-\alpha(X_{i-1} + y)} dy \\
&\leq e^{-\alpha X_{i-1}} ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)|d| \int_{-X_{i-1}}^0 e^{-\alpha(X_{i-1} + y)} dy \\
&\leq C e^{-\alpha X_{i-1}} ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)|d| \\
&\leq C e^{-\alpha X_m} ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)|d|
\end{align*}

since $\alpha - 2 |\nu(\lambda)| > \tilde{\alpha}$ and $y \leq 0$. Putting this all together, we have

\begin{align*}
&\left| \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; \lambda) G_i^-(y) W_i^-(y) \rangle dy \right| \\
&\leq C \Big( e^{-2 \alpha X_m}( |\lambda|^2 + |D|) + e^{-\alpha X_m} ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) \Big) |d| \\
&\leq C \Big( e^{-\alpha X_m} |\lambda|^2 + e^{-(\alpha + \tilde{\alpha}) X_m} |D| \Big) |d|
\end{align*}

The bound for the other integral is the same.

\end{proof}
\end{lemma}

Next, we look at the ``noncenter'' integrals involving $H$. These will give us our higher order Melnikov integral.

% lemma : noncenter integrals involving H

\begin{lemma}\label{noncenterH}

\begin{align*}
\langle \Psi(0), &\int_{X_i}^0 \Phi^u_+(0, y; \beta_i^+, \lambda) \lambda^2 d_i \tilde{H}_i^+(y) dy - \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) \lambda^2 d_i \tilde{H}_i^-(y) dy \rangle \\ 
&= -d_i \lambda^2 \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy + \mathcal{O}\left( (|\lambda| + e^{-\alpha X_m} ) |\lambda|^2 |d| \right)
\end{align*}

\begin{proof}

Looking at the ``negative'' integral (which is multiplied by $d_i \lambda^2$), we write it as

\begin{align*}
\langle \Psi(0)&, \int_{-X_{i-1}}^0 \Phi^s_-(0, y; \beta_i^-, \lambda) \tilde{H}_i^-(y) dy \rangle \\ 
&= \int_{-X_{i-1}}^0 \langle \Psi(0), \Phi^s_-(0, y; 0, 0) \tilde{H}_i^-(y) \rangle dy + 
\int_{-X_{i-1}}^0 \langle \Psi(0), (\Phi^s_-(0, y; \beta_i^-, \lambda) - \Phi^s_-(0, y; 0, 0)) \tilde{H}_i^-(y) \rangle dy
\end{align*}

where we use this trick in order to get the Melnikov term we want. For the second integral, we have

\begin{align*}
\Big| \int_{-X_{i-1}}^0 \langle &\Psi(0), (\Phi^s_-(0, y; \beta_i^-, \lambda) - \Phi^s_-(0, y; 0, 0)) \tilde{H}_i^-(y) \rangle dy \Big| \\
&\leq C \int_{-X_{i-1}}^0 |\Phi^s_-(0, y; \beta_i^-, \lambda) - \Phi^s_-(0, y; 0, 0)| |\tilde{H}_i^-(y)| dy \\
&\leq C \int_{-X_{i-1}}^0 p_6(y; \beta_i^+, \beta_i^-, \lambda) dy \\
&\leq C ( |\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})\int_{-X_{i-1}}^0 e^{\alpha y} dy \\
&\leq C ( |\lambda| + e^{-2 \alpha X_m}) \\
\end{align*}

where we used the estimate for $p_6$ from Lemma \ref{projbounds} and the fact that $\tilde{H}_i^\pm$ is bounded.\\

For the first integral, we manipulate things to bring the limits out to $\pm \infty$ (to get the higher order Melnikov integral) and to replace $\tilde{H}_i^\pm$ by $H$ (so that the Melnikov integral only involves the single pulse).

\begin{align*}
\int_{-X_{i-1}}^0 &\langle \Psi(0), \Phi^s_-(0, y; 0, 0) \tilde{H}_i^-(y) \rangle dy = 
\int_{-X_{i-1}}^0 \langle \Psi(y), H(y) \rangle dy + \int_{-X_{i-1}}^0 \langle \Psi(y), \Delta H(y) \rangle dy \\
&= \int_{-\infty}^0 \langle \Psi(y), H(y) \rangle dy - \int_{-\infty}^{-X_{i-1}} \langle \Psi(y), H(y) \rangle dy + \int_{-X_{i-1}}^0 \langle \Psi(y), \Delta H(y) \rangle dy 
\end{align*}

The first integral on the RHS is the left half of our higher order Melnikov integral. The second integral is order $e^{-\alpha X_{i-1}}$, since $H$ decays exponentially with order $\alpha$ and $\Psi$ is bounded. The third integral is order $e^{-\alpha X_m}$, which is the order of $\Delta H$. When we do the ``plus'' piece, the first integral is the other half of the Melnikov integral; the second integral is order $e^{-\alpha X_i}$; and the third integral is the same order. Combining all of these gives us our  result.

\end{proof}
\end{lemma}

Finally, we look at the ``center'' integral terms. As before, we can split this into integrals involving $W$ and integrals not involving $W$. First, we look at the integral involving $W$.

% lemma : center integrals involving W

\begin{lemma}\label{centerW}

\begin{align*}
\left| \langle \Psi(0), \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \rangle \right| &\leq C e^{-\tilde{\alpha}X_m} ( |\lambda| + e^{-2\alpha X_m} )( |\lambda|^2 + |D|)|d| \\
\left| \Psi(0), \int_{X_i}^0 e^{-\nu(\lambda)y} v_+(0; \beta_i^+, \lambda) \langle G_i^+(y)W_i^+(y), w_+(y; \beta_i^+, \lambda) \rangle dy  \right| &\leq C e^{-\tilde{\alpha}X_m} ( |\lambda| + e^{-2\alpha X_m} )( |\lambda|^2 + |D|)|d|
\end{align*}

\begin{proof}

We do the ``minus'' integral here.

\begin{align*}
\langle \Psi(0) &, \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \rangle \\
&= \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \beta_i^- ,\lambda) \rangle \langle G_i^-(y)W_i^-(y), w_-(y; \beta_i^- , \lambda) \rangle dy \\
&\leq C |\langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle| 
\int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} |G_i^-(y)||W_i^-(y)| dy 
\end{align*}

From \eqref{vpsiIP} in Lemma \ref{jumpc}, $|\langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle| = \mathcal{O}(|\lambda| + e^{-2 \alpha X_i} + e^{-2 \alpha X_{i-1}})$. Substituting in our bound for $G_i^-(y)$ and the improved bound for $W_i^-(y)$ from Lemma \ref{Wboundimproved}, we have

\begin{align*}
\langle \Psi(0) &, \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \lambda) \rangle dy \rangle \\
&\leq C (|\lambda| + e^{-2 \alpha X_m}) \int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} |G_i^-(y)||W_i^-(y)| dy \\
&\leq C (|\lambda| + e^{-2 \alpha X_m}) \int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)}\Big(e^{-\alpha(X_{i-1} + y)}( |\lambda|^2 + |D|)
\\
&+ e^{-2|\nu(\lambda)|y}( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) \Big)|d| dy
\end{align*}

We have two integrals here, which are similar to those in Lemma \ref{noncenterW}.

For the first integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 &e^{-|\nu(\lambda)|y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} e^{-\alpha(X_{i-1} + y)}( |\lambda|^2 + |D|)|d| dy \\
&= ( |\lambda|^2 + |D|)|d| \int_{-X_{i-1}}^0 e^{-|\nu(\lambda)|y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} e^{-\alpha(X_{i-1} + y)} dy \\
&\leq ( |\lambda|^2 + |D|)|d| \int_{-X_{i-1}}^0 e^{|\nu(\lambda)|X_{i-1}} e^{-\alpha X_{i-1}} e^{-2\alpha(X_{i-1} + y)} dy \\
&= ( |\lambda|^2 + |D|) e^{-(\alpha - |\nu(\lambda)|)X_{i-1}} |d| \int_{-X_{i-1}}^0 e^{-2\alpha(X_{i-1} + y)} dy \\
&\leq C ( |\lambda|^2 + |D|) e^{-\tilde{\alpha}X_m} |d|
\end{align*}

For the second integral, we have

\begin{align*}
\int_{-X_{i-1}}^0 & e^{-|\nu(\lambda)|y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} e^{-2|\nu(\lambda)|y}( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|) |d| dy \\
&= ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)|d|\int_{-X_{i-1}}^0 e^{-3 |\nu(\lambda)|y} e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + y)} dy \\
&\leq ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)|d|\int_{-X_{i-1}}^0 e^{-(\alpha - 3 |\nu(\lambda)|) X_{i-1}} e^{-\alpha(X_{i-1} + y)} dy \\
&\leq C ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)e^{-\tilde{\alpha}X_m}|d|
\end{align*}

Putting this all together, we have

\begin{align*}
&\left| \langle \Psi(0), \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \lambda) \langle G_i^-(y)W_i^-(y), w_-(y; \lambda) \rangle dy \rangle \right| \\
&\leq C \Big( (|\lambda| + e^{-2 \alpha X_m}) (( |\lambda|^2 + |D|) e^{-\tilde{\alpha}X_m} + ( |\lambda|^2 + e^{-\tilde{\alpha} X_m}|D|)e^{-\tilde{\alpha}X_m}) \Big) |d| \\
&\leq C e^{-\tilde{\alpha}X_m} ( |\lambda| + e^{-2\alpha X_m} )( |\lambda|^2 + |D|)|d|
\end{align*}

The other integral has the same bound.

\end{proof}
\end{lemma}

% lemma : center not involving H

Finally, we look at the ``center'' integral term not involving $W$.

\begin{lemma}\label{centerH}

\begin{align*}
\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \right| &\leq C (|\lambda| + e^{-2 \alpha X_m} ) |\lambda|^2 |d|\\
\left| \int_{X_i}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_+(0; \beta_i^+, \lambda) \rangle \langle \lambda^2 d_i \tilde{H}_i^+(y), w_+(y; \beta_i^+,\lambda) \rangle dy \right| &\leq C (|\lambda| + e^{-2 \alpha X_m} ) |\lambda|^2  |d| \\
\end{align*}

\begin{proof}

For the ``minus'' integral, we have

\begin{align*}
\langle \Psi(0) &, \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} v_-(0; \beta_i^-, \lambda) \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy \rangle \\
&= \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \beta_i^-, \lambda) \rangle dy 
\end{align*}

From \eqref{vpsiIP} in Lemma \ref{jumpc}, $\Psi(0), v_-(0; \beta_i^-, lambda) \rangle| = \mathcal{O}(|\lambda| + e^{-2 \alpha X_m})$. Thus we have

\begin{align*}
&\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \lambda) \rangle \langle \lambda^2 d_i \tilde{H}_i^-(y), w_-(y; \lambda) \rangle dy \right| \\
&\leq C (|\lambda| + e^{-2 \alpha X_m} ) |\lambda|^2 |d| 
\int_{-X_{i-1}}^0 e^{|\nu(\lambda)|y} |\tilde{H}_i^-(y) dy|
\end{align*}

Since $\tilde{H}(y)$ decays exponentially with rate $\alpha$, this becomes

\begin{align*}
&\left| \int_{-X_{i-1}}^0
e^{\nu(\lambda)y} \langle \Psi(0), v_-(0; \beta_i^-, \lambda) \rangle \langle \lambda^2 d_i \tilde{H}(y), w_-(y; \beta_i^-, \lambda) \rangle dy \right| \\
&\leq C (|\lambda| + e^{-2 \alpha X_m}) |\lambda|^2  |d| 
\int_{-X_{i-1}}^0 e^{(\alpha - |\nu(\lambda)|)y} dy \\
&\leq C (|\lambda| + e^{-2 \alpha X_m}) |\lambda|^2  |d|
\end{align*}

The ``plus'' integral is similar.

\end{proof} 
\end{lemma}

We are now ready to put all of this together.

% lemma : jump expression

\begin{lemma}\label{jump}

We have the following expression for the jumps 

\[
\xi_i = \langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle
\]

at $x = 0$.

\begin{equation}\label{jumpexp}
\xi_i = \langle \Psi(X_i), P^u_0 D_i d \rangle + \langle \Psi(-X_{i-1}), P^u_0 D_{i-1} d \rangle - d_i \lambda^2 \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy + R(\lambda)_i(d)
\end{equation}

where the remainder term $R(\lambda)_i(d)$ has bound

\begin{align}\label{remainder1}
R(\lambda)(d)_i &\leq C \Big( ( e^{-\alpha X_m} + p_5(\beta_i^+, \beta_i^-, \lambda) + |\lambda|  )(|\lambda|^2 + e^{-\tilde{\alpha}X_m} |D|\Big) |d|
\end{align}

\begin{proof}
Using the fixed point equations at $x = 0$, we evaluate $\langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle$. The first two terms on the RHS of \eqref{jumpexp} come from Lemma \ref{jumpa}. The higher order Melnikov integral term comes from Lemma \ref{noncenterH}. For the remainder term, we use all the other jump estimation lemmas above to get the estimate

\begin{align*}
|R&(\lambda)(d)_i| \leq C \Big( 
e^{-\alpha X_m} (|\lambda|^2  + (e^{-\tilde{\alpha} X_m} + |\lambda|)|D|)|d|  \\
&+ p_5(\beta_i^+, \beta_i^-, \lambda) (e^{-\tilde{\alpha} X_m} |D| + |\lambda|^2 )|d| \\
&+ (|\lambda| + e^{-2 \alpha X_m} )( e^{-\tilde{\alpha} X_m} |D| + |\lambda|^2 )|d| \\
&+ (e^{-2 \alpha X_m} |\lambda|^2 + e^{-(\alpha + \tilde{\alpha}) X_m} |D|) |d| \\
&+ ( |\lambda| + e^{-\alpha X_m} ) |\lambda|^2 |d| \\
&+ e^{-\tilde{\alpha} X_m} (|\lambda| + e^{-2 \alpha X_m})(|\lambda|^2 + |D|) |d| \\
&+ (|\lambda| + e^{-2 \alpha X_m} ) |\lambda|^2  |d|
\end{align*}

Simplifying and dropping higher order terms, this becomes

\begin{align*}
R(\lambda)(d)_i &\leq C \Big( ( e^{-\alpha X_m} + p_5(\beta_i^+, \beta_i^-, \lambda) + |\lambda|  )(|\lambda|^2 + e^{-\tilde{\alpha}X_m} |D|) \Big) |d|
\end{align*}

\end{proof}
\end{lemma}

We are now ready to substitute in all the things to get something we can use to solve for the eigenvalues $\lambda$.

% theorem : solution to EVP

\begin{theorem}\label{evpsol}

The eigenvalue problem has a solution for nonzero eigenvalue $\lambda \in V_\lambda$ if and only if

\begin{equation}\label{matrixdet}
E(\lambda) = \det S(\lambda) = \det(A - \lambda^2 MI + R(\lambda) ) = 0
\end{equation}

where $M$ is the higher order Melnikov integral 

\begin{equation}
M =  \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy
\end{equation}

and $A$ is the matrix defined by

\begin{align*}
A &= \begin{pmatrix}
-a_0 + \tilde{a}_1 & a_0 - \tilde{a}_1 \\
-\tilde{a}_0 + a_1 & \tilde{a}_0 - a_1
\end{pmatrix} && n = 2 \\
A &= \begin{pmatrix}
\tilde{a}_{n-1} - a_0 & a_0 & & & \dots & -\tilde{a}_{n-1}\\
-\tilde{a}_0 & \tilde{a}_0 - a_1 &  a_1 \\
& -\tilde{a}_1 & \tilde{a}_1 - a_2 &  a_2 \\
& & \vdots & & \vdots \\
a_{n-1} & & & & -\tilde{a}_{n-2} & \tilde{a}_{n-2} - a_{n-1} \\
\end{pmatrix} && n > 2
\end{align*}

where

\begin{align*}
a_i &= \langle \Psi(X_i), Q'(-X_i) \rangle \\
\tilde{a}_i &= \langle \Psi(-X_i), Q'(X_i) \rangle
\end{align*}

The remainder $R(\lambda)$ is analytic in $\lambda$ and has bound

\begin{align*}
|R(\lambda)(d)| &\leq C \Big( e^{-(\alpha + \tilde{\alpha})X_1}( e^{-\alpha X_1} + |\lambda|  )  
+ (e^{-\alpha X_1} + |\lambda| ) |\lambda|^2 \Big) |d|
\end{align*}

\begin{proof}

First, we plug in $D_i$ and $D_{i-1}$ into \eqref{jumpexp} from the previous lemma. 
Recall that we have the following expression for $D_i$ from Hypothesis \ref{problembounds}.

\[
D_i = ( Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) + \mathcal{O} \left( e^{-\alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\]

where $i = 0, \dots, n-1$. Substituting this into $\langle \Psi(X_i), P^u_0 D_i d \rangle$ and using the fact that $\Psi(\pm X_i)$ is order $e^{-\alpha X_i}$, we have

\begin{align*}
\langle \Psi(X_i), P^u_0 D_i d \rangle &= \langle \Psi(X_i), (Q'(X_i) + Q'(-X_i)(d_{i+1} - d_i ) \rangle + \mathcal{O} \left( e^{-2 \alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\end{align*}

Note that $\langle \Psi(X_i), Q'(X_i) \rangle = 0$, since $\langle \Psi(0), Q'(0) \rangle = 0$ and the inner product is constant in $x$. Thus we have 

\begin{align*}
\langle \Psi(X_i), P^u_0 D_i d \rangle &= \langle \Psi(X_i), Q'(-X_i) \rangle (d_{i+1} - d_i ) + \mathcal{O} \left( e^{-2 \alpha X_i} \left( |\lambda| +  e^{-\alpha X_i}  \right) |d| \right)
\end{align*}

Similarly, we have

\begin{align*}
\langle \Psi(-X_{i-1}), P^u_0 D_{i-1} d \rangle &= \langle \Psi(-X_{i-1}), Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) + \mathcal{O} \left( e^{-2 \alpha X_{i-1}} \left( |\lambda| +  e^{-\alpha X_{i-1}}  \right) |d| \right)
\end{align*}

Thus the jumps at $x = 0$ are given by

\begin{align*}
\xi_i &= \langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle \\
&= \langle \Psi(X_i), Q'(-X_i) \rangle (d_{i+1} - d_i ) + \langle \Psi(-X_{i-1}), Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) - \lambda^2 d_i M + R(\lambda)(d)_i
\end{align*}

where $M$ is the higher order Melnikov integral defined above. The bound for the remainder term $R(\lambda)(d)_i$ in this expression is given by the bound for the remainder term from Lemma \ref{jump} together with the additional remainder terms from the substitution of the $D_i$.

\begin{align*}
R(\lambda)(d)_i &\leq C \Big( ( e^{-\alpha X_m} + p_5(\beta_i^+, \beta_i^-, \lambda) + |\lambda|  )(|\lambda|^2 + e^{-\tilde{\alpha}X_m} |D|) \\
&+ e^{-2 \alpha X_m} ( |\lambda| +  e^{-\alpha X_m} ) \Big) |d|
\end{align*}

Since $|D| = \mathcal{O}(e^{-\alpha X_m})$ and, from Lemma \ref{projbounds}, 
$|p_5(\beta_i^+, \beta_i^-, \lambda)| \leq C( e^{-2 \alpha X_m} + |\lambda|)$, we have

Thus we have

\begin{align*}
R(\lambda)(d)_i &\leq C \Big( ( e^{-\alpha X_m} +  e^{-2 \alpha X_m} + |\lambda|  )(|\lambda|^2 + e^{-\tilde{\alpha}X_m} e^{-\alpha X_m}) + e^{-2 \alpha X_m} ( |\lambda| +  e^{-\alpha X_m} ) \Big) |d|
\end{align*}

Simplifying and dropping higher order terms, the bound becomes

\begin{align*}
R(\lambda)(d)_i &\leq C \Big( ( e^{-\alpha X_m} + |\lambda|  )(e^{-(\alpha + \tilde{\alpha})X_m} + |\lambda|^2 ) \Big) |d|
\end{align*}

Since we are taking $\lambda = \mathcal{O}(e^{-\alpha X_m})$, this remainder bound is sufficient!\\

Analogous to San98, we let

\begin{align*}
a_i &= \langle \Psi(X_i), Q'(-X_i) \rangle \\
\tilde{a}_i &= \langle \Psi(-X_i), Q'(X_i) \rangle
\end{align*}

where $i = 0, \dots, n-1$. Then the jumps are given by 

\begin{align*}
\xi_i &= a_i (d_{i+1} - d_i ) + \tilde{a}_{i-1} (d_i - d_{i-1} ) - \lambda^2 d_i M + R(\lambda)(d)_i
\end{align*}

As in San98, we can write the jump equations in matrix form as 

\begin{align*}
S(\lambda)d = (A - \lambda^2 MI + R(\lambda))d = 0
\end{align*}

where $A$ is the following $n \times n$ matrix, which is a ``periodic analogue'' of the tridiagonal matrix $A$ in San98. For $n = 2$, we have

\[
A = 
\begin{pmatrix}
-a_0 + \tilde{a}_1 & a_0 - \tilde{a}_1 \\
-\tilde{a}_0 + a_1 & \tilde{a}_0 - a_1
\end{pmatrix}
\]

and for $n > 2$, we have

\[
A = 
\begin{pmatrix}
\tilde{a}_{n-1} - a_0 & a_0 & & & \dots & -\tilde{a}_{n-1}\\
-\tilde{a}_0 & \tilde{a}_0 - a_1 &  a_1 \\
& -\tilde{a}_1 & \tilde{a}_1 - a_2 &  a_2 \\
& & \vdots & & \vdots \\
a_{n-1} & & & & -\tilde{a}_{n-2} & \tilde{a}_{n-2} - a_{n-1} \\
\end{pmatrix}
\]

The eigenvalue problem thus has a solution for $\lambda \neq 0$ if and only if the equation $S(\lambda)d = 0$ has a nonzero solution $d$, i.e. if and only if 

\[
E(\lambda) = \det S(\lambda) = \det(A - \lambda^2 MI + R(\lambda) ) = 0
\]

\end{proof}
\end{theorem}

As a corollary, for the 2-periodic pulse in KdV5, we can compute the eigenvalues exactly.

% corrolary : eigenvalues for 2-per pulse

\begin{corollary}
The nonzero eigenvalues are given, to leading order, by

\begin{equation}
\lambda = \pm \sqrt{-2a/M}
\end{equation}

where $M$ is the higher order Melnikov integral defined in Theorem \ref{evpsol} and 

\begin{equation}
a = \langle \Psi (X_1), Q'(-X_1) \rangle + \langle \Psi (X_2), Q'(-X_2) \rangle 
\end{equation}

For $M a < 0$, the eigenvalues lie on the real axis and for $M a > 0$ the eigenvalues lie on the imaginary axis.

\begin{proof}

For KdV5, we know the form of $\Psi(x)$ (we showed this for the exponentially weighted version on the real line), thus it is not hard to show that

\[
\tilde{a}_i = \langle \Psi(-X_i), Q'(X_i) \rangle = -\langle \Psi(X_i), Q'(-X_i) \rangle = -a_i
\]

Thus the matrix $A$ from Theorem \ref{evpsol} becomes

\begin{align*}
A = 
\begin{pmatrix}
-a_0 - a_1 & a_0 + a_1 \\
a_0 + a_1 & -a_0 - a_1
\end{pmatrix}
= a \begin{pmatrix}
-1 & 1 \\
1 & -1
\end{pmatrix}
\end{align*}

where $a = a_1 + a_2$. Using Theorem \ref{evpsol}, the eigenvalues are given, to leading order, by 

\begin{align*}
\det \left[ a \begin{pmatrix}
-1 & 1 \\
1 & -1
\end{pmatrix}
- \lambda^2 MI \right] = 
\det \begin{pmatrix}
-a - \lambda^2 M & a \\
a & -a - \lambda^2 M
\end{pmatrix}
 = 0
\end{align*}

Solving this for $\lambda$, the eigenvalues are given, to leading order, by

\begin{align*}
0 &= (-a - \lambda^2 M)^2 - a^2 \\
&= a^2 + 2 a \lambda^2 M + \lambda^4 M^2 - a^2 \\
&= 2 a \lambda^2 M + \lambda^4 M^2 \\
&= \lambda^2 M (2a + M \lambda^2 )
\end{align*}

This has two roots at 0 (corresponding to the 2-dimensional generalized kernel) as well as two roots at $\pm \sqrt{-2a/M}$. To leading order, these will be purely imaginary or real depending on the sign of $a$. By Theorem \ref{evpsol} these are the only four small eigenvalues. By symmetry we know that if there is an eigenvalue in the first quadrant of the complex plane, i.e. $\lambda = \alpha + \beta i$ with $\alpha, \beta > 0$, we must have a quartet of eigenvalues. This is not possible here, since there must be two eigenvalues at 0 and there are only 4 total eigenvalues. Thus the only possibilities are that the eigenvalues lie on the real axis (for $M a < 0$) or on the imaginary axis for $M a > 0$.

\end{proof}
\end{corollary}

\end{document}